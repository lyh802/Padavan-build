From bb4e7089661d6aaa5b8c5a03bcbf4e3e30979023 Mon Sep 17 00:00:00 2001
From: lyh802 <lyh802@126.com>
Date: Mon, 3 Jul 2023 22:09:09 +0800
Subject: [PATCH] Fix hw_nat

---
 .../drivers/net/ethernet/raeth/Kconfig        |   53 +
 .../drivers/net/ethernet/raeth/Makefile       |    5 +
 .../net/ethernet/raeth/mtk_esw/esw_common.h   |   34 +
 .../net/ethernet/raeth/mtk_esw/ioctl.c        |  238 +++
 .../net/ethernet/raeth/mtk_esw/ioctl.h        |  198 ++
 .../net/ethernet/raeth/mtk_esw/ioctl_mt762x.c | 1838 +++++++++++++++++
 .../net/ethernet/raeth/mtk_esw/ioctl_mt762x.h |  236 +++
 .../drivers/net/ethernet/raeth/mtk_eth_soc.h  |  883 ++++++++
 .../drivers/net/ethernet/raeth/ra_dbg_proc.c  |    2 +
 .../drivers/net/ethernet/raeth/ra_switch.c    |   24 +-
 .../drivers/net/ethernet/raeth/ra_switch.h    |    2 +
 .../drivers/net/ethernet/raeth/raeth_config.h |   11 +-
 .../drivers/net/ethernet/raeth/raeth_reg.h    |    3 +
 .../drivers/net/ethernet/raeth/raether.c      |  125 +-
 .../drivers/net/ethernet/raeth/raether.h      |   13 +-
 .../drivers/net/ethernet/raeth/raether_pdma.c |   27 +
 .../drivers/net/ethernet/raeth/raether_qdma.c |   31 +-
 .../net/ethernet/raeth/rtl8367c/rtk_hal.c     |    5 +-
 trunk/linux-4.4.x/include/net/ra_nat.h        |   37 +-
 trunk/linux-4.4.x/net/core/skbuff.c           |   16 +-
 trunk/linux-4.4.x/net/ipv4/ip_output.c        |    3 +
 trunk/linux-4.4.x/net/nat/foe_hook/hook.c     |   31 +
 trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c    |    1 +
 .../linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c  |    6 +-
 trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c     |   49 +-
 trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h     |   67 +-
 26 files changed, 3851 insertions(+), 87 deletions(-)
 create mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/esw_common.h
 create mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.h
 create mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.h
 create mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_eth_soc.h

diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Kconfig b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Kconfig
index f5be18ef..b2c59272 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Kconfig
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Kconfig
@@ -36,4 +36,57 @@ config  ETH_PAGE_ALLOC_SKB
 
 endchoice
 
+config  RAETH_ESW_CONTROL
+	bool "Embedded (or MT7530) Switch Control Module (VLAN/Isolation/Status)"
+	default y
+
+config  RAETH_ESW_PORT_WAN
+	int "ESW WAN Port ID (0..4)"
+	depends on RAETH_ESW_CONTROL
+	default 4
+
+config  RAETH_ESW_PORT_LAN1
+	int "ESW LAN1 Port ID (0..4)"
+	depends on RAETH_ESW_CONTROL
+	default 0
+
+config  RAETH_ESW_PORT_LAN2
+	int "ESW LAN2 Port ID (0..4)"
+	depends on RAETH_ESW_CONTROL
+	default 1
+
+config  RAETH_ESW_PORT_LAN3
+	int "ESW LAN3 Port ID (0..4)"
+	depends on RAETH_ESW_CONTROL
+	default 2
+
+config  RAETH_ESW_PORT_LAN4
+	int "ESW LAN4 Port ID (0..4)"
+	depends on RAETH_ESW_CONTROL
+	default 3
+
+config NET_MEDIATEK_HNAT
+	tristate "MediaTek HW NAT support"
+#	depends on NET_MEDIATEK_SOC && NF_CONNTRACK && NF_CONNTRACK_IPV4 && IP_NF_NAT
+	depends on NF_CONNTRACK && NF_CONNTRACK_IPV4 && IP_NF_NAT
+	---help---
+	  This driver supports the hardward
+	  Network Address Translation in the
+	  MediaTek MT2701/MT7622/MT7629/MT7621
+	  chipset family
+
+config NET_MEDIATEK_HW_QOS
+	bool "Mediatek HW QoS support"
+	depends on NET_MEDIATEK_HNAT
+	default n
+	---help---
+	  This driver supports the hardward
+	  quality of service (QoS) control
+	  for the hardware NAT in the
+	  MediaTek chipset family.
+
+config ARCH_MT7622_WIFI_HW_NAT
+	bool
+	default y if NET_MEDIATEK_HNAT=m && RA_HW_NAT=n && MTK_EMI_7622=y
+
 endif 	# RAETH
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Makefile b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Makefile
index a1b901c1..212e4b3d 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Makefile
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Makefile
@@ -1,4 +1,5 @@
 obj-$(CONFIG_RAETH) += raeth.o
+obj-$(CONFIG_NET_MEDIATEK_HNAT) += mtk_hnat/
 raeth-objs := raether.o raether_pdma.o ra_mac.o mii_mgr.o ra_switch.o ra_dbg_proc.o
 raeth-objs += raether_qdma.o
 raeth-objs += raether_rss.o
@@ -11,6 +12,9 @@ raeth-objs += raether_hwlro.o
 raeth-objs += ra_dbg_hwlro.o
 raeth-objs += ra_dbg_hwioc.o
 
+ifeq ($(CONFIG_RAETH_ESW_CONTROL),y)
+raeth-objs += mtk_esw/ioctl_mt762x.o
+else
 ccflags-y += -Idrivers/net/ethernet/raeth/rtl8367c/include  -D_LITTLE_ENDIAN -DMDC_MDIO_OPERATION
 ccflags-y += -Idrivers/net/ethernet/raeth
 ccflags-y += -Iinclude/linux/
@@ -70,6 +74,7 @@ raeth-objs += rtl8367c/svlan.o
 raeth-objs += rtl8367c/trap.o
 raeth-objs += rtl8367c/trunk.o
 raeth-objs += rtl8367c/vlan.o
+endif
 
 ifeq ($(CONFIG_RAETH_PDMA_DVT),y)
 raeth-objs += dvt/raether_pdma_dvt.o
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/esw_common.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/esw_common.h
new file mode 100644
index 00000000..64e6e7c8
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/esw_common.h
@@ -0,0 +1,34 @@
+#ifndef __MTK_ESW_COMMON__
+#define __MTK_ESW_COMMON__
+
+#define CONFIG_MT7530_GSW 				1
+#define CONFIG_GE2_INTERNAL_GMAC_P5		1
+#define CONFIG_RAETH_BOTH_GMAC			1
+
+//#define CONFIG_RAETH_ESW_IGMP_SNOOP_OFF	1
+#define CONFIG_RAETH_ESW_IGMP_SNOOP_HW	1
+
+#define ESW_PORT_ID_MAX			6
+
+#define REG_ESW_PORT_PCR_P0		0x2004
+#define REG_ESW_PORT_PIC_P0		0x2008
+#define REG_ESW_PORT_PVC_P0		0x2010
+#define REG_ESW_PORT_PPBV1_P0		0x2014
+#define REG_ESW_PORT_BSR_P0		0x201C
+#define REG_ESW_MAC_PMCR_P0		0x3000
+#define REG_ESW_MAC_PMSR_P0		0x3008
+#define REG_ESW_MAC_GMACCR		0x30E0
+#define REG_ESW_IMC			0x1C
+#undef ESW_PORT_PPE
+
+#ifdef __KERNEL__
+typedef union _ULARGE_INTEGER {
+	struct {
+		uint32_t LowPart;
+		uint32_t HighPart;
+	} u;
+	uint64_t QuadPart;
+} ULARGE_INTEGER;
+#endif
+
+#endif
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.c
new file mode 100644
index 00000000..908f890b
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.c
@@ -0,0 +1,238 @@
+/*
+ * switch control IOCTL implementation (common code)
+ */
+
+////////////////////////////////////////////////////////////////////////////////////
+
+extern void (*esw_link_status_hook)(u32 port_id, int port_link);
+
+static void fill_bridge_members(void)
+{
+#if defined (CONFIG_MT7530_GSW)
+	set_bit(1, g_vlan_pool);
+	set_bit(2, g_vlan_pool); // VID2 filled on U-Boot
+#endif
+	memset(g_bwan_member, 0, sizeof(g_bwan_member));
+
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1][LAN_PORT_1].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1][LAN_PORT_1].rule = SWAPI_VLAN_RULE_WAN_LAN1;
+
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN2][LAN_PORT_2].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN2][LAN_PORT_2].rule = SWAPI_VLAN_RULE_WAN_LAN2;
+
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3][LAN_PORT_3].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3][LAN_PORT_3].rule = SWAPI_VLAN_RULE_WAN_LAN3;
+
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN4][LAN_PORT_4].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN4][LAN_PORT_4].rule = SWAPI_VLAN_RULE_WAN_LAN4;
+
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3_LAN4][LAN_PORT_3].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3_LAN4][LAN_PORT_3].rule = SWAPI_VLAN_RULE_WAN_LAN3;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3_LAN4][LAN_PORT_4].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3_LAN4][LAN_PORT_4].rule = SWAPI_VLAN_RULE_WAN_LAN4;
+
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2][LAN_PORT_1].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2][LAN_PORT_1].rule = SWAPI_VLAN_RULE_WAN_LAN1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2][LAN_PORT_2].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2][LAN_PORT_2].rule = SWAPI_VLAN_RULE_WAN_LAN2;
+
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_1].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_1].rule = SWAPI_VLAN_RULE_WAN_LAN1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_2].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_2].rule = SWAPI_VLAN_RULE_WAN_LAN2;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_3].bwan = 1;
+	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_3].rule = SWAPI_VLAN_RULE_WAN_LAN3;
+}
+
+////////////////////////////////////////////////////////////////////////////////////
+
+static long mtk_esw_ioctl(struct file *file, unsigned int req, unsigned long arg)
+{
+	int ioctl_result = 0;
+	u32 uint_value = 0;
+	u32 uint_result = 0;
+	port_bytes_t port_bytes = {0};
+	esw_mib_counters_t port_counters;
+
+	unsigned int uint_param = (req >> MTK_ESW_IOCTL_CMD_LENGTH_BITS);
+	req &= ((1u << MTK_ESW_IOCTL_CMD_LENGTH_BITS)-1);
+
+	mutex_lock(&esw_access_mutex);
+
+	switch(req)
+	{
+	case MTK_ESW_IOCTL_STATUS_LINK_PORT: /* used by rc */
+		uint_result = esw_status_link_port_uapi(uint_param);
+		put_user(uint_result, (unsigned int __user *)arg);
+		break;
+	case MTK_ESW_IOCTL_STATUS_LINK_PORTS_WAN: /* used by rc */
+		uint_result = esw_status_link_ports(1);
+		put_user(uint_result, (unsigned int __user *)arg);
+		break;
+	case MTK_ESW_IOCTL_STATUS_LINK_PORTS_LAN: /* used by rc */
+		uint_result = esw_status_link_ports(0);
+		put_user(uint_result, (unsigned int __user *)arg);
+		break;
+	case MTK_ESW_IOCTL_STATUS_LINK_CHANGED: /* used by rc */
+		uint_result = esw_status_link_changed();
+		put_user(uint_result, (unsigned int __user *)arg);
+		break;
+
+	case MTK_ESW_IOCTL_STATUS_SPEED_PORT: /* used by rc */
+		uint_result = esw_status_speed_port_uapi(uint_param);
+		put_user(uint_result, (unsigned int __user *)arg);
+		break;
+
+	case MTK_ESW_IOCTL_STATUS_BYTES_PORT: /* used by rc */
+		ioctl_result = esw_status_bytes_port_uapi(uint_param, &port_bytes);
+		copy_to_user((port_bytes_t __user *)arg, &port_bytes, sizeof(port_bytes_t));
+		break;
+
+	case MTK_ESW_IOCTL_STATUS_MIB_PORT: /* used by rc */
+		ioctl_result = esw_status_mib_port_uapi(uint_param, &port_counters);
+		copy_to_user((esw_mib_counters_t __user *)arg, &port_counters, sizeof(esw_mib_counters_t));
+		break;
+
+	case MTK_ESW_IOCTL_PORTS_POWER: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		change_ports_power(uint_param, uint_value);
+		break;
+
+	case MTK_ESW_IOCTL_PORTS_WAN_LAN_POWER: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		change_wan_lan_ports_power(uint_param, uint_value);
+		break;
+	case MTK_ESW_IOCTL_MAC_TABLE_CLEAR: /* used by rc */
+		esw_mac_table_clear();
+		break;
+
+	case MTK_ESW_IOCTL_BRIDGE_MODE: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		ioctl_result = change_bridge_mode(uint_param, uint_value);
+		break;
+
+	case MTK_ESW_IOCTL_VLAN_RESET_TABLE: /* used by rc */
+		esw_vlan_reset_table();
+		break;
+	case MTK_ESW_IOCTL_VLAN_PVID_WAN_GET: /* used by rc */
+		uint_result = g_vlan_pvid_wan_untagged;
+		put_user(uint_result, (unsigned int __user *)arg);
+		break;
+	case MTK_ESW_IOCTL_VLAN_ACCEPT_PORT_MODE:  /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		vlan_accept_port_mode(uint_param, uint_value);
+		break;
+	case MTK_ESW_IOCTL_VLAN_CREATE_PORT_VID: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		vlan_create_entry(uint_param, uint_value, 1);
+		break;
+	case MTK_ESW_IOCTL_VLAN_CREATE_ENTRY: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		vlan_create_entry(uint_param, uint_value, 0);
+		break;
+	case MTK_ESW_IOCTL_VLAN_RULE_SET: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		ioctl_result = change_vlan_rule(uint_param, uint_value);
+		break;
+
+	case MTK_ESW_IOCTL_STORM_BROADCAST:  /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		change_storm_control_broadcast(uint_value);
+		break;
+
+	case MTK_ESW_IOCTL_JUMBO_FRAMES: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		change_jumbo_frames_accept(uint_value);
+		break;
+
+	case MTK_ESW_IOCTL_IGMP_SNOOPING: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		change_igmp_snooping_control(uint_value);
+		break;
+
+	case MTK_ESW_IOCTL_IGMP_STATIC_PORTS: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		change_igmp_static_ports(uint_value);
+		break;
+
+	case MTK_ESW_IOCTL_LED_MODE: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		change_led_mode(uint_value);
+		break;
+
+	case MTK_ESW_IOCTL_SPEED_PORT: /* used by rc */
+		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
+		ioctl_result = change_port_link_mode_uapi(uint_param, uint_value);
+		break;
+
+	default:
+		ioctl_result = -ENOIOCTLCMD;
+	}
+
+	mutex_unlock(&esw_access_mutex);
+
+	return ioctl_result;
+}
+
+////////////////////////////////////////////////////////////////////////////////////
+
+static int mtk_esw_open(struct inode *inode, struct file *file)
+{
+	try_module_get(THIS_MODULE);
+	return 0;
+}
+
+////////////////////////////////////////////////////////////////////////////////////
+
+static int mtk_esw_release(struct inode *inode, struct file *file)
+{
+	module_put(THIS_MODULE);
+	return 0;
+}
+
+////////////////////////////////////////////////////////////////////////////////////
+
+static const struct file_operations mtk_esw_fops =
+{
+	.owner		= THIS_MODULE,
+	.unlocked_ioctl	= mtk_esw_ioctl,
+	.open		= mtk_esw_open,
+	.release	= mtk_esw_release,
+};
+
+////////////////////////////////////////////////////////////////////////////////////
+
+int esw_ioctl_init(void)
+{
+	int r;
+
+	fill_bridge_members();
+
+	r = register_chrdev(MTK_ESW_DEVMAJOR, MTK_ESW_DEVNAME, &mtk_esw_fops);
+	if (r < 0) {
+		printk(KERN_ERR MTK_ESW_DEVNAME ": unable to register character device\n");
+		return r;
+	}
+
+	esw_link_status_hook = esw_link_status_changed_state;
+
+#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_SW)
+	igmp_sn_init();
+#endif
+
+	return 0;
+}
+
+////////////////////////////////////////////////////////////////////////////////////
+
+void esw_ioctl_uninit(void)
+{
+	esw_link_status_hook = NULL;
+
+#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_SW)
+	igmp_sn_uninit();
+#endif
+
+	unregister_chrdev(MTK_ESW_DEVMAJOR, MTK_ESW_DEVNAME);
+}
+
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.h
new file mode 100644
index 00000000..a3b80986
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.h
@@ -0,0 +1,198 @@
+/*
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
+ * MA 02111-1307 USA
+ *
+ */
+
+#ifndef __MTK_ESW_IOCTL_H__
+#define __MTK_ESW_IOCTL_H__
+
+#include "esw_common.h"
+
+#define MTK_ESW_DEVNAME				"mtk_esw"
+#define MTK_ESW_DEVPATH				"/dev/mtk_esw"
+#define MTK_ESW_DEVMAJOR			(219)
+
+#define MTK_ESW_IOCTL_CMD_LENGTH_BITS		(8)
+
+/////////////////////////////////////////////////
+// SWITCH STATUS
+/////////////////////////////////////////////////
+
+#define MTK_ESW_IOCTL_STATUS_LINK_PORT		10
+#define MTK_ESW_IOCTL_STATUS_LINK_PORTS_WAN	11
+#define MTK_ESW_IOCTL_STATUS_LINK_PORTS_LAN	12
+#define MTK_ESW_IOCTL_STATUS_LINK_CHANGED	17
+
+#define MTK_ESW_IOCTL_STATUS_SPEED_PORT		20
+
+#define MTK_ESW_IOCTL_STATUS_BYTES_PORT		26
+
+#define MTK_ESW_IOCTL_STATUS_MIB_PORT		30
+#define MTK_ESW_IOCTL_STATUS_MIB_RESET_ALL	38
+
+/////////////////////////////////////////////////
+// INIT CONTROL
+/////////////////////////////////////////////////
+
+#define MTK_ESW_IOCTL_RESET_SWITCH		40
+#define MTK_ESW_IOCTL_PORTS_POWER		41
+#define MTK_ESW_IOCTL_PORTS_WAN_LAN_POWER	42
+#define MTK_ESW_IOCTL_MAC_TABLE_CLEAR		43
+
+/////////////////////////////////////////////////
+// BRIDGE CONTROL (WAN/LAN HW ISOLATION)
+/////////////////////////////////////////////////
+
+#define MTK_ESW_IOCTL_BRIDGE_MODE		50
+#define MTK_ESW_IOCTL_PORT_FORWARD_MASK		55
+
+/////////////////////////////////////////////////
+// VLAN CONTROL
+/////////////////////////////////////////////////
+
+#define MTK_ESW_IOCTL_VLAN_RESET_TABLE		60
+#define MTK_ESW_IOCTL_VLAN_PVID_WAN_GET		61
+#define MTK_ESW_IOCTL_VLAN_ACCEPT_PORT_MODE	62
+#define MTK_ESW_IOCTL_VLAN_CREATE_PORT_VID	63
+#define MTK_ESW_IOCTL_VLAN_CREATE_ENTRY		64
+#define MTK_ESW_IOCTL_VLAN_RULE_SET		65
+
+/////////////////////////////////////////////////
+// USER CONTROL
+/////////////////////////////////////////////////
+
+#define MTK_ESW_IOCTL_STORM_BROADCAST		73
+#define MTK_ESW_IOCTL_JUMBO_FRAMES		75
+#define MTK_ESW_IOCTL_EEE_LPI			77
+#define MTK_ESW_IOCTL_IGMP_SNOOPING		78
+#define MTK_ESW_IOCTL_IGMP_STATIC_PORTS		79
+#define MTK_ESW_IOCTL_LED_MODE			80
+#define MTK_ESW_IOCTL_SPEED_PORT		90
+
+// *** VALUES DEFINITION ***
+
+/////////////////////////////////////////////////
+// MAGIC
+/////////////////////////////////////////////////
+
+#define SWAPI_MAGIC_RESET_ASIC			(0x25252525)
+
+/////////////////////////////////////////////////
+// HW INDEPENDENT PORT ID
+/////////////////////////////////////////////////
+
+#define SWAPI_PORT_WAN				0
+#define SWAPI_PORT_LAN1				1
+#define SWAPI_PORT_LAN2				2
+#define SWAPI_PORT_LAN3				3
+#define SWAPI_PORT_LAN4				4
+#define SWAPI_PORT_LAN5				5
+#define SWAPI_PORT_CPU_LAN			14
+#define SWAPI_PORT_CPU_WAN			15
+
+/////////////////////////////////////////////////
+// HW INDEPENDENT PORT MASK
+/////////////////////////////////////////////////
+
+#define SWAPI_PORTMASK_WAN			(1u<<SWAPI_PORT_WAN)
+#define SWAPI_PORTMASK_LAN1			(1u<<SWAPI_PORT_LAN1)
+#define SWAPI_PORTMASK_LAN2			(1u<<SWAPI_PORT_LAN2)
+#define SWAPI_PORTMASK_LAN3			(1u<<SWAPI_PORT_LAN3)
+#define SWAPI_PORTMASK_LAN4			(1u<<SWAPI_PORT_LAN4)
+#define SWAPI_PORTMASK_LAN5			(1u<<SWAPI_PORT_LAN5)
+#define SWAPI_PORTMASK_CPU_LAN			(1u<<SWAPI_PORT_CPU_LAN)
+#define SWAPI_PORTMASK_CPU_WAN			(1u<<SWAPI_PORT_CPU_WAN)
+
+/////////////////////////////////////////////////
+// BRIDGE MODES
+/////////////////////////////////////////////////
+
+#define SWAPI_WAN_BRIDGE_DISABLE		(0)
+#define SWAPI_WAN_BRIDGE_LAN1			(1)
+#define SWAPI_WAN_BRIDGE_LAN2			(2)
+#define SWAPI_WAN_BRIDGE_LAN3			(3)
+#define SWAPI_WAN_BRIDGE_LAN4			(4)
+#define SWAPI_WAN_BRIDGE_LAN3_LAN4		(5)
+#define SWAPI_WAN_BRIDGE_LAN1_LAN2		(6)
+#define SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3		(7)
+#define SWAPI_WAN_BRIDGE_DISABLE_WAN		(8)
+#define SWAPI_WAN_BRIDGE_NUM			(SWAPI_WAN_BRIDGE_DISABLE_WAN+1)
+
+/////////////////////////////////////////////////
+// BRIDGE WAN ISOLATION MODES
+/////////////////////////////////////////////////
+
+#define SWAPI_WAN_BWAN_ISOLATION_NONE		(0)
+#define SWAPI_WAN_BWAN_ISOLATION_FROM_CPU	(1)
+#define SWAPI_WAN_BWAN_ISOLATION_BETWEEN	(2)
+
+/////////////////////////////////////////////////
+// VLAN MODES
+/////////////////////////////////////////////////
+
+#define SWAPI_VLAN_ACCEPT_FRAMES_ALL		(0)
+#define SWAPI_VLAN_ACCEPT_FRAMES_TAG_ONLY	(1)
+#define SWAPI_VLAN_ACCEPT_FRAMES_UNTAG_ONLY	(2)
+
+#define SWAPI_VLAN_RULE_WAN_INET		(0)
+#define SWAPI_VLAN_RULE_WAN_IPTV		(1)
+#define SWAPI_VLAN_RULE_WAN_LAN1		(2)
+#define SWAPI_VLAN_RULE_WAN_LAN2		(3)
+#define SWAPI_VLAN_RULE_WAN_LAN3		(4)
+#define SWAPI_VLAN_RULE_WAN_LAN4		(5)
+#define SWAPI_VLAN_RULE_NUM			(SWAPI_VLAN_RULE_WAN_LAN4+1)
+
+/////////////////////////////////////////////////
+// LINK MODES
+/////////////////////////////////////////////////
+
+#define SWAPI_LINK_SPEED_MODE_AUTO		(0)
+#define SWAPI_LINK_SPEED_MODE_AUTO_1000_FD	(1)
+#define SWAPI_LINK_SPEED_MODE_AUTO_100_FD	(2)
+#define SWAPI_LINK_SPEED_MODE_AUTO_100_HD	(3)
+#define SWAPI_LINK_SPEED_MODE_AUTO_10_FD	(4)
+#define SWAPI_LINK_SPEED_MODE_AUTO_10_HD	(5)
+#define SWAPI_LINK_SPEED_MODE_FORCE_100_FD	(6)
+#define SWAPI_LINK_SPEED_MODE_FORCE_100_HD	(7)
+#define SWAPI_LINK_SPEED_MODE_FORCE_10_FD	(8)
+#define SWAPI_LINK_SPEED_MODE_FORCE_10_HD	(9)
+#define SWAPI_LINK_SPEED_MODE_FORCE_POWER_OFF	(15)
+
+#define SWAPI_LINK_FLOW_CONTROL_TX_RX		(0)
+#define SWAPI_LINK_FLOW_CONTROL_TX_ASYNC	(1)
+#define SWAPI_LINK_FLOW_CONTROL_DISABLE		(2)
+
+/////////////////////////////////////////////////
+// LED MODES
+/////////////////////////////////////////////////
+
+#define SWAPI_LED_PHYMODE_100_ACT		(1)
+#define SWAPI_LED_PHYMODE_10_ACT		(2)
+#define SWAPI_LED_PHYMODE_100			(5)
+#define SWAPI_LED_LINK_ACT			(7)
+#define SWAPI_LED_DUPLEX_COLLISION		(10)
+#define SWAPI_LED_OFF				(11)
+
+/////////////////////////////////////////////////
+
+typedef struct port_bytes_s
+{
+	uint64_t RX;
+	uint64_t TX;
+} port_bytes_t;
+
+#endif
+
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.c
new file mode 100644
index 00000000..b9288ccf
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.c
@@ -0,0 +1,1838 @@
+/*
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
+ * MA 02111-1307 USA
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/mutex.h>
+#include <linux/fs.h>
+#include <linux/delay.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+
+#include "../raether.h"
+#include "../ra_switch.h"
+
+#include "ioctl.h"
+//#include "ioctl_igmp.h"
+#include "ioctl_mt762x.h"
+
+////////////////////////////////////////////////////////////////////////////////////
+
+static DEFINE_MUTEX(esw_access_mutex);
+static DECLARE_BITMAP(g_vlan_pool, 4096);
+
+
+static u32 g_wan_bridge_mode                     = SWAPI_WAN_BRIDGE_DISABLE;
+static u32 g_wan_bwan_isolation                  = SWAPI_WAN_BWAN_ISOLATION_NONE;
+
+static u32 g_led_phy_mode                        = SWAPI_LED_LINK_ACT;
+
+static u32 g_jumbo_frames_enabled                = ESW_DEFAULT_JUMBO_FRAMES;
+
+#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
+static u32 g_igmp_snooping_enabled               = ESW_DEFAULT_IGMP_SNOOPING;
+static u32 g_igmp_static_ports                   = 0;
+#endif
+
+static u32 g_storm_rate_limit                    = ESW_DEFAULT_STORM_RATE;
+
+static u32 g_port_link_mode[ESW_EPHY_ID_MAX+1]   = {0, 0, 0, 0, 0};
+static u32 g_port_phy_power[ESW_EPHY_ID_MAX+1]   = {0, 0, 0, 0, 0};
+
+static u32 g_vlan_rule[SWAPI_VLAN_RULE_NUM]      = {0x0, 0x0, 0x0, 0x0, 0x0, 0x0};
+static u32 g_vlan_rule_user[SWAPI_VLAN_RULE_NUM] = {0x0, 0x0, 0x0, 0x0, 0x0, 0x0};
+
+////////////////////////////////////////////////////////////////////////////////////
+
+static atomic_t g_switch_inited                  = ATOMIC_INIT(0);
+static atomic_t g_switch_allow_irq               = ATOMIC_INIT(0);
+static atomic_t g_port_link_changed              = ATOMIC_INIT(0);
+
+static bwan_member_t g_bwan_member[SWAPI_WAN_BRIDGE_NUM][ESW_EPHY_ID_MAX+1];
+
+static u32 g_vlan_pvid_wan_untagged              = 2;
+
+////////////////////////////////////////////////////////////////////////////////////
+u32 esw_reg_get(u32 addr)
+{
+	u32 data = 0;
+	if (mii_mgr_read(0x1f, addr, &data))
+		return data;
+	printk("%s: FAILED at read from 0x%08X!\n", __FUNCTION__, addr);
+	return 0;
+
+}
+
+void esw_reg_set(u32 addr, u32 data)
+{
+	if (!mii_mgr_write(0x1f, addr, data))
+		printk("%s: FAILED at write to 0x%08X!\n", __FUNCTION__, addr);
+}
+
+static
+int mt7530_gsw_wait_wt_mac(void)
+{
+	u32 i, atc_val;
+
+	for (i = 0; i < 200; i++) {
+		udelay(100);
+		atc_val = 0;
+		mii_mgr_read(0x1f, 0x80, &atc_val);
+		if (!(atc_val & BIT(15)))
+			return 0;
+	}
+
+	return -1;
+}
+
+static
+int mt7530_gsw_mac_table_clear(int static_only)
+{
+	u32 atc_val;
+
+	/* clear all (non)static MAC entries */
+	atc_val = (static_only) ? 0x8602 : 0x8002;
+
+	mii_mgr_write(0x1f, 0x80, atc_val);
+
+	return mt7530_gsw_wait_wt_mac();
+}
+
+static
+u32 esw_get_port_mib_rgoc(u32 port_id, u32 *HighPart)
+{
+	u32 mib_val = 0;
+	mib_val   = esw_reg_get(0x40A8 + 0x100*port_id);
+	*HighPart = esw_reg_get(0x40AC + 0x100*port_id);
+	return mib_val;
+}
+
+static
+u32 esw_get_port_mib_tgoc(u32 port_id, u32 *HighPart)
+{
+	u32 mib_val = 0;
+	mib_val   = esw_reg_get(0x4048 + 0x100*port_id);
+	*HighPart = esw_reg_get(0x404C + 0x100*port_id);
+	return mib_val;
+}
+
+u32 get_ports_mask_lan(u32 include_cpu, int is_phy_id)
+{
+	u32 i, wan_bridge_mode, portmask_lan;
+
+	wan_bridge_mode = g_wan_bridge_mode;
+
+	portmask_lan = MASK_LAN_PORTS_ALL;
+	if (include_cpu)
+		portmask_lan |= MASK_LAN_PORT_CPU;
+
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if (g_bwan_member[wan_bridge_mode][i].bwan)
+			portmask_lan &= ~(1u << i);
+	}
+
+	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE_WAN) {
+		if (is_phy_id)
+			portmask_lan |= (1u << WAN_PORT_X);
+		else
+			portmask_lan |= MASK_WAN_PORT_X;
+	}
+
+	return portmask_lan;
+}
+
+static u32 get_ports_mask_wan(u32 include_cpu, int is_phy_id)
+{
+	u32 i, wan_bridge_mode, portmask_wan;
+
+	wan_bridge_mode = g_wan_bridge_mode;
+	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE_WAN)
+		return 0;
+
+	if (is_phy_id)
+		portmask_wan = (1u << WAN_PORT_X);
+	else
+		portmask_wan = MASK_WAN_PORT_X;
+
+	if (include_cpu)
+		portmask_wan |= MASK_WAN_PORT_CPU;
+
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if (g_bwan_member[wan_bridge_mode][i].bwan)
+			portmask_wan |= (1u << i);
+	}
+
+	return portmask_wan;
+}
+
+static u32 get_ports_mask_from_uapi(u32 port_mask_uapi, int is_phy_id)
+{
+	u32 gsw_ports_mask = 0;
+
+	if (port_mask_uapi & SWAPI_PORTMASK_WAN) {
+		if (is_phy_id)
+			gsw_ports_mask |= (1u << WAN_PORT_X);
+		else
+			gsw_ports_mask |= MASK_WAN_PORT_X;
+	}
+	if (port_mask_uapi & SWAPI_PORTMASK_LAN1)
+		gsw_ports_mask |= MASK_LAN_PORT_1;
+	if (port_mask_uapi & SWAPI_PORTMASK_LAN2)
+		gsw_ports_mask |= MASK_LAN_PORT_2;
+	if (port_mask_uapi & SWAPI_PORTMASK_LAN3)
+		gsw_ports_mask |= MASK_LAN_PORT_3;
+	if (port_mask_uapi & SWAPI_PORTMASK_LAN4)
+		gsw_ports_mask |= MASK_LAN_PORT_4;
+	if (port_mask_uapi & SWAPI_PORTMASK_LAN5)
+		gsw_ports_mask |= MASK_LAN_PORT_5;
+	if (port_mask_uapi & SWAPI_PORTMASK_CPU_LAN)
+		gsw_ports_mask |= MASK_LAN_PORT_CPU;
+	if (port_mask_uapi & SWAPI_PORTMASK_CPU_WAN)
+		gsw_ports_mask |= MASK_WAN_PORT_CPU;
+
+	return gsw_ports_mask;
+}
+
+static u32 get_port_from_uapi(u32 port_id_uapi)
+{
+	switch (port_id_uapi)
+	{
+	case SWAPI_PORT_WAN:
+		return WAN_PORT_X;
+	case SWAPI_PORT_LAN1:
+		return LAN_PORT_1;
+	case SWAPI_PORT_LAN2:
+		return LAN_PORT_2;
+	case SWAPI_PORT_LAN3:
+		return LAN_PORT_3;
+	case SWAPI_PORT_LAN4:
+		return LAN_PORT_4;
+#if defined (LAN_PORT_5)
+	case SWAPI_PORT_LAN5:
+		return LAN_PORT_5;
+#endif
+	case SWAPI_PORT_CPU_LAN:
+		return LAN_PORT_CPU;
+	case SWAPI_PORT_CPU_WAN:
+		return WAN_PORT_CPU;
+	}
+
+	return ESW_PORT_ID_MAX+1;
+}
+
+static const char* get_port_desc(u32 port_id)
+{
+	const char *port_desc;
+
+	switch (port_id)
+	{
+	case WAN_PORT_X:
+		port_desc = "WAN";
+		break;
+	case LAN_PORT_1:
+		port_desc = "LAN1";
+		break;
+	case LAN_PORT_2:
+		port_desc = "LAN2";
+		break;
+	case LAN_PORT_3:
+		port_desc = "LAN3";
+		break;
+	case LAN_PORT_4:
+		port_desc = "LAN4";
+		break;
+#if defined (LAN_PORT_5)
+	case LAN_PORT_5:
+		port_desc = "LAN5";
+		break;
+#endif
+	case LAN_PORT_CPU:
+	default:
+		port_desc = "CPU";
+		break;
+	}
+
+	return port_desc;
+}
+
+static void esw_show_bridge_partitions(u32 wan_bridge_mode)
+{
+	const char *wanl, *wanr;
+	char lans[8];
+
+	wanl = "W|";
+	wanr = "";
+
+	switch (wan_bridge_mode)
+	{
+	case SWAPI_WAN_BRIDGE_LAN1:
+		strcpy(lans, "WLLL");
+		break;
+	case SWAPI_WAN_BRIDGE_LAN2:
+		strcpy(lans, "LWLL");
+		break;
+	case SWAPI_WAN_BRIDGE_LAN3:
+		strcpy(lans, "LLWL");
+		break;
+	case SWAPI_WAN_BRIDGE_LAN4:
+		strcpy(lans, "LLLW");
+		break;
+	case SWAPI_WAN_BRIDGE_LAN3_LAN4:
+		strcpy(lans, "LLWW");
+		break;
+	case SWAPI_WAN_BRIDGE_LAN1_LAN2:
+		strcpy(lans, "WWLL");
+		break;
+	case SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3:
+		strcpy(lans, "WWWL");
+		break;
+	case SWAPI_WAN_BRIDGE_DISABLE_WAN:
+		strcpy(lans, "LLLL");
+		wanl = "L";
+		wanr = "";
+		break;
+	default:
+		strcpy(lans, "LLLL");
+		break;
+	}
+
+#if defined (LAN_PORT_5)
+	strcat(lans, "L");
+#endif
+
+	printk("%s - %s: %s%s%s\n", MTK_ESW_DEVNAME, "hw bridge", wanl, lans, wanr);
+}
+
+static void esw_port_matrix_set(u32 port_id, u32 fwd_mask, u32 pvlan_ingress_mode)
+{
+	u32 reg_pcr;
+
+	reg_pcr = esw_reg_get(REG_ESW_PORT_PCR_P0 + 0x100*port_id);
+	reg_pcr &= ~(0xFF << 16);
+	reg_pcr &= ~(0x03);
+	reg_pcr |= ((fwd_mask & 0xFF) << 16);
+	reg_pcr |= (pvlan_ingress_mode & 0x03);
+	esw_reg_set(REG_ESW_PORT_PCR_P0 + 0x100*port_id, reg_pcr);
+}
+
+static void esw_port_ingress_mode_set(u32 port_id, u32 pvlan_ingress_mode)
+{
+	u32 reg_pcr;
+
+	reg_pcr = esw_reg_get(REG_ESW_PORT_PCR_P0 + 0x100*port_id);
+	reg_pcr &= ~(0x03);
+	reg_pcr |= (pvlan_ingress_mode & 0x03);
+	esw_reg_set(REG_ESW_PORT_PCR_P0 + 0x100*port_id, reg_pcr);
+}
+
+static void esw_port_attrib_set(u32 port_id, u32 port_attribute)
+{
+	u32 reg_pvc;
+
+	reg_pvc = esw_reg_get(REG_ESW_PORT_PVC_P0 + 0x100*port_id);
+	reg_pvc &= 0x0000FF3F;
+	reg_pvc |= 0x81000000; // STAG VPID 8100
+	reg_pvc |= ((port_attribute & 0x03) << 6);
+	esw_reg_set(REG_ESW_PORT_PVC_P0 + 0x100*port_id, reg_pvc);
+}
+
+static void esw_port_accept_set(u32 port_id, u32 accept_frames)
+{
+	u32 reg_pvc;
+
+	reg_pvc = esw_reg_get(REG_ESW_PORT_PVC_P0 + 0x100*port_id);
+	reg_pvc &= 0xFFFFFFFC;
+	reg_pvc |= (accept_frames & 0x03);
+	esw_reg_set(REG_ESW_PORT_PVC_P0 + 0x100*port_id, reg_pvc);
+}
+
+static void esw_vlan_pvid_set(u32 port_id, u32 pvid, u32 prio)
+{
+	u32 reg_ppbv = (1u << 16) | ((prio & 0x7) << 13) | (pvid & 0xfff);
+
+	esw_reg_set(REG_ESW_PORT_PPBV1_P0 + 0x100*port_id, reg_ppbv);
+}
+
+#if !defined (CONFIG_RAETH_ESW_IGMP_SNOOP_OFF)
+void esw_igmp_flood_to_cpu(int flood_to_cpu)
+{
+	u32 reg_imc;
+
+	reg_imc = esw_reg_get(REG_ESW_IMC);
+	reg_imc &= ~((0x7<<28)|(0x7<<12));
+	/* Note: TO_CPU applied to P5 port too and IGMP/MLD P5->WAN will be dropped */
+#if !defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) && !defined (CONFIG_GE2_INTERNAL_GMAC_P5)
+	if (flood_to_cpu)
+		reg_imc |= (0x6<<28)|(0x6<<12);
+#endif
+	esw_reg_set(REG_ESW_IMC, reg_imc);
+}
+#endif
+
+#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
+static void esw_igmp_ports_config(u32 wan_bridge_mode)
+{
+	u32 i, reg_isc, mask_no_learn;
+
+	mask_no_learn = 0;
+
+	if (wan_bridge_mode != SWAPI_WAN_BRIDGE_DISABLE_WAN) {
+		mask_no_learn = get_ports_mask_wan(0, 0);
+		for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+			if ((mask_no_learn >> i) & 0x1)
+				esw_reg_set(REG_ESW_PORT_PIC_P0 + 0x100*i, 0x8000);
+		}
+	}
+
+	/* make CPU ports always static */
+	mask_no_learn |= MASK_WAN_PORT_CPU;
+	mask_no_learn |= MASK_LAN_PORT_CPU;
+
+	if (g_igmp_snooping_enabled)
+		mask_no_learn |= g_igmp_static_ports;
+	else
+		mask_no_learn |= get_ports_mask_lan(0, 0);
+
+	reg_isc = esw_reg_get(REG_ESW_ISC);
+	reg_isc &= ~0xFF1C00FF;
+	reg_isc |= mask_no_learn;
+
+	/* also enable upstream router port learning (in AP mode) */
+	if (g_igmp_static_ports)
+		reg_isc |= (1u << 19) | (1u << 18);
+
+	esw_reg_set(REG_ESW_ISC, reg_isc);
+}
+
+static void esw_igmp_mld_snooping(u32 enable_igmp, u32 enable_mld)
+{
+	u32 i, mask_lan, dst_igmp, src_join, reg_pic, reg_pic_lan;
+	u32 mask_static = g_igmp_static_ports;
+
+	dst_igmp = 0;
+	src_join = 0;
+	reg_pic = (2u << 14);			// Robustness = 2
+
+	if (enable_mld) {
+		dst_igmp |= (1u << 9);		// IPM_33
+		
+		src_join |= (1u << 13);		// MLD_HW_LEAVE
+		src_join |= (1u << 7);		// MLD2_JOIN_EN
+		src_join |= (1u << 5);		// MLD_JOIN_EN
+	}
+
+	if (enable_igmp) {
+		dst_igmp |= (1u << 8);		// IPM_01
+		
+		src_join |= (1u << 12);		// IGMP_HW_LEAVE
+		src_join |= (1u << 6);		// IGMP3_JOIN_EN
+		src_join |= (1u << 4);		// IGMP_JOIN_EN
+	}
+
+	mask_lan = get_ports_mask_lan(0, 0);
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if ((mask_lan >> i) & 0x1) {
+			reg_pic_lan = reg_pic;
+			if ((mask_static >> i) & 0x1)
+				reg_pic_lan |= dst_igmp;
+			else
+				reg_pic_lan |= src_join;
+			esw_reg_set(REG_ESW_PORT_PIC_P0 + 0x100*i, reg_pic_lan);
+		}
+	}
+
+	/* make CPU port always static */
+	esw_reg_set(REG_ESW_PORT_PIC_P0 + 0x100*LAN_PORT_CPU, reg_pic | dst_igmp);
+}
+#endif
+
+static void esw_mac_table_clear(void)
+{
+	mt7530_gsw_mac_table_clear(0);
+#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || \
+    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
+	mt7620_esw_mac_table_clear(0);
+#endif
+}
+
+static int esw_write_vtcr(u32 vtcr_cmd, u32 vtcr_val)
+{
+	u32 i, reg_vtcr;
+
+	reg_vtcr = (vtcr_cmd << 12) | vtcr_val | 0x80000000;
+	esw_reg_set(REG_ESW_VLAN_VTCR, reg_vtcr);
+
+	for (i = 0; i < 200; i++) {
+		udelay(100);
+		reg_vtcr = esw_reg_get(REG_ESW_VLAN_VTCR);
+		if (!(reg_vtcr & 0x80000000))
+			return 0;
+	}
+
+	printk("%s: VTCR timeout!\n", MTK_ESW_DEVNAME);
+	return -1;
+}
+
+static void esw_vlan_set(u32 cvid, u32 svid, u32 mask_member, u32 mask_untag, u32 mask_swap, u32 fid)
+{
+	u32 i, reg_val, reg_val2;
+
+	cvid &= 0xfff;
+	svid &= 0xfff;
+	mask_member &= 0x7f;
+	mask_untag &= 0x7f;
+	mask_swap &= 0x7f;
+	fid &= 0x7;
+
+	reg_val2 = 0;
+
+	// set vlan member
+	reg_val = 1;				// VALID
+#if !ESW_USE_IVL_MODE
+	if (fid > 0)
+		reg_val |= (fid << 1);		// FID
+	else
+#endif
+	reg_val |= (1u << 30);			// IVL=1
+	reg_val |= (svid << 4);			// S_TAG
+	reg_val |= (mask_member << 16);		// PORT_MEM
+	if (svid)
+		reg_val |= (1u << 27);		// COPY_PRI
+	reg_val |= (1u << 28);			// VTAG_EN=1
+
+	/* set vlan untag ports */
+	for (i = 0; i < 7; i++) {
+		if (!(mask_member & (1u << i)))
+			continue;
+		
+		if (!(mask_untag & (1u << i))) {
+			if (mask_swap & (1u << i))
+				reg_val2 |= (0x1u << (i*2));	// EG_TAG=Swap
+			else
+				reg_val2 |= (0x2u << (i*2));	// EG_TAG=Tagged
+		}
+	}
+
+	esw_reg_set(REG_ESW_VLAN_VAWD1, reg_val);
+	esw_reg_set(REG_ESW_VLAN_VAWD2, reg_val2);
+
+	esw_write_vtcr(1, cvid);
+	set_bit(cvid, g_vlan_pool);
+}
+
+static void esw_vlan_reset_table(void)
+{
+	u32 i;
+
+	/* Reset VLAN table from VID #2 */
+	for (i = 2; i < 4096; i++) {
+		if (test_and_clear_bit(i, g_vlan_pool))
+			esw_write_vtcr(2, i);
+	}
+}
+
+#define VLAN_ENTRY_ID_MAX	(15)
+static u32 find_vlan_slot(vlan_entry_t *vlan_entry, u32 start_idx, u32 cvid)
+{
+	u32 i;
+
+	for (i = start_idx; i <= VLAN_ENTRY_ID_MAX; i++) {
+		if (!vlan_entry[i].valid || vlan_entry[i].cvid == cvid)
+			return i;
+	}
+
+	return VLAN_ENTRY_ID_MAX + 1; // not found
+}
+
+static u32 find_free_min_pvid(u32 *pvid_list, u32 vid)
+{
+	u32 i, vid_new;
+
+	vid_new = vid;
+	for (i = 0; i < SWAPI_VLAN_RULE_NUM; i++) {
+		if (vid == pvid_list[i]) {
+			/* recursion step */
+			vid_new = find_free_min_pvid(pvid_list, vid+1);
+			break;
+		}
+	}
+	return vid_new;
+}
+
+static int is_vlan_rule_included(u32 wan_bridge_mode, u32 rule_id)
+{
+	u32 i;
+
+	if (rule_id == SWAPI_VLAN_RULE_WAN_INET ||
+	    rule_id == SWAPI_VLAN_RULE_WAN_IPTV)
+		return 1;
+
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if (g_bwan_member[wan_bridge_mode][i].bwan &&
+		    g_bwan_member[wan_bridge_mode][i].rule == (u8)rule_id)
+			return 1;
+	}
+
+	return 0;
+}
+
+static int is_wan_vid_valid(u32 vid)
+{
+	return (vid == 2 || vid >= MIN_EXT_VLAN_VID) ? 1 : 0;
+}
+
+static void esw_vlan_apply_rules(u32 wan_bridge_mode, u32 wan_bwan_isolation)
+{
+	vlan_entry_t vlan_entry[VLAN_ENTRY_ID_MAX+1];
+	pvlan_member_t pvlan_member[ESW_EPHY_ID_MAX+1];
+	u32 pvid[SWAPI_VLAN_RULE_NUM] = {0};
+	u32 prio[SWAPI_VLAN_RULE_NUM] = {0};
+	u32 tagg[SWAPI_VLAN_RULE_NUM] = {0};
+	u32 i, cvid, next_fid, untg_vid, vlan_idx, vlan_filter_on;
+
+#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
+	pvlan_member_t pvlan_member_cpu_wan;
+#endif
+
+	untg_vid = 2;	// default PVID for untagged WAN traffic
+	next_fid = 3;
+	vlan_filter_on = 0;
+
+	memset(vlan_entry, 0, sizeof(vlan_entry));
+	memset(pvlan_member, 0, sizeof(pvlan_member));
+
+	for (i = 0; i < SWAPI_VLAN_RULE_NUM; i++) {
+		if (!is_vlan_rule_included(wan_bridge_mode, i))
+			continue;
+		pvid[i] =  (g_vlan_rule_user[i] & 0xFFF);
+		prio[i] = ((g_vlan_rule_user[i] >> 16) & 0x7);
+		tagg[i] = ((g_vlan_rule_user[i] >> 24) & 0x1);
+		if (is_wan_vid_valid(pvid[i]))
+			vlan_filter_on = 1;
+	}
+
+	/* find minimal unused VID, when VID=2 is used */
+	if (vlan_filter_on) {
+		untg_vid = find_free_min_pvid(pvid, 2);
+	}
+
+	g_vlan_pvid_wan_untagged = untg_vid;
+
+	if (!is_wan_vid_valid(pvid[SWAPI_VLAN_RULE_WAN_INET])) {
+		pvid[SWAPI_VLAN_RULE_WAN_INET] = untg_vid; // VID 2
+		prio[SWAPI_VLAN_RULE_WAN_INET] = 0;
+		tagg[SWAPI_VLAN_RULE_WAN_INET] = 0;
+	} else {
+		tagg[SWAPI_VLAN_RULE_WAN_INET] = 1;
+	}
+
+	if (!is_wan_vid_valid(pvid[SWAPI_VLAN_RULE_WAN_IPTV])) {
+		pvid[SWAPI_VLAN_RULE_WAN_IPTV] = untg_vid; // VID 2
+		prio[SWAPI_VLAN_RULE_WAN_IPTV] = 0;
+		tagg[SWAPI_VLAN_RULE_WAN_IPTV] = 0;
+	} else {
+		tagg[SWAPI_VLAN_RULE_WAN_IPTV] = 1;
+	}
+
+	/* fill WAN port (use PVID 2 for handle untagged traffic -> VID2) */
+	pvlan_member[WAN_PORT_X].pvid = untg_vid;
+
+#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
+	/* fill CPU WAN port (use PVID 2 for handle untagged traffic -> VID2) */
+	pvlan_member_cpu_wan.pvid = untg_vid;
+	pvlan_member_cpu_wan.prio = 0;
+	pvlan_member_cpu_wan.tagg = 0;
+#endif
+
+	/* VID #1 */
+	vlan_entry[0].valid = 1;
+	vlan_entry[0].fid = 1;
+	vlan_entry[0].cvid = 1;
+	vlan_entry[0].port_member |= MASK_LAN_PORT_CPU;
+#if defined (MT7530_P6_UNTAGGED)
+	vlan_entry[0].port_untag  |= MASK_LAN_PORT_CPU;
+#endif
+
+	/* VID #2 */
+	vlan_entry[1].valid = 1;
+	vlan_entry[1].fid = 2;
+	vlan_entry[1].cvid = untg_vid;
+	vlan_entry[1].port_member |= (MASK_WAN_PORT_X | MASK_WAN_PORT_CPU);
+	vlan_entry[1].port_untag  |=  MASK_WAN_PORT_X;
+
+#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || \
+    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
+	/* clear vlan members on MT7620 ESW (slot idx 2..3) */
+	mt7620_esw_vlan_clear_idx(2);
+	mt7620_esw_vlan_clear_idx(3);
+
+	/* update VID=2 members (P7|P6|P4) */
+	mt7620_esw_vlan_set_idx(1, untg_vid, 0xd0);
+
+	/* set P4 PVID */
+	mt7620_esw_pvid_set(4, untg_vid, 0);
+#endif
+
+	/* check IPTV tagged */
+	if (tagg[SWAPI_VLAN_RULE_WAN_IPTV]) {
+		cvid = pvid[SWAPI_VLAN_RULE_WAN_IPTV];
+		vlan_idx = find_vlan_slot(vlan_entry, 2, cvid);
+		if (vlan_idx <= VLAN_ENTRY_ID_MAX) {
+			if (!vlan_entry[vlan_idx].valid) {
+				vlan_entry[vlan_idx].valid = 1;
+				vlan_entry[vlan_idx].fid = next_fid++;
+				vlan_entry[vlan_idx].cvid = cvid;
+				
+#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || \
+    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
+				/* need add vlan members on MT7620 ESW P4 (ESW members P7|P6|P4) */
+				mt7620_esw_vlan_set_idx(2, cvid, 0xd0);
+#endif
+			}
+			vlan_entry[vlan_idx].port_member |= (MASK_WAN_PORT_X | MASK_WAN_PORT_CPU);
+			pvlan_member[WAN_PORT_X].tagg = 1;
+		}
+	}
+
+	/* check INET tagged */
+	if (tagg[SWAPI_VLAN_RULE_WAN_INET]) {
+		cvid = pvid[SWAPI_VLAN_RULE_WAN_INET];
+		vlan_idx = find_vlan_slot(vlan_entry, 2, cvid);
+		if (vlan_idx <= VLAN_ENTRY_ID_MAX) {
+			if (!vlan_entry[vlan_idx].valid) {
+				vlan_entry[vlan_idx].valid = 1;
+				vlan_entry[vlan_idx].fid = next_fid++;
+				vlan_entry[vlan_idx].cvid = cvid;
+				
+#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || \
+    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
+				/* need add vlan members on MT7620 ESW P4 (ESW members P7|P6|P4) */
+				mt7620_esw_vlan_set_idx(3, cvid, 0xd0);
+#endif
+			}
+			vlan_entry[vlan_idx].port_member |= (MASK_WAN_PORT_X | MASK_WAN_PORT_CPU);
+			pvlan_member[WAN_PORT_X].tagg = 1;
+		}
+	}
+
+#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
+	/* if INET and IPTV tagged with common VID, untag WAN_CPU + use PVID */
+	if (tagg[SWAPI_VLAN_RULE_WAN_INET] && pvid[SWAPI_VLAN_RULE_WAN_INET] == pvid[SWAPI_VLAN_RULE_WAN_IPTV]) {
+		/* update VID #2 members (do not forward untagged packets to WAN_CPU) */
+		vlan_entry[1].port_member &= ~(MASK_WAN_PORT_CPU);
+		cvid = pvid[SWAPI_VLAN_RULE_WAN_INET];
+		vlan_idx = find_vlan_slot(vlan_entry, 2, cvid);
+		if (vlan_idx <= VLAN_ENTRY_ID_MAX && vlan_entry[vlan_idx].valid)
+			vlan_entry[vlan_idx].port_untag |= MASK_WAN_PORT_CPU;
+		pvlan_member_cpu_wan.pvid = cvid;
+		pvlan_member_cpu_wan.prio = prio[SWAPI_VLAN_RULE_WAN_IPTV];
+	} else if (!tagg[SWAPI_VLAN_RULE_WAN_INET] && !tagg[SWAPI_VLAN_RULE_WAN_IPTV]) {
+		/* update VID #2 untag members */
+		vlan_entry[1].port_untag |= MASK_WAN_PORT_CPU;
+	} else {
+		/* mark CPU WAN as tagged */
+		pvlan_member_cpu_wan.tagg = 1;
+	}
+#endif
+
+	/* fill physical LAN ports */
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		int rule_id;
+		
+		if (i == WAN_PORT_X)
+			continue;
+		
+		if ((1u << i) & ESW_MASK_EXCLUDE)
+			continue;
+		
+		if (!g_bwan_member[wan_bridge_mode][i].bwan) {
+			pvlan_member[i].pvid = 1;
+			
+			/* VID #1 */
+			vlan_entry[0].port_member |= (1u << i);
+			vlan_entry[0].port_untag  |= (1u << i);
+			
+			continue;
+		}
+		
+		rule_id = g_bwan_member[wan_bridge_mode][i].rule;
+		if (!is_wan_vid_valid(pvid[rule_id])) {
+			pvlan_member[i].pvid = untg_vid;
+			
+			/* VID #2 */
+			vlan_entry[1].port_member |= (1u << i);
+			vlan_entry[1].port_untag  |= (1u << i);
+		} else {
+			cvid = pvid[rule_id];
+			vlan_idx = find_vlan_slot(vlan_entry, 2, cvid);
+			if (vlan_idx <= VLAN_ENTRY_ID_MAX) {
+				if (!vlan_entry[vlan_idx].valid) {
+					vlan_entry[vlan_idx].valid = 1;
+					vlan_entry[vlan_idx].fid = next_fid++;
+					vlan_entry[vlan_idx].cvid = cvid;
+				}
+				vlan_entry[vlan_idx].port_member |= ((1u << i) | MASK_WAN_PORT_X);
+#if !defined (RAETH_GE2_MAC_TO_GPHY)
+				if (wan_bwan_isolation != SWAPI_WAN_BWAN_ISOLATION_FROM_CPU)
+#endif
+				{
+					vlan_entry[vlan_idx].port_member |= MASK_WAN_PORT_CPU;
+#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
+					/* mark CPU WAN as tagged */
+					pvlan_member_cpu_wan.tagg = 1;
+#endif
+				}
+				if (!tagg[rule_id])
+					vlan_entry[vlan_idx].port_untag |= (1u << i);
+				
+				pvlan_member[i].pvid = cvid;
+				pvlan_member[i].prio = prio[rule_id];
+				pvlan_member[i].tagg = tagg[rule_id];
+				
+				pvlan_member[WAN_PORT_X].tagg = 1;
+			} else {
+				pvlan_member[i].pvid = untg_vid;
+				
+				/* VID #2 */
+				vlan_entry[1].port_member |= (1u << i);
+				vlan_entry[1].port_untag  |= (1u << i);
+			}
+		}
+	}
+
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+	for (i = 0; i <= VLAN_ENTRY_ID_MAX; i++) {
+		if (!vlan_entry[i].valid)
+			continue;
+		if (!vlan_entry[i].port_member)
+			continue;
+		if (wan_bridge_mode != SWAPI_WAN_BRIDGE_DISABLE) {
+			vlan_entry[i].port_member |= MASK_LAN_PORT_CPU;
+			vlan_entry[i].port_untag &= ~MASK_LAN_PORT_CPU;
+		}
+	}
+#endif
+
+#if defined (ESW_PORT_PPE)
+	/* add PPE port to members with CPU port */
+	for (i = 0; i <= VLAN_ENTRY_ID_MAX; i++) {
+		if (!vlan_entry[i].valid)
+			continue;
+		if (vlan_entry[i].port_member & (1u << ESW_PORT_CPU))
+			vlan_entry[i].port_member |= (1u << ESW_PORT_PPE);
+		if (vlan_entry[i].port_swap & (1u << ESW_PORT_CPU))
+			vlan_entry[i].port_swap |= (1u << ESW_PORT_PPE);
+	}
+#endif
+
+	/* configure physical LAN/WAN ports */
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if ((1u << i) & ESW_MASK_EXCLUDE)
+			continue;
+		esw_vlan_pvid_set(i, pvlan_member[i].pvid, pvlan_member[i].prio);
+		if (!pvlan_member[i].tagg) {
+			esw_port_attrib_set(i, PORT_ATTRIBUTE_TRANSPARENT);
+			esw_port_accept_set(i, PORT_ACCEPT_FRAMES_UNTAGGED);
+		} else {
+			esw_port_attrib_set(i, PORT_ATTRIBUTE_USER);
+			esw_port_accept_set(i, PORT_ACCEPT_FRAMES_ALL);
+		}
+	}
+
+	/* configure CPU LAN port */
+	esw_vlan_pvid_set(LAN_PORT_CPU, 1, 0);
+	esw_port_accept_set(LAN_PORT_CPU, PORT_ACCEPT_FRAMES_ALL);
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+	esw_port_attrib_set(LAN_PORT_CPU, (wan_bridge_mode != SWAPI_WAN_BRIDGE_DISABLE) ? PORT_ATTRIBUTE_USER : PORT_ATTRIBUTE_TRANSPARENT);
+#elif defined (MT7530_P6_UNTAGGED)
+	esw_port_attrib_set(LAN_PORT_CPU, PORT_ATTRIBUTE_TRANSPARENT);
+#else
+	esw_port_attrib_set(LAN_PORT_CPU, PORT_ATTRIBUTE_USER);
+#endif
+
+	esw_port_ingress_mode_set(LAN_PORT_CPU, PVLAN_INGRESS_MODE_SECURITY);
+
+	/* configure CPU WAN port */
+#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
+	/* [MT7620 P4 -> MT7530 P5] or [MT7621 GE2 -> MT7530 P5] */
+	esw_vlan_pvid_set(WAN_PORT_CPU, pvlan_member_cpu_wan.pvid, pvlan_member_cpu_wan.prio);
+	esw_port_accept_set(WAN_PORT_CPU, PORT_ACCEPT_FRAMES_ALL);
+	esw_port_attrib_set(WAN_PORT_CPU, (pvlan_member_cpu_wan.pvid != untg_vid || pvlan_member_cpu_wan.tagg) ? PORT_ATTRIBUTE_USER : PORT_ATTRIBUTE_TRANSPARENT);
+	esw_port_ingress_mode_set(WAN_PORT_CPU, PVLAN_INGRESS_MODE_SECURITY);
+#endif
+
+	/* reset VLAN table */
+	esw_vlan_reset_table();
+
+	/* fill VLAN table */
+	for (i = 0; i <= VLAN_ENTRY_ID_MAX; i++) {
+		if (!vlan_entry[i].valid)
+			continue;
+		if (!vlan_entry[i].port_member)
+			continue;
+		esw_vlan_set(vlan_entry[i].cvid, vlan_entry[i].svid,
+			vlan_entry[i].port_member, vlan_entry[i].port_untag, 0, vlan_entry[i].fid);
+	}
+
+	/* save VLAN rules */
+	for (i = 0; i < SWAPI_VLAN_RULE_NUM; i++)
+		g_vlan_rule[i] = g_vlan_rule_user[i];
+}
+
+static void esw_vlan_init_vid1(void)
+{
+	u32 i, port_member, port_untag;
+
+	port_member = 0xFF;
+	port_member &= ~(ESW_MASK_EXCLUDE);
+	port_untag = port_member;
+#if defined (ESW_PORT_PPE)
+	port_untag &= ~(1u << ESW_PORT_PPE);
+#endif
+
+	/* configure physical LAN ports */
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if ((1u << i) & ESW_MASK_EXCLUDE)
+			continue;
+		esw_vlan_pvid_set(i, 1, 0);
+		esw_port_attrib_set(i, PORT_ATTRIBUTE_TRANSPARENT);
+		esw_port_accept_set(i, PORT_ACCEPT_FRAMES_UNTAGGED);
+	}
+
+	/* configure CPU port */
+	esw_vlan_pvid_set(LAN_PORT_CPU, 1, 0);
+	esw_port_accept_set(LAN_PORT_CPU, PORT_ACCEPT_FRAMES_ALL);
+#if defined (CONFIG_RALINK_MT7620) && !defined (MT7530_P5_ENABLED)
+	port_untag &= ~(MASK_LAN_PORT_CPU);
+	esw_port_attrib_set(LAN_PORT_CPU, PORT_ATTRIBUTE_USER);
+#else
+	esw_port_attrib_set(LAN_PORT_CPU, PORT_ATTRIBUTE_TRANSPARENT);
+#endif
+
+	esw_port_ingress_mode_set(LAN_PORT_CPU, PVLAN_INGRESS_MODE_SECURITY);
+
+	/* reset VLAN table */
+	esw_vlan_reset_table();
+
+	/* set all ports to VLAN 1 member (no SVID, no SWAP) */
+	esw_vlan_set(1, 0, port_member, port_untag, 0, 1);
+
+}
+
+static void esw_mask_bridge_isolate(u32 wan_bridge_mode, u32 wan_bwan_isolation)
+{
+	u32 i;
+	u32 fwd_mask_bwan_lan;
+	u32 fwd_mask_lan, fwd_mask_wan, fwd_mask;
+
+	fwd_mask_lan = get_ports_mask_lan(1, 0);
+
+	/* LAN forward mask */
+	for (i = 0; i <= ESW_PORT_ID_MAX; i++) {
+		if ((fwd_mask_lan >> i) & 0x1) {
+			fwd_mask = fwd_mask_lan;
+			/* set all port ingress to security mode (VLAN + fwd_mask) */
+			esw_port_matrix_set(i, fwd_mask, PVLAN_INGRESS_MODE_SECURITY);
+		}
+	}
+
+	/* clear forward mask for P5 */
+#if (MASK_WAN_PORT_CPU == 0)
+	esw_port_matrix_set(5, 0, PVLAN_INGRESS_MODE_SECURITY);
+#endif
+
+	/* clear forward mask for P4/P0 */
+#if (MASK_WAN_PORT_X == 0 && WAN_PORT_X < 5)
+	esw_port_matrix_set(WAN_PORT_X, 0, PVLAN_INGRESS_MODE_SECURITY);
+#endif
+
+	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE_WAN)
+		return;
+
+	fwd_mask_wan = get_ports_mask_wan(1, 0);
+	fwd_mask_bwan_lan = fwd_mask_wan & ~(MASK_WAN_PORT_X|MASK_WAN_PORT_CPU);
+
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+	if (wan_bridge_mode != SWAPI_WAN_BRIDGE_DISABLE)
+		fwd_mask_wan |= MASK_LAN_PORT_CPU;
+#endif
+
+	/* WAN forward mask */
+	for (i = 0; i <= ESW_PORT_ID_MAX; i++) {
+		if ((fwd_mask_wan >> i) & 0x1) {
+			fwd_mask = fwd_mask_wan;
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+			/* force add all LAN ports to forward from CPU */
+			if (i == LAN_PORT_CPU)
+				fwd_mask |= MASK_LAN_PORTS_ALL;
+#else
+#if !defined (MT7530_P6_UNTAGGED)
+			/* force add all LAN ports to forward from CPU */
+			if (i == WAN_PORT_CPU)
+				fwd_mask |= MASK_LAN_PORTS_ALL;
+#endif
+			if (wan_bwan_isolation == SWAPI_WAN_BWAN_ISOLATION_FROM_CPU) {
+				if (i == WAN_PORT_CPU)
+					fwd_mask &= ~fwd_mask_bwan_lan;
+				else if ((1u << i) & MASK_LAN_PORTS_ALL)
+					fwd_mask &= ~MASK_WAN_PORT_CPU;
+			} else
+#endif
+			if (wan_bwan_isolation == SWAPI_WAN_BWAN_ISOLATION_BETWEEN) {
+				if (i <= ESW_EPHY_ID_MAX) {
+					fwd_mask &= ~(MASK_WAN_PORT_X|MASK_LAN_PORTS_ALL);
+					fwd_mask |= (1u << i);
+				}
+			}
+			
+			/* set all port ingress to security mode (VLAN + fwd_mask) */
+			esw_port_matrix_set(i, fwd_mask, PVLAN_INGRESS_MODE_SECURITY);
+		}
+	}
+}
+
+static void esw_vlan_bridge_isolate(u32 wan_bridge_mode, u32 wan_bwan_isolation, int bridge_changed, int br_iso_changed, int vlan_rule_changed)
+{
+	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE_WAN) {
+		if (!bridge_changed)
+			return;
+		
+		esw_vlan_init_vid1();
+	} else {
+		if (!bridge_changed && !br_iso_changed && !vlan_rule_changed)
+			return;
+		
+		esw_vlan_apply_rules(wan_bridge_mode, wan_bwan_isolation);
+	}
+
+	if (bridge_changed) {
+#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
+		esw_igmp_ports_config(wan_bridge_mode);
+		if (g_igmp_snooping_enabled)
+			esw_igmp_mld_snooping(1, 1);
+#endif
+		esw_show_bridge_partitions(wan_bridge_mode);
+	}
+
+	esw_mac_table_clear();
+}
+
+static void esw_mac_to_phy_enable(void)
+{
+	u32 i, mac_mask, reg_pmcr;
+
+	/* full AN */
+	reg_pmcr = 0x00056330;
+
+	mac_mask = MASK_WAN_PORT_X | MASK_LAN_PORTS_ALL;
+
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if ((mac_mask >> i) & 0x1)
+			esw_reg_set(REG_ESW_MAC_PMCR_P0 + 0x100*i, reg_pmcr);
+	}
+}
+
+static int esw_port_phy_power(u32 phy_port_id, u32 power_on, int is_force)
+{
+	u32 esw_phy_mcr = 0x3100;
+	u32 phy_mdio_addr = phy_port_id;
+	u32 i_port_speed, is_power_on;
+
+	if (phy_port_id > ESW_EPHY_ID_MAX)
+		return 0;
+
+	/* external GigaPHY */
+#if defined (CONFIG_P4_MAC_TO_PHY_MODE)
+	if (phy_port_id == 4)
+		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2;
+#endif
+#if defined (CONFIG_P5_MAC_TO_PHY_MODE)
+	if (phy_port_id == 5)
+		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR;
+#elif defined (CONFIG_GE2_RGMII_AN)
+	if (phy_port_id == 5)
+		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2;
+#endif
+
+	i_port_speed = (g_port_link_mode[phy_port_id] & 0x0F);
+	if (i_port_speed == SWAPI_LINK_SPEED_MODE_FORCE_POWER_OFF)
+		power_on = 0;
+
+	is_power_on = 0;
+	if (mii_mgr_read(phy_mdio_addr, 0, &esw_phy_mcr)) {
+		is_power_on = (esw_phy_mcr & (1<<11)) ? 0 : 1;
+		esw_phy_mcr &= ~((1<<11)|(1<<9));
+		
+		/* fix PHY init after buggy Uboot 4.3.0.0 */
+		if (i_port_speed < SWAPI_LINK_SPEED_MODE_FORCE_100_FD)
+			esw_phy_mcr |= (1<<12);
+		
+		if (power_on)
+			esw_phy_mcr |= (1<<9);
+		else
+			esw_phy_mcr |= (1<<11);
+		
+		if (is_force || (is_power_on ^ power_on))
+			mii_mgr_write(phy_mdio_addr, 0, esw_phy_mcr);
+	}
+
+	g_port_phy_power[phy_port_id] = (power_on) ? 1 : 0;
+
+	/* return 1 when PHY power is changed */
+	return (is_power_on ^ power_on) ? 1 : 0;
+}
+
+static void esw_storm_control(u32 port_id, int set_bcast, int set_mcast, int set_ucast, u32 rate_mbps)
+{
+	u32 reg_bsr = 0;
+	u32 rate_unit_1000;
+	u32 rate_unit_100;
+	u32 rate_unit_10;
+
+	if (rate_mbps > 0) {
+		if (rate_mbps > (0xff * 4))
+			rate_mbps = (0xff * 4);
+		
+		rate_unit_1000 = rate_mbps;
+		rate_unit_100 = (rate_mbps < 90) ? rate_mbps : 90;
+		rate_unit_10 = (rate_mbps < 9) ? rate_mbps : 9;
+		
+		reg_bsr |= BIT(31);			// STRM_MODE = Rate-based
+		if (set_bcast)
+			reg_bsr |= BIT(30);		// STRM_BC_INC
+		if (set_mcast)
+			reg_bsr |= BIT(29);		// STRM_MC_INC
+		if (set_ucast)
+			reg_bsr |= BIT(28);		// STRM_UC_INC
+		
+		if (rate_mbps > 0xff) {
+			rate_unit_1000 >>= 2;
+			rate_unit_100 >>= 2;
+			rate_unit_10 >>= 2;
+			reg_bsr |= (3u << 24);		// STRM_UNIT = 4 Mbps
+		} else {
+			reg_bsr |= (2u << 24);		// STRM_UNIT = 1 Mbps
+		}
+		
+		reg_bsr |= (rate_unit_1000 << 16);	// STORM_1G
+		reg_bsr |= (rate_unit_100 << 8);	// STORM_100M
+		reg_bsr |= (rate_unit_10);		// STORM_10M
+	}
+
+	esw_reg_set(REG_ESW_PORT_BSR_P0 + 0x100*port_id, reg_bsr);
+}
+
+static void esw_jumbo_control(u32 jumbo_frames_enabled)
+{
+	u32 reg_gmaccr;
+
+	reg_gmaccr = esw_reg_get(REG_ESW_MAC_GMACCR);
+	reg_gmaccr &= ~(0x3f);
+	reg_gmaccr |= (9u << 2);		// MAX_RX_JUMBO = 9 KB
+
+	if (jumbo_frames_enabled) {
+		reg_gmaccr |= 0x3;		// MAX_RX_JUMBO
+	} else {
+		reg_gmaccr |= 0x1;		// 1536 bytes
+	}
+
+	esw_reg_set(REG_ESW_MAC_GMACCR, reg_gmaccr);
+}
+
+
+
+static void esw_led_mode(u32 led_mode)
+{
+	u32 reg_ledc;
+
+	reg_ledc = esw_reg_get(0x7d00);
+	reg_ledc |= 0x77777;
+
+	if (led_mode == SWAPI_LED_OFF)
+		reg_ledc &= ~(0x77777);
+
+	esw_reg_set(0x7d00, reg_ledc);
+}
+
+static u32 esw_status_link_port(u32 port_id)
+{
+	u32 reg_pmsr;
+
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+	if (port_id == WAN_PORT_X)
+		reg_pmsr = sysRegRead(REG_ETH_GE2_MAC_STATUS);	// read state from GE2
+	else
+#elif defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
+	if (port_id == WAN_PORT_X)
+		reg_pmsr = sysRegRead(RALINK_ETH_SW_BASE+REG_ESW_MAC_PMSR_P0 + 0x100*4);	// read state from P4
+	else
+#endif
+		reg_pmsr = esw_reg_get(REG_ESW_MAC_PMSR_P0 + 0x100*port_id);
+
+	return (reg_pmsr & 0x1);
+}
+
+static u32 esw_status_speed_port_uapi(u32 port_id_uapi)
+{
+	u32 port_link, port_duplex, port_speed;
+	u32 port_eee, port_fc_rx, port_fc_tx;
+	u32 reg_pmsr;
+	u32 port_id = get_port_from_uapi(port_id_uapi);
+
+	if (port_id > ESW_EPHY_ID_MAX)
+		return 0;
+
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+	if (port_id == WAN_PORT_X) {
+		reg_pmsr = sysRegRead(REG_ETH_GE2_MAC_STATUS);	// read state from GE2
+#if defined (CONFIG_GE2_RGMII_AN)
+		reg_pmsr |= ext_gphy_fill_pmsr(CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2);
+#endif
+	} else
+#elif defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
+	if (port_id == WAN_PORT_X)
+		reg_pmsr = sysRegRead(RALINK_ETH_SW_BASE+REG_ESW_MAC_PMSR_P0 + 0x100*4);	// read state from P4
+	else
+#endif
+		reg_pmsr = esw_reg_get(REG_ESW_MAC_PMSR_P0 + 0x100*port_id);
+
+	port_link = (reg_pmsr & 0x1);
+
+	if (!port_link)
+		return 0;
+
+	port_duplex = (reg_pmsr >> 1) & 0x1;
+	port_speed  = (reg_pmsr >> 2) & 0x3;
+	port_fc_tx  = (reg_pmsr >> 4) & 0x1;
+	port_fc_rx  = (reg_pmsr >> 5) & 0x1;
+	port_eee    = (reg_pmsr >> 6) & 0x3;
+
+	return ((port_link << 16) | (port_eee << 11) | (port_fc_rx << 10) | (port_fc_tx << 9) | (port_duplex << 8) | port_speed);
+}
+
+static u32 esw_status_link_port_uapi(u32 port_id_uapi)
+{
+	u32 port_id = get_port_from_uapi(port_id_uapi);
+
+	if (port_id > ESW_EPHY_ID_MAX)
+		return 0;
+
+	return esw_status_link_port(port_id);
+}
+
+static u32 esw_status_link_ports(int is_wan_ports)
+{
+	int i;
+	u32 port_link = 0;
+	u32 portmask;
+
+	if (is_wan_ports)
+		portmask = get_ports_mask_wan(0, 1);
+	else
+		portmask = get_ports_mask_lan(0, 1);
+
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if ((portmask >> i) & 0x1) {
+			port_link = esw_status_link_port(i);
+			if (port_link)
+				break;
+		}
+	}
+
+	return port_link;
+}
+
+static u32 esw_status_link_changed(void)
+{
+	return atomic_cmpxchg(&g_port_link_changed, 1, 0);
+}
+
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+extern int VirtualIF_get_bytes(port_bytes_t *pb);
+#endif
+
+static int esw_status_mib_port_uapi(u32 port_id_uapi, esw_mib_counters_t *mibc)
+{
+	ULARGE_INTEGER rx_goct, tx_goct;
+	u32 port_id = get_port_from_uapi(port_id_uapi);
+
+	if (port_id > ESW_PORT_ID_MAX)
+		return -EINVAL;
+
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+	if (port_id == WAN_PORT_X || port_id == WAN_PORT_CPU) {
+		port_bytes_t pb;
+		memset(mibc, 0, sizeof(esw_mib_counters_t));
+		if (VirtualIF_get_bytes(&pb) == 0) {
+			mibc->TxGoodOctets = pb.TX;
+			mibc->RxGoodOctets = pb.RX;
+		}
+		return 0;
+	}
+#endif
+
+	rx_goct.u.LowPart = esw_get_port_mib_rgoc(port_id, &rx_goct.u.HighPart);
+	tx_goct.u.LowPart = esw_get_port_mib_tgoc(port_id, &tx_goct.u.HighPart);
+
+	mibc->TxGoodOctets	= tx_goct.QuadPart;
+	mibc->RxGoodOctets	= rx_goct.QuadPart;
+
+	mibc->TxDropFrames	= esw_reg_get(0x4000 + 0x100*port_id);
+	mibc->TxCRCError	= esw_reg_get(0x4004 + 0x100*port_id);
+	mibc->TxUcastFrames	= esw_reg_get(0x4008 + 0x100*port_id);
+	mibc->TxMcastFrames	= esw_reg_get(0x400c + 0x100*port_id);
+	mibc->TxBcastFrames	= esw_reg_get(0x4010 + 0x100*port_id);
+	mibc->TxCollision	= esw_reg_get(0x4014 + 0x100*port_id);
+	mibc->TxPauseFrames	= esw_reg_get(0x402c + 0x100*port_id);
+
+	mibc->RxDropFrames	= esw_reg_get(0x4060 + 0x100*port_id);
+	mibc->RxFilterFrames	= esw_reg_get(0x4064 + 0x100*port_id);
+	mibc->RxUcastFrames	= esw_reg_get(0x4068 + 0x100*port_id);
+	mibc->RxMcastFrames	= esw_reg_get(0x406c + 0x100*port_id);
+	mibc->RxBcastFrames	= esw_reg_get(0x4070 + 0x100*port_id);
+	mibc->RxAligmentError	= esw_reg_get(0x4074 + 0x100*port_id);
+	mibc->RxCRCError	= esw_reg_get(0x4078 + 0x100*port_id);
+//	mibc->RxUndersizeError	= esw_reg_get(0x407c + 0x100*port_id);
+//	mibc->RxFragmentError	= esw_reg_get(0x4080 + 0x100*port_id);
+//	mibc->RxOversizeError	= esw_reg_get(0x4084 + 0x100*port_id);
+//	mibc->RxJabberError	= esw_reg_get(0x4088 + 0x100*port_id);
+	mibc->RxPauseFrames	= esw_reg_get(0x408c + 0x100*port_id);
+	return 0;
+}
+
+static int esw_status_bytes_port_uapi(u32 port_id_uapi, port_bytes_t *pb)
+{
+	ULARGE_INTEGER rx_goct, tx_goct;
+	u32 port_id = get_port_from_uapi(port_id_uapi);
+
+	if (port_id > ESW_PORT_ID_MAX)
+		return -EINVAL;
+
+#if defined (RAETH_GE2_MAC_TO_GPHY)
+	if (port_id == WAN_PORT_X || port_id == WAN_PORT_CPU)
+		return VirtualIF_get_bytes(pb);
+#endif
+
+	rx_goct.u.LowPart = esw_get_port_mib_rgoc(port_id, &rx_goct.u.HighPart);
+	tx_goct.u.LowPart = esw_get_port_mib_tgoc(port_id, &tx_goct.u.HighPart);
+
+	pb->RX = rx_goct.QuadPart;
+	pb->TX = tx_goct.QuadPart;
+
+	return 0;
+}
+
+static void change_ports_power(u32 power_on, u32 ports_mask)
+{
+	u32 i;
+
+	ports_mask = get_ports_mask_from_uapi(ports_mask, 1);
+
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if ((ports_mask >> i) & 0x1)
+			esw_port_phy_power(i, power_on, 0);
+	}
+}
+
+static int change_wan_lan_ports_power(u32 power_on, u32 is_wan)
+{
+	int power_changed = 0;
+	u32 i, ports_mask;
+
+	if (is_wan)
+		ports_mask = get_ports_mask_wan(0, 1);
+	else
+		ports_mask = get_ports_mask_lan(0, 1);
+
+	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+		if ((ports_mask >> i) & 0x1)
+			power_changed |= esw_port_phy_power(i, power_on, 0);
+	}
+
+	return power_changed;
+}
+
+static int change_bridge_mode(u32 wan_bwan_isolation, u32 wan_bridge_mode)
+{
+	int i, bridge_changed, br_iso_changed, vlan_rule_changed, power_changed;
+
+	if (wan_bridge_mode > SWAPI_WAN_BRIDGE_DISABLE_WAN)
+		return -EINVAL;
+
+	if (wan_bwan_isolation > SWAPI_WAN_BWAN_ISOLATION_BETWEEN)
+		return -EINVAL;
+
+	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE)
+		wan_bwan_isolation = SWAPI_WAN_BWAN_ISOLATION_NONE;
+
+	bridge_changed = (g_wan_bridge_mode != wan_bridge_mode) ? 1 : 0;
+	br_iso_changed = (g_wan_bwan_isolation != wan_bwan_isolation) ? 1 : 0;
+	vlan_rule_changed = 0;
+	for (i = 0; i <= SWAPI_VLAN_RULE_WAN_LAN4; i++) {
+		if (g_vlan_rule[i] != g_vlan_rule_user[i]) {
+			vlan_rule_changed = 1;
+			break;
+		}
+	}
+
+	// set global bridge_mode first
+	g_wan_bridge_mode = wan_bridge_mode;
+	g_wan_bwan_isolation = wan_bwan_isolation;
+
+	if (atomic_read(&g_switch_inited) == 0)
+		return 0;
+
+	power_changed = 0;
+	if (bridge_changed || vlan_rule_changed) {
+		power_changed = change_wan_lan_ports_power(0, 1);
+		if (power_changed) {
+			// wait for PHY link down
+			msleep(500);
+		}
+	}
+
+	if (bridge_changed || br_iso_changed)
+		esw_mask_bridge_isolate(wan_bridge_mode, wan_bwan_isolation);
+
+	esw_vlan_bridge_isolate(wan_bridge_mode, wan_bwan_isolation, bridge_changed, br_iso_changed, vlan_rule_changed);
+
+	if (power_changed)
+		change_wan_lan_ports_power(1, 1);
+
+	return 0;
+}
+
+static void vlan_accept_port_mode(u32 accept_mode, u32 port_mask)
+{
+	u32 i, admit_frames = PORT_ACCEPT_FRAMES_ALL;
+
+	switch (accept_mode)
+	{
+	case SWAPI_VLAN_ACCEPT_FRAMES_UNTAG_ONLY:
+		admit_frames = PORT_ACCEPT_FRAMES_UNTAGGED;
+		break;
+	case SWAPI_VLAN_ACCEPT_FRAMES_TAG_ONLY:
+		admit_frames = PORT_ACCEPT_FRAMES_TAGGED;
+		break;
+	}
+
+	port_mask = get_ports_mask_from_uapi(port_mask, 0);
+
+	for (i = 0; i <= ESW_PORT_ID_MAX; i++) {
+		if ((port_mask >> i) & 0x1)
+			esw_port_accept_set(i, admit_frames);
+	}
+}
+
+static void vlan_create_entry(u32 vlan4k_info, u32 vlan4k_mask, int set_port_vid)
+{
+	u32 i, cvid, prio, fid;
+	u32 mask_member, mask_untag;
+
+	cvid = (vlan4k_info & 0x0FFF);
+	prio = ((vlan4k_info >> 12) & 0x7);
+	fid  = ((vlan4k_info >> 16) & 0xFF);
+	mask_member = get_ports_mask_from_uapi((vlan4k_mask & 0xFFFF), 0);
+	mask_untag  = get_ports_mask_from_uapi((vlan4k_mask >> 16) & 0xFFFF, 0);
+#if defined (ESW_PORT_PPE)
+	if (mask_member & (1u << ESW_PORT_CPU))
+		mask_member |= (1u << ESW_PORT_PPE);
+#endif
+	if (cvid < 1)
+		cvid = 1;
+
+	/* set vlan table */
+	esw_vlan_set(cvid, 0, mask_member, mask_untag, 0, fid);
+
+	/* set ports attrib */
+	for (i = 0; i <= ESW_PORT_ID_MAX; i++) {
+		if ((1u << i) & mask_member) {
+			if (!((1u << i) & mask_untag)) {
+				esw_port_attrib_set(i, PORT_ATTRIBUTE_USER);
+			} else {
+				if (set_port_vid)
+					esw_vlan_pvid_set(i, cvid, prio);
+				esw_port_attrib_set(i, PORT_ATTRIBUTE_TRANSPARENT);
+			}
+		}
+	}
+
+	printk("%s - create vlan %s: vid=[%d], prio=[%d], member=[0x%02X], untag=[0x%02X], fid=[%d]\n",
+			MTK_ESW_DEVNAME, (set_port_vid) ? "ports" : "entry", cvid, prio, mask_member, mask_untag, fid);
+}
+
+static int change_port_link_mode_uapi(u32 port_id_uapi, u32 port_link_mode)
+{
+	const char *link_desc = "Auto", *flow_desc = "ON";
+	u32 i_port_speed, i_port_flowc, i_port_power;
+	u32 esw_phy_ana = 0x05e1;
+	u32 esw_phy_mcr = 0x3100; /* 100 FD + auto-negotiation */
+	u32 phy_mdio_addr;
+	u32 port_id = get_port_from_uapi(port_id_uapi);
+
+	if (port_id > ESW_EPHY_ID_MAX)
+		return -EINVAL;
+
+	if (g_port_link_mode[port_id] == port_link_mode)
+		return 0;
+
+	phy_mdio_addr = port_id;
+
+	i_port_speed =  (port_link_mode & 0x0F);
+	i_port_flowc = ((port_link_mode >> 8) & 0x03);
+	i_port_power = (i_port_speed == SWAPI_LINK_SPEED_MODE_FORCE_POWER_OFF) ? 0 : 1;
+
+	if (!i_port_power)
+		i_port_speed = SWAPI_LINK_SPEED_MODE_AUTO;
+
+	switch (i_port_speed)
+	{
+	case SWAPI_LINK_SPEED_MODE_AUTO_100_FD:
+		link_desc = "100FD [AN]";
+		/* disable ability 100 HD, 10 FD, 10 HD */
+		esw_phy_ana &= ~((1<<7)|(1<<6)|(1<<5));
+		break;
+	case SWAPI_LINK_SPEED_MODE_AUTO_100_HD:
+		link_desc = "100HD [AN]";
+		/* disable ability 100 FD, 10 FD, 10 HD */
+		esw_phy_ana &= ~((1<<8)|(1<<6)|(1<<5));
+		/* disable FD */
+		esw_phy_mcr &= ~((1<<8));
+		break;
+	case SWAPI_LINK_SPEED_MODE_AUTO_10_FD:
+		link_desc = "10FD [AN]";
+		/* disable ability 100 FD, 100 HD, 10 HD */
+		esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<5));
+		/* set 10Mbps */
+		esw_phy_mcr &= ~((1<<13));
+		break;
+	case SWAPI_LINK_SPEED_MODE_AUTO_10_HD:
+		link_desc = "10HD [AN]";
+		/* disable ability 100 FD, 100 HD, 10 FD */
+		esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<6));
+		/* set 10Mbps, disable FD */
+		esw_phy_mcr &= ~((1<<13)|(1<<8));
+		break;
+	case SWAPI_LINK_SPEED_MODE_FORCE_100_FD:
+		link_desc = "100FD [Force]";
+		/* disable ability 100 HD, 10 FD, 10 HD */
+		esw_phy_ana &= ~((1<<7)|(1<<6)|(1<<5));
+		/* disable auto-negotiation */
+		esw_phy_mcr &= ~((1<<12));
+		break;
+	case SWAPI_LINK_SPEED_MODE_FORCE_100_HD:
+		link_desc = "100HD [Force]";
+		/* disable ability 100 FD, 10 FD, 10 HD */
+		esw_phy_ana &= ~((1<<8)|(1<<6)|(1<<5));
+		/* disable auto-negotiation, disable FD */
+		esw_phy_mcr &= ~((1<<12)|(1<<8));
+		break;
+	case SWAPI_LINK_SPEED_MODE_FORCE_10_FD:
+		link_desc = "10FD [Force]";
+		/* disable ability 100 FD, 100 HD, 10 HD */
+		esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<5));
+		/* disable auto-negotiation, set 10Mbps */
+		esw_phy_mcr &= ~((1<<13)|(1<<12));
+		break;
+	case SWAPI_LINK_SPEED_MODE_FORCE_10_HD:
+		link_desc = "10HD [Force]";
+		/* disable ability 100 FD, 100 HD, 10 FD */
+		esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<6));
+		/* disable auto-negotiation, set 10Mbps, disable FD */
+		esw_phy_mcr &= ~((1<<13)|(1<<12)|(1<<8));
+		break;
+	}
+
+	switch (i_port_flowc)
+	{
+	case SWAPI_LINK_FLOW_CONTROL_TX_ASYNC:
+	case SWAPI_LINK_FLOW_CONTROL_DISABLE:
+		flow_desc = "OFF";
+		/* disable pause ability (A6,A5) */
+		esw_phy_ana &= ~((1<<11)|(1<<10));
+		break;
+	}
+
+	/* external GigaPHY */
+#if defined (CONFIG_P4_MAC_TO_PHY_MODE)
+	if (port_id == 4)
+		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2;
+#endif
+#if defined (CONFIG_P5_MAC_TO_PHY_MODE)
+	if (port_id == 5)
+		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR;
+#elif defined (CONFIG_GE2_RGMII_AN)
+	if (port_id == 5)
+		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2;
+#endif
+
+	/* MT7621/MT7530 GSW or external GigaPHY */
+#if 1
+	{
+		u32 esw_phy_gcr = 0;
+		
+		/* set MII control register [6,13] */
+		if (i_port_speed <= SWAPI_LINK_SPEED_MODE_AUTO_1000_FD) {
+			/* set 1000 Mbps */
+			esw_phy_mcr &= ~(1<<13);
+			esw_phy_mcr |=  (1<<6);
+		}
+		
+		/* set auto-negotiation advertisement register [5,6,7,8] */
+		if (i_port_speed == SWAPI_LINK_SPEED_MODE_AUTO_1000_FD) {
+			/* disable ability 100 FD, 100 HD, 10 FD, 10 HD */
+			esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<6)|(1<<5));
+			link_desc = "1000FD [AN]";
+		}
+		
+		/* set auto-negotiation advertisement register [11] */
+		if (i_port_speed <= SWAPI_LINK_SPEED_MODE_AUTO_1000_FD &&
+		    i_port_flowc == SWAPI_LINK_FLOW_CONTROL_TX_ASYNC) {
+			/* enable asymmetric pause ability (A6) */
+			esw_phy_ana |= (1<<11);
+			flow_desc = "TX Asy";
+		}
+		
+		/* set 1000Base-T control register [8,9] */
+		mii_mgr_read(phy_mdio_addr, 9, &esw_phy_gcr);
+		if (i_port_speed <= SWAPI_LINK_SPEED_MODE_AUTO_1000_FD) {
+			/* enable 1000Base-T Advertisement */
+			esw_phy_gcr |=  ((1<<9)|(1<<8));
+		} else {
+			/* disable 1000Base-T Advertisement */
+			esw_phy_gcr &= ~((1<<9)|(1<<8));
+		}
+		mii_mgr_write(phy_mdio_addr, 9, esw_phy_gcr);
+	}
+#endif
+
+	/* set PHY ability */
+	mii_mgr_write(phy_mdio_addr, 4, esw_phy_ana);
+
+	if (i_port_power) {
+		if (!(esw_phy_mcr & (1<<12))) {
+			/* power-down PHY */
+			esw_phy_mcr |= (1<<11);
+			
+			/* set PHY mode */
+			mii_mgr_write(phy_mdio_addr, 0, esw_phy_mcr);
+			
+			/* wait for PHY down */
+			msleep(500);
+			
+			/* power-up PHY */
+			esw_phy_mcr &= ~(1<<11);
+		} else {
+			/* restart PHY auto-negotiation */
+			esw_phy_mcr |= (1<<9);
+		}
+	} else {
+		/* power-down PHY */
+		esw_phy_mcr |= (1<<11);
+	}
+
+	/* set PHY mode */
+	mii_mgr_write(phy_mdio_addr, 0, esw_phy_mcr);
+
+	g_port_link_mode[port_id] = port_link_mode;
+
+	if (!i_port_power) {
+		link_desc = "Power OFF";
+		flow_desc = "N/A";
+	}
+
+	printk("%s - %s link speed: %s, flow control: %s\n",
+		MTK_ESW_DEVNAME, get_port_desc(port_id), link_desc, flow_desc);
+
+	return 0;
+}
+
+static void change_storm_control_broadcast(u32 control_rate_mbps)
+{
+	u32 i;
+	char rate_desc[16];
+
+	if (control_rate_mbps >= 1024)
+		control_rate_mbps = 0;
+
+	if (g_storm_rate_limit != control_rate_mbps) {
+		g_storm_rate_limit = control_rate_mbps;
+		
+		if (control_rate_mbps > 0)
+			snprintf(rate_desc, sizeof(rate_desc), "%d mbps", control_rate_mbps);
+		else
+			strcpy(rate_desc, "off");
+		
+		printk("%s - set broadcast storm control rate as: %s\n", MTK_ESW_DEVNAME, rate_desc);
+		
+		for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
+			if ((1u << i) & ESW_MASK_EXCLUDE)
+				continue;
+			esw_storm_control(i, 1, 0, 0, control_rate_mbps);
+		}
+	}
+}
+
+static void change_jumbo_frames_accept(u32 jumbo_frames_enabled)
+{
+	if (jumbo_frames_enabled)
+		jumbo_frames_enabled = 1;
+
+	if (g_jumbo_frames_enabled != jumbo_frames_enabled) {
+		g_jumbo_frames_enabled = jumbo_frames_enabled;
+		printk("%s - jumbo frames accept: %d bytes\n", MTK_ESW_DEVNAME, (jumbo_frames_enabled) ? 9000 : 1536);
+		
+		esw_jumbo_control(jumbo_frames_enabled);
+	}
+}
+
+
+static void change_igmp_static_ports(u32 ports_mask)
+{
+	ports_mask = get_ports_mask_from_uapi(ports_mask, 0);
+
+#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
+	if (g_igmp_static_ports != ports_mask) {
+		g_igmp_static_ports = ports_mask;
+		
+		if (g_igmp_snooping_enabled) {
+			esw_igmp_ports_config(g_wan_bridge_mode);
+			esw_igmp_flood_to_cpu( (!ports_mask) ? 1 : 0 );
+			esw_igmp_mld_snooping(1, 1);
+		}
+	}
+#endif
+}
+
+static void change_igmp_snooping_control(u32 igmp_snooping_enabled)
+{
+#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
+	if (igmp_snooping_enabled)
+		igmp_snooping_enabled = 1;
+
+	if (g_igmp_snooping_enabled != igmp_snooping_enabled) {
+		g_igmp_snooping_enabled = igmp_snooping_enabled;
+		printk("%s - hardware IGMP/MLD snooping: %s\n", MTK_ESW_DEVNAME, (igmp_snooping_enabled) ? "on" : "off");
+		
+		esw_igmp_ports_config(g_wan_bridge_mode);
+		esw_igmp_flood_to_cpu( (igmp_snooping_enabled && !g_igmp_static_ports) ? 1 : 0 );
+		esw_igmp_mld_snooping(igmp_snooping_enabled, igmp_snooping_enabled);
+	}
+#endif
+}
+
+static void change_led_mode(u32 led_mode)
+{
+	if (led_mode != SWAPI_LED_OFF)
+		led_mode = SWAPI_LED_LINK_ACT;
+
+	if (g_led_phy_mode != led_mode) {
+		g_led_phy_mode = led_mode;
+		esw_led_mode(led_mode);
+	}
+}
+
+static int change_vlan_rule(u32 vlan_rule_id, u32 vlan_rule)
+{
+	if (vlan_rule_id > SWAPI_VLAN_RULE_WAN_LAN4)
+		return -EINVAL;
+
+	if ((vlan_rule & 0xFFFF) > 4094)
+		return -EINVAL;
+
+	if (((vlan_rule >> 16) & 0xFF) > 7)
+		return -EINVAL;
+
+	g_vlan_rule_user[vlan_rule_id] = vlan_rule;
+
+	return 0;
+}
+
+static void esw_link_status_changed_state(u32 port_id, int port_link)
+{
+	const char *port_state;
+	u32 wan_ports_mask;
+
+	if (port_id <= ESW_EPHY_ID_MAX)
+		atomic_set(&g_port_link_changed, 1);
+
+	/* only printk wan link change */
+	wan_ports_mask = get_ports_mask_wan(0, 1);
+
+	if (!(wan_ports_mask & (1u << port_id)))
+		return;
+
+	port_state = (port_link) ? "Up" : "Down";
+
+	printk("%s: Link Status Changed - Port %s Link %s\n",
+		MTK_ESW_DEVNAME, get_port_desc(port_id), port_state);
+}
+
+int esw_ioctl_init_post(void)
+{
+	/* configure bridge isolation mode via forwards mask */
+	esw_mask_bridge_isolate(g_wan_bridge_mode, g_wan_bwan_isolation);
+
+	/* enable MAC for all PHY ports */
+	esw_mac_to_phy_enable();
+
+	/* configure bridge isolation mode via VLAN */
+	esw_vlan_bridge_isolate(g_wan_bridge_mode, g_wan_bwan_isolation, 1, 1, 1);
+
+#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
+	/* configure igmp/mld snooping */
+	esw_igmp_flood_to_cpu( (g_igmp_snooping_enabled && !g_igmp_static_ports) ? 1 : 0 );
+	esw_igmp_mld_snooping(g_igmp_snooping_enabled, g_igmp_snooping_enabled);
+#endif
+
+	/* configure leds */
+	esw_led_mode(g_led_phy_mode);
+
+	atomic_set(&g_switch_inited, 1);
+	atomic_set(&g_switch_allow_irq, 1);
+
+	return 0;
+}
+
+#if defined (CONFIG_RA_HW_NAT) || defined (CONFIG_RA_HW_NAT_MODULE)
+#if !defined (CONFIG_RAETH_BOTH_GMAC)
+int esw_get_traffic_port_wan(struct rtnl_link_stats64 *stats)
+{
+	ULARGE_INTEGER rx_goct, tx_goct;
+
+	rx_goct.u.LowPart = esw_get_port_mib_rgoc(WAN_PORT_X, &rx_goct.u.HighPart);
+	tx_goct.u.LowPart = esw_get_port_mib_tgoc(WAN_PORT_X, &tx_goct.u.HighPart);
+
+	stats->rx_packets = esw_get_port_mib_rgpc(WAN_PORT_X);
+	stats->tx_packets = esw_get_port_mib_tgpc(WAN_PORT_X);
+
+	stats->rx_bytes = rx_goct.QuadPart;
+	stats->tx_bytes = tx_goct.QuadPart;
+
+	return 0;
+}
+EXPORT_SYMBOL(esw_get_traffic_port_wan);
+#endif
+#endif
+
+////////////////////////////////////////////////////////////////////////////////////
+#include "ioctl.c"
+////////////////////////////////////////////////////////////////////////////////////
+
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.h
new file mode 100644
index 00000000..c76fc602
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.h
@@ -0,0 +1,236 @@
+/*
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
+ * MA 02111-1307 USA
+ *
+ */
+
+#ifndef __IOCTL_MT762X_H__
+#define __IOCTL_MT762X_H__
+
+#include "esw_common.h"
+////////////////////////////////////////////////////////////////////////////////////
+
+#define LAN_PORT_1			CONFIG_RAETH_ESW_PORT_LAN1
+#define LAN_PORT_2			CONFIG_RAETH_ESW_PORT_LAN2
+#define LAN_PORT_3			CONFIG_RAETH_ESW_PORT_LAN3
+#define LAN_PORT_4			CONFIG_RAETH_ESW_PORT_LAN4
+
+#define MASK_LAN_PORT_1			(1u << LAN_PORT_1)
+#define MASK_LAN_PORT_2			(1u << LAN_PORT_2)
+#define MASK_LAN_PORT_3			(1u << LAN_PORT_3)
+#define MASK_LAN_PORT_4			(1u << LAN_PORT_4)
+
+#if defined (CONFIG_RAETH_ESW_PORT_LAN5) && (CONFIG_RAETH_ESW_PORT_LAN5 >= 0)
+#define LAN_PORT_5			CONFIG_RAETH_ESW_PORT_LAN5
+#define MASK_LAN_PORT_5			(1u << LAN_PORT_5)
+#else
+#define MASK_LAN_PORT_5			0
+#endif
+
+#define MASK_LAN_PORTS_ALL		(MASK_LAN_PORT_1|MASK_LAN_PORT_2|MASK_LAN_PORT_3|MASK_LAN_PORT_4|MASK_LAN_PORT_5)
+
+#define ESW_PORT_CPU			6
+#define LAN_PORT_CPU			6
+#define MASK_LAN_PORT_CPU		(1u << LAN_PORT_CPU)
+
+#if defined (CONFIG_MT7530_GSW)
+#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
+#define WAN_PORT_X			CONFIG_RAETH_ESW_PORT_WAN
+#define WAN_PORT_CPU			5	/* P5 = CPU WAN */
+#define MASK_WAN_PORT_X			(1u << WAN_PORT_X)
+#define MASK_WAN_PORT_CPU		(1u << WAN_PORT_CPU)
+#define ESW_EPHY_ID_MAX			4
+#define ESW_MASK_EXCLUDE		0
+#elif defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_GE2_INTERNAL_GPHY_P0)
+#define WAN_PORT_X			0	/* P0 PHY */
+#define WAN_PORT_CPU			5	/* fake */
+#define MASK_WAN_PORT_X			0
+#define MASK_WAN_PORT_CPU		0
+#define ESW_EPHY_ID_MAX			4
+#define ESW_MASK_EXCLUDE		((1<<5)|(1<<0))	/* P5/P0 excluded */
+#elif defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4) || defined (CONFIG_GE2_INTERNAL_GPHY_P4)
+#define WAN_PORT_X			4	/* P4 PHY */
+#define WAN_PORT_CPU			5	/* fake */
+#define MASK_WAN_PORT_X			0
+#define MASK_WAN_PORT_CPU		0
+#define ESW_EPHY_ID_MAX			4
+#define ESW_MASK_EXCLUDE		((1<<5)|(1<<4))	/* P5/P4 excluded */
+#elif defined (CONFIG_GE2_RGMII_AN)
+#define WAN_PORT_X			5	/* External PHY */
+#define WAN_PORT_CPU			5	/* fake */
+#define MASK_WAN_PORT_X			0
+#define MASK_WAN_PORT_CPU		0
+#define ESW_EPHY_ID_MAX			5
+#define ESW_MASK_EXCLUDE		(1<<5)	/* P5 excluded */
+#else
+#define WAN_PORT_X			CONFIG_RAETH_ESW_PORT_WAN
+#define WAN_PORT_CPU			6	/* P6 = CPU LAN + WAN */
+#define MASK_WAN_PORT_X			(1u << WAN_PORT_X)
+#define MASK_WAN_PORT_CPU		(1u << WAN_PORT_CPU)
+#define ESW_EPHY_ID_MAX			4
+#define ESW_MASK_EXCLUDE		(1<<5)	/* P5 excluded */
+#endif
+#else /* !CONFIG_MT7530_GSW */
+#define WAN_PORT_X			CONFIG_RAETH_ESW_PORT_WAN
+#define WAN_PORT_CPU			6	/* P6 = CPU LAN + WAN */
+#define MASK_WAN_PORT_X			(1u << WAN_PORT_X)
+#define MASK_WAN_PORT_CPU		(1u << WAN_PORT_CPU)
+#if defined (CONFIG_P5_MAC_TO_PHY_MODE)
+#define ESW_EPHY_ID_MAX			5
+#define ESW_MASK_EXCLUDE		0
+#else
+#define ESW_EPHY_ID_MAX			4
+#define ESW_MASK_EXCLUDE		(1<<5)	/* P5 excluded */
+#endif
+#endif
+
+#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_GE2_INTERNAL_GPHY_P0) || \
+    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4) || defined (CONFIG_GE2_INTERNAL_GPHY_P4) || \
+    defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
+#define MT7530_P5_ENABLED
+#endif
+
+#if defined (MT7530_P5_ENABLED) || defined (CONFIG_RAETH_GMAC2)
+#define MT7530_P6_UNTAGGED
+#endif
+
+#if defined (CONFIG_GE2_INTERNAL_GPHY_P0) || defined (CONFIG_GE2_RGMII_AN) || \
+    defined (CONFIG_GE2_INTERNAL_GPHY_P4)
+#define RAETH_GE2_MAC_TO_GPHY
+#endif
+
+////////////////////////////////////////////////////////////////////////////////////
+
+#define ESW_DEFAULT_JUMBO_FRAMES	0
+#define ESW_DEFAULT_EEE_LPI		0
+#define ESW_DEFAULT_STORM_RATE		0
+#define ESW_DEFAULT_IGMP_SNOOPING	1
+
+////////////////////////////////////////////////////////////////////////////////////
+
+#define MIN_EXT_VLAN_VID		2
+#define ESW_USE_IVL_MODE		1	/* always use IVL (instead of SVL) */
+#define ESW_PRINT_LINK_ALL		0	/* printk only WAN link changed */
+
+////////////////////////////////////////////////////////////////////////////////////
+
+enum
+{
+	PVLAN_INGRESS_MODE_MATRIX   = 0x00,
+	PVLAN_INGRESS_MODE_FALLBACK = 0x01,
+	PVLAN_INGRESS_MODE_CHECK    = 0x02,
+	PVLAN_INGRESS_MODE_SECURITY = 0x03
+};
+
+enum
+{
+	PVLAN_EGRESS_UNTAG = 0x00,
+	PVLAN_EGRESS_SWAP  = 0x01,
+	PVLAN_EGRESS_TAG   = 0x02,
+	PVLAN_EGRESS_STACK = 0x03
+};
+
+enum
+{
+	PORT_ACCEPT_FRAMES_ALL      = 0x00,
+	PORT_ACCEPT_FRAMES_TAGGED   = 0x01,
+	PORT_ACCEPT_FRAMES_UNTAGGED = 0x02
+};
+
+enum
+{
+	PORT_ATTRIBUTE_USER         = 0x00,
+	PORT_ATTRIBUTE_STACK        = 0x01,
+	PORT_ATTRIBUTE_TRANSLATION  = 0x02,
+	PORT_ATTRIBUTE_TRANSPARENT  = 0x03
+};
+
+////////////////////////////////////////////////////////////////////////////////////
+
+typedef struct
+{
+	u8 bwan:1;
+	u8 rule:7;
+} bwan_member_t;
+
+typedef struct
+{
+	u16 pvid:12;
+	u16 prio:3;
+	u16 tagg:1;
+} pvlan_member_t;
+
+typedef struct
+{
+	u32 valid:1;
+	u32 fid:3;
+	u32 cvid:12;
+	u32 svid:12;
+	u32 unused1:4;
+	u32 port_member:8;
+	u32 port_untag:8;
+	u32 port_swap:8;
+	u32 unused2:8;
+} vlan_entry_t;
+
+////////////////////////////////////////////////////////////////////////////////////
+
+#if defined (CONFIG_MT7530_GSW)
+typedef struct esw_mib_counters_s
+{
+	uint64_t TxGoodOctets;
+	uint32_t TxUcastFrames;
+	uint32_t TxMcastFrames;
+	uint32_t TxBcastFrames;
+	uint32_t TxDropFrames;
+	uint32_t TxPauseFrames;
+	uint32_t TxCollision;
+	uint32_t TxCRCError;
+	uint64_t RxGoodOctets;
+	uint32_t RxUcastFrames;
+	uint32_t RxMcastFrames;
+	uint32_t RxBcastFrames;
+	uint32_t RxDropFrames;
+	uint32_t RxPauseFrames;
+	uint32_t RxFilterFrames;
+	uint32_t RxCRCError;
+	uint32_t RxAligmentError;
+} esw_mib_counters_t;
+#else
+typedef struct esw_mib_counters_s
+{
+	uint64_t TxGoodOctets;
+	uint32_t TxGoodFrames;
+	uint32_t TxBadOctets;
+	uint32_t TxBadFrames;
+	uint32_t TxDropFrames;
+	uint64_t RxGoodOctets;
+	uint32_t RxGoodFrames;
+	uint32_t RxBadOctets;
+	uint32_t RxBadFrames;
+	uint32_t RxDropFramesFilter;
+	uint32_t RxDropFramesErr;
+} esw_mib_counters_t;
+#endif
+
+////////////////////////////////////////////////////////////////////////////////////
+
+u32 get_ports_mask_lan(u32 include_cpu, int is_phy_id);
+void esw_igmp_flood_to_cpu(int flood_to_cpu);
+
+////////////////////////////////////////////////////////////////////////////////////
+
+#endif
+
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_eth_soc.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_eth_soc.h
new file mode 100644
index 00000000..336fc690
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_eth_soc.h
@@ -0,0 +1,883 @@
+/*   This program is free software; you can redistribute it and/or modify
+ *   it under the terms of the GNU General Public License as published by
+ *   the Free Software Foundation; version 2 of the License
+ *
+ *   This program is distributed in the hope that it will be useful,
+ *   but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *   GNU General Public License for more details.
+ *
+ *   Copyright (C) 2009-2016 John Crispin <blogic@openwrt.org>
+ *   Copyright (C) 2009-2016 Felix Fietkau <nbd@openwrt.org>
+ *   Copyright (C) 2013-2016 Michael Lee <igvtee@gmail.com>
+ */
+
+#ifndef MTK_ETH_H
+#define MTK_ETH_H
+
+#include <linux/dma-mapping.h>
+#include <linux/netdevice.h>
+#include <linux/of_net.h>
+#include <linux/u64_stats_sync.h>
+
+#define MTK_QDMA_PAGE_SIZE	2048
+#define	MTK_MAX_RX_LENGTH	1536
+#define MTK_TX_DMA_BUF_LEN	0x3fff
+#define MTK_DMA_SIZE		2048
+#define MTK_NAPI_WEIGHT		64
+#define MTK_MAC_COUNT		2
+#define MTK_RX_ETH_HLEN		(VLAN_ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN)
+#define MTK_RX_HLEN		(NET_SKB_PAD + MTK_RX_ETH_HLEN + NET_IP_ALIGN)
+#define MTK_DMA_DUMMY_DESC	0xffffffff
+#define MTK_DEFAULT_MSG_ENABLE	(NETIF_MSG_DRV | \
+				 NETIF_MSG_PROBE | \
+				 NETIF_MSG_LINK | \
+				 NETIF_MSG_TIMER | \
+				 NETIF_MSG_IFDOWN | \
+				 NETIF_MSG_IFUP | \
+				 NETIF_MSG_RX_ERR | \
+				 NETIF_MSG_TX_ERR)
+#define MTK_HW_FEATURES		(NETIF_F_IP_CSUM | \
+				 NETIF_F_RXCSUM | \
+				 NETIF_F_HW_VLAN_CTAG_TX | \
+				 NETIF_F_HW_VLAN_CTAG_RX | \
+				 NETIF_F_SG | NETIF_F_TSO | \
+				 NETIF_F_TSO6 | \
+				 NETIF_F_IPV6_CSUM)
+#define NEXT_RX_DESP_IDX(X, Y)	(((X) + 1) & ((Y) - 1))
+
+#define MTK_MAX_RX_RING_NUM	4
+#define MTK_HW_LRO_DMA_SIZE	8
+
+#define	MTK_MAX_LRO_RX_LENGTH		(4096 * 3)
+#define	MTK_MAX_LRO_IP_CNT		2
+#define	MTK_HW_LRO_TIMER_UNIT		1	/* 20 us */
+#define	MTK_HW_LRO_REFRESH_TIME		50000	/* 1 sec. */
+#define	MTK_HW_LRO_AGG_TIME		10	/* 200us */
+#define	MTK_HW_LRO_AGE_TIME		50	/* 1ms */
+#define	MTK_HW_LRO_MAX_AGG_CNT		64
+#define	MTK_HW_LRO_BW_THRE		3000
+#define	MTK_HW_LRO_REPLACE_DELTA	1000
+#define	MTK_HW_LRO_SDL_REMAIN_ROOM	1522
+
+/* Frame Engine Global Reset Register */
+#define MTK_RST_GL		0x04
+#define RST_GL_PSE		BIT(0)
+
+/* Frame Engine Interrupt Status Register */
+#define MTK_INT_STATUS2		0x08
+#define MTK_GDM1_AF		BIT(28)
+#define MTK_GDM2_AF		BIT(29)
+
+/* PDMA HW LRO Alter Flow Timer Register */
+#define MTK_PDMA_LRO_ALT_REFRESH_TIMER	0x1c
+
+/* Frame Engine Interrupt Grouping Register */
+#define MTK_FE_INT_GRP		0x20
+
+/* CDMP Ingress Control Register */
+#define MTK_CDMQ_IG_CTRL	0x1400
+#define MTK_CDMQ_STAG_EN	BIT(0)
+
+/* CDMP Ingress Control Register */
+#define MTK_CDMP_IG_CTRL       0x400
+#define MTK_CDMP_STAG_EN	BIT(0)
+
+/* CDMP Exgress Control Register */
+#define MTK_CDMP_EG_CTRL	0x404
+
+/* GDM Exgress Control Register */
+#define MTK_GDMA_FWD_CFG(x)	(0x500 + (x * 0x1000))
+#define MTK_GDMA_SPEC_TAG	BIT(24)
+#define MTK_GDMA_ICS_EN		BIT(22)
+#define MTK_GDMA_TCS_EN		BIT(21)
+#define MTK_GDMA_UCS_EN		BIT(20)
+#define MTK_GDMA_DROP_ALL       0x7777
+#define MTK_GDMA_PDMA_ALL       0x0
+
+/* Unicast Filter MAC Address Register - Low */
+#define MTK_GDMA_MAC_ADRL(x)	(0x508 + (x * 0x1000))
+
+/* Unicast Filter MAC Address Register - High */
+#define MTK_GDMA_MAC_ADRH(x)	(0x50C + (x * 0x1000))
+
+/* PDMA RX Base Pointer Register */
+#define MTK_PRX_BASE_PTR0	0x900
+#define MTK_PRX_BASE_PTR_CFG(x)	(MTK_PRX_BASE_PTR0 + (x * 0x10))
+
+/* PDMA RX Maximum Count Register */
+#define MTK_PRX_MAX_CNT0	0x904
+#define MTK_PRX_MAX_CNT_CFG(x)	(MTK_PRX_MAX_CNT0 + (x * 0x10))
+
+/* PDMA RX CPU Pointer Register */
+#define MTK_PRX_CRX_IDX0	0x908
+#define MTK_PRX_CRX_IDX_CFG(x)	(MTK_PRX_CRX_IDX0 + (x * 0x10))
+
+/* PDMA HW LRO Control Registers */
+#define MTK_PDMA_LRO_CTRL_DW0	0x980
+#define MTK_LRO_EN			BIT(0)
+#define MTK_L3_CKS_UPD_EN		BIT(7)
+#define MTK_LRO_ALT_PKT_CNT_MODE	BIT(21)
+#define MTK_LRO_RING_RELINQUISH_REQ	(0x7 << 26)
+#define MTK_LRO_RING_RELINQUISH_DONE	(0x7 << 29)
+
+#define MTK_PDMA_LRO_CTRL_DW1	0x984
+#define MTK_PDMA_LRO_CTRL_DW2	0x988
+#define MTK_PDMA_LRO_CTRL_DW3	0x98c
+#define MTK_ADMA_MODE		BIT(15)
+#define MTK_LRO_MIN_RXD_SDL	(MTK_HW_LRO_SDL_REMAIN_ROOM << 16)
+
+/* PDMA Global Configuration Register */
+#define MTK_PDMA_GLO_CFG	0xa04
+#define MTK_MULTI_EN		BIT(10)
+
+/* PDMA Reset Index Register */
+#define MTK_PDMA_RST_IDX	0xa08
+#define MTK_PST_DRX_IDX0	BIT(16)
+#define MTK_PST_DRX_IDX_CFG(x)	(MTK_PST_DRX_IDX0 << (x))
+
+/* PDMA Delay Interrupt Register */
+#define MTK_PDMA_DELAY_INT		0xa0c
+#define MTK_PDMA_DELAY_RX_EN		BIT(15)
+#define MTK_PDMA_DELAY_RX_PINT		4
+#define MTK_PDMA_DELAY_RX_PINT_SHIFT	8
+#define MTK_PDMA_DELAY_RX_PTIME		4
+#define MTK_PDMA_DELAY_RX_DELAY		\
+	(MTK_PDMA_DELAY_RX_EN | MTK_PDMA_DELAY_RX_PTIME | \
+	(MTK_PDMA_DELAY_RX_PINT << MTK_PDMA_DELAY_RX_PINT_SHIFT))
+
+/* PDMA Interrupt Status Register */
+#define MTK_PDMA_INT_STATUS	0xa20
+
+/* PDMA Interrupt Mask Register */
+#define MTK_PDMA_INT_MASK	0xa28
+
+/* PDMA HW LRO Alter Flow Delta Register */
+#define MTK_PDMA_LRO_ALT_SCORE_DELTA	0xa4c
+
+/* PDMA Interrupt grouping registers */
+#define MTK_PDMA_INT_GRP1	0xa50
+#define MTK_PDMA_INT_GRP2	0xa54
+
+/* PDMA HW LRO IP Setting Registers */
+#define MTK_LRO_RX_RING0_DIP_DW0	0xb04
+#define MTK_LRO_DIP_DW0_CFG(x)		(MTK_LRO_RX_RING0_DIP_DW0 + (x * 0x40))
+#define MTK_RING_MYIP_VLD		BIT(9)
+
+/* PDMA HW LRO Ring Control Registers */
+#define MTK_LRO_RX_RING0_CTRL_DW1	0xb28
+#define MTK_LRO_RX_RING0_CTRL_DW2	0xb2c
+#define MTK_LRO_RX_RING0_CTRL_DW3	0xb30
+#define MTK_LRO_CTRL_DW1_CFG(x)		(MTK_LRO_RX_RING0_CTRL_DW1 + (x * 0x40))
+#define MTK_LRO_CTRL_DW2_CFG(x)		(MTK_LRO_RX_RING0_CTRL_DW2 + (x * 0x40))
+#define MTK_LRO_CTRL_DW3_CFG(x)		(MTK_LRO_RX_RING0_CTRL_DW3 + (x * 0x40))
+#define MTK_RING_AGE_TIME_L		((MTK_HW_LRO_AGE_TIME & 0x3ff) << 22)
+#define MTK_RING_AGE_TIME_H		((MTK_HW_LRO_AGE_TIME >> 10) & 0x3f)
+#define MTK_RING_AUTO_LERAN_MODE	(3 << 6)
+#define MTK_RING_VLD			BIT(8)
+#define MTK_RING_MAX_AGG_TIME		((MTK_HW_LRO_AGG_TIME & 0xffff) << 10)
+#define MTK_RING_MAX_AGG_CNT_L		((MTK_HW_LRO_MAX_AGG_CNT & 0x3f) << 26)
+#define MTK_RING_MAX_AGG_CNT_H		((MTK_HW_LRO_MAX_AGG_CNT >> 6) & 0x3)
+
+/* QDMA TX Queue Configuration Registers */
+#define MTK_QTX_CFG(x)		(0x1800 + (x * 0x10))
+#define QDMA_RES_THRES		4
+
+/* QDMA TX Queue Scheduler Registers */
+#define MTK_QTX_SCH(x)		(0x1804 + (x * 0x10))
+
+/* QDMA RX Base Pointer Register */
+#define MTK_QRX_BASE_PTR0	0x1900
+
+/* QDMA RX Maximum Count Register */
+#define MTK_QRX_MAX_CNT0	0x1904
+
+/* QDMA RX CPU Pointer Register */
+#define MTK_QRX_CRX_IDX0	0x1908
+
+/* QDMA RX DMA Pointer Register */
+#define MTK_QRX_DRX_IDX0	0x190C
+
+/* QDMA Global Configuration Register */
+#define MTK_QDMA_GLO_CFG	0x1A04
+#define MTK_RX_2B_OFFSET	BIT(31)
+#define MTK_RX_BT_32DWORDS	(3 << 11)
+#define MTK_NDP_CO_PRO		BIT(10)
+#define MTK_TX_WB_DDONE		BIT(6)
+#define MTK_DMA_SIZE_16DWORDS	(2 << 4)
+#define MTK_RX_DMA_BUSY		BIT(3)
+#define MTK_TX_DMA_BUSY		BIT(1)
+#define MTK_RX_DMA_EN		BIT(2)
+#define MTK_TX_DMA_EN		BIT(0)
+#define MTK_DMA_BUSY_TIMEOUT	HZ
+
+/* QDMA Reset Index Register */
+#define MTK_QDMA_RST_IDX	0x1A08
+
+/* QDMA Delay Interrupt Register */
+#define MTK_QDMA_DELAY_INT	0x1A0C
+
+/* QDMA Flow Control Register */
+#define MTK_QDMA_FC_THRES	0x1A10
+#define FC_THRES_DROP_MODE	BIT(20)
+#define FC_THRES_DROP_EN	(7 << 16)
+#define FC_THRES_MIN		0x4444
+
+/* QDMA Interrupt Status Register */
+#define MTK_QMTK_INT_STATUS	0x1A18
+#define MTK_RX_DONE_DLY		BIT(30)
+#define MTK_RX_DONE_INT3	BIT(19)
+#define MTK_RX_DONE_INT2	BIT(18)
+#define MTK_RX_DONE_INT1	BIT(17)
+#define MTK_RX_DONE_INT0	BIT(16)
+#define MTK_TX_DONE_INT3	BIT(3)
+#define MTK_TX_DONE_INT2	BIT(2)
+#define MTK_TX_DONE_INT1	BIT(1)
+#define MTK_TX_DONE_INT0	BIT(0)
+#define MTK_RX_DONE_INT		MTK_RX_DONE_DLY
+#define MTK_TX_DONE_DLY         BIT(28)
+#define MTK_TX_DONE_INT         MTK_TX_DONE_DLY
+
+
+/* QDMA Interrupt grouping registers */
+#define MTK_QDMA_INT_GRP1	0x1a20
+#define MTK_QDMA_INT_GRP2	0x1a24
+#define MTK_RLS_DONE_INT	BIT(0)
+
+/* QDMA Interrupt Status Register */
+#define MTK_QDMA_INT_MASK	0x1A1C
+
+/* QDMA Interrupt Mask Register */
+#define MTK_QDMA_HRED2		0x1A44
+
+/* QDMA TX Forward CPU Pointer Register */
+#define MTK_QTX_CTX_PTR		0x1B00
+
+/* QDMA TX Forward DMA Pointer Register */
+#define MTK_QTX_DTX_PTR		0x1B04
+
+/* QDMA TX Release CPU Pointer Register */
+#define MTK_QTX_CRX_PTR		0x1B10
+
+/* QDMA TX Release DMA Pointer Register */
+#define MTK_QTX_DRX_PTR		0x1B14
+
+/* QDMA FQ Head Pointer Register */
+#define MTK_QDMA_FQ_HEAD	0x1B20
+
+/* QDMA FQ Head Pointer Register */
+#define MTK_QDMA_FQ_TAIL	0x1B24
+
+/* QDMA FQ Free Page Counter Register */
+#define MTK_QDMA_FQ_CNT		0x1B28
+
+/* QDMA FQ Free Page Buffer Length Register */
+#define MTK_QDMA_FQ_BLEN	0x1B2C
+
+/* GMA1 Received Good Byte Count Register */
+#define MTK_GDM1_TX_GBCNT	0x2400
+#define MTK_STAT_OFFSET		0x40
+
+/* QDMA TX NUM */
+#define MTK_QDMA_TX_NUM		16
+#define MTK_QDMA_TX_MASK	((MTK_QDMA_TX_NUM) - 1)
+#define QID_LOW_BITS(x)		((x) & 0xf)
+#define QID_HIGH_BITS(x)	((((x) >> 4) & 0x3) << 20)
+
+/* QDMA descriptor txd4 */
+#define TX_DMA_CHKSUM		(0x7 << 29)
+#define TX_DMA_TSO		BIT(28)
+#define TX_DMA_FPORT_SHIFT	25
+#define TX_DMA_FPORT_MASK	0x7
+#define TX_DMA_INS_VLAN		BIT(16)
+
+/* QDMA descriptor txd3 */
+#define TX_DMA_OWNER_CPU	BIT(31)
+#define TX_DMA_LS0		BIT(30)
+#define TX_DMA_PLEN0(_x)	(((_x) & MTK_TX_DMA_BUF_LEN) << 16)
+#define TX_DMA_SWC		BIT(14)
+#define TX_DMA_SDL(_x)		(((_x) & 0x3fff) << 16)
+
+/* QDMA descriptor rxd2 */
+#define RX_DMA_DONE		BIT(31)
+#define RX_DMA_PLEN0(_x)	(((_x) & 0x3fff) << 16)
+#define RX_DMA_GET_PLEN0(_x)	(((_x) >> 16) & 0x3fff)
+#define RX_DMA_VTAG             BIT(15)
+
+/* QDMA descriptor rxd3 */
+#define RX_DMA_VID(_x)		((_x) & VLAN_VID_MASK)
+#define RX_DMA_TCI(_x)		((_x) & (VLAN_PRIO_MASK | VLAN_VID_MASK))
+#define RX_DMA_VPID(_x)		(((_x) >> 16) & 0xffff)
+
+/* QDMA descriptor rxd4 */
+#define RX_DMA_L4_VALID		BIT(24)
+#define RX_DMA_FPORT_SHIFT	19
+#define RX_DMA_FPORT_MASK	0x7
+
+/* PHY Indirect Access Control registers */
+#define MTK_PHY_IAC		0x10004
+#define PHY_IAC_ACCESS		BIT(31)
+#define PHY_IAC_READ		BIT(19)
+#define PHY_IAC_WRITE		BIT(18)
+#define PHY_IAC_START		BIT(16)
+#define PHY_IAC_ADDR_SHIFT	20
+#define PHY_IAC_REG_SHIFT	25
+#define PHY_IAC_TIMEOUT		HZ
+
+#define MTK_MAC_MISC		0x1000c
+#define MTK_MUX_TO_ESW		BIT(0)
+
+/* Mac control registers */
+#define MTK_MAC_MCR(x)		(0x10100 + (x * 0x100))
+#define MAC_MCR_MAX_RX_1536	BIT(24)
+#define MAC_MCR_IPG_CFG		(BIT(18) | BIT(16))
+#define MAC_MCR_FORCE_MODE	BIT(15)
+#define MAC_MCR_TX_EN		BIT(14)
+#define MAC_MCR_RX_EN		BIT(13)
+#define MAC_MCR_BACKOFF_EN	BIT(9)
+#define MAC_MCR_BACKPR_EN	BIT(8)
+#define MAC_MCR_MDIO_EEE_1000T  BIT(7)
+#define MAC_MCR_MDIO_EEE_100TX  BIT(6)
+#define MAC_MCR_FORCE_RX_FC	BIT(5)
+#define MAC_MCR_FORCE_TX_FC	BIT(4)
+#define MAC_MCR_SPEED_1000	BIT(3)
+#define MAC_MCR_SPEED_100	BIT(2)
+#define MAC_MCR_FORCE_DPX	BIT(1)
+#define MAC_MCR_FORCE_LINK	BIT(0)
+#define MAC_MCR_FIXED_LINK	(MAC_MCR_MAX_RX_1536 | MAC_MCR_IPG_CFG | \
+				 MAC_MCR_FORCE_MODE | MAC_MCR_TX_EN | \
+				 MAC_MCR_RX_EN | MAC_MCR_BACKOFF_EN | \
+				 MAC_MCR_BACKPR_EN | MAC_MCR_FORCE_RX_FC | \
+				 MAC_MCR_FORCE_TX_FC | MAC_MCR_SPEED_1000 | \
+				 MAC_MCR_FORCE_DPX | MAC_MCR_FORCE_LINK)
+
+/* TRGMII RXC control register */
+#define TRGMII_RCK_CTRL		0x10300
+#define DQSI0(x)		((x << 0) & GENMASK(6, 0))
+#define DQSI1(x)		((x << 8) & GENMASK(14, 8))
+#define RXCTL_DMWTLAT(x)	((x << 16) & GENMASK(18, 16))
+#define RXC_DQSISEL		BIT(30)
+#define RCK_CTRL_RGMII_1000	(RXC_DQSISEL | RXCTL_DMWTLAT(2) | DQSI1(16))
+#define RCK_CTRL_RGMII_10_100	RXCTL_DMWTLAT(2)
+
+/* TRGMII RXC control register */
+#define TRGMII_TCK_CTRL		0x10340
+#define TXCTL_DMWTLAT(x)	((x << 16) & GENMASK(18, 16))
+#define TXC_INV			BIT(30)
+#define TCK_CTRL_RGMII_1000	TXCTL_DMWTLAT(2)
+#define TCK_CTRL_RGMII_10_100	(TXC_INV | TXCTL_DMWTLAT(2))
+
+/* TRGMII Interface mode register */
+#define INTF_MODE		0x10390
+#define TRGMII_INTF_DIS		BIT(0)
+#define TRGMII_MODE		BIT(1)
+#define TRGMII_CENTRAL_ALIGNED	BIT(2)
+#define INTF_MODE_RGMII_1000    (TRGMII_MODE | TRGMII_CENTRAL_ALIGNED)
+#define INTF_MODE_RGMII_10_100  0
+
+/* GPIO port control registers for GMAC 2*/
+#define GPIO_OD33_CTRL8		0x4c0
+#define GPIO_BIAS_CTRL		0xed0
+#define GPIO_DRV_SEL10		0xf00
+
+/* ethernet subsystem chip id register */
+#define ETHSYS_CHIPID0_3	0x0
+#define ETHSYS_CHIPID4_7	0x4
+#define MT7623_ETH		7623
+#define MT7622_ETH		7622
+
+/* ethernet system control register */
+#define ETHSYS_SYSCFG		0x10
+#define SYSCFG_DRAM_TYPE_DDR2	BIT(4)
+
+/* ethernet subsystem config register */
+#define ETHSYS_SYSCFG0		0x14
+#define SYSCFG0_GE_MASK		0x3
+#define SYSCFG0_GE_MODE(x, y)	(x << (12 + (y * 2)))
+#define SYSCFG0_SGMII_MASK	GENMASK(9, 8)
+#define SYSCFG0_SGMII_GMAC1	((2 << 8) & SYSCFG0_SGMII_MASK)
+#define SYSCFG0_SGMII_GMAC2	((3 << 8) & SYSCFG0_SGMII_MASK)
+#define SYSCFG0_SGMII_GMAC1_V2	BIT(9)
+#define SYSCFG0_SGMII_GMAC2_V2	BIT(8)
+
+/* ethernet subsystem clock register */
+#define ETHSYS_CLKCFG0		0x2c
+#define ETHSYS_TRGMII_CLK_SEL362_5	BIT(11)
+#define ETHSYS_TRGMII_MT7621_MASK	(BIT(5) | BIT(6))
+#define ETHSYS_TRGMII_MT7621_APLL	BIT(6)
+#define ETHSYS_TRGMII_MT7621_DDR_PLL	BIT(5)
+
+/* ethernet reset control register */
+#define ETHSYS_RSTCTRL		0x34
+#define RSTCTRL_FE		BIT(6)
+#define RSTCTRL_PPE		BIT(31)
+#define RSTCTRL_ETH		BIT(23)
+
+/* SGMII subsystem config registers */
+/* Register to auto-negotiation restart */
+#define SGMSYS_PCS_CONTROL_1	0x0
+#define SGMII_AN_RESTART	BIT(9)
+
+/* Register to programmable link timer, the unit in 2 * 8ns */
+#define SGMSYS_PCS_LINK_TIMER	0x18
+#define SGMII_LINK_TIMER_DEFAULT	(0x186a0 & GENMASK(19, 0))
+
+/* Register to control remote fault */
+#define SGMSYS_SGMII_MODE	0x20
+#define SGMII_REMOTE_FAULT_DIS	BIT(8)
+
+/* Register to power up QPHY */
+#define SGMSYS_QPHY_PWR_STATE_CTRL 0xe8
+#define	SGMII_PHYA_PWD		BIT(4)
+
+/* Infrasys subsystem config registers */
+#define INFRA_MISC2		0x70c
+#define CO_QPHY_SEL		BIT(0)
+#define GEPHY_MAC_SEL		BIT(1)
+
+/*MDIO control*/
+#define MII_MMD_ACC_CTL_REG             0x0d
+#define MII_MMD_ADDR_DATA_REG           0x0e
+#define MMD_OP_MODE_DATA BIT(14)
+
+struct mtk_rx_dma {
+	unsigned int rxd1;
+	unsigned int rxd2;
+	unsigned int rxd3;
+	unsigned int rxd4;
+} __packed __aligned(4);
+
+struct mtk_tx_dma {
+	unsigned int txd1;
+	unsigned int txd2;
+	unsigned int txd3;
+	unsigned int txd4;
+} __packed __aligned(4);
+
+struct mtk_eth;
+struct mtk_mac;
+
+/* struct mtk_hw_stats - the structure that holds the traffic statistics.
+ * @stats_lock:		make sure that stats operations are atomic
+ * @reg_offset:		the status register offset of the SoC
+ * @syncp:		the refcount
+ *
+ * All of the supported SoCs have hardware counters for traffic statistics.
+ * Whenever the status IRQ triggers we can read the latest stats from these
+ * counters and store them in this struct.
+ */
+struct mtk_hw_stats {
+	u64 tx_bytes;
+	u64 tx_packets;
+	u64 tx_skip;
+	u64 tx_collisions;
+	u64 rx_bytes;
+	u64 rx_packets;
+	u64 rx_overflow;
+	u64 rx_fcs_errors;
+	u64 rx_short_errors;
+	u64 rx_long_errors;
+	u64 rx_checksum_errors;
+	u64 rx_flow_control_packets;
+
+	spinlock_t		stats_lock;
+	u32			reg_offset;
+	struct u64_stats_sync	syncp;
+};
+
+enum mtk_tx_flags {
+	/* PDMA descriptor can point at 1-2 segments. This enum allows us to
+	 * track how memory was allocated so that it can be freed properly.
+	 */
+	MTK_TX_FLAGS_SINGLE0	= 0x01,
+	MTK_TX_FLAGS_PAGE0	= 0x02,
+
+	/* MTK_TX_FLAGS_FPORTx allows tracking which port the transmitted
+	 * SKB out instead of looking up through hardware TX descriptor.
+	 */
+	MTK_TX_FLAGS_FPORT0	= 0x04,
+	MTK_TX_FLAGS_FPORT1	= 0x08,
+};
+
+/* This enum allows us to identify how the clock is defined on the array of the
+ * clock in the order
+ */
+enum mtk_clks_map {
+	MTK_CLK_ETHIF,
+	MTK_CLK_SGMIITOP,
+	MTK_CLK_ESW,
+	MTK_CLK_GP0,
+	MTK_CLK_GP1,
+	MTK_CLK_GP2,
+	MTK_CLK_FE,
+	MTK_CLK_TRGPLL,
+	MTK_CLK_SGMII_TX_250M,
+	MTK_CLK_SGMII_RX_250M,
+	MTK_CLK_SGMII_CDR_REF,
+	MTK_CLK_SGMII_CDR_FB,
+	MTK_CLK_SGMII2_TX_250M,
+	MTK_CLK_SGMII2_RX_250M,
+	MTK_CLK_SGMII2_CDR_REF,
+	MTK_CLK_SGMII2_CDR_FB,
+	MTK_CLK_SGMII_CK,
+	MTK_CLK_ETH2PLL,
+	MTK_CLK_MAX
+};
+
+#define MT7623_CLKS_BITMAP	(BIT(MTK_CLK_ETHIF) | BIT(MTK_CLK_ESW) |  \
+				 BIT(MTK_CLK_GP1) | BIT(MTK_CLK_GP2) | \
+				 BIT(MTK_CLK_TRGPLL))
+#define MT7622_CLKS_BITMAP	(BIT(MTK_CLK_ETHIF) | BIT(MTK_CLK_ESW) |  \
+				 BIT(MTK_CLK_GP0) | BIT(MTK_CLK_GP1) | \
+				 BIT(MTK_CLK_GP2) | \
+				 BIT(MTK_CLK_SGMII_TX_250M) | \
+				 BIT(MTK_CLK_SGMII_RX_250M) | \
+				 BIT(MTK_CLK_SGMII_CDR_REF) | \
+				 BIT(MTK_CLK_SGMII_CDR_FB) | \
+				 BIT(MTK_CLK_SGMII_CK) | \
+				 BIT(MTK_CLK_ETH2PLL))
+#define LEOPARD_CLKS_BITMAP     (BIT(MTK_CLK_ETHIF) | BIT(MTK_CLK_ESW) |  \
+				BIT(MTK_CLK_GP0) | BIT(MTK_CLK_GP1) | \
+				BIT(MTK_CLK_GP2) | BIT(MTK_CLK_FE) | \
+				BIT(MTK_CLK_SGMII_TX_250M) | \
+				BIT(MTK_CLK_SGMII_RX_250M) | \
+				BIT(MTK_CLK_SGMII_CDR_REF) | \
+				BIT(MTK_CLK_SGMII_CDR_FB) | \
+				BIT(MTK_CLK_SGMII2_TX_250M) | \
+				BIT(MTK_CLK_SGMII2_RX_250M) | \
+				BIT(MTK_CLK_SGMII2_CDR_REF) | \
+				BIT(MTK_CLK_SGMII2_CDR_FB) | \
+				BIT(MTK_CLK_SGMII_CK) | \
+				BIT(MTK_CLK_ETH2PLL) | BIT(MTK_CLK_SGMIITOP))
+
+#define MT7621_CLKS_BITMAP 0
+
+enum mtk_dev_state {
+	MTK_HW_INIT,
+	MTK_RESETTING
+};
+
+/* struct mtk_tx_buf -	This struct holds the pointers to the memory pointed at
+ *			by the TX descriptor	s
+ * @skb:		The SKB pointer of the packet being sent
+ * @dma_addr0:		The base addr of the first segment
+ * @dma_len0:		The length of the first segment
+ * @dma_addr1:		The base addr of the second segment
+ * @dma_len1:		The length of the second segment
+ */
+struct mtk_tx_buf {
+	struct sk_buff *skb;
+	u32 flags;
+	DEFINE_DMA_UNMAP_ADDR(dma_addr0);
+	DEFINE_DMA_UNMAP_LEN(dma_len0);
+	DEFINE_DMA_UNMAP_ADDR(dma_addr1);
+	DEFINE_DMA_UNMAP_LEN(dma_len1);
+};
+
+/* struct mtk_tx_ring -	This struct holds info describing a TX ring
+ * @dma:		The descriptor ring
+ * @buf:		The memory pointed at by the ring
+ * @phys:		The physical addr of tx_buf
+ * @next_free:		Pointer to the next free descriptor
+ * @last_free:		Pointer to the last free descriptor
+ * @thresh:		The threshold of minimum amount of free descriptors
+ * @free_count:		QDMA uses a linked list. Track how many free descriptors
+ *			are present
+ */
+struct mtk_tx_ring {
+	struct mtk_tx_dma *dma;
+	struct mtk_tx_buf *buf;
+	dma_addr_t phys;
+	struct mtk_tx_dma *next_free;
+	struct mtk_tx_dma *last_free;
+	u16 thresh;
+	atomic_t free_count;
+};
+
+/* PDMA rx ring mode */
+enum mtk_rx_flags {
+	MTK_RX_FLAGS_NORMAL = 0,
+	MTK_RX_FLAGS_HWLRO,
+	MTK_RX_FLAGS_QDMA,
+};
+
+/* struct mtk_rx_ring -	This struct holds info describing a RX ring
+ * @dma:		The descriptor ring
+ * @data:		The memory pointed at by the ring
+ * @phys:		The physical addr of rx_buf
+ * @frag_size:		How big can each fragment be
+ * @buf_size:		The size of each packet buffer
+ * @calc_idx:		The current head of ring
+ */
+struct mtk_rx_ring {
+	struct mtk_rx_dma *dma;
+	u8 **data;
+	dma_addr_t phys;
+	u16 frag_size;
+	u16 buf_size;
+	u16 dma_size;
+	bool calc_idx_update;
+	u16 calc_idx;
+	u32 crx_idx_reg;
+};
+
+enum mtk_eth_mux {
+	MTK_ETH_MUX_GDM1_TO_GMAC1_ESW,
+	MTK_ETH_MUX_GMAC2_GMAC0_TO_GEPHY,
+	MTK_ETH_MUX_U3_GMAC2_TO_QPHY,
+	MTK_ETH_MUX_GMAC1_GMAC2_TO_SGMII_RGMII,
+	MTK_ETH_MUX_GMAC12_TO_GEPHY_SGMII,
+	MTK_ETH_MUX_MAX,
+};
+
+enum mtk_eth_path {
+	MTK_ETH_PATH_GMAC1_RGMII,
+	MTK_ETH_PATH_GMAC1_TRGMII,
+	MTK_ETH_PATH_GMAC1_SGMII,
+	MTK_ETH_PATH_GMAC2_RGMII,
+	MTK_ETH_PATH_GMAC2_SGMII,
+	MTK_ETH_PATH_GMAC2_GEPHY,
+	MTK_ETH_PATH_GDM1_ESW,
+	MTK_ETH_PATH_MAX,
+};
+
+/* Capability for function group */
+#define MTK_RGMII			BIT(0)
+#define MTK_TRGMII			BIT(1)
+#define MTK_SGMII			BIT(2)
+#define MTK_ESW				BIT(3)
+#define MTK_GEPHY			BIT(4)
+#define MTK_MUX				BIT(5)
+#define MTK_INFRA			BIT(6)
+#define MTK_SHARED_SGMII		BIT(7)
+#define MTK_HWLRO			BIT(8)
+#define MTK_SHARED_INT			BIT(9)
+#define MTK_TRGMII_MT7621_CLK		BIT(10)
+
+/* Capability for features on SoCs */
+#define MTK_PATH_BIT(x)		BIT((x) + 10)
+
+#define MTK_GMAC1_RGMII		\
+	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC1_RGMII) | MTK_RGMII)
+
+#define MTK_GMAC1_TRGMII	\
+	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC1_TRGMII) | MTK_TRGMII)
+
+#define MTK_GMAC1_SGMII		\
+	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC1_SGMII) | MTK_SGMII)
+
+#define MTK_GMAC2_RGMII		\
+	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC2_RGMII) | MTK_RGMII)
+
+#define MTK_GMAC2_SGMII		\
+	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC2_SGMII) | MTK_SGMII)
+
+#define MTK_GMAC2_GEPHY		\
+	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC2_GEPHY) | MTK_GEPHY)
+
+#define MTK_GDM1_ESW		\
+	(MTK_PATH_BIT(MTK_ETH_PATH_GDM1_ESW) | MTK_ESW)
+
+#define MTK_MUX_BIT(x)		BIT((x) + 20)
+
+/* Capability for MUXes present on SoCs */
+/* 0: GDM1 -> GMAC1, 1: GDM1 -> ESW */
+#define MTK_MUX_GDM1_TO_GMAC1_ESW	\
+	(MTK_MUX_BIT(MTK_ETH_MUX_GDM1_TO_GMAC1_ESW) | MTK_MUX)
+
+/* 0: GMAC2 -> GEPHY, 1: GMAC0 -> GePHY */
+#define MTK_MUX_GMAC2_GMAC0_TO_GEPHY	\
+	(MTK_MUX_BIT(MTK_ETH_MUX_GMAC2_GMAC0_TO_GEPHY) | MTK_MUX | MTK_INFRA)
+
+/* 0: U3 -> QPHY, 1: GMAC2 -> QPHY */
+#define MTK_MUX_U3_GMAC2_TO_QPHY	\
+	(MTK_MUX_BIT(MTK_ETH_MUX_U3_GMAC2_TO_QPHY) | MTK_MUX | MTK_INFRA)
+
+/* 2: GMAC1 -> SGMII, 3: GMAC2 -> SGMII */
+#define MTK_MUX_GMAC1_GMAC2_TO_SGMII_RGMII	\
+	(MTK_MUX_BIT(MTK_ETH_MUX_GMAC1_GMAC2_TO_SGMII_RGMII) | MTK_MUX | \
+	 MTK_SHARED_SGMII)
+
+/* 0: GMACx -> GEPHY, 1: GMACx -> SGMII where x is 1 or 2 */
+#define MTK_MUX_GMAC12_TO_GEPHY_SGMII	\
+	(MTK_MUX_BIT(MTK_ETH_MUX_GMAC12_TO_GEPHY_SGMII) | MTK_MUX)
+
+#define MTK_HAS_CAPS(caps, _x)		(((caps) & (_x)) == (_x))
+
+#define MT7622_CAPS  (MTK_GMAC1_RGMII | MTK_GMAC1_SGMII | MTK_GMAC2_RGMII | \
+		      MTK_GMAC2_SGMII | MTK_GDM1_ESW | \
+		      MTK_MUX_GDM1_TO_GMAC1_ESW | \
+		      MTK_MUX_GMAC1_GMAC2_TO_SGMII_RGMII)
+
+#define MT7623_CAPS  (MTK_GMAC1_RGMII | MTK_GMAC1_TRGMII | MTK_GMAC2_RGMII)
+
+#define LEOPARD_CAPS  (MTK_GMAC1_SGMII | MTK_GMAC2_SGMII | MTK_GMAC2_GEPHY | \
+		      MTK_GDM1_ESW | MTK_MUX_GDM1_TO_GMAC1_ESW | \
+		      MTK_MUX_GMAC2_GMAC0_TO_GEPHY | \
+		      MTK_MUX_U3_GMAC2_TO_QPHY | \
+		      MTK_MUX_GMAC12_TO_GEPHY_SGMII)
+
+#define MT7621_CAPS  (MTK_GMAC1_RGMII | MTK_GMAC1_TRGMII | MTK_GMAC2_RGMII | \
+		      MTK_SHARED_INT | MTK_TRGMII_MT7621_CLK)
+
+/* struct mtk_eth_data -	This is the structure holding all differences
+ *				among various plaforms
+ * @ana_rgc3:			The offset for register ANA_RGC3 related to
+ *				sgmiisys syscon
+ * @caps			Flags shown the extra capability for the SoC
+ * @required_clks		Flags shown the bitmap for required clocks on
+ *				the target SoC
+ * @required_pctl		A bool value to show whether the SoC requires
+ *				the extra setup for those pins used by GMAC.
+ * @irq_num			total eth irq num support in target SoC
+ */
+struct mtk_soc_data {
+	u32		ana_rgc3;
+	u32		caps;
+	u32		required_clks;
+	bool		required_pctl;
+	u32             irq_num;
+};
+
+/* currently no SoC has more than 2 macs */
+#define MTK_MAX_DEVS			2
+
+struct mtk_eth_debug {
+	struct dentry *root;
+};
+
+#define MTK_SGMII_PHYSPEED_AN		BIT(31)
+#define MTK_SGMII_PHYSPEED_MASK		GENMASK(2, 0)
+#define MTK_SGMII_PHYSPEED_1000		BIT(0)
+#define MTK_SGMII_PHYSPEED_2500		BIT(1)
+#define MTK_HAS_FLAGS(flags, _x)	(((flags) & (_x)) == (_x))
+
+/* struct mtk_sgmii -	This is the structure holding sgmii regmap and its
+ *			characteristics
+ * @regmap:		The register map pointing at the range used to setup
+ *			SGMII modes
+ * @flags:		The enum refers to which mode the sgmii wants to run on
+ * @ana_rgc3:		The offset refers to register ANA_RGC3 related to regmap
+ */
+
+struct mtk_sgmii {
+	struct regmap	*regmap[MTK_MAX_DEVS];
+	u32		flags[MTK_MAX_DEVS];
+	u32		ana_rgc3;
+};
+
+/* struct mtk_eth -	This is the main datasructure for holding the state
+ *			of the driver
+ * @dev:		The device pointer
+ * @base:		The mapped register i/o base
+ * @page_lock:		Make sure that register operations are atomic
+ * @tx_irq__lock:	Make sure that IRQ register operations are atomic
+ * @rx_irq__lock:	Make sure that IRQ register operations are atomic
+ * @dummy_dev:		we run 2 netdevs on 1 physical DMA ring and need a
+ *			dummy for NAPI to work
+ * @netdev:		The netdev instances
+ * @mac:		Each netdev is linked to a physical MAC
+ * @irq:		The IRQ that we are using
+ * @msg_enable:		Ethtool msg level
+ * @ethsys:		The register map pointing at the range used to setup
+ *			MII modes
+ * @infra:		The register map pointing at the range used to setup
+ *			SGMII and GePHY path
+ * @pctl:		The register map pointing at the range used to setup
+ *			GMAC port drive/slew values
+ * @dma_refcnt:		track how many netdevs are using the DMA engine
+ * @tx_ring:		Pointer to the memory holding info about the TX ring
+ * @rx_ring:		Pointer to the memory holding info about the RX ring
+ * @rx_ring_qdma:	Pointer to the memory holding info about the QDMA RX
+ *			ring
+ * @tx_napi:		The TX NAPI struct
+ * @rx_napi:		The RX NAPI struct
+ * @scratch_ring:	Newer SoCs need memory for a second HW managed TX ring
+ * @phy_scratch_ring:	physical address of scratch_ring
+ * @scratch_head:	The scratch memory that scratch_ring points to.
+ * @clks:		clock array for all clocks required
+ * @mii_bus:		If there is a bus we need to create an instance for it
+ * @pending_work:	The workqueue used to reset the dma ring
+ * @state:		Initialization and runtime state of the device
+ * @soc:		Holding specific data among vaious SoCs
+ * @debug:		Holding specific data for mtk_eth_dbg usage.
+ */
+
+struct mtk_eth {
+	struct device			*dev;
+	void __iomem			*base;
+	spinlock_t			page_lock;
+	/* spin_lock for enable/disable tx irq critial section */
+	spinlock_t			tx_irq_lock;
+	/* spin_lock for enable/disable rx irq critial section */
+	spinlock_t			rx_irq_lock;
+	struct net_device		dummy_dev;
+	struct net_device		*netdev[MTK_MAX_DEVS];
+	struct mtk_mac			*mac[MTK_MAX_DEVS];
+	int				irq[3];
+	u32				msg_enable;
+	unsigned long			sysclk;
+	struct regmap			*ethsys;
+	struct regmap			*infra;
+	struct mtk_sgmii		*sgmii;
+	struct regmap			*pctl;
+	bool				hwlro;
+	atomic_t			dma_refcnt;
+	struct mtk_tx_ring		tx_ring;
+	struct mtk_rx_ring		rx_ring[MTK_MAX_RX_RING_NUM];
+	struct mtk_rx_ring		rx_ring_qdma;
+	struct napi_struct		tx_napi;
+	struct napi_struct		rx_napi;
+	struct mtk_tx_dma		*scratch_ring;
+	dma_addr_t			phy_scratch_ring;
+	void				*scratch_head;
+	struct clk			*clks[MTK_CLK_MAX];
+
+	struct mii_bus			*mii_bus;
+	struct work_struct		pending_work;
+	unsigned long			state;
+
+	const struct mtk_soc_data	*soc;
+	struct mtk_eth_debug		debug;
+};
+
+/* struct mtk_mac -	the structure that holds the info about the MACs of the
+ *			SoC
+ * @id:			The number of the MAC
+ * @ge_mode:            Interface mode kept for setup restoring
+ * @of_node:		Our devicetree node
+ * @hw:			Backpointer to our main datastruture
+ * @hw_stats:		Packet statistics counter
+ * @trgmii		Indicate if the MAC uses TRGMII connected to internal
+			switch
+ * @phy_dev:		The attached PHY if available
+ */
+struct mtk_mac {
+	int				id;
+	int				ge_mode;
+	struct device_node		*of_node;
+	struct mtk_eth			*hw;
+	struct mtk_hw_stats		*hw_stats;
+	__be32				hwlro_ip[MTK_MAX_LRO_IP_CNT];
+	int				hwlro_ip_cnt;
+	bool				trgmii;
+	struct phy_device		*phy_dev;
+	phy_interface_t			phymode;
+};
+
+/* the struct describing the SoC. these are declared in the soc_xyz.c files */
+extern const struct of_device_id of_mtk_match[];
+
+/* read the hardware status register */
+void mtk_stats_update_mac(struct mtk_mac *mac);
+
+void mtk_w32(struct mtk_eth *eth, u32 val, unsigned reg);
+u32 mtk_r32(struct mtk_eth *eth, unsigned reg);
+
+int mtk_sgmii_init(struct mtk_sgmii *ss, struct device_node *np,
+		   u32 ana_rgc3);
+int mtk_sgmii_setup_mode_an(struct mtk_sgmii *ss, int id);
+int mtk_sgmii_setup_mode_force(struct mtk_sgmii *ss, int id);
+int mtk_setup_hw_path(struct mtk_eth *eth, int mac_id, int phymode);
+
+#endif /* MTK_ETH_H */
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_dbg_proc.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_dbg_proc.c
index 705441f1..e1323b50 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_dbg_proc.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_dbg_proc.c
@@ -1223,7 +1223,9 @@ void pse_qdma_drop_cnt(void)
 
 void external_gsw_cnt_read(void)
 {
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 	rtk_hal_dump_mib();
+#endif
 }
 
 void embedded_sw_cnt_read(struct seq_file *seq)
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.c
index 4e48245d..47189a19 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.c
@@ -2791,6 +2791,7 @@ void trgmii_set_7530(void)
 	pr_info("trgmii_set_7530 Completed!!\n");
 }
 
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 static void is_switch_vlan_table_busy(void)
 {
 	int j = 0;
@@ -2873,6 +2874,7 @@ static void lan_wan_partition(void)
 		is_switch_vlan_table_busy();
 	}
 }
+#endif
 
 static void mt7530_phy_setting(void)
 {
@@ -3093,7 +3095,9 @@ static void setup_internal_gsw(void)
 		sys_reg_write(ETHDMASYS_ETH_SW_BASE + 0x0378, 0x855);
 	}
 
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 	lan_wan_partition();
+#endif
 	mt7530_phy_setting();
 	for (i = 0; i <= 4; i++) {
 		/*turn on PHY */
@@ -3217,6 +3221,7 @@ void fe_sw_preinit(struct END_DEVICE *ei_local)
 	}
 }
 
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 int init_rtl8367s(void)
 {
 	struct END_DEVICE *ei_local = netdev_priv(dev_raether);
@@ -3443,6 +3448,7 @@ void set_sgmii_an(int port_num)
 	sys_reg_write(virt_addr + 0xe8, reg_value);
 	iounmap(virt_addr);
 }
+#endif
 
 static void mt7622_esw_5port_gpio(void)
 {
@@ -3742,8 +3748,10 @@ void fe_sw_init(void)
 		set_ge2_force_1000();
 		if (ei_local->chip_name == MT7623_FE)
 			setup_external_gsw();
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 		if (ei_local->chip_name == MT7622_FE)
 			set_rtl8367s_rgmii();
+#endif
 	}
 	/*TODO
 	 * else
@@ -3794,6 +3802,7 @@ void fe_sw_init(void)
 		sys_reg_write(ethsys_base_virt + 0x14, reg_value);
 	}
 
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 	if (ei_local->architecture & GE1_SGMII_FORCE_2500) {
 		set_rtl8367s_sgmii();
 		set_sgmii_force_link(1, 1);
@@ -3801,6 +3810,7 @@ void fe_sw_init(void)
 		enable_auto_negotiate(ei_local);
 		set_sgmii_an(1);
 	}
+#endif
 	if (ei_local->chip_name == LEOPARD_FE) {
 		if (ei_local->architecture & GE2_RAETH_SGMII) {
 			/*bit[1]: gphy connect GMAC0 or GMAC2 1:GMAC0. 0:GMAC2*/
@@ -3813,6 +3823,7 @@ void fe_sw_init(void)
 		}
 	}
 
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 	if (ei_local->architecture & GE2_SGMII_FORCE_2500) {
 		if (ei_local->architecture & SGMII_SWITCH)
 			set_rtl8367s_sgmii();
@@ -3821,6 +3832,7 @@ void fe_sw_init(void)
 		enable_auto_negotiate(ei_local);
 		set_sgmii_an(2);
 	}
+#endif
 
 	if (ei_local->architecture & MT7622_EPHY) {
 		mt7622_ephy_cal();
@@ -3939,16 +3951,22 @@ void fe_sw_deinit(struct END_DEVICE *ei_local)
 	}
 }
 
+void (*esw_link_status_hook)(u32 port_id, int port_link) = NULL;
+EXPORT_SYMBOL(esw_link_status_hook);
+
 static void esw_link_status_changed(int port_no, void *dev_id)
 {
 	unsigned int reg_val;
 
 	mii_mgr_read(31, (0x3008 + (port_no * 0x100)), &reg_val);
-	if (reg_val & 0x1)
+	if (reg_val & 0x1)
 		pr_info("ESW: Link Status Changed - Port%d Link UP\n", port_no);
 	else
 		pr_info("ESW: Link Status Changed - Port%d Link Down\n",
-			port_no);
+			port_no);
+
+	if (esw_link_status_hook)
+		esw_link_status_hook(port_no, reg_val & 0x1);
 }
 
 irqreturn_t gsw_interrupt(int irq, void *resv)
@@ -4140,6 +4158,7 @@ irqreturn_t esw_interrupt(int irq, void *resv)
 
 void sw_ioctl(struct ra_switch_ioctl_data *ioctl_data)
 {
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 	unsigned int cmd;
 
 	cmd = ioctl_data->cmd;
@@ -4286,6 +4305,7 @@ void sw_ioctl(struct ra_switch_ioctl_data *ioctl_data)
 	default:
 		break;
 	}
+#endif
 }
 
 int ephy_ioctl(struct net_device *dev, struct ifreq *ifr,
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.h
index 201a697f..aa243d51 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.h
@@ -13,11 +13,13 @@
 #ifndef RA_SWITCH_H
 #define RA_SWITCH_H
 
+#if !defined (CONFIG_RAETH_ESW_CONTROL)
 #include  "./rtl8367c/include/rtk_switch.h"
 #include  "./rtl8367c/include/rtk_hal.h"
 #include  "./rtl8367c/include/port.h"
 #include  "./rtl8367c/include/vlan.h"
 #include  "./rtl8367c/include/rtl8367c_asicdrv_port.h"
+#endif
 
 extern struct net_device *dev_raether;
 #define ANACAL_INIT		0x01
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_config.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_config.h
index d9eed660..203dc4d0 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_config.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_config.h
@@ -19,7 +19,8 @@
 #define DELAY_INT
 
 #define CONFIG_RAETH_RW_PDMAPTR_FROM_VAR
-/*#define CONFIG_QDMA_QOS_WEB*/
+#define CONFIG_QDMA_SUPPORT_QOS
+/*#define CONFIG_QDMA_QOS_WEB*/
 #define CONFIG_QDMA_QOS_MARK
 
 #if !defined(CONFIG_SOC_MT7621)
@@ -31,7 +32,7 @@
 
 #if defined(CONFIG_SOC_MT7621)
 #define CONFIG_GE1_RGMII_FORCE_1000
-#define CONFIG_GE1_RGMII_FORCE_1200
+//#define CONFIG_GE1_RGMII_FORCE_1200
 #define CONFIG_RA_NETWORK_TASKLET_BH
 #endif
 /*CONFIG_RA_NETWORK_TASKLET_BH*/
@@ -44,12 +45,12 @@
 /* #define CONFIG_RAETH_HW_LRO_FORCE */
 /* #define CONFIG_RAETH_HW_LRO_DVT */
 #define CONFIG_RAETH_HW_VLAN_TX
-/*CONFIG_RAETH_HW_VLAN_RX*/
+#define CONFIG_RAETH_HW_VLAN_RX
 #define CONFIG_RAETH_TSO
 /*#define CONFIG_RAETH_ETHTOOL*/
 #define CONFIG_RAETH_QDMA
-/*CONFIG_RAETH_QDMATX_QDMARX*/
-/*CONFIG_HW_SFQ*/
+/*#define CONFIG_RAETH_QDMATX_QDMARX*/
+/*#define CONFIG_HW_SFQ*/
 #define CONFIG_RAETH_HW_IOCOHERENT
 #define	CONFIG_RAETH_GMAC2
 /*#define CONFIG_RAETH_RSS_4RING*/
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_reg.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_reg.h
index 8078ccfd..2ccae3a8 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_reg.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_reg.h
@@ -121,6 +121,9 @@ extern void __iomem *ethdma_frame_engine_base;
 #define RSTCTL_ETH_RST			BIT(23)
 #define RALINK_ETH_RST			RSTCTL_ETH_RST
 
+#define RSTCTL_PPE_RST			BIT(31)
+#define RALINK_PPE_RST			RSTCTL_PPE_RST
+
 /* FE_INT_STATUS */
 #define RX_COHERENT      BIT(31)
 #define RX_DLY_INT       BIT(30)
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.c
index 78d18004..87a26daf 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.c
@@ -70,27 +70,30 @@ static const char *const mtk_clks_source_name[] = {
 /* reset frame engine */
 static void fe_reset(void)
 {
-	u32 val;
+	u32 val = 0;
 
 	val = sys_reg_read(RSTCTRL);
-	val = val | RALINK_FE_RST;
+	val = val | RALINK_FE_RST | RALINK_PPE_RST;
 	sys_reg_write(RSTCTRL, val);
+	udelay(10);
 
-	val = val & ~(RALINK_FE_RST);
+	val = val & ~(RALINK_FE_RST | RALINK_PPE_RST);
 	sys_reg_write(RSTCTRL, val);
+	udelay(1000);
 }
 
 static void fe_gmac_reset(void)
 {
-	u32 val;
-	/*Reset GMAC */
-	/* sys_reg_write(RALINK_SYSCTL_BASE + 0x34, 0x00800000); */
-	/* sys_reg_write(RALINK_SYSCTL_BASE + 0x34, 0x00000000); */
-	val = sys_reg_read(RALINK_SYSCTL_BASE + 0x34);
-	val |= (1 << 23);
-	sys_reg_write(RALINK_SYSCTL_BASE + 0x34, val);
-	val &= ~(1 << 23);
-	sys_reg_write(RALINK_SYSCTL_BASE + 0x34, val);
+	u32 val = 0;
+
+	val = sys_reg_read(RSTCTRL);
+	val |= RALINK_ETH_RST;
+	sys_reg_write(RSTCTRL, val);
+	udelay(10);
+
+	val &= ~(RALINK_ETH_RST);
+	sys_reg_write(RSTCTRL, val);
+	udelay(1000);
 }
 
 /* Set the hardware MAC address. */
@@ -279,28 +282,43 @@ static int rt2880_eth_recv(struct net_device *dev,
 		/* skb processing */
 		skb_put(rx_skb, length);
 
+		/* rx checksum offload */
+		if (rx_ring->rxd_info4.L4VLD)
+			rx_skb->ip_summed = CHECKSUM_UNNECESSARY;
+		else
+			rx_skb->ip_summed = CHECKSUM_NONE;
+
+	if (ei_local->features & FE_HW_VLAN_RX) {
+		if (rx_ring->rxd_info2.TAG)
+			__vlan_hwaccel_put_tag(rx_skb,
+					       htons(ETH_P_8021Q),
+					       rx_ring->rxd_info3.VID);
+	}
+
 		/* rx packet from GE2 */
 		if (rx_ring->rxd_info4.SP == 2) {
 			if (likely(ei_local->pseudo_dev)) {
 				rx_skb->dev = ei_local->pseudo_dev;
-				rx_skb->protocol =
-				    eth_type_trans(rx_skb,
-						   ei_local->pseudo_dev);
+				//rx_skb->protocol =
+				//    eth_type_trans(rx_skb,
+				//		   ei_local->pseudo_dev);
+				p_ad->stat.rx_packets++;
+				p_ad->stat.rx_bytes += length;
 			} else {
 				pr_err("pseudo_dev is still not initialize ");
 				pr_err("but receive packet from GMAC2\n");
+				rx_skb->dev = dev;
+				dev_kfree_skb_any(rx_skb);
+				ei_local->stat.rx_dropped++;
+				goto skb_skip;
 			}
 		} else {
 			rx_skb->dev = dev;
-			rx_skb->protocol = eth_type_trans(rx_skb, dev);
+			//rx_skb->protocol = eth_type_trans(rx_skb, dev);
+			ei_local->stat.rx_packets++;
+			ei_local->stat.rx_bytes += length;
 		}
 
-		/* rx checksum offload */
-		if (rx_ring->rxd_info4.L4VLD)
-			rx_skb->ip_summed = CHECKSUM_UNNECESSARY;
-		else
-			rx_skb->ip_summed = CHECKSUM_NONE;
-
 #if defined(CONFIG_RA_HW_NAT)  || defined(CONFIG_RA_HW_NAT_MODULE)
 		if (ra_sw_nat_hook_rx) {
 			if (IS_SPACE_AVAILABLE_HEAD(rx_skb)) {
@@ -318,15 +336,23 @@ static int rt2880_eth_recv(struct net_device *dev,
 				FOE_TAG_PROTECT_TAIL(rx_skb) = TAG_PROTECT;
 			}
 		}
+#elif defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+		if (likely(IS_SPACE_AVAILABLE_HEAD(rx_skb))) {
+			*(uint32_t *)(FOE_INFO_START_ADDR_HEAD(rx_skb)) =
+				*(uint32_t *)&rx_ring->rxd_info4;
+			FOE_ALG_HEAD(rx_skb) = 1;
+			FOE_MAGIC_TAG_HEAD(rx_skb) = FOE_MAGIC_GE;
+			FOE_TAG_PROTECT_HEAD(rx_skb) = TAG_PROTECT;
+			if (unlikely(!ra_sw_nat_hook_rx))
+				goto skb_recv;
+			else if (!ra_sw_nat_hook_rx(rx_skb))
+				goto skb_skip;
+		} else
+
+skb_recv:
+			rx_skb->protocol = eth_type_trans(rx_skb, rx_skb->dev);
 #endif
 
-	if (ei_local->features & FE_HW_VLAN_RX) {
-		if (rx_ring->rxd_info2.TAG)
-			__vlan_hwaccel_put_tag(rx_skb,
-					       htons(ETH_P_8021Q),
-					       rx_ring->rxd_info3.VID);
-	}
-
 /* ra_sw_nat_hook_rx return 1 --> continue
  * ra_sw_nat_hook_rx return 0 --> FWD & without netif_rx
  */
@@ -354,18 +380,11 @@ static int rt2880_eth_recv(struct net_device *dev,
 						netif_rx(rx_skb);
 				}
 			}
-#if defined(CONFIG_RA_HW_NAT)  || defined(CONFIG_RA_HW_NAT_MODULE)
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 		}
 #endif
 
-		if (rx_ring->rxd_info4.SP == 2) {
-			p_ad->stat.rx_packets++;
-			p_ad->stat.rx_bytes += length;
-		} else {
-			ei_local->stat.rx_packets++;
-			ei_local->stat.rx_bytes += length;
-		}
-
+skb_skip:
 		/* init RX desc. */
 		fe_rx_desc_init(rx_ring, dma_addr);
 		ei_local->netrx_skb_data[0][rx_dma_owner_idx] = new_data;
@@ -681,7 +700,8 @@ static void ei_func_register(struct END_DEVICE *ei_local)
 	}
 
 	/* HW NAT handling */
-#if defined(CONFIG_RA_HW_NAT)  || defined(CONFIG_RA_HW_NAT_MODULE)
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE) || \
+    defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
 	if (!(ei_local->features & FE_HW_NAT)) {
 		ra_sw_nat_hook_rx = NULL;
 		ra_sw_nat_hook_tx = NULL;
@@ -1879,6 +1899,13 @@ static int fe_int_enable(struct net_device *dev)
 					 "gsw", NULL))
 			pr_err("fail to request irq\n");
 
+		/* enable switch link change intr */
+		mii_mgr_write(31, 0x7008, 0x1f);
+	} else if (ei_local->chip_name == MT7621_FE) {
+		if (request_threaded_irq(ei_local->esw_irq, gsw_interrupt, NULL, 0,
+					 "gsw", NULL))
+			pr_err("fail to request irq\n");
+
 		/* enable switch link change intr */
 		mii_mgr_write(31, 0x7008, 0x1f);
 	}
@@ -2034,7 +2061,8 @@ static int fe_int_disable(struct net_device *dev)
 		free_irq(ei_local->irq2, dev);
 	}
 
-	if (ei_local->architecture & RAETH_ESW)
+	if (ei_local->architecture & RAETH_ESW ||
+	    ei_local->chip_name == MT7621_FE)
 		free_irq(ei_local->esw_irq, dev);
 
 	if (ei_local->features & (FE_RSS_4RING | FE_RSS_2RING))
@@ -2545,12 +2573,15 @@ int ei_open(struct net_device *dev)
 	}
 
 	/* initialize fe and switch register */
-	if (ei_local->chip_name != LEOPARD_FE)
+	if (ei_local->chip_name == MT7622_FE)
 		fe_sw_preinit(ei_local);
 
 	if (ei_local->features & FE_SW_LRO)
 		fe_set_sw_lro_my_ip(ei_local->lan_ip4_addr);
 
+#if defined (CONFIG_RAETH_ESW_CONTROL)
+	esw_ioctl_init_post();
+#endif
 	forward_config(dev);
 
 	if ((ei_local->chip_name == MT7623_FE) &&
@@ -2616,7 +2647,7 @@ int ei_close(struct net_device *dev)
 
 	ei_deinit_dma(dev);
 
-	if (ei_local->chip_name != LEOPARD_FE)
+	if (ei_local->chip_name == MT7622_FE)
 		fe_sw_deinit(ei_local);
 
 	module_put(THIS_MODULE);
@@ -3275,6 +3306,8 @@ static int rather_probe(struct platform_device *pdev)
 		else if (ei_local->architecture & LEOPARD_EPHY)
 			ei_local->esw_irq = platform_get_irq(pdev, 4);
 		pr_info("ei_local->esw_irq = %d\n", ei_local->esw_irq);
+	} else if (ei_local->chip_name == MT7621_FE) {
+		ei_local->esw_irq = platform_get_irq(pdev, 1);
 	}
 
 	ei_clock_enable(ei_local);
@@ -3326,7 +3359,9 @@ static int rather_probe(struct platform_device *pdev)
 		else
 			virtualif_open(ei_local->pseudo_dev);
 	}
-
+#if defined (CONFIG_RAETH_ESW_CONTROL)
+	esw_ioctl_init();
+#endif
 	return 0;
 
 err_free_dev:
@@ -3337,7 +3372,9 @@ err_free_dev:
 static int raether_remove(struct platform_device *pdev)
 {
 	struct END_DEVICE *ei_local = netdev_priv(dev_raether);
-
+#if defined (CONFIG_RAETH_ESW_CONTROL)
+	esw_ioctl_uninit();
+#endif
 	if (ei_local->features & FE_QDMA_FQOS)
 		if (ei_local->qdma_pdev)
 			ei_local->qdma_pdev->dev.release
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.h
index 81e27b72..fa831fb0 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.h
@@ -75,7 +75,8 @@
 #include <linux/platform_device.h>
 #include <linux/pm_runtime.h>
 
-#if defined(CONFIG_RA_HW_NAT)  || defined(CONFIG_RA_HW_NAT_MODULE)
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE) || \
+    defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
 #include <net/ra_nat.h>
 #endif
 
@@ -357,6 +358,12 @@ static inline void ei_lro_flush_all(struct net_lro_mgr *lro_mgr)
 
 struct net_device_stats *ra_get_stats(struct net_device *dev);
 
+#if defined (CONFIG_RAETH_ESW_CONTROL)
+void esw_ioctl_uninit(void);
+int esw_ioctl_init(void);
+int esw_ioctl_init_post(void);
+#endif
+
 int ei_open(struct net_device *dev);
 int ei_close(struct net_device *dev);
 
@@ -373,8 +380,8 @@ u32 mii_mgr_write_cl45(u32 port_num, u32 dev_addr, u32 reg_addr,
 
 /* HNAT functions */
 #if defined(CONFIG_RA_NAT_NONE)
-static int (*ra_sw_nat_hook_rx)(struct sk_buff *skb);
-static int (*ra_sw_nat_hook_tx)(struct sk_buff *skb, int gmac_no);
+//static int (*ra_sw_nat_hook_rx)(struct sk_buff *skb);
+//static int (*ra_sw_nat_hook_tx)(struct sk_buff *skb, int gmac_no);
 #else
 extern int (*ra_sw_nat_hook_rx)(struct sk_buff *skb);
 extern int (*ra_sw_nat_hook_tx)(struct sk_buff *skb, int gmac_no);
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_pdma.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_pdma.c
index 12514e2d..28b4edd7 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_pdma.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_pdma.c
@@ -11,6 +11,9 @@
  * GNU General Public License for more details.
  */
 #include "raether.h"
+#if defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+//#include "mtk_hnat/nf_hnat_mtk.h"
+#endif
 
 int fe_pdma_wait_dma_idle(void)
 {
@@ -253,6 +256,18 @@ int fe_fill_tx_desc(struct net_device *dev,
 			}
 		}
 	}
+#elif defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+	//if (is_to_ppe(skb)) {
+	//	//clr_from_extge(skb);
+	//	txd_info4_tmp.FPORT = 4;
+	//}
+	if (FOE_MAGIC_TAG_HEAD(skb) == FOE_MAGIC_PPE &&
+	    IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) &&
+	    likely(IS_SPACE_AVAILABLE_HEAD(skb))) {
+		/* PPE */
+		FOE_MAGIC_TAG_HEAD(skb) = 0;
+		txd_info4_tmp.FPORT = 4;
+	}
 #endif
 
 	txd_info2_tmp.LS0_bit = 1;
@@ -515,6 +530,18 @@ int fe_fill_tx_desc_tso(struct net_device *dev,
 			}
 		}
 	}
+#elif defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+	//if (is_to_ppe(skb)) {
+	//	//clr_from_extge(skb);
+	//	tx_ring->txd_info4.FPORT = 4;
+	//}
+	if (FOE_MAGIC_TAG_HEAD(skb) == FOE_MAGIC_PPE &&
+	    IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) &&
+	    likely(IS_SPACE_AVAILABLE_HEAD(skb))) {
+		/* PPE */
+		FOE_MAGIC_TAG_HEAD(skb) = 0;
+		tx_ring->txd_info4.FPORT = 4;
+	}
 #endif
 	ei_local->skb_txd_num = 1;
 
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_qdma.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_qdma.c
index a956441f..771a4a6f 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_qdma.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_qdma.c
@@ -14,6 +14,9 @@
 #include "raether.h"
 #include "ra_ioctl.h"
 #include "raether_qdma.h"
+#if defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+//#include "mtk_hnat/nf_hnat_mtk.h"
+#endif
 
 /* skb->mark to queue mapping table */
 struct QDMA_txdesc *free_head;
@@ -645,7 +648,8 @@ int rt2880_qdma_eth_send(struct END_DEVICE *ei_local, struct net_device *dev,
 
 	if ((ei_local->features & QDMA_QOS_MARK) && (skb->mark != 0)) {
 		if (skb->mark < 64) {
-			qidx = M2Q_table[skb->mark];
+			qidx = M2Q_table[skb->mark];
+			//qidx = skb->mark;
 			cpu_ptr->txd_info4.QID = ((qidx & 0x30) >> 4);
 			cpu_ptr->txd_info3.QID = (qidx & 0x0f);
 		} else {
@@ -681,6 +685,17 @@ int rt2880_qdma_eth_send(struct END_DEVICE *ei_local, struct net_device *dev,
 			}
 		}
 	}
+#elif defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+	//if (is_to_ppe(skb)) {
+	//	//clr_from_extge(skb);
+	//	cpu_ptr->txd_info4.FPORT = 4;	/* PPE */
+	//}
+	if (FOE_MAGIC_TAG_HEAD(skb) == FOE_MAGIC_PPE &&
+	    IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) &&
+	    likely(IS_SPACE_AVAILABLE_HEAD(skb))) {
+		FOE_MAGIC_TAG_HEAD(skb) = 0;
+		cpu_ptr->txd_info4.FPORT = 4;	/* PPE */
+	}
 #endif
 
 	/* dma_sync_single_for_device(NULL, virt_to_phys(skb->data), */
@@ -803,7 +818,8 @@ int rt2880_qdma_eth_send_tso(struct END_DEVICE *ei_local,
 	/* cpu_ptr->txd_info3.QID = ring_no; */
 	if ((ei_local->features & QDMA_QOS_MARK) && (skb->mark != 0)) {
 		if (skb->mark < 64) {
-			qidx = M2Q_table[skb->mark];
+			qidx = M2Q_table[skb->mark];
+			//qidx = skb->mark;
 			cpu_ptr->txd_info4.QID = ((qidx & 0x30) >> 4);
 			cpu_ptr->txd_info3.QID = (qidx & 0x0f);
 		} else {
@@ -858,6 +874,17 @@ int rt2880_qdma_eth_send_tso(struct END_DEVICE *ei_local,
 			}
 		}
 	}
+#elif defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
+	//if (is_to_ppe(skb)) {
+	//	//clr_from_extge(skb);
+	//	cpu_ptr->txd_info4.FPORT = 4;	/* PPE */
+	//}
+	if (FOE_MAGIC_TAG_HEAD(skb) == FOE_MAGIC_PPE &&
+	    IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) &&
+	    likely(IS_SPACE_AVAILABLE_HEAD(skb))) {
+		FOE_MAGIC_TAG_HEAD(skb) = 0;
+		cpu_ptr->txd_info4.FPORT = 4;	/* PPE */
+	}
 #endif
 
 	cpu_ptr->txd_info3.SWC_bit = 1;
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/rtl8367c/rtk_hal.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/rtl8367c/rtk_hal.c
index b9373492..6bbeaca2 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/rtl8367c/rtk_hal.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/rtl8367c/rtk_hal.c
@@ -501,10 +501,11 @@ void rtk_hal_qos_get_table2type(struct ra_switch_ioctl_data *data)
 	rtk_api_ret_t ret;
 	rtk_priority_select_t PriDec;
 
-	if (data->qos_table_idx == 0)
+	if (data->qos_table_idx == 0) {
         ret = rtk_qos_priSel_get(PRIDECTBL_IDX0, &PriDec);
-    else
+	} else {
         ret = rtk_qos_priSel_get(PRIDECTBL_IDX1, &PriDec);
+	}
 
 	if (ret != 0)
         printk("rtk_qos_priSel_set failed\n");
diff --git a/trunk/linux-4.4.x/include/net/ra_nat.h b/trunk/linux-4.4.x/include/net/ra_nat.h
index d9399d68..171d995e 100644
--- a/trunk/linux-4.4.x/include/net/ra_nat.h
+++ b/trunk/linux-4.4.x/include/net/ra_nat.h
@@ -154,10 +154,12 @@ struct pdma_rx_desc_info4 {
 #endif
 	uint32_t ALG:1;
 	uint16_t IF:8;
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 	u8 WDMAID;
 	uint16_t RXID:2;
 	uint16_t WCID:8;
 	uint16_t BSSID:6;
+#endif
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 	u16 SOURCE;
 	u16 DEST;
@@ -176,11 +178,12 @@ struct head_rx_descinfo4 {
 	uint32_t ALG:1;
 	uint32_t IF:8;
 	u16 MAGIC_TAG_PROTECT;
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 	u8 WDMAID;
 	uint16_t RXID:2;
 	uint16_t WCID:8;
 	uint16_t BSSID:6;
-
+#endif
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 	u16 SOURCE;
 	u16 DEST;
@@ -200,10 +203,12 @@ struct cb_rx_desc_info4 {
 	uint32_t ALG:1;
 	uint32_t IF:8;
 	u16 MAGIC_TAG_PROTECT1;
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 	u8 WDMAID;
 	uint16_t RXID:2;
 	uint16_t WCID:8;
 	uint16_t BSSID:6;
+#endif
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 	u16 SOURCE;
 	u16 DEST;
@@ -274,19 +279,19 @@ struct cb_rx_desc_info4 {
 	(((struct head_rx_descinfo4 *)((skb)->head))->SPORT)
 #define FOE_MAGIC_TAG(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->IF)
-
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->RXID)
 #define FOE_WC_ID(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->BSSID)
-
+#endif
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 #define FOE_SOURCE(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->SOURCE)
 #define FOE_DEST(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->DEST)
 #endif
 
-#define IS_SPACE_AVAILABLE_HEAD(skb)  \
+#define IS_SPACE_AVAILABLED_HEAD(skb)  \
 	((((skb_headroom(skb) >= FOE_INFO_LEN) ? 1 : 0)))
 #define IS_SPACE_AVAILABLE_HEAD(skb)  \
 	((((skb_headroom(skb) >= FOE_INFO_LEN) ? 1 : 0)))
@@ -317,6 +322,7 @@ struct cb_rx_desc_info4 {
 #define FOE_MAGIC_TAG_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->IF)
 
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID_HEAD(skb)  \
@@ -325,6 +331,7 @@ struct cb_rx_desc_info4 {
 	(((struct head_rx_descinfo4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->BSSID)
+#endif
 
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 #define FOE_SOURCE_HEAD(skb)  \
@@ -333,6 +340,7 @@ struct cb_rx_desc_info4 {
 	(((struct head_rx_descinfo4 *)((skb)->head))->DEST)
 #endif
 
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID_HEAD(skb)  \
@@ -341,6 +349,7 @@ struct cb_rx_desc_info4 {
 	(((struct head_rx_descinfo4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->BSSID)
+#endif
 
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 #define FOE_SOURCE_HEAD(skb)  \
@@ -348,7 +357,7 @@ struct cb_rx_desc_info4 {
 #define FOE_DEST_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->DEST)
 #endif
-#define IS_SPACE_AVAILABLE_TAIL(skb)  \
+#define IS_SPACE_AVAILABLED_TAIL(skb)  \
 	(((skb_tailroom(skb) >= FOE_INFO_LEN) ? 1 : 0))
 #define IS_SPACE_AVAILABLE_TAIL(skb)  \
 	(((skb_tailroom(skb) >= FOE_INFO_LEN) ? 1 : 0))
@@ -388,6 +397,7 @@ struct cb_rx_desc_info4 {
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->DEST)
 #endif
 
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_TAIL(skb)  \
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->WDMAID)
 #define FOE_RX_ID_TAIL(skb)  \
@@ -396,6 +406,7 @@ struct cb_rx_desc_info4 {
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->WCID)
 #define FOE_BSS_ID_TAIL(skb)  \
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->BSSID)
+#endif
 
 /* change the position of skb_CB if necessary */
 #define CB_OFFSET		    40
@@ -421,6 +432,8 @@ struct cb_rx_desc_info4 {
 #define FOE_DEST_CB(skb)	(((struct cb_rx_desc_info4 *)((skb)->cb + CB_OFFSET))->DEST)
 #endif
 
+
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_CB(skb)  \
 	(((struct cb_rx_desc_info4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID_CB(skb)  \
@@ -429,6 +442,7 @@ struct cb_rx_desc_info4 {
 	(((struct cb_rx_desc_info4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID_CB(skb)  \
 	(((struct cb_rx_desc_info4 *)((skb)->head))->BSSID)
+#endif
 
 #define IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb)  \
 	(FOE_TAG_PROTECT_HEAD(skb) == TAG_PROTECT)
@@ -452,6 +466,7 @@ struct cb_rx_desc_info4 {
 	(FOE_MAGIC_TAG_CB(skb) == FOE_MAGIC_WLAN))
 
 /* macros */
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 #define magic_tag_set_zero(skb) \
 { \
 	if ((FOE_MAGIC_TAG_HEAD(skb) == FOE_MAGIC_PCI) || \
@@ -467,13 +482,23 @@ struct cb_rx_desc_info4 {
 			FOE_MAGIC_TAG_TAIL(skb) = 0; \
 	} \
 }
+#else
+#define magic_tag_set_zero(skb) \
+{ \
+	if (IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) && \
+	    likely(IS_SPACE_AVAILABLE_HEAD(skb))) { \
+		FOE_ALG_HEAD(skb) = 1; \
+	} \
+}
+#endif
 
 static inline void hwnat_set_l2tp_unhit(struct iphdr *iph, struct sk_buff *skb)
 {
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 	/* only clear headeroom for TCP OR not L2TP packets */
 	if ((iph->protocol == 0x6) || (ntohs(udp_hdr(skb)->dest) != 1701)) {
-		if (IS_SPACE_AVAILABLE_HEAD(skb)) {
+		if (IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) && \
+		    likely(IS_SPACE_AVAILABLED_HEAD(skb))) {
 			FOE_MAGIC_TAG(skb) = 0;
 			FOE_AI(skb) = UN_HIT;
 		}
diff --git a/trunk/linux-4.4.x/net/core/skbuff.c b/trunk/linux-4.4.x/net/core/skbuff.c
index 1c2408cf..2e677780 100644
--- a/trunk/linux-4.4.x/net/core/skbuff.c
+++ b/trunk/linux-4.4.x/net/core/skbuff.c
@@ -1154,6 +1154,14 @@ int pskb_expand_head(struct sk_buff *skb, int nhead, int ntail,
 		goto nodata;
 	size = SKB_WITH_OVERHEAD(ksize(data));
 
+	/*headroom copy*/
+	memcpy(data, skb->head, FOE_INFO_LEN);
+
+	/*hwnat copy headroom*/
+	hwnat_copy_headroom(data, skb);
+	/*hwnat copy tailroom*/
+	hwnat_copy_tailroom(data, size, skb);
+
 	/* Copy only real data... and, alas, header. This should be
 	 * optimized for the cases when header is void.
 	 */
@@ -1162,14 +1170,6 @@ int pskb_expand_head(struct sk_buff *skb, int nhead, int ntail,
 	memcpy((struct skb_shared_info *)(data + size),
 	       skb_shinfo(skb),
 	       offsetof(struct skb_shared_info, frags[skb_shinfo(skb)->nr_frags]));
-
-	/*headroom copy*/
-	memcpy(data, skb->head, FOE_INFO_LEN);
-
-	/*hwnat copy headroom*/
-	hwnat_copy_headroom(data, skb);
-	/*hwnat copy tailroom*/
-	hwnat_copy_tailroom(data, size, skb);
 	/*remove hwnat information to avoid skb reuse causing error binding*/
 	hwnat_set_headroom_zero(skb);
 	hwnat_set_tailroom_zero(skb);
diff --git a/trunk/linux-4.4.x/net/ipv4/ip_output.c b/trunk/linux-4.4.x/net/ipv4/ip_output.c
index 87c5c049..b2b21dcc 100644
--- a/trunk/linux-4.4.x/net/ipv4/ip_output.c
+++ b/trunk/linux-4.4.x/net/ipv4/ip_output.c
@@ -461,8 +461,11 @@ packet_routed:
 	skb->mark = sk->sk_mark;
 
 	/* hw_nat use*/
+#if defined (CONFIG_RA_HW_NAT_PPTP_L2TP)
 	hwnat_set_l2tp_unhit(iph, skb);
+#else
 	hwnat_check_magic_tag(skb);
+#endif
 
 	res = ip_local_out(net, sk, skb);
 	rcu_read_unlock();
diff --git a/trunk/linux-4.4.x/net/nat/foe_hook/hook.c b/trunk/linux-4.4.x/net/nat/foe_hook/hook.c
index 327021e8..89b2698d 100644
--- a/trunk/linux-4.4.x/net/nat/foe_hook/hook.c
+++ b/trunk/linux-4.4.x/net/nat/foe_hook/hook.c
@@ -11,11 +11,13 @@
 #include <linux/skbuff.h>
 #include <net/ra_nat.h>
 
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 struct net_device	*dst_port[MAX_IF_NUM];
 EXPORT_SYMBOL(dst_port);
 
 struct foe_entry *ppe_virt_foe_base_tmp;
 EXPORT_SYMBOL(ppe_virt_foe_base_tmp);
+#endif
 
 int (*ra_sw_nat_hook_rx)(struct sk_buff *skb) = NULL;
 EXPORT_SYMBOL(ra_sw_nat_hook_rx);
@@ -29,6 +31,7 @@ EXPORT_SYMBOL(ppe_dev_unregister_hook);
 
 void  hwnat_magic_tag_set_zero(struct sk_buff *skb)
 {
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 	if ((FOE_MAGIC_TAG_HEAD(skb) == FOE_MAGIC_PCI) ||
 	    (FOE_MAGIC_TAG_HEAD(skb) == FOE_MAGIC_WLAN) ||
 	    (FOE_MAGIC_TAG_HEAD(skb) == FOE_MAGIC_GE)) {
@@ -41,11 +44,17 @@ void  hwnat_magic_tag_set_zero(struct sk_buff *skb)
 		if (IS_SPACE_AVAILABLE_TAIL(skb))
 			FOE_MAGIC_TAG_TAIL(skb) = 0;
 	}
+#else
+	if (IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) &&
+	    likely(IS_SPACE_AVAILABLE_HEAD(skb)))
+		FOE_ALG_HEAD(skb) = 1;
+#endif
 }
 EXPORT_SYMBOL(hwnat_magic_tag_set_zero);
 
 void hwnat_check_magic_tag(struct sk_buff *skb)
 {
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 	if (IS_SPACE_AVAILABLE_HEAD(skb)) {
 		FOE_MAGIC_TAG_HEAD(skb) = 0;
 		FOE_AI_HEAD(skb) = UN_HIT;
@@ -54,11 +63,19 @@ void hwnat_check_magic_tag(struct sk_buff *skb)
 		FOE_MAGIC_TAG_TAIL(skb) = 0;
 		FOE_AI_TAIL(skb) = UN_HIT;
 	}
+#else
+	if (IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) &&
+	    likely(IS_SPACE_AVAILABLE_HEAD(skb))) {
+		FOE_MAGIC_TAG_HEAD(skb) = 0;
+		FOE_AI_HEAD(skb) = UN_HIT;
+	}
+#endif
 }
 EXPORT_SYMBOL(hwnat_check_magic_tag);
 
 void hwnat_set_headroom_zero(struct sk_buff *skb)
 {
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 	if (skb->cloned != 1) {
 		if (IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) ||
 		    (FOE_MAGIC_TAG(skb) == FOE_MAGIC_PPE)) {
@@ -67,11 +84,20 @@ void hwnat_set_headroom_zero(struct sk_buff *skb)
 				       FOE_INFO_LEN);
 		}
 	}
+#else
+	if (skb->cloned != 1) {
+		if (IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb) &&
+		    likely(IS_SPACE_AVAILABLE_HEAD(skb)))
+				memset(FOE_INFO_START_ADDR_HEAD(skb), 0,
+				       FOE_INFO_LEN);
+	}
+#endif
 }
 EXPORT_SYMBOL(hwnat_set_headroom_zero);
 
 void hwnat_set_tailroom_zero(struct sk_buff *skb)
 {
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 	if (skb->cloned != 1) {
 		if (IS_MAGIC_TAG_PROTECT_VALID_TAIL(skb) ||
 		    (FOE_MAGIC_TAG(skb) == FOE_MAGIC_PPE)) {
@@ -80,19 +106,24 @@ void hwnat_set_tailroom_zero(struct sk_buff *skb)
 				       FOE_INFO_LEN);
 		}
 	}
+#endif
 }
 EXPORT_SYMBOL(hwnat_set_tailroom_zero);
 
 void hwnat_copy_headroom(u8 *data, struct sk_buff *skb)
 {
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 	memcpy(data, skb->head, FOE_INFO_LEN);
+#endif
 }
 EXPORT_SYMBOL(hwnat_copy_headroom);
 
 void hwnat_copy_tailroom(u8 *data, int size, struct sk_buff *skb)
 {
+#if defined(CONFIG_RA_HW_NAT) || defined(CONFIG_RA_HW_NAT_MODULE)
 	memcpy((data + size - FOE_INFO_LEN), (skb_end_pointer(skb) - FOE_INFO_LEN),
 	       FOE_INFO_LEN);
+#endif
 }
 EXPORT_SYMBOL(hwnat_copy_tailroom);
 
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c b/trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c
index 4dcf6e17..68eefd7d 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c
@@ -17,6 +17,7 @@
 #include <linux/timer.h>
 #include <linux/skbuff.h>
 #include <linux/netdevice.h>
+#include <linux/ppp_defs.h>
 
 #include "frame_engine.h"
 #include "foe_fdb.h"
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c b/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c
index 78e651ba..42e1e5ca 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c
@@ -25,9 +25,9 @@
 #include "mcast_tbl.h"
 #endif
 
-unsigned char bind_dir = BIDIRECTION;
-unsigned short lan_vid = CONFIG_RA_HW_NAT_LAN_VLANID;
-unsigned short wan_vid = CONFIG_RA_HW_NAT_WAN_VLANID;
+unsigned char bind_dir __read_mostly = BIDIRECTION;
+unsigned short lan_vid __read_mostly = CONFIG_RA_HW_NAT_LAN_VLANID;
+extern unsigned short wan_vid;
 int debug_level;
 
 #if defined (CONFIG_HW_NAT_IPI)
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c b/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c
index fc750e69..1c9ec2c5 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c
@@ -49,6 +49,11 @@
 #include "util.h"
 #include "hwnat_ioctl.h"
 #include "hwnat_define.h"
+
+unsigned short wan_vid __read_mostly = CONFIG_RA_HW_NAT_WAN_VLANID;
+module_param(wan_vid, ushort, S_IRUGO|S_IWUSR);
+MODULE_PARM_DESC(wan_vid, "VLAN ID for WAN traffic");
+
 struct timer_list hwnat_clear_entry_timer;
 static void hwnat_clear_entry(unsigned long data)
 {
@@ -2104,7 +2109,8 @@ int32_t ppe_setforce_port_info(struct sk_buff *skb, struct foe_entry *entry, int
 	if (IS_IPV4_GRP(entry)) {
 		if (skb->mark > 63)
 			skb->mark = 0;
-		qidx = M2Q_table[skb->mark];
+		qidx = M2Q_table[skb->mark];
+		//qidx = skb->mark;
 #if defined(CONFIG_ARCH_MT7622) 
 		entry->ipv4_hnapt.iblk2.qid1 = ((qidx & 0x30) >> 4);
 #endif
@@ -2129,12 +2135,13 @@ int32_t ppe_setforce_port_info(struct sk_buff *skb, struct foe_entry *entry, int
 	else if (IS_IPV6_GRP(entry)) {
 		if (skb->mark > 63)
 			skb->mark = 0;
-#ifdef CONFIG_PSEUDO_SUPPORT
-		qidx = M2Q_table[skb->mark];
+		qidx = M2Q_table[skb->mark];
+		//qidx = skb->mark;
 #if defined(CONFIG_ARCH_MT7622) 
 		entry->ipv6_3t_route.iblk2.qid1 = ((qidx & 0x30) >> 4);
 #endif
 		entry->ipv6_3t_route.iblk2.qid = (qidx & 0x0f);
+#ifdef CONFIG_PSEUDO_SUPPORT
 		if (lan_wan_separate == 1 && gmac_no == 2) {
 			entry->ipv6_3t_route.iblk2.qid += 8;
 #if defined(CONFIG_HW_SFQ)
@@ -2699,21 +2706,46 @@ defined(CONFIG_MT7610_AP_APCLI) || defined(CONFIG_APCLI_SUPPORT)
 
 	if (IS_IPV4_HNAT(entry) || IS_IPV4_HNAPT(entry)) {
 		entry->ipv4_hnapt.act_dp = offset;
+#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv4_hnapt.iblk2.acnt = offset;
+#else
+		entry->ipv4_hnapt.iblk2.port_mg = 0x3f;
+		entry->ipv4_hnapt.iblk2.port_ag = offset;
+#endif
 	}
 #if defined(CONFIG_RA_HW_NAT_IPV6)
 	else if (IS_IPV4_DSLITE(entry)) {
 		entry->ipv4_dslite.act_dp = offset;
+#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv4_dslite.iblk2.acnt = offset;
+#else
+		entry->ipv4_dslite.iblk2.port_mg = 0x3f;
+		entry->ipv4_dslite.iblk2.port_ag = offset;
+#endif
 	} else if (IS_IPV6_3T_ROUTE(entry)) {
 		entry->ipv6_3t_route.act_dp = offset;
+#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv6_3t_route.iblk2.acnt = offset;
+#else
+		entry->ipv6_3t_route.iblk2.port_mg = 0x3f;
+		entry->ipv6_3t_route.iblk2.port_ag = offset;
+#endif
 	} else if (IS_IPV6_5T_ROUTE(entry)) {
 		entry->ipv6_5t_route.act_dp = offset;
+#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv6_5t_route.iblk2.acnt = offset;
+#else
+		entry->ipv6_5t_route.iblk2.port_mg = 0x3f;
+		entry->ipv6_5t_route.iblk2.port_ag = offset;
+#endif
 	} else if (IS_IPV6_6RD(entry)) {
 		entry->ipv6_6rd.act_dp = offset;
+#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv6_6rd.iblk2.acnt = offset;
+#else
+		entry->ipv6_6rd.iblk2.port_mg = 0x3f;
+		entry->ipv6_6rd.iblk2.port_ag = offset;
+#endif
 	} else {
 		return 1;
 	}
@@ -2763,6 +2795,11 @@ void ppe_set_entry_bind(struct sk_buff *skb, struct foe_entry *entry)
 void ppe_dev_reg_handler(struct net_device *dev)
 {
 	int i;
+
+	/* skip apcli interface */
+	if (strncmp(dev->name, "apcli", 5) == 0)
+		return;
+
 	for (i = 0; i < MAX_IF_NUM; i++) {
 		if (dst_port[i] == dev) {
 			pr_info("%s : %s dst_port table has beed registered(%d)\n", __func__, dev->name, i);
@@ -3068,12 +3105,14 @@ int32_t ppe_tx_handler(struct sk_buff *skb, int gmac_no)
 		if (ppe_parse_result.is_mcast) {
 			foe_mcast_entry_qid(ppe_parse_result.vlan1,
 					    ppe_parse_result.dmac,
-					    M2Q_table[skb->mark]);
+					    M2Q_table[skb->mark]);
+					    //skb->mark);
 #ifdef CONFIG_PSEUDO_SUPPORT
 			if (lan_wan_separate == 1 && gmac_no == 2) {
 				foe_mcast_entry_qid(ppe_parse_result.vlan1,
 						    ppe_parse_result.dmac,
-						    M2Q_table[skb->mark] + 8);
+						    M2Q_table[skb->mark] + 8);
+						    //skb->mark + 8);
 #if defined(CONFIG_HW_SFQ)
 				if (web_sfq_enable == 1 && (skb->mark == 2))
 					foe_mcast_entry_qid(ppe_parse_result.vlan1,
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h b/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h
index 6e3ba731..0e5d25a9 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h
@@ -193,7 +193,12 @@ struct pdma_rx_desc_info4 {
 	u16 MAGIC_TAG_PROTECT;
 	uint32_t foe_entry_num:14;
 	uint32_t CRSN:5;
-	uint32_t SPORT:4;
+	uint32_t SPORT:3;
+#if defined(CONFIG_MACH_LEOPARD)
+	uint32_t foe_entry_num_32:1;
+#else
+	uint32_t rsv:1;
+#endif
 	uint32_t ALG:1;
 	uint16_t IF:8;
 #if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
@@ -211,7 +216,12 @@ struct pdma_rx_desc_info4 {
 struct head_rx_descinfo4 {
 	uint32_t foe_entry_num:14;
 	uint32_t CRSN:5;
-	uint32_t SPORT:4;
+	uint32_t SPORT:3;
+#if defined(CONFIG_MACH_LEOPARD)
+	uint32_t foe_entry_num_32:1;
+#else
+	uint32_t rsv:1;
+#endif
 	uint32_t ALG:1;
 	uint32_t IF:8;
 	u16 MAGIC_TAG_PROTECT;
@@ -231,7 +241,12 @@ struct cb_rx_desc_info4 {
 	u16 MAGIC_TAG_PROTECT0;
 	uint32_t foe_entry_num:14;
 	uint32_t CRSN:5;
-	uint32_t SPORT:4;
+	uint32_t SPORT:3;
+#if defined(CONFIG_MACH_LEOPARD)
+	uint32_t foe_entry_num_32:1;
+#else
+	uint32_t rsv:1;
+#endif
 	uint32_t ALG:1;
 	uint32_t IF:8;
 	u16 MAGIC_TAG_PROTECT1;
@@ -288,8 +303,21 @@ struct cb_rx_desc_info4 {
 
 #define FOE_TAG_PROTECT(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->MAGIC_TAG_PROTECT)
+
+#define FOE_ENTRY_NUM_LSB(skb)  \
+	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num)
+
+#if defined(CONFIG_MACH_LEOPARD)
+#define FOE_ENTRY_NUM_MSB(skb)  \
+	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num_32)
+#define FOE_ENTRY_NUM(skb)  \
+	(((FOE_ENTRY_NUM_MSB(skb) & 0x1) << 14) | FOE_ENTRY_NUM_LSB(skb))
+#else
+#define FOE_ENTRY_NUM_MSB(skb)  \
+	(((struct head_rx_descinfo4 *)((skb)->head))->rsv)
 #define FOE_ENTRY_NUM(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num)
+#endif
 #define FOE_ALG(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->ALG)
 #define FOE_AI(skb)  \
@@ -318,8 +346,20 @@ struct cb_rx_desc_info4 {
 
 #define FOE_TAG_PROTECT_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->MAGIC_TAG_PROTECT)
+#define FOE_ENTRY_NUM_LSB_HEAD(skb)  \
+	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num)
+#if defined(CONFIG_MACH_LEOPARD)
+#define FOE_ENTRY_NUM_MSB_HEAD(skb)  \
+	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num_32)
+#define FOE_ENTRY_NUM_HEAD(skb)  \
+	(((FOE_ENTRY_NUM_MSB_HEAD(skb) & 0x1) << 14) | FOE_ENTRY_NUM_LSB_HEAD(skb))
+#else
+#define FOE_ENTRY_NUM_MSB_HEAD(skb)  \
+	(((struct head_rx_descinfo4 *)((skb)->head))->rsv)
 #define FOE_ENTRY_NUM_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num)
+#endif
+
 #define FOE_ALG_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->ALG)
 #define FOE_AI_HEAD(skb)  \
@@ -373,8 +413,21 @@ struct cb_rx_desc_info4 {
 
 #define FOE_TAG_PROTECT_TAIL(skb)  \
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->MAGIC_TAG_PROTECT)
+#define FOE_ENTRY_NUM_LSB_TAIL(skb)  \
+	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->foe_entry_num)
+
+#if defined(CONFIG_MACH_LEOPARD)
+#define FOE_ENTRY_NUM_MSB_TAIL(skb)  \
+	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->foe_entry_num_32)
+#define FOE_ENTRY_NUM_TAIL(skb)  \
+	(((FOE_ENTRY_NUM_MSB_TAIL(skb) & 0x1) << 14) | FOE_ENTRY_NUM_LSB_TAIL(skb))
+#else
+#define FOE_ENTRY_NUM_MSB_TAIL(skb)  \
+	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->rsv)
 #define FOE_ENTRY_NUM_TAIL(skb)  \
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->foe_entry_num)
+#endif
+
 #define FOE_ALG_TAIL(skb)  \
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->ALG)
 #define FOE_AI_TAIL(skb)  \
@@ -393,13 +446,13 @@ struct cb_rx_desc_info4 {
 
 #if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((skb)->head))->WDMAID)
+	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->WDMAID)
 #define FOE_RX_ID_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((skb)->head))->RXID)
+	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->RXID)
 #define FOE_WC_ID_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((skb)->head))->WCID)
+	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->WCID)
 #define FOE_BSS_ID_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((skb)->head))->BSSID)
+	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->BSSID)
 #endif
 
 /* change the position of skb_CB if necessary */
-- 
2.32.0.windows.2

