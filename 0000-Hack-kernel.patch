From a0857e8a033d0c2355ec441d4b39136c23ce4e04 Mon Sep 17 00:00:00 2001
From: lyh802 <lyh802@126.com>
Date: Mon, 10 Jul 2023 17:00:03 +0000
Subject: [PATCH] Hack kernel

---
 trunk/linux-4.4.x/.gitignore                  |    3 +
 trunk/linux-4.4.x/Kconfig                     |    4 +
 trunk/linux-4.4.x/Makefile                    |   13 +
 trunk/linux-4.4.x/arch/mips/Kconfig           |    4 +
 .../arch/mips/boot/dts/ralink/mt7621.dtsi     |    2 +-
 .../arch/mips/include/asm/dma-mapping.h       |    2 +-
 trunk/linux-4.4.x/arch/mips/pci/pci-mt7621.c  | 1493 ++++-----
 trunk/linux-4.4.x/arch/mips/ralink/mt7621.c   |    3 +-
 trunk/linux-4.4.x/build.config.aarch64        |   11 +
 trunk/linux-4.4.x/build.config.common         |    9 +
 .../build.config.cuttlefish.aarch64           |    5 +
 .../build.config.cuttlefish.x86_64            |    5 +
 trunk/linux-4.4.x/build.config.goldfish.arm   |   13 +
 trunk/linux-4.4.x/build.config.goldfish.arm64 |   13 +
 trunk/linux-4.4.x/build.config.goldfish.mips  |   12 +
 .../linux-4.4.x/build.config.goldfish.mips64  |   12 +
 trunk/linux-4.4.x/build.config.goldfish.x86   |   13 +
 .../linux-4.4.x/build.config.goldfish.x86_64  |   13 +
 trunk/linux-4.4.x/build.config.x86_64         |   11 +
 trunk/linux-4.4.x/drivers/crypto/Kconfig      |    2 +
 trunk/linux-4.4.x/drivers/crypto/Makefile     |    1 +
 .../drivers/crypto/mtk-eip93/Kconfig          |    6 +
 .../drivers/crypto/mtk-eip93/Makefile         |    3 +
 .../drivers/crypto/mtk-eip93/eip93-cipher.c   | 2053 ++++++++++++
 .../drivers/crypto/mtk-eip93/eip93-cipher.h   |   89 +
 .../drivers/crypto/mtk-eip93/eip93-common.h   |  202 ++
 .../drivers/crypto/mtk-eip93/eip93-core.c     |  566 ++++
 .../drivers/crypto/mtk-eip93/eip93-core.h     |   91 +
 .../drivers/crypto/mtk-eip93/eip93-prng.c     |  363 +++
 .../drivers/crypto/mtk-eip93/eip93-prng.h     |   34 +
 .../drivers/crypto/mtk-eip93/eip93-regs.h     |  190 ++
 .../drivers/crypto/mtk-eip93/eip93-ring.c     |   82 +
 .../drivers/crypto/mtk-eip93/eip93-ring.h     |   11 +
 trunk/linux-4.4.x/drivers/gpio/Makefile       |    2 +-
 trunk/linux-4.4.x/drivers/gpio/gpio-sx150x.c  |   49 +-
 trunk/linux-4.4.x/drivers/leds/Makefile       |    2 +
 .../linux-4.4.x/drivers/leds/ledtrig-usbdev.c |  347 ++
 .../linux-4.4.x/drivers/leds/trigger/Kconfig  |   14 +
 trunk/linux-4.4.x/drivers/mtd/Kconfig         |    4 +
 trunk/linux-4.4.x/drivers/mtd/Makefile        |    4 +
 trunk/linux-4.4.x/drivers/mtd/mtdcore.c       |   76 +-
 .../linux-4.4.x/drivers/mtd/mtdsplit/Kconfig  |    6 +
 .../linux-4.4.x/drivers/mtd/mtdsplit/Makefile |    1 +
 .../drivers/mtd/mtdsplit/mtdsplit_asus.c      |  201 ++
 .../drivers/mtd/mtdsplit/mtdsplit_squashfs.c  |   22 +
 .../linux-4.4.x/drivers/mtd/mtk-snand/Kconfig |   14 +
 .../drivers/mtd/mtk-snand/Makefile            |   11 +
 .../drivers/mtd/mtk-snand/mtk-snand-def.h     |  266 ++
 .../drivers/mtd/mtk-snand/mtk-snand-ecc.c     |  264 ++
 .../drivers/mtd/mtk-snand/mtk-snand-ids.c     |  511 +++
 .../drivers/mtd/mtk-snand/mtk-snand-mtd.c     |  730 +++++
 .../drivers/mtd/mtk-snand/mtk-snand-os.c      |   48 +
 .../drivers/mtd/mtk-snand/mtk-snand-os.h      |  133 +
 .../drivers/mtd/mtk-snand/mtk-snand.c         | 1776 ++++++++++
 .../drivers/mtd/mtk-snand/mtk-snand.h         |   77 +
 trunk/linux-4.4.x/drivers/mtd/nand/mtk_nand.c |    4 +
 .../linux-4.4.x/drivers/mtd/nand/mtk_snand.c  |   40 +-
 trunk/linux-4.4.x/drivers/mtd/nand/nand_ids.c |    6 +
 trunk/linux-4.4.x/drivers/mtd/nmbm/Kconfig    |   35 +
 trunk/linux-4.4.x/drivers/mtd/nmbm/Makefile   |    6 +
 .../linux-4.4.x/drivers/mtd/nmbm/nmbm-core.c  | 2814 ++++++++++++++++
 .../linux-4.4.x/drivers/mtd/nmbm/nmbm-debug.h |   20 +
 .../drivers/mtd/nmbm/nmbm-debug.inl           |    0
 trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-mtd.c |  831 +++++
 .../drivers/mtd/nmbm/nmbm-private.h           |  137 +
 trunk/linux-4.4.x/drivers/mtd/ubi/build.c     |    1 -
 trunk/linux-4.4.x/drivers/net/Kconfig         |  119 +
 trunk/linux-4.4.x/drivers/net/Makefile        |    1 +
 trunk/linux-4.4.x/drivers/net/dsa/mt7530.c    |    6 +
 trunk/linux-4.4.x/drivers/net/dsa/mt7530.h    |    4 +
 .../net/ethernet/mediatek/mtk_eth_dbg.c       |  511 ++-
 .../net/ethernet/mediatek/mtk_eth_dbg.h       |  148 +-
 .../net/ethernet/mediatek/mtk_eth_soc.c       |  246 +-
 .../net/ethernet/mediatek/mtk_eth_soc.h       |   88 +-
 .../net/ethernet/mediatek/mtk_hnat/Makefile   |    6 +-
 .../net/ethernet/mediatek/mtk_hnat/hnat.c     |   38 +-
 .../net/ethernet/mediatek/mtk_hnat/hnat.h     |   14 +-
 .../ethernet/mediatek/mtk_hnat/hnat_debugfs.c |  241 +-
 .../ethernet/mediatek/mtk_hnat/hnat_nf_hook.c |  157 +-
 .../net/ethernet/mediatek/mtk_hnat/hnat_sfq.c |  109 +
 .../net/ethernet/mediatek/mtk_hnat/hnat_sfq.h |  152 +
 .../ethernet/mediatek/mtk_hnat/nf_hnat_mtk.h  |    2 +-
 .../drivers/net/ethernet/mediatek/mtk_sgmii.c |   19 +-
 .../drivers/net/ethernet/raeth/Kconfig        |   48 -
 .../drivers/net/ethernet/raeth/Makefile       |    5 -
 .../net/ethernet/raeth/mtk_esw/esw_common.h   |   34 -
 .../net/ethernet/raeth/mtk_esw/ioctl.c        |  238 --
 .../net/ethernet/raeth/mtk_esw/ioctl.h        |  198 --
 .../net/ethernet/raeth/mtk_esw/ioctl_mt762x.c | 1838 -----------
 .../net/ethernet/raeth/mtk_esw/ioctl_mt762x.h |  236 --
 .../drivers/net/ethernet/raeth/mtk_eth_soc.h  |  883 -----
 .../net/ethernet/raeth/mtk_hnat/Makefile      |    4 -
 .../net/ethernet/raeth/mtk_hnat/hnat.c        |  641 ----
 .../net/ethernet/raeth/mtk_hnat/hnat.h        |  814 -----
 .../ethernet/raeth/mtk_hnat/hnat_debugfs.c    | 1903 -----------
 .../net/ethernet/raeth/mtk_hnat/hnat_mcast.c  |  348 --
 .../net/ethernet/raeth/mtk_hnat/hnat_mcast.h  |   69 -
 .../ethernet/raeth/mtk_hnat/hnat_nf_hook.c    | 1991 -----------
 .../net/ethernet/raeth/mtk_hnat/hnat_stag.c   |   55 -
 .../net/ethernet/raeth/mtk_hnat/nf_hnat_mtk.h |  107 -
 .../drivers/net/ethernet/raeth/ra_switch.c    |   15 +-
 .../drivers/net/ethernet/raeth/raeth_config.h |   10 +-
 .../drivers/net/ethernet/raeth/raeth_reg.h    |    3 -
 .../drivers/net/ethernet/raeth/raether.c      |   64 +-
 .../drivers/net/ethernet/raeth/raether.h      |   16 +-
 .../drivers/net/ethernet/raeth/raether_pdma.c |    7 +-
 .../drivers/net/ethernet/raeth/raether_qdma.c |   11 +-
 .../net/ethernet/raeth/rtl8367c/rtk_hal.c     |    5 +-
 trunk/linux-4.4.x/drivers/net/imq.c           |  903 +++++
 trunk/linux-4.4.x/drivers/net/phy/Kconfig     |   25 +
 trunk/linux-4.4.x/drivers/net/phy/Makefile    |    4 +
 trunk/linux-4.4.x/drivers/net/phy/airoha.c    |  396 +++
 trunk/linux-4.4.x/drivers/net/phy/airoha.h    |  178 +
 .../drivers/net/phy/mtk/gphy/Makefile         |    2 +
 .../drivers/net/phy/mtk/gphy/mtk_gphy.c       |  217 ++
 .../drivers/net/phy/mtk/gphy/mtk_gphy_cal.c   | 2187 +++++++++++++
 trunk/linux-4.4.x/drivers/net/phy/mtk_gphy.c  |   53 +
 .../linux-4.4.x/drivers/net/phy/phy_device.c  |   48 +-
 .../linux-4.4.x/drivers/net/phy/rtk/Makefile  |   66 +
 .../drivers/net/phy/rtk/rtl8367s.c            |  580 ++++
 .../drivers/net/phy/rtk/rtl8367s_dbg.c        |  655 ++++
 .../drivers/net/phy/rtk/rtl8367s_mdio.c       |  312 ++
 .../linux-4.4.x/drivers/net/ppp/ppp_generic.c |    2 +-
 trunk/linux-4.4.x/drivers/net/ppp/pppoe.c     |   10 +-
 trunk/linux-4.4.x/drivers/net/usb/ipheth.c    |   10 +-
 trunk/linux-4.4.x/drivers/net/usb/qmi_wwan.c  |   22 +-
 .../drivers/pci/host/pcie-mediatek.c          |    2 +-
 .../drivers/pinctrl/pinctrl-sx150x.c          | 1261 +++++++
 trunk/linux-4.4.x/drivers/spi/spi-mt7621.c    |    4 +-
 trunk/linux-4.4.x/drivers/usb/class/usblp.c   |  244 ++
 trunk/linux-4.4.x/drivers/usb/core/devio.c    |    5 +
 trunk/linux-4.4.x/drivers/usb/core/message.c  |    1 +
 trunk/linux-4.4.x/drivers/usb/core/usb.c      |   65 +
 trunk/linux-4.4.x/drivers/usb/host/Makefile   |    7 +-
 trunk/linux-4.4.x/drivers/usb/host/xhci-hub.c |   12 +-
 trunk/linux-4.4.x/drivers/usb/host/xhci-mem.c |   19 +
 .../drivers/usb/host/xhci-mtk-test.c          |  739 +++++
 .../drivers/usb/host/xhci-mtk-test.h          |   17 +
 trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.c |    7 +
 trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.h |    2 +
 trunk/linux-4.4.x/drivers/usb/host/xhci.c     |   10 +-
 trunk/linux-4.4.x/drivers/usb/host/xhci.h     |    4 +-
 trunk/linux-4.4.x/drivers/usb/serial/option.c |  243 +-
 .../drivers/usb/serial/usb-serial.c           |    3 +
 .../linux-4.4.x/drivers/usb/serial/usb-wwan.h |    3 +
 .../linux-4.4.x/drivers/usb/serial/usb_wwan.c |   13 +
 .../drivers/usb/storage/uas-detect.h          |    4 +-
 .../drivers/usb/storage/unusual_uas.h         |   13 +
 trunk/linux-4.4.x/drivers/watchdog/mtk_wdt.c  |    2 +-
 trunk/linux-4.4.x/fs/jffs2/summary.c          |    2 +-
 trunk/linux-4.4.x/include/linux/gfp.h         |    1 +
 trunk/linux-4.4.x/include/linux/imq.h         |   13 +
 trunk/linux-4.4.x/include/linux/mm.h          |   14 +
 trunk/linux-4.4.x/include/linux/mtd/mtd.h     |    2 +
 trunk/linux-4.4.x/include/linux/netdevice.h   |   15 +
 .../include/linux/netfilter/compat_skbuff.h   |   16 +
 .../include/linux/netfilter/compat_xtables.h  |   92 +
 .../include/linux/netfilter/compat_xtnu.h     |   67 +
 .../linux/netfilter/nf_conntrack_quake3.h     |   16 +
 .../linux/netfilter/nf_conntrack_rtsp.h       |   72 +
 .../include/linux/netfilter/xt_IMQ.h          |    9 +
 .../include/linux/netfilter/xt_condition.h    |   16 +
 .../include/linux/netfilter/xt_ethport.h      |   20 +
 .../include/linux/netfilter/xt_geoip.h        |   58 +
 .../include/linux/netfilter/xt_layer7.h       |   14 +
 .../include/linux/netfilter_helpers.h         |  133 +
 .../include/linux/netfilter_ipv4/ip_autofw.h  |   35 +
 .../include/linux/netfilter_ipv4/ipt_IMQ.h    |   10 +
 .../include/linux/netfilter_ipv4/ipt_ROUTE.h  |   23 +
 .../include/linux/netfilter_ipv4/ipt_TOS.h    |   12 +
 .../linux/netfilter_ipv4/ipt_TRIGGER.h        |   25 +
 .../include/linux/netfilter_ipv4/ipt_geoip.h  |   24 +
 .../include/linux/netfilter_ipv4/ipt_ipp2p.h  |   31 +
 .../include/linux/netfilter_ipv4/ipt_tos.h    |   13 +
 .../include/linux/netfilter_ipv4/ipt_web.h    |   30 +
 .../include/linux/netfilter_ipv4/ipt_webmon.h |   63 +
 .../include/linux/netfilter_ipv6/ip6t_IMQ.h   |   10 +
 .../include/linux/netfilter_ipv6/ip6t_ROUTE.h |   23 +
 .../include/linux/netfilter_mime.h            |   89 +
 trunk/linux-4.4.x/include/linux/netlink.h     |    8 +
 trunk/linux-4.4.x/include/linux/skbuff.h      |   38 +-
 .../include/linux/swrt_fastpath/fast_path.h   |    6 +
 trunk/linux-4.4.x/include/linux/timer.h       |    5 +-
 trunk/linux-4.4.x/include/linux/usb.h         |    1 +
 trunk/linux-4.4.x/include/linux/vmalloc.h     |    1 +
 trunk/linux-4.4.x/include/net/mtk_esp.h       |  421 +++
 .../net/netfilter/nf_conntrack_ecache.h       |   14 +-
 .../include/net/netfilter/nf_hnat.h           |    4 +-
 .../include/net/netfilter/nf_nat.h            |    6 +
 .../include/net/netfilter/nf_nat_l4proto.h    |    6 +-
 .../include/net/netfilter/nf_nat_rule.h       |   15 +
 .../include/net/netfilter/nf_queue.h          |    7 +
 trunk/linux-4.4.x/include/net/pkt_sched.h     |    2 +
 trunk/linux-4.4.x/include/net/ra_nat.h        |   85 -
 trunk/linux-4.4.x/include/net/sch_generic.h   |    6 +
 trunk/linux-4.4.x/include/nmbm/nmbm-os.h      |   68 +
 trunk/linux-4.4.x/include/nmbm/nmbm.h         |   96 +
 .../include/uapi/linux/ip6_tunnel.h           |    2 +
 .../include/uapi/linux/netfilter.h            |    4 +-
 .../include/uapi/linux/netfilter/Kbuild       |    5 +-
 .../linux/netfilter/nf_conntrack_common.h     |    3 +
 .../netfilter/nf_conntrack_tuple_common.h     |    7 +
 .../include/uapi/linux/netfilter/nf_nat.h     |    3 +-
 .../uapi/linux/netfilter/xt_connmark.h        |    3 +-
 .../include/uapi/linux/netfilter/xt_ethport.h |   20 +
 .../include/uapi/linux/netfilter/xt_geoip.h   |   53 +
 .../include/uapi/linux/netfilter/xt_layer7.h  |   14 +
 .../include/uapi/linux/netfilter_ipv4/Kbuild  |    7 +
 .../uapi/linux/netfilter_ipv4/ipt_ROUTE.h     |   23 +
 .../uapi/linux/netfilter_ipv4/ipt_TOS.h       |   12 +
 .../uapi/linux/netfilter_ipv4/ipt_TRIGGER.h   |   25 +
 .../uapi/linux/netfilter_ipv4/ipt_geoip.h     |   24 +
 .../uapi/linux/netfilter_ipv4/ipt_ipp2p.h     |   31 +
 .../uapi/linux/netfilter_ipv4/ipt_tos.h       |   13 +
 .../uapi/linux/netfilter_ipv4/ipt_web.h       |   30 +
 .../include/uapi/linux/netfilter_ipv6/Kbuild  |    1 +
 .../uapi/linux/netfilter_ipv6/ip6t_ROUTE.h    |   23 +
 .../linux-4.4.x/include/uapi/linux/netlink.h  |    1 +
 .../include/uapi/linux/wapp/wapp_cmm_type.h   |   29 +-
 trunk/linux-4.4.x/kernel/irq/irqdesc.c        |    1 +
 trunk/linux-4.4.x/kernel/pid.c                |    1 +
 trunk/linux-4.4.x/mm/oom_kill.c               |   24 +-
 trunk/linux-4.4.x/mm/util.c                   |   45 +
 trunk/linux-4.4.x/mm/vmalloc.c                |    2 +-
 trunk/linux-4.4.x/net/8021q/vlan_dev.c        |    5 +-
 trunk/linux-4.4.x/net/Kconfig                 |   14 +-
 trunk/linux-4.4.x/net/Makefile                |    1 +
 trunk/linux-4.4.x/net/bridge/Kconfig          |    5 +
 trunk/linux-4.4.x/net/bridge/Makefile         |    2 +
 trunk/linux-4.4.x/net/bridge/br_fdb.c         |   13 +-
 trunk/linux-4.4.x/net/bridge/br_if.c          |    4 +-
 trunk/linux-4.4.x/net/bridge/br_oop.c         |  107 +
 trunk/linux-4.4.x/net/core/dev.c              |   18 +-
 trunk/linux-4.4.x/net/core/rtnetlink.c        |   18 +-
 trunk/linux-4.4.x/net/core/skbuff.c           |  126 +
 trunk/linux-4.4.x/net/ipv4/Makefile           |    5 +
 trunk/linux-4.4.x/net/ipv4/esp4.c             |   18 +
 trunk/linux-4.4.x/net/ipv4/ip_input.c         |   16 +-
 trunk/linux-4.4.x/net/ipv4/ip_output.c        |   21 +-
 trunk/linux-4.4.x/net/ipv4/mtk_esp4.c         | 2904 +++++++++++++++++
 trunk/linux-4.4.x/net/ipv4/netfilter/Kconfig  |  101 +-
 trunk/linux-4.4.x/net/ipv4/netfilter/Makefile |   21 +
 trunk/linux-4.4.x/net/ipv4/netfilter/dnsmq.c  |  372 +++
 .../net/ipv4/netfilter/ip_tables.c            |   17 +
 .../net/ipv4/netfilter/ipt_MASQUERADE.c       |    2 +
 .../net/ipv4/netfilter/ipt_ROUTE.c            |  501 +++
 .../linux-4.4.x/net/ipv4/netfilter/ipt_TOS.c  |   76 +
 .../net/ipv4/netfilter/ipt_TRIGGER.c          |  447 +++
 .../net/ipv4/netfilter/ipt_ipp2p.c            |  780 +++++
 .../linux-4.4.x/net/ipv4/netfilter/ipt_tos.c  |   47 +
 .../linux-4.4.x/net/ipv4/netfilter/ipt_web.c  |  214 ++
 .../net/ipv4/netfilter/ipt_webmon.c           | 1053 ++++++
 .../ipv4/netfilter/nf_nat_masquerade_ipv4.c   |   46 +-
 .../net/ipv4/netfilter/nf_nat_proto_icmp.c    |   37 +-
 .../net/ipv4/netfilter/nf_nat_quake3.c        |   92 +
 .../net/ipv4/netfilter/nf_nat_rtsp.c          |  617 ++++
 .../linux-4.4.x/net/ipv4/netfilter/tree_map.h | 1084 ++++++
 .../net/ipv4/xfrm4_mode_transport.c           |   22 +
 .../linux-4.4.x/net/ipv4/xfrm4_mode_tunnel.c  |   22 +
 trunk/linux-4.4.x/net/ipv6/addrconf.c         |   47 +-
 trunk/linux-4.4.x/net/ipv6/ip6_output.c       |   11 +
 trunk/linux-4.4.x/net/ipv6/ip6_tunnel.c       |    4 +-
 trunk/linux-4.4.x/net/ipv6/ndisc.c            |    4 +-
 .../net/ipv6/netfilter/nf_nat_proto_icmpv6.c  |    6 +-
 trunk/linux-4.4.x/net/ipv6/route.c            |    5 +-
 trunk/linux-4.4.x/net/ipv6/sit.c              |   18 +
 trunk/linux-4.4.x/net/l2tp/l2tp_core.c        |    2 +-
 trunk/linux-4.4.x/net/l2tp/l2tp_ppp.c         |    2 +-
 trunk/linux-4.4.x/net/nat/hw_nat/fast_path.c  |    2 +-
 trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c    |    1 -
 .../linux-4.4.x/net/nat/hw_nat/hwnat_config.h |    2 +-
 .../linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c  |    6 +-
 trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c     |   74 +-
 trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h     |  239 +-
 trunk/linux-4.4.x/net/netfilter/Kconfig       |  253 +-
 trunk/linux-4.4.x/net/netfilter/Makefile      |   31 +
 trunk/linux-4.4.x/net/netfilter/core.c        |   12 +-
 .../net/netfilter/nf_conntrack_core.c         |    3 +
 .../net/netfilter/nf_conntrack_expect.c       |    2 +-
 .../net/netfilter/nf_conntrack_netlink.c      |    4 +-
 .../net/netfilter/nf_conntrack_proto_tcp.c    |    2 +-
 .../net/netfilter/nf_conntrack_quake3.c       |  200 ++
 .../net/netfilter/nf_conntrack_rtsp.c         |  576 ++++
 .../net/netfilter/nf_conntrack_standalone.c   |    2 +-
 .../linux-4.4.x/net/netfilter/nf_internals.h  |    2 +-
 trunk/linux-4.4.x/net/netfilter/nf_nat_core.c |   16 +-
 .../net/netfilter/nf_nat_proto_common.c       |   49 +-
 .../net/netfilter/nf_nat_proto_unknown.c      |    3 +-
 trunk/linux-4.4.x/net/netfilter/nf_queue.c    |   41 +-
 trunk/linux-4.4.x/net/netfilter/nf_shortcut.c |  177 +
 .../net/netfilter/nf_shortcut_hook.c          |   17 +
 trunk/linux-4.4.x/net/netfilter/xt_IMQ.c      |   72 +
 .../linux-4.4.x/net/netfilter/xt_condition.c  |  241 ++
 trunk/linux-4.4.x/net/netfilter/xt_connmark.c |    9 +
 trunk/linux-4.4.x/net/netfilter/xt_ethport.c  |   84 +
 trunk/linux-4.4.x/net/netfilter/xt_geoip.c    |  371 +++
 trunk/linux-4.4.x/net/netfilter/xt_layer7.c   |  705 ++++
 trunk/linux-4.4.x/net/netfilter/xt_mac.c      |    4 +-
 trunk/linux-4.4.x/net/netfilter/xt_webstr.c   |  580 ++--
 trunk/linux-4.4.x/net/sched/cobalt_compat.h   |    4 +-
 trunk/linux-4.4.x/net/sched/sch_generic.c     |    8 +
 trunk/linux-4.4.x/net/swrt_fastpath/Makefile  |    4 +
 .../net/swrt_fastpath/fast_path.obj           |  Bin 0 -> 6996 bytes
 trunk/linux-4.4.x/net/xfrm/xfrm_input.c       |   12 +
 trunk/linux-4.4.x/net/xfrm/xfrm_output.c      |   24 +-
 trunk/linux-4.4.x/net/xfrm/xfrm_state.c       |   15 +
 trunk/linux-4.4.x/ralink/Kconfig              |  420 +++
 trunk/linux-4.4.x/ralink/Kconfig.misc         |   34 +
 308 files changed, 37547 insertions(+), 11364 deletions(-)
 create mode 100644 trunk/linux-4.4.x/build.config.aarch64
 create mode 100644 trunk/linux-4.4.x/build.config.common
 create mode 100644 trunk/linux-4.4.x/build.config.cuttlefish.aarch64
 create mode 100644 trunk/linux-4.4.x/build.config.cuttlefish.x86_64
 create mode 100644 trunk/linux-4.4.x/build.config.goldfish.arm
 create mode 100644 trunk/linux-4.4.x/build.config.goldfish.arm64
 create mode 100644 trunk/linux-4.4.x/build.config.goldfish.mips
 create mode 100644 trunk/linux-4.4.x/build.config.goldfish.mips64
 create mode 100644 trunk/linux-4.4.x/build.config.goldfish.x86
 create mode 100644 trunk/linux-4.4.x/build.config.goldfish.x86_64
 create mode 100644 trunk/linux-4.4.x/build.config.x86_64
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/Kconfig
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/Makefile
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-cipher.c
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-cipher.h
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-common.h
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-core.c
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-core.h
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-prng.c
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-prng.h
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-regs.h
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-ring.c
 create mode 100644 trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-ring.h
 create mode 100644 trunk/linux-4.4.x/drivers/leds/ledtrig-usbdev.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtdsplit/mtdsplit_asus.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/Kconfig
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/Makefile
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-def.h
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-ecc.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-ids.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-mtd.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-os.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-os.h
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand.h
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/nmbm/Kconfig
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/nmbm/Makefile
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-core.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-debug.h
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-debug.inl
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-mtd.c
 create mode 100644 trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-private.h
 create mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_sfq.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_sfq.h
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/esw_common.h
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.c
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.h
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.c
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.h
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_eth_soc.h
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/Makefile
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat.c
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat.h
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_debugfs.c
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_mcast.c
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_mcast.h
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_nf_hook.c
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_stag.c
 delete mode 100644 trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/nf_hnat_mtk.h
 create mode 100644 trunk/linux-4.4.x/drivers/net/imq.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/airoha.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/airoha.h
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/Makefile
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/mtk_gphy.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/mtk_gphy_cal.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/mtk_gphy.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/rtk/Makefile
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s_dbg.c
 create mode 100644 trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s_mdio.c
 create mode 100644 trunk/linux-4.4.x/drivers/pinctrl/pinctrl-sx150x.c
 create mode 100644 trunk/linux-4.4.x/drivers/usb/host/xhci-mtk-test.c
 create mode 100644 trunk/linux-4.4.x/drivers/usb/host/xhci-mtk-test.h
 create mode 100644 trunk/linux-4.4.x/include/linux/imq.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/compat_skbuff.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/compat_xtables.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/compat_xtnu.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/nf_conntrack_quake3.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/nf_conntrack_rtsp.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/xt_IMQ.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/xt_condition.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/xt_ethport.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/xt_geoip.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter/xt_layer7.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_helpers.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ip_autofw.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_IMQ.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_ROUTE.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_TOS.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_TRIGGER.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_geoip.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_ipp2p.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_tos.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_web.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_webmon.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv6/ip6t_IMQ.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_ipv6/ip6t_ROUTE.h
 create mode 100644 trunk/linux-4.4.x/include/linux/netfilter_mime.h
 create mode 100644 trunk/linux-4.4.x/include/linux/swrt_fastpath/fast_path.h
 create mode 100644 trunk/linux-4.4.x/include/net/mtk_esp.h
 create mode 100644 trunk/linux-4.4.x/include/net/netfilter/nf_nat_rule.h
 create mode 100644 trunk/linux-4.4.x/include/nmbm/nmbm-os.h
 create mode 100644 trunk/linux-4.4.x/include/nmbm/nmbm.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_ethport.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_geoip.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_layer7.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_ROUTE.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_TOS.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_TRIGGER.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_geoip.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_ipp2p.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_tos.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_web.h
 create mode 100644 trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv6/ip6t_ROUTE.h
 create mode 100644 trunk/linux-4.4.x/net/bridge/br_oop.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/mtk_esp4.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/dnsmq.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/ipt_ROUTE.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/ipt_TOS.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/ipt_TRIGGER.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/ipt_ipp2p.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/ipt_tos.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/ipt_web.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/ipt_webmon.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_quake3.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_rtsp.c
 create mode 100644 trunk/linux-4.4.x/net/ipv4/netfilter/tree_map.h
 create mode 100644 trunk/linux-4.4.x/net/netfilter/nf_conntrack_quake3.c
 create mode 100644 trunk/linux-4.4.x/net/netfilter/nf_conntrack_rtsp.c
 create mode 100644 trunk/linux-4.4.x/net/netfilter/nf_shortcut.c
 create mode 100644 trunk/linux-4.4.x/net/netfilter/nf_shortcut_hook.c
 create mode 100644 trunk/linux-4.4.x/net/netfilter/xt_IMQ.c
 create mode 100644 trunk/linux-4.4.x/net/netfilter/xt_condition.c
 create mode 100644 trunk/linux-4.4.x/net/netfilter/xt_ethport.c
 create mode 100644 trunk/linux-4.4.x/net/netfilter/xt_geoip.c
 create mode 100644 trunk/linux-4.4.x/net/netfilter/xt_layer7.c
 create mode 100644 trunk/linux-4.4.x/net/swrt_fastpath/Makefile
 create mode 100644 trunk/linux-4.4.x/net/swrt_fastpath/fast_path.obj
 create mode 100644 trunk/linux-4.4.x/ralink/Kconfig
 create mode 100644 trunk/linux-4.4.x/ralink/Kconfig.misc

diff --git a/trunk/linux-4.4.x/.gitignore b/trunk/linux-4.4.x/.gitignore
index 34fe1346a..b17dcd217 100644
--- a/trunk/linux-4.4.x/.gitignore
+++ b/trunk/linux-4.4.x/.gitignore
@@ -113,3 +113,6 @@ all.config
 
 # Kdevelop4
 *.kdev4
+
+# fetched Android config fragments
+android/configs/android-*.cfg
diff --git a/trunk/linux-4.4.x/Kconfig b/trunk/linux-4.4.x/Kconfig
index c13f48d65..5e6dab044 100644
--- a/trunk/linux-4.4.x/Kconfig
+++ b/trunk/linux-4.4.x/Kconfig
@@ -8,4 +8,8 @@ config SRCARCH
 	string
 	option env="SRCARCH"
 
+config SUPPORT_OPENWRT
+	bool "Support OpenWrt"
+	default n
+
 source "arch/$SRCARCH/Kconfig"
diff --git a/trunk/linux-4.4.x/Makefile b/trunk/linux-4.4.x/Makefile
index 2ea39ceef..ab88f8381 100644
--- a/trunk/linux-4.4.x/Makefile
+++ b/trunk/linux-4.4.x/Makefile
@@ -395,6 +395,8 @@ KBUILD_CFLAGS   := -Wall -Wundef -Wstrict-prototypes -Wno-trigraphs \
 		   -Wno-format-security \
 		   -std=gnu89 $(call cc-option,-fno-PIE)
 
+#MODEL = $(subst -,,$(BUILD_NAME))
+#KBUILD_CFLAGS += -D$(MODEL)
 
 KBUILD_AFLAGS_KERNEL :=
 KBUILD_CFLAGS_KERNEL :=
@@ -477,6 +479,9 @@ asm-generic:
 version_h := include/generated/uapi/linux/version.h
 old_version_h := include/linux/version.h
 
+#ASUS EXT
+#include/linux/version.h: include/generated/uapi/linux/version.h
+
 no-dot-config-targets := clean mrproper distclean \
 			 cscope gtags TAGS tags help% %docs check% coccicheck \
 			 $(version_h) headers_% archheaders archscripts \
@@ -642,6 +647,14 @@ KBUILD_CFLAGS	+= $(call cc-disable-warning, int-in-bool-context)
 KBUILD_CFLAGS	+= $(call cc-disable-warning, address-of-packed-member)
 KBUILD_CFLAGS	+= $(call cc-disable-warning, attribute-alias)
 
+#ifneq ($(wildcard ./net/swrt_fastpath/*.c),)
+#KBUILD_CFLAGS += -DPGB_QUICK_PATH
+#export PGB_QUICK_PATH=y
+#else ifneq ($(wildcard ./net/swrt_fastpath/*.obj),)
+#KBUILD_CFLAGS += -DPGB_QUICK_PATH
+#export PGB_QUICK_PATH=y
+#endif
+
 ifdef CONFIG_CC_OPTIMIZE_FOR_SIZE
 KBUILD_CFLAGS	+= -Os $(EXTRA_OPTIMIZATION)
 else
diff --git a/trunk/linux-4.4.x/arch/mips/Kconfig b/trunk/linux-4.4.x/arch/mips/Kconfig
index 17bf5beb2..92732a882 100644
--- a/trunk/linux-4.4.x/arch/mips/Kconfig
+++ b/trunk/linux-4.4.x/arch/mips/Kconfig
@@ -3122,3 +3122,7 @@ source "crypto/Kconfig"
 source "lib/Kconfig"
 
 source "arch/mips/kvm/Kconfig"
+
+#source "ralink/Kconfig"
+
+#source "ralink/Kconfig.misc"
diff --git a/trunk/linux-4.4.x/arch/mips/boot/dts/ralink/mt7621.dtsi b/trunk/linux-4.4.x/arch/mips/boot/dts/ralink/mt7621.dtsi
index c1515f902..c349f27f4 100644
--- a/trunk/linux-4.4.x/arch/mips/boot/dts/ralink/mt7621.dtsi
+++ b/trunk/linux-4.4.x/arch/mips/boot/dts/ralink/mt7621.dtsi
@@ -452,7 +452,7 @@
 		u2port0: usb-phy@0x1e1d0800 {
 			reg = <0x1e1d0800 0x00000100>;
 			#phy-cells = <1>;
-		clocks = <&sysclock125M>;
+			clocks = <&sysclock125M>;
 			clock-names = "ref";
 		};
 
diff --git a/trunk/linux-4.4.x/arch/mips/include/asm/dma-mapping.h b/trunk/linux-4.4.x/arch/mips/include/asm/dma-mapping.h
index 19a79d998..7db238a53 100644
--- a/trunk/linux-4.4.x/arch/mips/include/asm/dma-mapping.h
+++ b/trunk/linux-4.4.x/arch/mips/include/asm/dma-mapping.h
@@ -72,7 +72,7 @@ static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
 	if (!dev->dma_mask)
 		return false;
 
-	return addr + size -1 <= *dev->dma_mask;
+	return addr + size - 1 <= *dev->dma_mask;
 }
 
 static inline void dma_mark_clean(void *addr, size_t size) {}
diff --git a/trunk/linux-4.4.x/arch/mips/pci/pci-mt7621.c b/trunk/linux-4.4.x/arch/mips/pci/pci-mt7621.c
index 8ea82377b..98aa83afd 100644
--- a/trunk/linux-4.4.x/arch/mips/pci/pci-mt7621.c
+++ b/trunk/linux-4.4.x/arch/mips/pci/pci-mt7621.c
@@ -1,958 +1,753 @@
-/**************************************************************************
- *
- *  BRIEF MODULE DESCRIPTION
- *     PCI init for Ralink RT2880 solution
- *
- *  Copyright 2007 Ralink Inc. (bruce_chang@ralinktech.com.tw)
- *
- *  This program is free software; you can redistribute  it and/or modify it
- *  under  the terms of  the GNU General  Public License as published by the
- *  Free Software Foundation;  either version 2 of the  License, or (at your
- *  option) any later version.
- *
- *  THIS  SOFTWARE  IS PROVIDED   ``AS  IS'' AND   ANY  EXPRESS OR IMPLIED
- *  WARRANTIES,   INCLUDING, BUT NOT  LIMITED  TO, THE IMPLIED WARRANTIES OF
- *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN
- *  NO  EVENT  SHALL   THE AUTHOR  BE    LIABLE FOR ANY   DIRECT, INDIRECT,
- *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
- *  NOT LIMITED   TO, PROCUREMENT OF  SUBSTITUTE GOODS  OR SERVICES; LOSS OF
- *  USE, DATA,  OR PROFITS; OR  BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
- *  ANY THEORY OF LIABILITY, WHETHER IN  CONTRACT, STRICT LIABILITY, OR TORT
- *  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
- *  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- *  You should have received a copy of the  GNU General Public License along
- *  with this program; if not, write  to the Free Software Foundation, Inc.,
- *  675 Mass Ave, Cambridge, MA 02139, USA.
- *
- *
- **************************************************************************
- * May 2007 Bruce Chang
- * Initial Release
+/*
+ * MediaTek MT7621 PCIe host support
  *
- * May 2009 Bruce Chang
- * support RT2880/RT3883 PCIe
+ * Copyright (C) 2018 MediaTek Inc.
+ * Author: Ryder Lee <ryder.lee@mediatek.com>
+ *	   Weijie Gao <weijie.gao@mediatek.com>
  *
- * May 2011 Bruce Chang
- * support RT6855/MT7620 PCIe
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
  *
- **************************************************************************
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
  */
 
-#include <linux/types.h>
+#include <asm/addrspace.h>
+#include <linux/irq.h>
 #include <linux/pci.h>
-#include <linux/kernel.h>
-#include <linux/slab.h>
-#include <linux/version.h>
-#include <asm/pci.h>
-#include <asm/io.h>
-#include <asm/mips-cm.h>
-#include <linux/init.h>
-#include <linux/module.h>
+#include <linux/reset.h>
 #include <linux/delay.h>
-#include <linux/of.h>
-#include <linux/of_pci.h>
+#include <linux/module.h>
+#include <linux/bitops.h>
+#include <linux/of_gpio.h>
 #include <linux/platform_device.h>
-#include <asm/rt2880/rt_mmap.h>
-#include <ralink_regs.h>
-#include <asm/rt2880/eureka_ep430.h>
-extern void pcie_phy_init(void);
-extern void chk_phy_pll(void);
+#include <asm/mach-ralink/mt7621.h>
+#include <asm/mach-ralink/ralink_regs.h>
+
+#define PCIE_IO_PORT_BASE		0x1e160000
+#define PCIE_IO_PORT_SIZE		0x10000
+
+#define PCIE_IO_MEM_BASE		0x60000000
+#define PCIE_IO_MEM_SIZE		0x10000000
+
+#define PCIE_CONFIG_REG			0x00
+#define PCIE_P2P_BR_DEVNUM_SHIFT(p)	(16 + (p) * 4)
+#define PCIE_P2P_BR_DEVNUM0_SHIFT	PCIE_P2P_BR_DEVNUM_SHIFT(0)
+#define PCIE_P2P_BR_DEVNUM1_SHIFT	PCIE_P2P_BR_DEVNUM_SHIFT(1)
+#define PCIE_P2P_BR_DEVNUM2_SHIFT	PCIE_P2P_BR_DEVNUM_SHIFT(2)
+#define PCIE_P2P_BR_DEVNUM_MASK		0xf
+#define PCIE_P2P_BR_DEVNUM_MASK_FULL	(0xfff << PCIE_P2P_BR_DEVNUM0_SHIFT)
+#define PCIE_EP_RESET_L			BIT(1)
+
+#define PCIE_INT_ENABLE_REG		0x0c
+#define PCIE_INT_PORT(p)		BIT(20 + (p))
+#define PCIE_INT_PORT0			PCIE_INT_PORT(0)
+#define PCIE_INT_PORT1			PCIE_INT_PORT(1)
+#define PCIE_INT_PORT2			PCIE_INT_PORT(2)
+
+#define PCIE_CFGADDR_REG		0x20
+#define PCIE_EXTREGNUM_SHIFT		24
+#define PCIE_EXTREGNUM_MASK		0xf
+#define PCIE_BUSNUM_SHIFT		16
+#define PCIE_BUSNUM_MASK		0xff
+#define PCIE_DEVICENUM_SHIFT		11
+#define PCIE_DEVICENUM_MASK		0x1f
+#define PCIE_FUNNUM_SHIFT		8
+#define PCIE_FUNNUM_MASK		0x7
+#define PCIE_REGNUM_SHIFT		2
+#define PCIE_REGNUM_MASK		0x3f
+
+#define PCIE_CFGDATA_REG		0x24
+
+#define PCIE_MEMBASE_REG		0x28
+#define PCIE_IOBASE_REG			0x2c
+
+/* PCIe Port registers */
+#define PCIE_PORT_REG_BASE(p)		(0x1000 * ((p) + 2))
+
+#define PCIE_BAR0SETUP_REG(p)		(PCIE_PORT_REG_BASE(p) + 0x10)
+#define PCIE_BAR1SETUP_REG(p)		(PCIE_PORT_REG_BASE(p) + 0x14)
+#define PCIE_BARMSK_SHIFT		16
+#define PCIE_BARMSK_MASK		0xffff
+#define PCIE_BAR_ENABLE			BIT(0)
+
+#define PCIE_IMBASEBAR0_REG(p)		(PCIE_PORT_REG_BASE(p) + 0x18)
+#define PCIE_IMBASEBAR0_SHIFT		15
+#define PCIE_IMBASEBAR0_MASK		0x1ffff
+
+#define PCIE_PORT_CLASS_REG(p)		(PCIE_PORT_REG_BASE(p) + 0x34)
+#define PCIE_CCODE_SHIFT		8
+#define PCIE_CCODE_MASK			0xffffff
+#define PCIE_REVID_SHIFT		0
+#define PCIE_REVID_MASK			0xff
+
+#define PCIE_PORT_STATUS_REG(p)		(PCIE_PORT_REG_BASE(p) + 0x50)
+#define PCIE_PORT_LINK_UP		BIT(0)
+
+/* PCIe PHY registers */
+#define PCIEPHY_P0P1_CTL_REG		0x9000
+#define PCIEPHY_P2_CTL_REG		0xA000
+
+#define PE1_PIPE_RST			BIT(12)
+#define PE1_PIPE_CMD_FRC		BIT(4)
+
+#define PE1_FORCE_H_XTAL_TYPE		BIT(8)
+#define PE1_H_XTAL_TYPE_SHIFT		9
+#define PE1_H_XTAL_TYPE_MASK		0x3
+
+#define PE1_FORCE_PHY_EN		BIT(4)
+#define PE1_PHY_EN			BIT(5)
+
+#define PE1_H_PLL_PREDIV_SHIFT		6
+#define PE1_H_PLL_PREDIV_MASK		0x3
+
+#define PE1_H_PLL_FBKSEL_SHIFT		4
+#define PE1_H_PLL_FBKSEL_MASK		0x3
+
+#define PE1_H_LCDDS_PCW_NCPO_SHIFT	0
+#define PE1_H_LCDDS_PCW_NCPO_MASK	0xffffffff
+
+#define PE1_H_LCDDS_SSC_PRD_SHIFT	0
+#define PE1_H_LCDDS_SSC_PRD_MASK	0xffff
+
+#define PE1_H_LCDDS_SSC_DELTA_SHIFT	0
+#define PE1_H_LCDDS_SSC_DELTA_MASK	0xfff
+
+#define PE1_H_LCDDS_SSC_DELTA1_SHIFT	16
+#define PE1_H_LCDDS_SSC_DELTA1_MASK	0xfff
+
+#define PE1_LCDDS_CLK_PH_INV		BIT(5)
+
+#define PE1_H_PLL_BC_SHIFT		22
+#define PE1_H_PLL_BC_MASK		0x3
+#define PE1_H_PLL_BP_SHIFT		18
+#define PE1_H_PLL_BP_MASK		0xf
+#define PE1_H_PLL_IR_SHIFT		12
+#define PE1_H_PLL_IR_MASK		0xf
+#define PE1_H_PLL_IC_SHIFT		8
+#define PE1_H_PLL_IC_MASK		0xf
+
+#define PE1_H_PLL_BR_SHIFT		16
+#define PE1_H_PLL_BR_MASK		0x7
+
+#define PE1_PLL_DIVEN_SHIFT		1
+#define PE1_PLL_DIVEN_MASK		0x7
+
+#define PE1_MSTCKDIV_SHIFT		6
+#define PE1_MSTCKDIV_MASK		0x3
+#define PE1_FORCE_MSTCKDIV		BIT(5)
 
-/*
- * These functions and structures provide the BIOS scan and mapping of the PCI
- * devices.
- */
+#define PE1_CRTMSEL_SHIFT		17
+#define PE1_CRTMSEL_MASK		0xf
+#define PE1_FORCE_CRTMSEL		BIT(16)
 
-#define CONFIG_PCIE_PORT0
-#define CONFIG_PCIE_PORT1
-#define CONFIG_PCIE_PORT2
-#define RALINK_PCIE0_CLK_EN             (1<<24)
-#define RALINK_PCIE1_CLK_EN             (1<<25)
-#define RALINK_PCIE2_CLK_EN             (1<<26)
-#define PCIE_SHARE_PIN_SW		10	// PERST_N GPIO Mode
-#define GPIO_PCIE_PORT0			19	// PERST_N
-#define UARTL3_SHARE_PIN_SW		PCIE_SHARE_PIN_SW
-#define GPIO_PCIE_PORT1			GPIO_PCIE_PORT0
-#define GPIO_PCIE_PORT2			GPIO_PCIE_PORT0
-#define RALINK_PCI_CONFIG_ADDR                         0x20
-#define RALINK_PCI_CONFIG_DATA_VIRTUAL_REG     0x24
-#define SURFBOARDINT_PCIE0       11      /* PCIE0 */
-#define RALINK_INT_PCIE0         SURFBOARDINT_PCIE0
-#define RALINK_INT_PCIE1         SURFBOARDINT_PCIE1
-#define RALINK_INT_PCIE2         SURFBOARDINT_PCIE2
-#define SURFBOARDINT_PCIE1       31     /* PCIE1 */
-#define SURFBOARDINT_PCIE2       32     /* PCIE2 */
-#define RALINK_PCI_MEMBASE              *(volatile u32 *)(RALINK_PCI_BASE + 0x0028)
-#define RALINK_PCI_IOBASE               *(volatile u32 *)(RALINK_PCI_BASE + 0x002C)
-#define RALINK_PCIE0_RST                (1<<24)
-#define RALINK_PCIE1_RST                (1<<25)
-#define RALINK_PCIE2_RST                (1<<26)
-#define RALINK_SYSCTL_BASE              0xBE000000
-#define RALINK_GPIO_CTRL0		*(volatile u32 *)(RALINK_PIO_BASE + 0x00)
-#define RALINK_GPIO_DSET0		*(volatile u32 *)(RALINK_PIO_BASE + 0x30)
-#define RALINK_GPIO_DCLR0		*(volatile u32 *)(RALINK_PIO_BASE + 0x40)
-#define RALINK_PCI_PCICFG_ADDR          *(volatile u32 *)(RALINK_PCI_BASE + 0x0000)
-#define RALINK_PCI_PCIMSK_ADDR          *(volatile u32 *)(RALINK_PCI_BASE + 0x000C)
-#define RALINK_PCI_BASE                 0xBE140000
-#define BAR0_MEMORY_BASE			0x0
-#define RALINK_PCIEPHY_P0P1_CTL_OFFSET (RALINK_PCI_BASE + 0x9000)
-#define RT6855_PCIE0_OFFSET     0x2000
-#define RT6855_PCIE1_OFFSET     0x3000
-#define RT6855_PCIE2_OFFSET     0x4000
-
-#define RALINK_PCI0_BAR0SETUP_ADDR      *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE0_OFFSET + 0x0010)
-#define RALINK_PCI0_IMBASEBAR0_ADDR     *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE0_OFFSET + 0x0018)
-#define RALINK_PCI0_ID                  *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE0_OFFSET + 0x0030)
-#define RALINK_PCI0_CLASS               *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE0_OFFSET + 0x0034)
-#define RALINK_PCI0_SUBID               *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE0_OFFSET + 0x0038)
-#define RALINK_PCI0_STATUS              *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE0_OFFSET + 0x0050)
-#define RALINK_PCI0_DERR                *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE0_OFFSET + 0x0060)
-#define RALINK_PCI0_ECRC                *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE0_OFFSET + 0x0064)
-
-#define RALINK_PCI1_BAR0SETUP_ADDR      *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE1_OFFSET + 0x0010)
-#define RALINK_PCI1_IMBASEBAR0_ADDR     *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE1_OFFSET + 0x0018)
-#define RALINK_PCI1_ID                  *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE1_OFFSET + 0x0030)
-#define RALINK_PCI1_CLASS               *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE1_OFFSET + 0x0034)
-#define RALINK_PCI1_SUBID               *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE1_OFFSET + 0x0038)
-#define RALINK_PCI1_STATUS              *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE1_OFFSET + 0x0050)
-#define RALINK_PCI1_DERR                *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE1_OFFSET + 0x0060)
-#define RALINK_PCI1_ECRC                *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE1_OFFSET + 0x0064)
-
-#define RALINK_PCI2_BAR0SETUP_ADDR      *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE2_OFFSET + 0x0010)
-#define RALINK_PCI2_IMBASEBAR0_ADDR     *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE2_OFFSET + 0x0018)
-#define RALINK_PCI2_ID                  *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE2_OFFSET + 0x0030)
-#define RALINK_PCI2_CLASS               *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE2_OFFSET + 0x0034)
-#define RALINK_PCI2_SUBID               *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE2_OFFSET + 0x0038)
-#define RALINK_PCI2_STATUS              *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE2_OFFSET + 0x0050)
-#define RALINK_PCI2_DERR                *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE2_OFFSET + 0x0060)
-#define RALINK_PCI2_ECRC                *(volatile u32 *)(RALINK_PCI_BASE + RT6855_PCIE2_OFFSET + 0x0064)
-
-#define RALINK_PCIEPHY_P0P1_CTL_OFFSET  (RALINK_PCI_BASE + 0x9000)
-#define RALINK_PCIEPHY_P2_CTL_OFFSET    (RALINK_PCI_BASE + 0xA000)
-
-
-#define MV_WRITE(ofs, data)  \
-        *(volatile u32 *)(RALINK_PCI_BASE+(ofs)) = cpu_to_le32(data)
-#define MV_READ(ofs, data)   \
-	        *(data) = le32_to_cpu(*(volatile u32 *)(RALINK_PCI_BASE+(ofs)))
-#define MV_READ_DATA(ofs)    \
-		        le32_to_cpu(*(volatile u32 *)(RALINK_PCI_BASE+(ofs)))
-
-#define MV_WRITE_16(ofs, data)  \
-        *(volatile u16 *)(RALINK_PCI_BASE+(ofs)) = cpu_to_le16(data)
-#define MV_READ_16(ofs, data)   \
-	        *(data) = le16_to_cpu(*(volatile u16 *)(RALINK_PCI_BASE+(ofs)))
-
-#define MV_WRITE_8(ofs, data)  \
-        *(volatile u8 *)(RALINK_PCI_BASE+(ofs)) = data
-#define MV_READ_8(ofs, data)   \
-	        *(data) = *(volatile u8 *)(RALINK_PCI_BASE+(ofs))
-
-
-
-#define RALINK_PCI_MM_MAP_BASE	0x60000000
-#define RALINK_PCI_IO_MAP_BASE	0x1e160000
-
-#define RALINK_SYSTEM_CONTROL_BASE	0xbe000000
-#define GPIO_PERST
-#define ASSERT_SYSRST_PCIE(val)		do {	\
-						if (*(unsigned int *)(0xbe00000c) == 0x00030101)	\
-							RALINK_RSTCTRL |= val;	\
-						else	\
-							RALINK_RSTCTRL &= ~val;	\
-					} while(0)
-#define DEASSERT_SYSRST_PCIE(val) 	do {	\
-						if (*(unsigned int *)(0xbe00000c) == 0x00030101)	\
-							RALINK_RSTCTRL &= ~val;	\
-						else	\
-							RALINK_RSTCTRL |= val;	\
-					} while(0)
-#define RALINK_SYSCFG1			*(unsigned int *)(RALINK_SYSTEM_CONTROL_BASE + 0x14)
-#define RALINK_CLKCFG1			*(unsigned int *)(RALINK_SYSTEM_CONTROL_BASE + 0x30)
-#define RALINK_RSTCTRL			*(unsigned int *)(RALINK_SYSTEM_CONTROL_BASE + 0x34)
-#define RALINK_GPIOMODE			*(unsigned int *)(RALINK_SYSTEM_CONTROL_BASE + 0x60)
-#define RALINK_PCIE_CLK_GEN		*(unsigned int *)(RALINK_SYSTEM_CONTROL_BASE + 0x7c)
-#define RALINK_PCIE_CLK_GEN1		*(unsigned int *)(RALINK_SYSTEM_CONTROL_BASE + 0x80)
-#define PPLL_CFG1			*(unsigned int *)(RALINK_SYSTEM_CONTROL_BASE + 0x9c)
-#define PPLL_DRV			*(unsigned int *)(RALINK_SYSTEM_CONTROL_BASE + 0xa0)
-//RALINK_SYSCFG1 bit
-#define RALINK_PCI_HOST_MODE_EN		(1<<7)
-#define RALINK_PCIE_RC_MODE_EN		(1<<8)
-//RALINK_RSTCTRL bit
-#define RALINK_PCIE_RST			(1<<23)
-#define RALINK_PCI_RST			(1<<24)
-//RALINK_CLKCFG1 bit
-#define RALINK_PCI_CLK_EN		(1<<19)
-#define RALINK_PCIE_CLK_EN		(1<<21)
-//RALINK_GPIOMODE bit
-#define PCI_SLOTx2			(1<<11)
-#define PCI_SLOTx1			(2<<11)
-//MTK PCIE PLL bit
-#define PDRV_SW_SET			(1<<31)
-#define LC_CKDRVPD_			(1<<19)
-
-#define MEMORY_BASE 0x0
-static int pcie_link_status = 0;
-
-#define PCI_ACCESS_READ_1  0
-#define PCI_ACCESS_READ_2  1
-#define PCI_ACCESS_READ_4  2
-#define PCI_ACCESS_WRITE_1 3
-#define PCI_ACCESS_WRITE_2 4
-#define PCI_ACCESS_WRITE_4 5
-static DEFINE_SPINLOCK(asic_pcr_lock);
-static int config_access(unsigned char access_type, struct pci_bus *bus,
-			unsigned int devfn, unsigned int where, u32 * data)
-{
-	unsigned int slot = PCI_SLOT(devfn);
-	u8 func = PCI_FUNC(devfn);
-	unsigned int address, shift, tmp;
-	unsigned long flags;
+struct mt7621_pci_controller {
+	void __iomem *base;
 
-#if defined(CONFIG_RALINK_RT3883)
-	if (busn == 0)
-		where &= 0xff; // high bits used only for RT3883 PCIe bus (busn 1)
-#endif
+	int is_mt7621_e2;
 
-	/* setup PCR address */
-	address = (1u << 31) | (((where & 0xf00) >> 8) << 24) | (bus->number << 16) | (slot << 11) | (func << 8) | (where & 0xfc);
+	int irq[3];
+	int irq_map[3];
+	uint32_t link_status;
+	unsigned reset_gpio[3];
+	struct reset_control *rstctrl[3];
+	spinlock_t lock;
 
-	shift = (where & 0x3) << 3;
+	struct pci_controller pci_controller;
+};
 
-	spin_lock_irqsave(&asic_pcr_lock, flags);
+static struct resource mt7621_pci_mem_res = {
+	.name = "PCI MEM space",
+	.start = PCIE_IO_MEM_BASE,
+	.end = PCIE_IO_MEM_BASE + PCIE_IO_MEM_SIZE - 1,
+	.flags = IORESOURCE_MEM,
+};
 
-	/* start the configuration cycle */
-	RALINK_PCI_PCR_ADDR = address;
+static struct resource mt7621_pci_io_res = {
+	.name = "PCI IO space",
+	.start = PCIE_IO_PORT_BASE,
+	.end = PCIE_IO_PORT_BASE + PCIE_IO_PORT_SIZE - 1,
+	.flags = IORESOURCE_IO,
+};
 
-	switch (access_type) {
-	case PCI_ACCESS_WRITE_1:
-		tmp = RALINK_PCI_PCR_DATA;
-		tmp &= ~(0xff << shift);
-		tmp |= ((*data & 0xff) << shift);
-		RALINK_PCI_PCR_DATA = tmp;
-		break;
-	case PCI_ACCESS_WRITE_2:
-		tmp = RALINK_PCI_PCR_DATA;
-		if (shift > 16)
-			shift = 16;
-		tmp &= ~(0xffff << shift);
-		tmp |= ((*data & 0xffff) << shift);
-		RALINK_PCI_PCR_DATA = tmp;
-		break;
-	case PCI_ACCESS_WRITE_4:
-		RALINK_PCI_PCR_DATA = *data;
-		break;
-	case PCI_ACCESS_READ_1:
-		tmp = RALINK_PCI_PCR_DATA;
-		*data = (tmp >> shift) & 0xff;
-		break;
-	case PCI_ACCESS_READ_2:
-		tmp = RALINK_PCI_PCR_DATA;
-		if (shift > 16)
-			shift = 16;
-		*data = (tmp >> shift) & 0xffff;
-		break;
-	case PCI_ACCESS_READ_4:
-		*data = RALINK_PCI_PCR_DATA;
-		break;
-	}
+static void mt7621_pci_wr(struct mt7621_pci_controller *mpc, u32 reg, u32 val)
+{
+	__raw_writel(val, mpc->base + reg);
+}
 
-	spin_unlock_irqrestore(&asic_pcr_lock, flags);
+static u32 mt7621_pci_rd(struct mt7621_pci_controller *mpc, u32 reg)
+{
+	return __raw_readl(mpc->base + reg);
+}
 
-	return PCIBIOS_SUCCESSFUL;
+static void mt7621_pci_rmw(struct mt7621_pci_controller *mpc,
+				u32 reg, u32 clr, u32 set)
+{
+	u32 val = __raw_readl(mpc->base + reg);
+
+	val &= ~clr;
+	val |= set;
+	__raw_writel(val, mpc->base + reg);
 }
 
+static inline struct mt7621_pci_controller *
+pci_bus_to_mt7621_pci_controller(struct pci_bus *bus)
+{
+	struct pci_controller *hose = (struct pci_controller *) bus->sysdata;
 
-static int ralink_pci_config_read(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 *val)
+	return container_of(hose, struct mt7621_pci_controller,
+		pci_controller);
+}
+
+static uint32_t pci_to_cfgaddr(uint32_t bus, uint32_t slot, uint32_t func,
+				int where)
+{
+	u32 regm = (where >> 8) & 0xf;
+	u32 regl = (where >> 2) & 0x3f;
+
+	return ((regm & PCIE_EXTREGNUM_MASK) << PCIE_EXTREGNUM_SHIFT) |
+		((bus & PCIE_BUSNUM_MASK) << PCIE_BUSNUM_SHIFT) |
+		((slot & PCIE_DEVICENUM_MASK) << PCIE_DEVICENUM_SHIFT) |
+		((func & PCIE_FUNNUM_MASK) << PCIE_FUNNUM_SHIFT) |
+		((regl & PCIE_REGNUM_MASK) << PCIE_REGNUM_SHIFT) |
+		0x80000000;
+}
+
+static int __mt7621_pci_config_read(struct mt7621_pci_controller *mpc,
+					uint32_t bus, uint32_t slot,
+					uint32_t func, int where, int size,
+					uint32_t *value)
 {
-	
-	int access_type = PCI_ACCESS_READ_4;
+	unsigned long flags;
+	u32 cfgaddr = pci_to_cfgaddr(bus, slot, func, where);
+	u32 data;
+
+	spin_lock_irqsave(&mpc->lock, flags);
+	mt7621_pci_wr(mpc, PCIE_CFGADDR_REG, cfgaddr);
+	data = mt7621_pci_rd(mpc, PCIE_CFGDATA_REG);
+	spin_unlock_irqrestore(&mpc->lock, flags);
 
 	switch (size) {
 	case 1:
-		access_type = PCI_ACCESS_READ_1;
+		*value = (data >> ((where & 0x3) << 3)) & 0xff;
 		break;
 	case 2:
-		access_type = PCI_ACCESS_READ_2;
+		*value = (data >> ((where & 0x3) << 3)) & 0xffff;
+		break;
+	case 4:
+		*value = data;
 		break;
 	}
 
-	return config_access(access_type, bus, devfn, where, val);
+	return PCIBIOS_SUCCESSFUL;
 }
 
-static int ralink_pci_config_write(struct pci_bus *bus, unsigned int devfn, int where, int size, u32 val)
+static int __mt7621_pci_config_write(struct mt7621_pci_controller *mpc,
+					uint32_t bus, uint32_t slot,
+					uint32_t func, int where, int size,
+					uint32_t value)
 {
-	
-	int access_type = PCI_ACCESS_WRITE_4;
+	unsigned long flags;
+	u32 cfgaddr = pci_to_cfgaddr(bus, slot, func, where);
+	u32 data;
+
+	spin_lock_irqsave(&mpc->lock, flags);
+	mt7621_pci_wr(mpc, PCIE_CFGADDR_REG, cfgaddr);
+	data = mt7621_pci_rd(mpc, PCIE_CFGDATA_REG);
 
 	switch (size) {
 	case 1:
-		access_type = PCI_ACCESS_WRITE_1;
+		data = (data & ~(0xff << ((where & 0x3) << 3))) |
+		       (value << ((where & 0x3) << 3));
 		break;
 	case 2:
-		access_type = PCI_ACCESS_WRITE_2;
+		data = (data & ~(0xffff << ((where & 0x3) << 3))) |
+		       (value << ((where & 0x3) << 3));
+		break;
+	case 4:
+		data = value;
 		break;
 	}
 
-	return config_access(access_type, bus, devfn, where, &val);
-}
-
-
-struct pci_ops mt7621_pci_ops= {
-	.read		=  ralink_pci_config_read,
-	.write		= ralink_pci_config_write,
-};
+	mt7621_pci_wr(mpc, PCIE_CFGDATA_REG, data);
+	spin_unlock_irqrestore(&mpc->lock, flags);
 
-static struct resource mt7621_res_pci_mem1 = {
-	.name		= "PCI MEM1",
-	.start		= RALINK_PCI_MM_MAP_BASE,
-	.end		= (u32)((RALINK_PCI_MM_MAP_BASE + (unsigned char *)0x0fffffff)),
-	.flags		= IORESOURCE_MEM,
-};
-static struct resource mt7621_res_pci_io1 = {
-	.name		= "PCI I/O1",
-	.start		= RALINK_PCI_IO_MAP_BASE,
-	.end		= (u32)((RALINK_PCI_IO_MAP_BASE + (unsigned char *)0x0ffff)),
-	.flags		= IORESOURCE_IO,
-};
+	return PCIBIOS_SUCCESSFUL;
+}
 
-static struct pci_controller mt7621_controller = {
-	.pci_ops	= &mt7621_pci_ops,
-	.mem_resource	= &mt7621_res_pci_mem1,
-	.io_resource	= &mt7621_res_pci_io1,
-	.mem_offset	= 0x00000000UL,
-	.io_offset	= 0x00000000UL,
-	.io_map_base	= 0xa0000000,
-};
-int pcibios_plat_dev_init(struct pci_dev *dev)
+static int mt7621_pci_config_read(struct pci_bus *bus, unsigned int devfn,
+				int where, int size, uint32_t *value)
 {
-	u32 __maybe_unused val;
-#ifdef RAPCI_DEBUG
-	int i;
-	struct resource *res;
-
-	printk("%s: ** bus: %d, slot: 0x%x\n", __FUNCTION__, dev->bus->number, PCI_SLOT(dev->devfn));
-
-	pci_read_config_dword(dev, PCI_BASE_ADDRESS_0, &val);
-	printk(" PCI_BASE_ADDRESS_0: 0x%08X\n", val);
-
-	pci_read_config_dword(dev, PCI_BASE_ADDRESS_1, &val);
-	printk(" PCI_BASE_ADDRESS_1: 0x%08X\n", val);
+	struct mt7621_pci_controller *mpc;
+	u32 slot = PCI_SLOT(devfn);
+	u32 func = PCI_FUNC(devfn);
 
-	pci_read_config_dword(dev, PCI_IO_BASE, &val);
-	printk(" PCI_IO_BASE: 0x%08X\n", val);
+	mpc = pci_bus_to_mt7621_pci_controller(bus);
 
-	for (i = 0; i < 2; i++) {
-		res = (struct resource*)&dev->resource[i];
-		printk(" res[%d]->start = %x\n", i, res->start);
-		printk(" res[%d]->end = %x\n", i, res->end);
-	}
-#endif
-
-	/* P2P bridge */
-	if (dev->bus->number == 0) {
-#if defined (CONFIG_RALINK_MT7620) || defined (CONFIG_RALINK_MT7621) || \
-    defined (CONFIG_RALINK_MT7628)
-		/* set N_FTS 0x28 -> 0x50 */
-		val = 0;
-		pci_read_config_dword(dev, 0x70c, &val);
-		val &= ~(0xff<<8);
-		val |=  (0x50<<8);
-		pci_write_config_dword(dev, 0x70c, val);
-#elif defined (CONFIG_RALINK_RT3883)
-		/* fix IO_BASE */
-		if (PCI_SLOT(dev->devfn) == 0x1)
-			pci_write_config_dword(dev, PCI_IO_BASE, 0x00000101);
-#endif
-		/* set CLS */
-		pci_write_config_byte(dev, PCI_CACHE_LINE_SIZE, (L1_CACHE_BYTES >> 2));
-	}
-
-	return 0;
+	return __mt7621_pci_config_read(mpc,
+		bus->number, slot, func, where, size, value);
 }
 
-
-int __init pcibios_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
+static int mt7621_pci_config_write(struct pci_bus *bus, unsigned int devfn,
+				int where, int size, uint32_t value)
 {
-	int pci_irq = 0;
-#if defined (CONFIG_RALINK_MT7621)
-	if ((dev->bus->number == 1) && (slot == 0x0)) {
-		switch (pcie_link_status) {
-		case 0x2:
-		case 0x6:
-			pci_irq = SURFBOARDINT_PCIE1;
-			break;
-		case 0x4:
-			pci_irq = SURFBOARDINT_PCIE2;
-			break;
-		default:
-			pci_irq = SURFBOARDINT_PCIE0;
-		}
-	} else if ((dev->bus->number == 2) && (slot == 0x0)) {
-		switch (pcie_link_status) {
-		case 0x5:
-		case 0x6:
-			pci_irq = SURFBOARDINT_PCIE2;
-			break;
-		default:
-			pci_irq = SURFBOARDINT_PCIE1;
-		}
-	} else if ((dev->bus->number == 2) && (slot == 0x1)) {
-		switch (pcie_link_status) {
-		case 0x5:
-		case 0x6:
-			pci_irq = SURFBOARDINT_PCIE2;
-			break;
-		default:
-			pci_irq = SURFBOARDINT_PCIE1;
-		}
-	} else if ((dev->bus->number == 3) && (slot == 0x0)) {
-		pci_irq = SURFBOARDINT_PCIE2;
-	} else if ((dev->bus->number == 3) && (slot == 0x1)) {
-		pci_irq = SURFBOARDINT_PCIE2;
-	} else if ((dev->bus->number == 3) && (slot == 0x2)) {
-		pci_irq = SURFBOARDINT_PCIE2;
-	}
-#elif defined (CONFIG_RALINK_MT7620) || defined(CONFIG_RALINK_MT7628)
-	if ((dev->bus->number == 1) && (slot == 0x0)) {
-		pci_irq = SURFBOARDINT_PCIE0;
-	}
-#elif defined (CONFIG_RALINK_RT3883)
-	if ((dev->bus->number == 0) && (slot == 0x11)) {
-		pci_irq = SURFBOARDINT_PCI0;
-	} else if ((dev->bus->number == 0) && (slot == 0x12)) {
-		pci_irq = SURFBOARDINT_PCI1;
-	} else if ((dev->bus->number == 1)) {
-		pci_irq = SURFBOARDINT_PCIE0;
-	}
-#endif
+	struct mt7621_pci_controller *mpc;
+	u32 slot = PCI_SLOT(devfn);
+	u32 func = PCI_FUNC(devfn);
 
-#ifdef RAPCI_DEBUG
-	printk("%s: ** bus: %d, slot: 0x%x -> irq: %d\n", __FUNCTION__, dev->bus->number, slot, pci_irq);
-#endif
+	mpc = pci_bus_to_mt7621_pci_controller(bus);
 
-	return pci_irq;
+	return __mt7621_pci_config_write(mpc,
+		bus->number, slot, func, where, size, value);
 }
 
+static struct pci_ops mt7621_pci_ops = {
+	.read =  mt7621_pci_config_read,
+	.write = mt7621_pci_config_write,
+};
 
-void
-set_pcie_phy(u32 *addr, int start_b, int bits, int val)
+static void mt7621_pci_bypass_pipe_rst(struct mt7621_pci_controller *mpc)
 {
-//	printk("0x%p:", addr);
-//	printk(" %x", *addr);
-	*(volatile u32 *)(addr) &= ~(((1<<bits) - 1)<<start_b);
-	*(volatile u32 *)(addr) |= val << start_b;
-//	printk(" -> %x\n", *addr);
+	/* PCIe port 0 */
+	mt7621_pci_rmw(mpc, PCIEPHY_P0P1_CTL_REG + 0x2c,
+			0, PE1_PIPE_RST);
+	mt7621_pci_rmw(mpc, PCIEPHY_P0P1_CTL_REG + 0x2c,
+			0, PE1_PIPE_CMD_FRC);
+
+	/* PCIe port 1 */
+	mt7621_pci_rmw(mpc, PCIEPHY_P0P1_CTL_REG + 0x12c,
+			0, PE1_PIPE_RST);
+	mt7621_pci_rmw(mpc, PCIEPHY_P0P1_CTL_REG + 0x12c,
+			0, PE1_PIPE_CMD_FRC);
+
+	/* PCIe port 2 */
+	mt7621_pci_rmw(mpc, PCIEPHY_P2_CTL_REG + 0x2c,
+			0, PE1_PIPE_RST);
+	mt7621_pci_rmw(mpc, PCIEPHY_P2_CTL_REG + 0x2c,
+			0, PE1_PIPE_CMD_FRC);
 }
 
-void
-bypass_pipe_rst(void)
+static void __mt7621_pci_phy_ssc_config(struct mt7621_pci_controller *mpc,
+					u32 reg_base, int dual_port)
 {
-#if defined (CONFIG_PCIE_PORT0)
-	/* PCIe Port 0 */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x02c), 12, 1, 0x01);	// rg_pe1_pipe_rst_b
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x02c),  4, 1, 0x01);	// rg_pe1_pipe_cmd_frc[4]
-#endif
-#if defined (CONFIG_PCIE_PORT1)
-	/* PCIe Port 1 */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x12c), 12, 1, 0x01);	// rg_pe1_pipe_rst_b
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x12c),  4, 1, 0x01);	// rg_pe1_pipe_cmd_frc[4]
-#endif
-#if defined (CONFIG_PCIE_PORT2)
-	/* PCIe Port 2 */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x02c), 12, 1, 0x01);	// rg_pe1_pipe_rst_b
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x02c),  4, 1, 0x01);	// rg_pe1_pipe_cmd_frc[4]
-#endif
-}
+	u32 xtal_mode;
+
+	xtal_mode = (rt_sysc_r32(SYSC_REG_SYSTEM_CONFIG0)
+			>> XTAL_MODE_SEL_SHIFT) & XTAL_MODE_SEL_MASK;
+
+	/* Set PCIe port to disable SSC */
+	mt7621_pci_rmw(mpc, reg_base + 0x400,
+		PE1_H_XTAL_TYPE_MASK << PE1_H_XTAL_TYPE_SHIFT,
+		PE1_FORCE_H_XTAL_TYPE);
+	/* Force port 0 enable control & disable port 0 */
+	mt7621_pci_rmw(mpc, reg_base + 0x000, PE1_PHY_EN, PE1_FORCE_PHY_EN);
+
+	if (dual_port) {
+		/* Force port 1 enable control & disable port 1 */
+		mt7621_pci_rmw(mpc, reg_base + 0x100,
+			PE1_PHY_EN, PE1_FORCE_PHY_EN);
+	}
 
-void set_phy_for_ssc(void)
-{
-	u32 reg = (*(volatile u32 *)(RALINK_SYSCTL_BASE + 0x10));
-
-	reg = (reg >> 6) & 0x7;
-#if defined (CONFIG_PCIE_PORT0) || defined (CONFIG_PCIE_PORT1)
-	/* Set PCIe Port0 & Port1 PHY to disable SSC */
-	/* Debug Xtal Type */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x400),  8, 1, 0x01);	// rg_pe1_frc_h_xtal_type
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x400),  9, 2, 0x00);	// rg_pe1_h_xtal_type
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x000),  4, 1, 0x01);	// rg_pe1_frc_phy_en               //Force Port 0 enable control
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x100),  4, 1, 0x01);	// rg_pe1_frc_phy_en               //Force Port 1 enable control
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x000),  5, 1, 0x00);	// rg_pe1_phy_en                   //Port 0 disable
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x100),  5, 1, 0x00);	// rg_pe1_phy_en                   //Port 1 disable
-	if (reg <= 5 && reg >= 3) {
+	if (xtal_mode >= 3 && xtal_mode <= 5) {
 		/* 40MHz Xtal */
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x490),  6, 2, 0x01);	// RG_PE1_H_PLL_PREDIV             //Pre-divider ratio (for host mode)
-		
+		/* Pre-divider ratio (for host mode) */
+		mt7621_pci_rmw(mpc, reg_base + 0x490,
+			PE1_H_PLL_PREDIV_MASK << PE1_H_PLL_PREDIV_SHIFT,
+			1 << PE1_H_PLL_PREDIV_SHIFT);
 		/* SSC option tune from -5000ppm to -1000ppm */
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a8),  0,12, 0x1a);	// RG_LC_DDS_SSC_DELTA
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a8), 16,12, 0x1a);	// RG_LC_DDS_SSC_DELTA1
-	} else {
-		/* 25MHz or 20MHz Xtal */
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x490),  6, 2, 0x00);	// RG_PE1_H_PLL_PREDIV             //Pre-divider ratio (for host mode)
-		if (reg >= 6) {
-			/* 25MHz Xtal */
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4bc),  4, 2, 0x01);	// RG_PE1_H_PLL_FBKSEL             //Feedback clock select
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x49c),  0,31, 0x18000000);	// RG_PE1_H_LCDDS_PCW_NCPO         //DDS NCPO PCW (for host mode)
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a4),  0,16, 0x18d);	// RG_PE1_H_LCDDS_SSC_PRD          //DDS SSC dither period control
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a8),  0,12, 0x4a);	// RG_PE1_H_LCDDS_SSC_DELTA        //DDS SSC dither amplitude control
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a8), 16,12, 0x4a);	// RG_PE1_H_LCDDS_SSC_DELTA1       //DDS SSC dither amplitude control for initial
-			
-			/* SSC option tune from -5000ppm to -1000ppm */
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a8),  0,12, 0x11);	// RG_LC_DDS_SSC_DELTA
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a8), 16,12, 0x11);	// RG_LC_DDS_SSC_DELTA1
-		} else {
-			/* 20MHz Xtal */
-			
-			/* SSC option tune from -5000ppm to -1000ppm */
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a8),  0,12, 0x1a);	// RG_LC_DDS_SSC_DELTA
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a8), 16,12, 0x1a);	// RG_LC_DDS_SSC_DELTA1
-		}
-	}
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4a0),  5, 1, 0x01);	// RG_PE1_LCDDS_CLK_PH_INV         //DDS clock inversion
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x490), 22, 2, 0x02);	// RG_PE1_H_PLL_BC                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x490), 18, 4, 0x06);	// RG_PE1_H_PLL_BP                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x490), 12, 4, 0x02);	// RG_PE1_H_PLL_IR                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x490),  8, 4, 0x01);	// RG_PE1_H_PLL_IC                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x4ac), 16, 3, 0x00);	// RG_PE1_H_PLL_BR                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x490),  1, 3, 0x02);	// RG_PE1_PLL_DIVEN                
-	if (reg <= 5 && reg >= 3) {
-		/* 40MHz Xtal */
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x414),  6, 2, 0x01);	// rg_pe1_mstckdiv		//value of da_pe1_mstckdiv when force mode enable
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x414),  5, 1, 0x01);	// rg_pe1_frc_mstckdiv          //force mode enable of da_pe1_mstckdiv      
-	}
-#ifdef PCIE_PHY_SSC
-	/* Enable Port0&Port1 SSC */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x414), 28, 2, 0x1);	// rg_pe1_frc_lcdds_ssc_en              //value of da_pe1_mstckdiv when force mode enable
-#else
-	/* Disable Port0&Port1 SSC */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x414), 28, 2, 0x0);	// rg_pe1_frc_lcdds_ssc_en              //value of da_pe1_mstckdiv when force mode enable
-#endif
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x040), 17, 4, 0x07);	// rg_pe1_crtmsel                   //value of da[x]_pe1_crtmsel when force mode enable for Port 0
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x040), 16, 1, 0x01);	// rg_pe1_frc_crtmsel               //force mode enable of da[x]_pe1_crtmsel for Port 0
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x140), 17, 4, 0x07);	// rg_pe1_crtmsel                   //value of da[x]_pe1_crtmsel when force mode enable for Port 1
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x140), 16, 1, 0x01);	// rg_pe1_frc_crtmsel               //force mode enable of da[x]_pe1_crtmsel for Port 1
-	/* Enable PHY and disable force mode */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x000),  5, 1, 0x01);	// rg_pe1_phy_en                   //Port 0 enable
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x100),  5, 1, 0x01);	// rg_pe1_phy_en                   //Port 1 enable
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x000),  4, 1, 0x00);	// rg_pe1_frc_phy_en               //Force Port 0 disable control
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P0P1_CTL_OFFSET + 0x100),  4, 1, 0x00);	// rg_pe1_frc_phy_en               //Force Port 1 disable control
-#endif
-#if defined (CONFIG_PCIE_PORT2)
-	/* Set PCIe Port2 PHY to disable SSC */
-	/* Debug Xtal Type */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x400),  8, 1, 0x01);	// rg_pe1_frc_h_xtal_type
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x400),  9, 2, 0x00);	// rg_pe1_h_xtal_type
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x000),  4, 1, 0x01);	// rg_pe1_frc_phy_en               //Force Port 0 enable control
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x000),  5, 1, 0x00);	// rg_pe1_phy_en                   //Port 0 disable
-	if (reg <= 5 && reg >= 3) {
-		/* 40MHz Xtal */
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x490),  6, 2, 0x01);	// RG_PE1_H_PLL_PREDIV             //Pre-divider ratio (for host mode)
-		
+		mt7621_pci_rmw(mpc, reg_base + 0x4a8,
+			PE1_H_LCDDS_SSC_DELTA_MASK |
+			(PE1_H_LCDDS_SSC_DELTA1_MASK << PE1_H_LCDDS_SSC_DELTA1_SHIFT),
+			0x1a | (0x1a << PE1_H_LCDDS_SSC_DELTA1_SHIFT));
+	} else if (xtal_mode >= 6) {
+		/* 25MHz Xtal */
+		/* Pre-divider ratio (for host mode) */
+		mt7621_pci_rmw(mpc, reg_base + 0x490,
+			PE1_H_PLL_PREDIV_MASK << PE1_H_PLL_PREDIV_SHIFT, 0);
+		/* Feedback clock select */
+		mt7621_pci_rmw(mpc, reg_base + 0x4bc,
+			PE1_H_PLL_FBKSEL_MASK << PE1_H_PLL_FBKSEL_SHIFT,
+			1 << PE1_H_PLL_FBKSEL_MASK);
+		/* DDS NCPO PCW (for host mode) */
+		mt7621_pci_rmw(mpc, reg_base + 0x49c,
+			PE1_H_LCDDS_PCW_NCPO_MASK, 0x18000000);
+		/* DDS SSC dither period control */
+		mt7621_pci_rmw(mpc, reg_base + 0x4a4,
+			PE1_H_LCDDS_SSC_PRD_MASK, 0x18d);
+		/* DDS SSC dither amplitude control */
+		mt7621_pci_rmw(mpc, reg_base + 0x4a8,
+			PE1_H_LCDDS_SSC_DELTA_MASK |
+			(PE1_H_LCDDS_SSC_DELTA1_MASK << PE1_H_LCDDS_SSC_DELTA1_SHIFT),
+			0x4a | (0x4a << PE1_H_LCDDS_SSC_DELTA1_SHIFT));
 		/* SSC option tune from -5000ppm to -1000ppm */
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a8),  0,12, 0x1a);	// RG_LC_DDS_SSC_DELTA
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a8), 16,12, 0x1a);	// RG_LC_DDS_SSC_DELTA1
+		mt7621_pci_rmw(mpc, reg_base + 0x4a8,
+			PE1_H_LCDDS_SSC_DELTA_MASK |
+			(PE1_H_LCDDS_SSC_DELTA1_MASK << PE1_H_LCDDS_SSC_DELTA1_SHIFT),
+			0x11 | (0x11 << PE1_H_LCDDS_SSC_DELTA1_SHIFT));
 	} else {
-		/* 25MHz or 20MHz Xtal */
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x490),  6, 2, 0x00);	// RG_PE1_H_PLL_PREDIV             //Pre-divider ratio (for host mode)
-		if (reg >= 6) {
-			/* 25MHz Xtal */
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4bc),  4, 2, 0x01);	// RG_PE1_H_PLL_FBKSEL             //Feedback clock select
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x49c),  0,31, 0x18000000);	// RG_PE1_H_LCDDS_PCW_NCPO         //DDS NCPO PCW (for host mode)
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a4),  0,16, 0x18d);	// RG_PE1_H_LCDDS_SSC_PRD          //DDS SSC dither period control
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a8),  0,12, 0x4a);	// RG_PE1_H_LCDDS_SSC_DELTA        //DDS SSC dither amplitude control
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a8), 16,12, 0x4a);	// RG_PE1_H_LCDDS_SSC_DELTA1       //DDS SSC dither amplitude control for initial
-			
-			 /* SSC option tune from -5000ppm to -1000ppm */
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a8),  0,12, 0x11);	// RG_LC_DDS_SSC_DELTA
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a8), 16,12, 0x11);	// RG_LC_DDS_SSC_DELTA1
-		} else {
-			/* 20MHz Xtal */
-			
-			/* SSC option tune from -5000ppm to -1000ppm */
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a8),  0,12, 0x1a);	// RG_LC_DDS_SSC_DELTA
-			set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a8), 16,12, 0x1a);	// RG_LC_DDS_SSC_DELTA1
-		}
+		/* 20MHz Xtal */
+		/* Pre-divider ratio (for host mode) */
+		mt7621_pci_rmw(mpc, reg_base + 0x490,
+			PE1_H_PLL_PREDIV_MASK << PE1_H_PLL_PREDIV_SHIFT, 0);
+		/* SSC option tune from -5000ppm to -1000ppm */
+		mt7621_pci_rmw(mpc, reg_base + 0x4a8,
+			PE1_H_LCDDS_SSC_DELTA_MASK |
+			(PE1_H_LCDDS_SSC_DELTA1_MASK << PE1_H_LCDDS_SSC_DELTA1_SHIFT),
+			0x1a | (0x1a << PE1_H_LCDDS_SSC_DELTA1_SHIFT));
 	}
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4a0),  5, 1, 0x01);	// RG_PE1_LCDDS_CLK_PH_INV         //DDS clock inversion
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x490), 22, 2, 0x02);	// RG_PE1_H_PLL_BC                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x490), 18, 4, 0x06);	// RG_PE1_H_PLL_BP                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x490), 12, 4, 0x02);	// RG_PE1_H_PLL_IR                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x490),  8, 4, 0x01);	// RG_PE1_H_PLL_IC                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x4ac), 16, 3, 0x00);	// RG_PE1_H_PLL_BR                 
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x490),  1, 3, 0x02);	// RG_PE1_PLL_DIVEN                
-	if (reg <= 5 && reg >= 3) {
+
+	/* DDS clock inversion */
+	mt7621_pci_rmw(mpc, reg_base + 0x4a0, 0, PE1_LCDDS_CLK_PH_INV);
+	mt7621_pci_rmw(mpc, reg_base + 0x490,
+		(PE1_H_PLL_BC_MASK << PE1_H_PLL_BC_SHIFT) |
+		(PE1_H_PLL_BP_MASK << PE1_H_PLL_BP_SHIFT) |
+		(PE1_H_PLL_IR_MASK << PE1_H_PLL_IR_SHIFT) |
+		(PE1_H_PLL_IC_MASK << PE1_H_PLL_IC_SHIFT),
+		(2 << PE1_H_PLL_BC_SHIFT) |
+		(6 << PE1_H_PLL_BP_SHIFT) |
+		(2 << PE1_H_PLL_IR_SHIFT) |
+		(1 << PE1_H_PLL_IC_SHIFT));
+	mt7621_pci_rmw(mpc, reg_base + 0x4ac,
+		PE1_H_PLL_BR_MASK << PE1_H_PLL_BR_SHIFT, 0);
+	mt7621_pci_rmw(mpc, reg_base + 0x490,
+		PE1_PLL_DIVEN_MASK << PE1_PLL_DIVEN_SHIFT,
+		2 << PE1_PLL_DIVEN_SHIFT);
+
+	if (xtal_mode >= 3 && xtal_mode <= 5) {
 		/* 40MHz Xtal */
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x414),  6, 2, 0x01);	// rg_pe1_mstckdiv		//value of da_pe1_mstckdiv when force mode enable
-		set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x414),  5, 1, 0x01);	// rg_pe1_frc_mstckdiv          //force mode enable of da_pe1_mstckdiv      
+		/* Value of PCIE_MSTCKDIV when force mode enable */
+		mt7621_pci_rmw(mpc, reg_base + 0x414,
+			PE1_MSTCKDIV_MASK << PE1_MSTCKDIV_SHIFT,
+			1 << PE1_MSTCKDIV_SHIFT);
+		/* Force mode enable of PCIE_MSTCKDIV */
+		mt7621_pci_rmw(mpc, reg_base + 0x414, 0, PE1_FORCE_MSTCKDIV);
 	}
-#ifdef PCIE_PHY_SSC
-	/* Enable Port2 SSC */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x414), 28, 2, 0x1);	// rg_pe1_frc_lcdds_ssc_en              //value of da_pe1_mstckdiv when force mode enable
-#else
-	/* Disable Port2 SSC */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x414), 28, 2, 0x0);	// rg_pe1_frc_lcdds_ssc_en              //value of da_pe1_mstckdiv when force mode enable
-#endif
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x040), 17, 4, 0x07);	// rg_pe1_crtmsel                   //value of da[x]_pe1_crtmsel when force mode enable for Port 0
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x040), 16, 1, 0x01);	// rg_pe1_frc_crtmsel               //force mode enable of da[x]_pe1_crtmsel for Port 0
+
 	/* Enable PHY and disable force mode */
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x000),  5, 1, 0x01);	// rg_pe1_phy_en                   //Port 0 enable
-	set_pcie_phy((u32 *)(RALINK_PCIEPHY_P2_CTL_OFFSET + 0x000),  4, 1, 0x00);	// rg_pe1_frc_phy_en               //Force Port 0 disable control
-#endif
+	mt7621_pci_rmw(mpc, reg_base + 0x040,
+		PE1_CRTMSEL_MASK << PE1_CRTMSEL_SHIFT,
+		(7 << PE1_CRTMSEL_SHIFT) | PE1_FORCE_CRTMSEL);
+	mt7621_pci_rmw(mpc, reg_base + 0x000, PE1_FORCE_PHY_EN, PE1_PHY_EN);
+
+	if (dual_port) {
+		mt7621_pci_rmw(mpc, reg_base + 0x140,
+			PE1_CRTMSEL_MASK << PE1_CRTMSEL_SHIFT,
+			(7 << PE1_CRTMSEL_SHIFT) | PE1_FORCE_CRTMSEL);
+		mt7621_pci_rmw(mpc, reg_base + 0x100,
+			PE1_FORCE_PHY_EN, PE1_PHY_EN);
+	}
 }
 
-void setup_cm_memory_region(struct resource *mem_resource)
+static void mt7621_pci_phy_ssc_config(struct mt7621_pci_controller *mpc)
+{
+	/* PCIe port 0/1 */
+	__mt7621_pci_phy_ssc_config(mpc, PCIEPHY_P0P1_CTL_REG, 1);
+
+	/* PCIe port 2 */
+	__mt7621_pci_phy_ssc_config(mpc, PCIEPHY_P2_CTL_REG, 0);
+}
+
+static void setup_cm_memory_region(struct resource *mem_resource)
 {
 	resource_size_t mask;
+
 	if (mips_cm_numiocu()) {
-		/* FIXME: hardware doesn't accept mask values with 1s after
-		   0s (e.g. 0xffef), so it would be great to warn if that's
-		   about to happen */
+		/*
+		 * FIXME: hardware doesn't accept mask values with 1s after
+		 * 0s (e.g. 0xffef), so it would be great to warn if that's
+		 * about to happen
+		 */
 		mask = ~(mem_resource->end - mem_resource->start);
 
 		write_gcr_reg1_base(mem_resource->start);
 		write_gcr_reg1_mask(mask | CM_GCR_REGn_MASK_CMTGT_IOCU0);
-		printk("PCI coherence region base: 0x%08lx, mask/settings: 0x%08lx\n",
-		       read_gcr_reg1_base(),
-		       read_gcr_reg1_mask());
+		pr_info("PCI coherence region base: 0x%08lx, mask/settings: 0x%08lx\n",
+		       read_gcr_reg1_base(), read_gcr_reg1_mask());
 	}
 }
 
-static int mt7621_pci_probe(struct platform_device *pdev)
+static void mt7621_pci_reset_assert(
+	struct mt7621_pci_controller *mpc, u32 idx)
 {
-	unsigned long val = 0;
-
-	iomem_resource.start = 0;
-	iomem_resource.end= ~0;
-	ioport_resource.start= 0;
-	ioport_resource.end = ~0;
-
-#if defined (CONFIG_RALINK_MT7621)
-	pcie_link_status = 0;
-	val = RALINK_PCIE0_RST | RALINK_PCIE1_RST | RALINK_PCIE2_RST;
-	ASSERT_SYSRST_PCIE(val);			// raise reset all PCIe ports
-	udelay(100);
-#if defined (GPIO_PERST)
-	val = RALINK_GPIOMODE;
-	val &= ~((0x3<<PCIE_SHARE_PIN_SW) | (0x3<<UARTL3_SHARE_PIN_SW));
-	val |=  ((0x1<<PCIE_SHARE_PIN_SW) | (0x1<<UARTL3_SHARE_PIN_SW));
-	RALINK_GPIOMODE = val;
-	val = 0;
-#if defined (CONFIG_PCIE_PORT0)
-	val |= (0x1<<GPIO_PCIE_PORT0);
-#endif
-#if defined (CONFIG_PCIE_PORT1)
-	val |= (0x1<<GPIO_PCIE_PORT1);
-#endif
-#if defined (CONFIG_PCIE_PORT2)
-	val |= (0x1<<GPIO_PCIE_PORT2);
-#endif
-	mdelay(50);
-	RALINK_GPIO_CTRL0 |= val;			// switch PERST_N pin to output mode
-	mdelay(50);
-	RALINK_GPIO_DCLR0 = val;			// fall PERST_N pin (reset peripherals)
-#else /* !defined (GPIO_PERST) */
-	RALINK_GPIOMODE &= ~(0x3<<PCIE_SHARE_PIN_SW);	// fall PERST_N pin (reset peripherals)
-#endif
-	mdelay(100);					// wait 100 ms pulse
-
-	val = 0;
-#if defined (CONFIG_PCIE_PORT0)
-	val |= RALINK_PCIE0_RST;
-#endif
-#if defined (CONFIG_PCIE_PORT1)
-	val |= RALINK_PCIE1_RST;
-#endif
-#if defined (CONFIG_PCIE_PORT2)
-	val |= RALINK_PCIE2_RST;
-#endif
-	DEASSERT_SYSRST_PCIE(val);			// release reset for needed PCIe ports
-
-	val = RALINK_CLKCFG1;
-	val &= ~(RALINK_PCIE0_CLK_EN | RALINK_PCIE1_CLK_EN | RALINK_PCIE2_CLK_EN);
-#if defined (CONFIG_PCIE_PORT0)
-	val |= RALINK_PCIE0_CLK_EN;
-#endif
-#if defined (CONFIG_PCIE_PORT1)
-	val |= RALINK_PCIE1_CLK_EN;
-#endif
-#if defined (CONFIG_PCIE_PORT2)
-	val |= RALINK_PCIE2_CLK_EN;
-#endif
-	RALINK_CLKCFG1 = val;				// enable clock for needed PCIe ports
-
-	mdelay(10);
-
-	if ((*(unsigned int *)(0xbe00000c)&0xFFFF) == 0x0101) // MT7621 E2
-		bypass_pipe_rst();
-	set_phy_for_ssc();
+	if (idx > 2)
+		return;
 
-	mdelay(100);
+	if (mpc->is_mt7621_e2)
+		reset_control_assert(mpc->rstctrl[idx]);
+	else
+		reset_control_deassert(mpc->rstctrl[idx]);
+}
+
+static void mt7621_pci_reset_deassert(
+	struct mt7621_pci_controller *mpc, u32 idx)
+{
+	if (idx > 2)
+		return;
+
+	if (mpc->is_mt7621_e2)
+		reset_control_deassert(mpc->rstctrl[idx]);
+	else
+		reset_control_assert(mpc->rstctrl[idx]);
+}
 
-#if defined (GPIO_PERST)
-	val = 0;
-#if defined (CONFIG_PCIE_PORT0)
-	val |= (0x1<<GPIO_PCIE_PORT0);
-#endif
-#if defined (CONFIG_PCIE_PORT1)
-	val |= (0x1<<GPIO_PCIE_PORT1);
-#endif
-#if defined (CONFIG_PCIE_PORT2)
-	val |= (0x1<<GPIO_PCIE_PORT2);
-#endif
-	RALINK_GPIO_DSET0 = val;			// rise PERST_N pin (complete reset peripherals)
-#else /* !defined (GPIO_PERST) */
-	RALINK_PCI_PCICFG_ADDR &= ~(1<<1);		// release PCIRST
-#endif
-
-#elif defined (CONFIG_RALINK_MT7628)
-	RALINK_GPIOMODE &= ~(0x01<<16);			// PERST_GPIO_MODE = 1'b0
-
-	RALINK_RSTCTRL &= ~RALINK_PCIE0_RST;
-	RALINK_CLKCFG1 |=  RALINK_PCIE0_CLK_EN;
+static void mt7621_pcie_init(struct mt7621_pci_controller *mpc)
+{
+	int i;
+	u32 val, n;
+	u32 num_linked_up = 0;
+	u32 p2p_br_devnum[3];
+
+	for (i = 0; i < 3; i++) {
+		/* PCIe RC reset assert */
+		mt7621_pci_reset_assert(mpc, i);
+
+		/* PCIe EP reset assert */
+		if (gpio_is_valid(mpc->reset_gpio[i]))
+			gpio_set_value(mpc->reset_gpio[i], 0);
+	}
 
 	mdelay(100);
 
-	pcie_phy_config();
+	/* PCIe RC reset deassert */
+	for (i = 0; i < 3; i++)
+		mt7621_pci_reset_deassert(mpc, i);
 
-	RALINK_PCI_PCICFG_ADDR &= ~(1<<1);		// release PCIRST
-#elif defined (CONFIG_RALINK_MT7620)
-	RALINK_GPIOMODE &= ~(0x3<<16);			// PERST_GPIO_MODE = 2'b00
+	if (mpc->is_mt7621_e2)
+		mt7621_pci_bypass_pipe_rst(mpc);
 
-	RALINK_SYSCFG1 |=  RALINK_PCIE_RC_MODE_EN;	// PCIe in RC mode
-	RALINK_RSTCTRL &= ~RALINK_PCIE0_RST;
-	RALINK_CLKCFG1 |=  RALINK_PCIE0_CLK_EN;
+	mt7621_pci_phy_ssc_config(mpc);
 
-	mdelay(50);
+	/* PCIe EP reset deassert */
+	for (i = 0; i < 3; i++) {
+		if (gpio_is_valid(mpc->reset_gpio[i]))
+			gpio_set_value(mpc->reset_gpio[i], 1);
+	}
 
-	if ( !(PPLL_CFG1 & (1<<23)) ) {
-		printk("MT7620 PPLL unlock, cannot enable PCIe!\n");
-		/* for power saving */
-		RALINK_RSTCTRL |=  RALINK_PCIE0_RST;
-		RALINK_CLKCFG1 &= ~RALINK_PCIE0_CLK_EN;
-		return 0;
+	mdelay(100);
+
+	/* Check port link status */
+	for (i = 0; i < 3; i++) {
+		val = mt7621_pci_rd(mpc, PCIE_PORT_STATUS_REG(i));
+		if (val & PCIE_PORT_LINK_UP) {
+			mpc->link_status |= BIT(i);
+			mt7621_pci_rmw(mpc,
+				PCIE_INT_ENABLE_REG, 0, PCIE_INT_PORT(i));
+			rt_sysc_m32(0, BIT(SYSC_CLK1_PCI0_SHIFT + i),
+				SYSC_REG_CLOCK_CONFIG1);
+			num_linked_up++;
+		} else {
+			pr_info("PCIe port %d link down\n", i);
+			mt7621_pci_reset_assert(mpc, i);
+			rt_sysc_m32(BIT(SYSC_CLK1_PCI0_SHIFT + i), 0,
+				SYSC_REG_CLOCK_CONFIG1);
+		}
 	}
 
-	PPLL_DRV |=  LC_CKDRVPD;			// PCIe clock driver power ON
-	PPLL_DRV &= ~LC_CKDRVOHZ;			// Reference PCIe Output clock mode enable
-	PPLL_DRV &= ~LC_CKDRVHZ;			// PCIe PHY clock enable
-	PPLL_DRV |=  PDRV_SW_SET;			// PDRV SW Set
-
-	mdelay(50);
-
-	RALINK_PCI_PCICFG_ADDR &= ~(1<<1);		// release PCIRST
-#elif defined (CONFIG_RALINK_RT3883)
-
-#if defined (CONFIG_PCIE_ONLY) || defined (CONFIG_PCIE_PCI_CONCURRENT)
-	RALINK_RSTCTRL |= RALINK_PCIE_RST;
-	RALINK_SYSCFG1 &= ~(0x30);
-	RALINK_SYSCFG1 |= (2 << 4);
-	RALINK_PCIE_CLK_GEN &= 0x7fffffff;
-	RALINK_PCIE_CLK_GEN1 &= 0x80ffffff;
-	RALINK_PCIE_CLK_GEN1 |= (0xa << 24);
-	RALINK_PCIE_CLK_GEN |= 0x80000000;
-	mdelay(50);
-	RALINK_RSTCTRL &= ~RALINK_PCIE_RST;
-#endif
-#if defined (CONFIG_PCI_ONLY) || defined (CONFIG_PCIE_PCI_CONCURRENT)
-	RALINK_GPIOMODE &= ~(PCI_SLOTx2|PCI_SLOTx1);
-	RALINK_GPIOMODE |= PCI_SLOTx2;	// enable PCI slot 1, disable PCI slot 2
-#endif
-	RALINK_SYSCFG1 |= (RALINK_PCI_HOST_MODE_EN | RALINK_PCIE_RC_MODE_EN);	// PCI in host mode, PCIe in RC mode
-#if defined (CONFIG_PCI_ONLY)
-	RALINK_RSTCTRL |=  RALINK_PCIE_RST;
-	RALINK_CLKCFG1 &= ~RALINK_PCIE_CLK_EN;
-#elif defined (CONFIG_PCIE_ONLY)
-	RALINK_RSTCTRL |=  RALINK_PCI_RST;
-	RALINK_CLKCFG1 &= ~RALINK_PCI_CLK_EN;
-#endif
-	mdelay(200);
-#if defined (CONFIG_PCIE_ONLY)
-	RALINK_PCI_PCICFG_ADDR = 0;		// virtual P2P bridge DEVNUM = 0, release PCIRST
-#else
-	RALINK_PCI_PCICFG_ADDR = (1 << 16);	// virtual P2P bridge DEVNUM = 1, release PCIRST
-#endif
-#endif
-
-	/* wait before detect card in slots */
-	mdelay(500);
-
-#if defined (CONFIG_RALINK_MT7621)
-#if defined (CONFIG_PCIE_PORT0)
-	if ((RALINK_PCI0_STATUS & 0x1) == 0) {
-		ASSERT_SYSRST_PCIE(RALINK_PCIE0_RST);
-		RALINK_CLKCFG1 &= ~RALINK_PCIE0_CLK_EN;
-		printk("%s: no card, disable it (RST&CLK)\n", "PCIe0");
-	} else {
-		pcie_link_status |= (1<<0);
+	if (!num_linked_up) {
+		pr_notice("No PCIe card found\n");
+		return;
 	}
-#endif
-#if defined (CONFIG_PCIE_PORT1)
-	if ((RALINK_PCI1_STATUS & 0x1) == 0) {
-		ASSERT_SYSRST_PCIE(RALINK_PCIE1_RST);
-		RALINK_CLKCFG1 &= ~RALINK_PCIE1_CLK_EN;
-		printk("%s: no card, disable it (RST&CLK)\n", "PCIe1");
-	} else {
-		pcie_link_status |= (1<<1);
+
+	/* Assign Device number of Virtual PCI-PCI bridges */
+	n = 0;
+
+	for (i = 0; i < 3; i++)
+		if (mpc->link_status & BIT(i))
+			p2p_br_devnum[i] = n++;
+
+	for (i = 0; i < 3; i++)
+		if ((mpc->link_status & BIT(i)) == 0)
+			p2p_br_devnum[i] = n++;
+
+	mt7621_pci_rmw(mpc, PCIE_CONFIG_REG,
+			PCIE_P2P_BR_DEVNUM_MASK_FULL,
+			(p2p_br_devnum[0] << PCIE_P2P_BR_DEVNUM0_SHIFT) |
+			(p2p_br_devnum[1] << PCIE_P2P_BR_DEVNUM1_SHIFT) |
+			(p2p_br_devnum[2] << PCIE_P2P_BR_DEVNUM2_SHIFT));
+
+	/* Assign IRQs */
+	n = 0;
+
+	for (i = 0; i < 3; i++)
+		if (mpc->link_status & BIT(i))
+			mpc->irq_map[n++] = mpc->irq[i];
+
+	for (i = n; i < 3; i++)
+		mpc->irq_map[i] = -1;
+
+	/* Setup MEMWIN and IOWIN */
+	mt7621_pci_wr(mpc, PCIE_MEMBASE_REG, 0xffffffff);
+	mt7621_pci_wr(mpc, PCIE_IOBASE_REG, PCIE_IO_PORT_BASE);
+
+	/* Setup PCIe ports */
+	for (i = 0; i < 3; i++) {
+		if ((mpc->link_status & BIT(i)) == 0)
+			continue;
+
+		mt7621_pci_wr(mpc, PCIE_BAR0SETUP_REG(i),
+			(PCIE_BARMSK_MASK << PCIE_BARMSK_SHIFT) | PCIE_BAR_ENABLE);
+		mt7621_pci_wr(mpc, PCIE_IMBASEBAR0_REG(i), 0);
+		mt7621_pci_wr(mpc, PCIE_PORT_CLASS_REG(i),
+			(0x60400 << PCIE_CCODE_SHIFT) | (1 << PCIE_REVID_SHIFT));
 	}
-#endif
-#if defined (CONFIG_PCIE_PORT2)
-	if ((RALINK_PCI2_STATUS & 0x1) == 0) {
-		ASSERT_SYSRST_PCIE(RALINK_PCIE2_RST);
-		RALINK_CLKCFG1 &= ~RALINK_PCIE2_CLK_EN;
-		printk("%s: no card, disable it (RST&CLK)\n", "PCIe2");
-	} else {
-		pcie_link_status |= (1<<2);
+
+	for (i = 0; i < num_linked_up; i++) {
+		__mt7621_pci_config_read(mpc, 0, i, 0, PCI_COMMAND, 4, &val);
+		val |= PCI_COMMAND_MASTER;
+		__mt7621_pci_config_write(mpc, 0, i, 0, PCI_COMMAND, 4, val);
+
+		__mt7621_pci_config_read(mpc, 0, i, 0, 0x70c, 4, &val);
+		val &= ~(0xff << 8);
+		val |= 0x50 << 8;
+		__mt7621_pci_config_write(mpc, 0, i, 0, 0x70c, 4, val);
 	}
-#endif
+}
 
-	/* No cards, exit */
-	if (pcie_link_status == 0)
-		return 0;
+int __init pcibios_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
+{
+	struct mt7621_pci_controller *mpc;
+	u16 cmd;
+	int irq = 0;
 
-/*
-	pcie(2/1/0) link status	pcie2_num	pcie1_num	pcie0_num
-	3'b000			x		x		x
-	3'b001			x		x		0
-	3'b010			x		0		x
-	3'b011			x		1		0
-	3'b100			0		x		x
-	3'b101			1		x		0
-	3'b110			1		0		x
-	3'b111			2		1		0
-*/
-	switch (pcie_link_status) {
-	case 0x2:
-		/* PCIe1 only  */
-		RALINK_PCI_PCICFG_ADDR &= ~0x00ff0000;
-		RALINK_PCI_PCICFG_ADDR |= (0x1 << 16);	// PCIe0 -> port1
-		RALINK_PCI_PCICFG_ADDR |= (0x0 << 20);	// PCIe1 -> port0 (*)
-		break;
-	case 0x4:
-		/* PCIe2 only  */
-		RALINK_PCI_PCICFG_ADDR &= ~0x0fff0000;
-		RALINK_PCI_PCICFG_ADDR |= (0x1 << 16);	// PCIe0 -> port1
-		RALINK_PCI_PCICFG_ADDR |= (0x2 << 20);	// PCIe1 -> port2
-		RALINK_PCI_PCICFG_ADDR |= (0x0 << 24);	// PCIe2 -> port0 (*)
-		break;
-	case 0x5:
-		/* PCIe0 + PCIe2 */
-		RALINK_PCI_PCICFG_ADDR &= ~0x0fff0000;
-		RALINK_PCI_PCICFG_ADDR |= (0x0 << 16);	// PCIe0 -> port0 (*)
-		RALINK_PCI_PCICFG_ADDR |= (0x2 << 20);	// PCIe1 -> port2
-		RALINK_PCI_PCICFG_ADDR |= (0x1 << 24);	// PCIe2 -> port1 (*)
+	mpc = pci_bus_to_mt7621_pci_controller(dev->bus);
+
+	switch (dev->bus->number) {
+	case 0:
+		__mt7621_pci_config_write(mpc, 0, slot, 0,
+					PCI_BASE_ADDRESS_0, 4, 0);
 		break;
-	case 0x6:
-		/* PCIe1 + PCIe2 */
-		RALINK_PCI_PCICFG_ADDR &= ~0x0fff0000;
-		RALINK_PCI_PCICFG_ADDR |= (0x2 << 16);	// PCIe0 -> port2
-		RALINK_PCI_PCICFG_ADDR |= (0x0 << 20);	// PCIe1 -> port0 (*)
-		RALINK_PCI_PCICFG_ADDR |= (0x1 << 24);	// PCIe2 -> port1 (*)
+	case 1:
+	case 2:
+	case 3:
+		if (slot >= dev->bus->number) {
+			pr_notice("pcibios_map_irq: invalid slot %d for bus %d\n",
+				slot, dev->bus->number);
+			return -1;
+		}
+
+		irq = mpc->irq_map[slot];
+		if (irq < 0) {
+			pr_notice("pcibios_map_irq: slot %d for bus %d is link-down\n",
+				slot, dev->bus->number);
+			return -1;
+		}
+
 		break;
+	default:
+		pr_notice("pcibios_map_irq: invalid bus number %d\n", dev->bus->number);
+		return -1;
 	}
-#elif defined (CONFIG_RALINK_MT7628)
-	if ((RALINK_PCI0_STATUS & 0x1) == 0) {
-		RALINK_RSTCTRL |=  RALINK_PCIE0_RST;
-		RALINK_CLKCFG1 &= ~RALINK_PCIE0_CLK_EN;
-		printk("%s: no card, disable it (RST&CLK)\n", "PCIe0");
-		return 0;
-	}
-#elif defined (CONFIG_RALINK_MT7620)
-	if ((RALINK_PCI0_STATUS & 0x1) == 0) {
-		RALINK_RSTCTRL |=  RALINK_PCIE0_RST;
-		RALINK_CLKCFG1 &= ~RALINK_PCIE0_CLK_EN;
-		PPLL_DRV &= ~LC_CKDRVPD;
-		PPLL_DRV |=  PDRV_SW_SET;
-		printk("%s: no card, disable it (RST&CLK)\n", "PCIe0");
-		return 0;
-	}
-#elif defined (CONFIG_RALINK_RT3883)
-#if defined (CONFIG_PCIE_ONLY) || defined (CONFIG_PCIE_PCI_CONCURRENT)
-	if ((RALINK_PCI1_STATUS & 0x1) == 0) {
-		RALINK_RSTCTRL |= RALINK_PCIE_RST;
-		RALINK_CLKCFG1 &= ~RALINK_PCIE_CLK_EN;
-		//cgrstb, cgpdb, pexdrven0, pexdrven1, cgpllrstb, cgpllpdb, pexclken
-		RALINK_PCIE_CLK_GEN &= 0x0fff3f7f;
-		pcie_disable = 1;
-		printk("%s: no card, disable it (RST&CLK)\n", "PCIe");
-#if defined (CONFIG_PCIE_ONLY)
-		return 0;
-#endif
-	}
-#endif
-	RALINK_PCI_ARBCTL = 0x79;
-#endif
-
-	RALINK_PCI_MEMBASE = 0xffffffff;			// valid for PCI host mode only
-	RALINK_PCI_IOBASE = RALINK_PCI_IO_MAP_BASE;		// valid for PCI host mode only
-
-#if defined (CONFIG_RALINK_MT7621)
-#if defined (CONFIG_PCIE_PORT0)
-	// PCIe0
-	if ((pcie_link_status & 0x1) != 0) {
-		RALINK_PCI0_BAR0SETUP_ADDR	= 0x7fff0001;	// open BAR0 (2GB)
-		RALINK_PCI0_BAR1SETUP_ADDR	= 0x00000000;	// disable BAR1 (used in EP mode)
-		RALINK_PCI0_IMBASEBAR0_ADDR	= BAR0_MEMORY_BASE;	// make BAR0
-		RALINK_PCI0_CLASS		= 0x06040001;
-		RALINK_PCI_PCIMSK_ADDR		|= (1<<20);	// enable PCIe0 interrupt
-	}
-#endif
-#if defined (CONFIG_PCIE_PORT1)
-	// PCIe1
-	if ((pcie_link_status & 0x2) != 0) {
-		RALINK_PCI1_BAR0SETUP_ADDR	= 0x7fff0001;	// open BAR0 (2GB)
-		RALINK_PCI1_BAR1SETUP_ADDR	= 0x00000000;	// disable BAR1 (used in EP mode)
-		RALINK_PCI1_IMBASEBAR0_ADDR	= BAR0_MEMORY_BASE;	// make BAR0
-		RALINK_PCI1_CLASS		= 0x06040001;
-		RALINK_PCI_PCIMSK_ADDR		|= (1<<21);	// enable PCIe1 interrupt
+
+	pci_write_config_byte(dev, PCI_CACHE_LINE_SIZE, 0x14);
+	pci_write_config_byte(dev, PCI_LATENCY_TIMER, 0xFF);
+
+	pci_read_config_word(dev, PCI_COMMAND, &cmd);
+	cmd = cmd | PCI_COMMAND_MASTER | PCI_COMMAND_IO | PCI_COMMAND_MEMORY;
+	pci_write_config_word(dev, PCI_COMMAND, cmd);
+
+	return irq;
+}
+
+static int mt7621_pci_probe(struct platform_device *pdev)
+{
+	struct mt7621_pci_controller *mpc;
+	struct resource *r;
+	char name[32];
+	u32 rev;
+	int ret, i;
+
+	mpc = devm_kzalloc(&pdev->dev,
+			   sizeof(struct mt7621_pci_controller),
+			   GFP_KERNEL);
+	if (!mpc)
+		return -ENOMEM;
+
+	spin_lock_init(&mpc->lock);
+
+	rev = rt_sysc_r32(SYSC_REG_CHIP_REV);
+	if (((rev >> CHIP_REV_VER_SHIFT) & CHIP_REV_VER_MASK) == 1 &&
+	    (rev & CHIP_REV_ECO_MASK) == 1)
+		mpc->is_mt7621_e2 = 1;
+
+	r = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	mpc->base = devm_ioremap_resource(&pdev->dev, r);
+	if (IS_ERR(mpc->base))
+		return PTR_ERR(mpc->base);
+
+	mpc->pci_controller.pci_ops = &mt7621_pci_ops;
+	mpc->pci_controller.io_resource = &mt7621_pci_io_res;
+	mpc->pci_controller.mem_resource = &mt7621_pci_mem_res;
+	mpc->pci_controller.io_map_base =
+		(unsigned long) ioremap(PCIE_IO_PORT_BASE, PCIE_IO_PORT_SIZE);
+
+	set_io_port_base(mpc->pci_controller.io_map_base);
+
+	ioport_resource.start = PCIE_IO_PORT_BASE;
+	ioport_resource.end = PCIE_IO_PORT_BASE + PCIE_IO_PORT_SIZE - 1;
+
+	for (i = 0; i < 3; i++) {
+		mpc->irq[i] = platform_get_irq(pdev, i);
+		if (mpc->irq[i] < 0) {
+			dev_notice(&pdev->dev,
+				"PCIe%d IRQ resource not found\n", i);
+			return -ENXIO;
+		}
+
+		snprintf(name, sizeof(name), "pcie%d", i);
+		mpc->rstctrl[i] = devm_reset_control_get(&pdev->dev, name);
+		if (IS_ERR(mpc->rstctrl[i])) {
+			dev_notice(&pdev->dev,
+				"PCIe%d reset control not found\n", i);
+			return PTR_ERR(mpc->rstctrl[i]);
+		}
+		if (!mpc->rstctrl[i]) {
+			dev_notice(&pdev->dev,
+				"PCIe%d reset control is not valid\n", i);
+			return -EINVAL;
+		}
+
+		mpc->reset_gpio[i] = of_get_named_gpio(pdev->dev.of_node,
+					"reset-gpios", i);
+
+		if (gpio_is_valid(mpc->reset_gpio[i])) {
+			snprintf(name, sizeof(name), "pcie%d-reset", i);
+			ret = devm_gpio_request_one(&pdev->dev,
+				mpc->reset_gpio[i], GPIOF_OUT_INIT_HIGH, name);
+			if (ret) {
+				dev_notice(&pdev->dev,
+					"Unable to request GPIO%d for %s\n",
+					mpc->reset_gpio[i], name);
+				return ret;
+			}
+		} else {
+			dev_notice(&pdev->dev,
+				"Failed to get gpio for PCIe%d\n", i);
+		}
 	}
-#endif
-#if defined (CONFIG_PCIE_PORT2)
-	// PCIe2
-	if ((pcie_link_status & 0x4) != 0) {
-		RALINK_PCI2_BAR0SETUP_ADDR	= 0x7fff0001;	// open BAR0 (2GB)
-		RALINK_PCI2_BAR1SETUP_ADDR	= 0x00000000;	// disable BAR1 (used in EP mode)
-		RALINK_PCI2_IMBASEBAR0_ADDR	= BAR0_MEMORY_BASE;	// make BAR0
-		RALINK_PCI2_CLASS		= 0x06040001;
-		RALINK_PCI_PCIMSK_ADDR		|= (1<<22);	// enable PCIe2 interrupt
+
+	mt7621_pcie_init(mpc);
+
+	for (i = 0; i < 3; i++) {
+		if ((mpc->link_status & BIT(i)) == 0)
+			if (gpio_is_valid(mpc->reset_gpio[i]))
+				devm_gpio_free(&pdev->dev, mpc->reset_gpio[i]);
 	}
-#endif
-#elif defined (CONFIG_RALINK_MT7620) || defined (CONFIG_RALINK_MT7628)
-	//PCIe0
-	RALINK_PCI0_BAR0SETUP_ADDR		= 0x7fff0001;	// open BAR0 (2GB)
-	RALINK_PCI0_BAR1SETUP_ADDR		= 0x00000000;	// disable BAR1 (used in EP mode)
-	RALINK_PCI0_IMBASEBAR0_ADDR		= BAR0_MEMORY_BASE;	// make BAR0
-	RALINK_PCI0_CLASS			= 0x06040001;
-	RALINK_PCI_PCIMSK_ADDR			= (1<<20);	// enable PCIe0 interrupt
-#elif defined (CONFIG_RALINK_RT3883)
-#if defined (CONFIG_PCI_ONLY) || defined (CONFIG_PCIE_PCI_CONCURRENT)
-	//PCI
-	RALINK_PCI0_BAR0SETUP_ADDR		= BAR0_MASK;	// disable BAR0
-	RALINK_PCI0_IMBASEBAR0_ADDR		= BAR0_MEMORY_BASE;
-	RALINK_PCI0_CLASS			= 0x00800001;
-	RALINK_PCI0_BAR0SETUP_ADDR		= BAR0_MASK|1;	// open BAR0
-	RALINK_PCI_PCIMSK_ADDR			= 0x000c0000;	// enable PCI interrupts
-#endif
-#if defined (CONFIG_PCIE_ONLY) || defined (CONFIG_PCIE_PCI_CONCURRENT)
-	//PCIe
-	if (!pcie_disable) {
-		RALINK_PCI1_BAR0SETUP_ADDR	= BAR0_MASK;	// disable BAR0
-		RALINK_PCI1_IMBASEBAR0_ADDR	= BAR0_MEMORY_BASE;
-		RALINK_PCI1_CLASS		= 0x06040001;
-		RALINK_PCI1_BAR0SETUP_ADDR	= BAR0_MASK|1;	// open BAR0
-		RALINK_PCI_PCIMSK_ADDR		|= (1<<20);	// enable PCIe interrupt
+
+	if (mpc->link_status) {
+		setup_cm_memory_region(mpc->pci_controller.mem_resource);
+		register_pci_controller(&mpc->pci_controller);
 	}
-#endif
-#endif
 
-	pci_load_of_ranges(&mt7621_controller, pdev->dev.of_node);
-	setup_cm_memory_region(mt7621_controller.mem_resource);
-	register_pci_controller(&mt7621_controller);
 	return 0;
-
 }
 
-
+int pcibios_plat_dev_init(struct pci_dev *dev)
+{
+	return 0;
+}
 
 static const struct of_device_id mt7621_pci_ids[] = {
 	{ .compatible = "mediatek,mt7621-pci" },
diff --git a/trunk/linux-4.4.x/arch/mips/ralink/mt7621.c b/trunk/linux-4.4.x/arch/mips/ralink/mt7621.c
index 98c74d611..0d51d6ff7 100644
--- a/trunk/linux-4.4.x/arch/mips/ralink/mt7621.c
+++ b/trunk/linux-4.4.x/arch/mips/ralink/mt7621.c
@@ -274,7 +274,7 @@ static void __init mt7621_detect_memory_region(struct ralink_soc_info *soc_info)
 		add_memory_region(0, size, BOOT_MEM_RAM);
 	} else {
 		add_memory_region(0, SZ_512M - SZ_64M, BOOT_MEM_RAM);
-		add_memory_region(SZ_512M, SZ_64M, BOOT_MEM_INIT_RAM);
+		add_memory_region(SZ_512M, SZ_64M, BOOT_MEM_RAM);
 	}
 }
 
@@ -321,6 +321,7 @@ void prom_soc_init(struct ralink_soc_info *soc_info)
 		 * config for CM regions and we have to configure them
 		 * again. This SoC cannot talk to pamlbus devices
 		 * witout proper iocu region set up.
+
 		 * FIXME: it would be better to do this with values
 		 * from DT, but we need this very early because
 		 * without this we cannot talk to pretty much anything
diff --git a/trunk/linux-4.4.x/build.config.aarch64 b/trunk/linux-4.4.x/build.config.aarch64
new file mode 100644
index 000000000..523bbc044
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.aarch64
@@ -0,0 +1,11 @@
+ARCH=arm64
+
+CLANG_TRIPLE=aarch64-linux-gnu-
+CROSS_COMPILE=aarch64-linux-androidkernel-
+LINUX_GCC_CROSS_COMPILE_PREBUILTS_BIN=prebuilts/gcc/linux-x86/aarch64/aarch64-linux-android-4.9/bin
+
+FILES="
+arch/arm64/boot/Image.gz
+vmlinux
+System.map
+"
diff --git a/trunk/linux-4.4.x/build.config.common b/trunk/linux-4.4.x/build.config.common
new file mode 100644
index 000000000..81cbb76e3
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.common
@@ -0,0 +1,9 @@
+BRANCH=android-4.4-p
+KERNEL_DIR=common
+
+CC=clang
+CLANG_PREBUILT_BIN=prebuilts-master/clang/host/linux-x86/clang-r365631c/bin
+BUILDTOOLS_PREBUILT_BIN=build/build-tools/path/linux-x86
+
+EXTRA_CMDS=''
+STOP_SHIP_TRACEPRINTK=1
diff --git a/trunk/linux-4.4.x/build.config.cuttlefish.aarch64 b/trunk/linux-4.4.x/build.config.cuttlefish.aarch64
new file mode 100644
index 000000000..0cb601958
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.cuttlefish.aarch64
@@ -0,0 +1,5 @@
+. ${ROOT_DIR}/common/build.config.common
+. ${ROOT_DIR}/common/build.config.aarch64
+
+DEFCONFIG=cuttlefish_defconfig
+POST_DEFCONFIG_CMDS="check_defconfig"
diff --git a/trunk/linux-4.4.x/build.config.cuttlefish.x86_64 b/trunk/linux-4.4.x/build.config.cuttlefish.x86_64
new file mode 100644
index 000000000..fed773ccc
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.cuttlefish.x86_64
@@ -0,0 +1,5 @@
+. ${ROOT_DIR}/common/build.config.common
+. ${ROOT_DIR}/common/build.config.x86_64
+
+DEFCONFIG=x86_64_cuttlefish_defconfig
+POST_DEFCONFIG_CMDS="check_defconfig"
diff --git a/trunk/linux-4.4.x/build.config.goldfish.arm b/trunk/linux-4.4.x/build.config.goldfish.arm
new file mode 100644
index 000000000..ff5646ab4
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.goldfish.arm
@@ -0,0 +1,13 @@
+ARCH=arm
+BRANCH=android-4.4
+CROSS_COMPILE=arm-linux-androidkernel-
+DEFCONFIG=ranchu_defconfig
+EXTRA_CMDS=''
+KERNEL_DIR=common
+LINUX_GCC_CROSS_COMPILE_PREBUILTS_BIN=prebuilts/gcc/linux-x86/arm/arm-linux-androideabi-4.9/bin
+FILES="
+arch/arm/boot/zImage
+vmlinux
+System.map
+"
+STOP_SHIP_TRACEPRINTK=1
diff --git a/trunk/linux-4.4.x/build.config.goldfish.arm64 b/trunk/linux-4.4.x/build.config.goldfish.arm64
new file mode 100644
index 000000000..4c896a679
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.goldfish.arm64
@@ -0,0 +1,13 @@
+ARCH=arm64
+BRANCH=android-4.4
+CROSS_COMPILE=aarch64-linux-android-
+DEFCONFIG=ranchu64_defconfig
+EXTRA_CMDS=''
+KERNEL_DIR=common
+LINUX_GCC_CROSS_COMPILE_PREBUILTS_BIN=prebuilts/gcc/linux-x86/aarch64/aarch64-linux-android-4.9/bin
+FILES="
+arch/arm64/boot/Image
+vmlinux
+System.map
+"
+STOP_SHIP_TRACEPRINTK=1
diff --git a/trunk/linux-4.4.x/build.config.goldfish.mips b/trunk/linux-4.4.x/build.config.goldfish.mips
new file mode 100644
index 000000000..9a14a444a
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.goldfish.mips
@@ -0,0 +1,12 @@
+ARCH=mips
+BRANCH=android-4.4
+CROSS_COMPILE=mips64el-linux-android-
+DEFCONFIG=ranchu_defconfig
+EXTRA_CMDS=''
+KERNEL_DIR=common
+LINUX_GCC_CROSS_COMPILE_PREBUILTS_BIN=prebuilts/gcc/linux-x86/mips/mips64el-linux-android-4.9/bin
+FILES="
+vmlinux
+System.map
+"
+STOP_SHIP_TRACEPRINTK=1
diff --git a/trunk/linux-4.4.x/build.config.goldfish.mips64 b/trunk/linux-4.4.x/build.config.goldfish.mips64
new file mode 100644
index 000000000..6ad9759f5
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.goldfish.mips64
@@ -0,0 +1,12 @@
+ARCH=mips
+BRANCH=android-4.4
+CROSS_COMPILE=mips64el-linux-android-
+DEFCONFIG=ranchu64_defconfig
+EXTRA_CMDS=''
+KERNEL_DIR=common
+LINUX_GCC_CROSS_COMPILE_PREBUILTS_BIN=prebuilts/gcc/linux-x86/mips/mips64el-linux-android-4.9/bin
+FILES="
+vmlinux
+System.map
+"
+STOP_SHIP_TRACEPRINTK=1
diff --git a/trunk/linux-4.4.x/build.config.goldfish.x86 b/trunk/linux-4.4.x/build.config.goldfish.x86
new file mode 100644
index 000000000..2266c6218
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.goldfish.x86
@@ -0,0 +1,13 @@
+ARCH=x86
+BRANCH=android-4.4
+CROSS_COMPILE=x86_64-linux-android-
+DEFCONFIG=i386_ranchu_defconfig
+EXTRA_CMDS=''
+KERNEL_DIR=common
+LINUX_GCC_CROSS_COMPILE_PREBUILTS_BIN=prebuilts/gcc/linux-x86/x86/x86_64-linux-android-4.9/bin
+FILES="
+arch/x86/boot/bzImage
+vmlinux
+System.map
+"
+STOP_SHIP_TRACEPRINTK=1
diff --git a/trunk/linux-4.4.x/build.config.goldfish.x86_64 b/trunk/linux-4.4.x/build.config.goldfish.x86_64
new file mode 100644
index 000000000..08c42c2eb
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.goldfish.x86_64
@@ -0,0 +1,13 @@
+ARCH=x86_64
+BRANCH=android-4.4
+CROSS_COMPILE=x86_64-linux-android-
+DEFCONFIG=x86_64_ranchu_defconfig
+EXTRA_CMDS=''
+KERNEL_DIR=common
+LINUX_GCC_CROSS_COMPILE_PREBUILTS_BIN=prebuilts/gcc/linux-x86/x86/x86_64-linux-android-4.9/bin
+FILES="
+arch/x86/boot/bzImage
+vmlinux
+System.map
+"
+STOP_SHIP_TRACEPRINTK=1
diff --git a/trunk/linux-4.4.x/build.config.x86_64 b/trunk/linux-4.4.x/build.config.x86_64
new file mode 100644
index 000000000..df73a47e7
--- /dev/null
+++ b/trunk/linux-4.4.x/build.config.x86_64
@@ -0,0 +1,11 @@
+ARCH=x86_64
+
+CLANG_TRIPLE=x86_64-linux-gnu-
+CROSS_COMPILE=x86_64-linux-androidkernel-
+LINUX_GCC_CROSS_COMPILE_PREBUILTS_BIN=prebuilts/gcc/linux-x86/x86/x86_64-linux-android-4.9/bin
+
+FILES="
+arch/x86/boot/bzImage
+vmlinux
+System.map
+"
diff --git a/trunk/linux-4.4.x/drivers/crypto/Kconfig b/trunk/linux-4.4.x/drivers/crypto/Kconfig
index 9351fc2d0..7b46bf3bd 100644
--- a/trunk/linux-4.4.x/drivers/crypto/Kconfig
+++ b/trunk/linux-4.4.x/drivers/crypto/Kconfig
@@ -515,4 +515,6 @@ config CRYPTO_DEV_MEDIATEK
 	  EIP97 which can be found on the MT7623 MT2701, MT8521p, etc ....
 	  Select this if you want to use it for AES/SHA1/SHA2 algorithms.
 
+source "drivers/crypto/mtk-eip93/Kconfig"
+
 endif # CRYPTO_HW
diff --git a/trunk/linux-4.4.x/drivers/crypto/Makefile b/trunk/linux-4.4.x/drivers/crypto/Makefile
index 1a246539e..e4f0a859e 100644
--- a/trunk/linux-4.4.x/drivers/crypto/Makefile
+++ b/trunk/linux-4.4.x/drivers/crypto/Makefile
@@ -30,3 +30,4 @@ obj-$(CONFIG_CRYPTO_DEV_QAT) += qat/
 obj-$(CONFIG_CRYPTO_DEV_QCE) += qce/
 obj-$(CONFIG_CRYPTO_DEV_VMX) += vmx/
 obj-$(CONFIG_CRYPTO_DEV_SUN4I_SS) += sunxi-ss/
+obj-$(CONFIG_CRYPTO_DEV_EIP93) += mtk-eip93/
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/Kconfig b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/Kconfig
new file mode 100644
index 000000000..aab2bade0
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/Kconfig
@@ -0,0 +1,6 @@
+config CRYPTO_DEV_EIP93
+	tristate "Support for EIP93 crypto HW accelerators"
+	depends on SOC_MT7621 || COMPILE_TEST
+	help
+	  EIP93 have various crypto HW accelerators. Select this if
+	  you want to use the EIP93 modules for any of the crypto algorithms.
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/Makefile b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/Makefile
new file mode 100644
index 000000000..6d919e3be
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/Makefile
@@ -0,0 +1,3 @@
+crypto-hw-eip93-objs:= eip93-core.o eip93-ring.o eip93-cipher.o eip93-prng.o
+
+obj-$(CONFIG_CRYPTO_DEV_EIP93) += crypto-hw-eip93.o
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-cipher.c b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-cipher.c
new file mode 100644
index 000000000..58082ef98
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-cipher.c
@@ -0,0 +1,2053 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+#define DEBUG 1
+#include <linux/version.h>
+#include <crypto/aead.h>
+#include <crypto/aes.h>
+#include <crypto/authenc.h>
+#include <crypto/ctr.h>
+#include <crypto/hmac.h>
+#include <crypto/internal/aead.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0)
+#include <crypto/des.h>
+#else
+#include <crypto/internal/des.h>
+#endif
+#include <crypto/internal/skcipher.h>
+#include <crypto/md5.h>
+#include <crypto/null.h>
+#include <crypto/scatterwalk.h>
+#include <crypto/sha.h>
+
+#include <linux/dma-mapping.h>
+#include <linux/dmapool.h>
+#include <linux/moduleparam.h>
+#include <linux/scatterlist.h>
+#include <linux/types.h>
+
+#include "eip93-common.h"
+#include "eip93-core.h"
+#include "eip93-cipher.h"
+#include "eip93-regs.h"
+#include "eip93-ring.h"
+
+static unsigned int aes_sw = NUM_AES_BYPASS;
+module_param(aes_sw, uint, 0644);
+MODULE_PARM_DESC(aes_sw,
+		 "Only use hardware for AES requests larger than this "
+		 "[0=always use hardware; default="
+		 __stringify(NUM_AES_BYPASS)"]");
+
+inline void mtk_free_sg_cpy(const int len, struct scatterlist **sg)
+{
+	if (!*sg || !len)
+		return;
+
+	free_pages((unsigned long)sg_virt(*sg), get_order(len));
+	kfree(*sg);
+	*sg = NULL;
+}
+
+inline int mtk_make_sg_cpy(struct mtk_device *mtk, struct scatterlist *src,
+		struct scatterlist **dst, const int len,
+		struct mtk_cipher_reqctx *rctx, const bool copy)
+{
+	void *pages;
+	int totallen;
+
+	*dst = kmalloc(sizeof(**dst), GFP_KERNEL);
+	if (!*dst) {
+		printk("NO MEM\n");
+		return -ENOMEM;
+	}
+	/* allocate enough memory for full scatterlist */
+	totallen = rctx->assoclen + rctx->textsize + rctx->authsize;
+
+	pages = (void *)__get_free_pages(GFP_KERNEL | GFP_DMA,
+					get_order(totallen));
+
+	if (!pages) {
+		kfree(*dst);
+		*dst = NULL;
+		printk("no free pages\n");
+		return -ENOMEM;
+	}
+
+	sg_init_table(*dst, 1);
+	sg_set_buf(*dst, pages, totallen);
+
+	/* copy only as requested */
+	if (copy)
+		sg_copy_to_buffer(src, sg_nents(src), pages, len);
+
+	return 0;
+}
+
+inline bool mtk_is_sg_aligned(struct scatterlist *sg, u32 len, const int blksz)
+{
+	int nents;
+
+	for (nents = 0; sg; sg = sg_next(sg), ++nents) {
+		/* When destination buffers are not aligned to the cache line
+		 * size we need bounce buffers. The DMA-API requires that the
+		 * entire line is owned by the DMA buffer.
+		 */
+		if (!IS_ALIGNED(sg->offset, 4))
+			return false;
+
+		/* segments need to be blocksize aligned */
+		if (len <= sg->length) {
+			if (!IS_ALIGNED(len, blksz))
+				return false;
+
+			return true;
+		}
+
+		if (!IS_ALIGNED(sg->length, blksz))
+			return false;
+
+		len -= sg->length;
+	}
+	return false;
+}
+
+void mtk_ctx_saRecord(struct mtk_cipher_ctx *ctx, const u8 *key,
+				const u32 nonce, const unsigned int keylen,
+				const unsigned long flags)
+{
+	struct saRecord_s *saRecord;
+
+	saRecord = ctx->sa;
+
+	saRecord->saCmd0.bits.ivSource = 2;
+	saRecord->saCmd0.bits.saveIv = 1;
+	saRecord->saCmd0.bits.opGroup = 0;
+	saRecord->saCmd0.bits.opCode = 0;
+
+	saRecord->saCmd0.bits.cipher = 15;
+	switch ((flags & MTK_ALG_MASK)) {
+	case MTK_ALG_AES:
+		saRecord->saCmd0.bits.cipher = 3;
+		saRecord->saCmd1.bits.aesKeyLen = (keylen / 8);
+		break;
+	case MTK_ALG_3DES:
+		saRecord->saCmd0.bits.cipher = 1;
+		break;
+	case MTK_ALG_DES:
+		saRecord->saCmd0.bits.cipher = 0;
+		break;
+	}
+
+	saRecord->saCmd0.bits.hash = 15;
+	switch ((flags & MTK_HASH_MASK)) {
+	case MTK_HASH_SHA256:
+		saRecord->saCmd0.bits.hash = 3;
+		break;
+	case MTK_HASH_SHA224:
+		saRecord->saCmd0.bits.hash = 2;
+		break;
+	case MTK_HASH_SHA1:
+		saRecord->saCmd0.bits.hash = 1;
+		break;
+	case MTK_HASH_MD5:
+		saRecord->saCmd0.bits.hash = 0;
+		break;
+	}
+
+	saRecord->saCmd0.bits.hdrProc = 0;
+	saRecord->saCmd0.bits.padType = 3;
+	saRecord->saCmd0.bits.extPad = 0;
+	saRecord->saCmd0.bits.scPad = 0;
+
+	switch ((flags & MTK_MODE_MASK)) {
+	case MTK_MODE_CBC:
+		saRecord->saCmd1.bits.cipherMode = 1;
+		break;
+	case MTK_MODE_CTR:
+		saRecord->saCmd1.bits.cipherMode = 2;
+		break;
+	case MTK_MODE_ECB:
+		saRecord->saCmd1.bits.cipherMode = 0;
+		break;
+	}
+
+	saRecord->saCmd1.bits.byteOffset = 0;
+	saRecord->saCmd1.bits.hashCryptOffset = 0;
+	saRecord->saCmd0.bits.digestLength = 0;
+	saRecord->saCmd1.bits.copyPayload = 0;
+
+	if (IS_HMAC(flags)) {
+		saRecord->saCmd1.bits.hmac = 1;
+		saRecord->saCmd1.bits.copyDigest = 1;
+		saRecord->saCmd1.bits.copyHeader = 1;
+	} else {
+		saRecord->saCmd1.bits.hmac = 0;
+		saRecord->saCmd1.bits.copyDigest = 0;
+		saRecord->saCmd1.bits.copyHeader = 0;
+	}
+
+	memcpy(saRecord->saKey, key, keylen);
+
+	if (IS_RFC3686(flags))
+		saRecord->saNonce = nonce;
+
+	/* Default for now, might be used for ESP offload */
+	saRecord->saCmd1.bits.seqNumCheck = 0;
+	saRecord->saSpi = 0x0;
+	saRecord->saSeqNumMask[0] = 0x0;
+	saRecord->saSeqNumMask[1] = 0x0;
+}
+
+/*
+ * Poor mans Scatter/gather function:
+ * Create a Descriptor for every segment to avoid copying buffers.
+ * For performance better to wait for hardware to perform multiple DMA
+ *
+ */
+inline int mtk_scatter_combine(struct mtk_device *mtk,
+ 			struct mtk_cipher_reqctx *rctx,
+			struct scatterlist *sgsrc, struct scatterlist *sgdst,
+			u32 datalen,  bool complete, unsigned int *areq,
+			int offsetin)
+{
+	dma_addr_t saRecord_base = rctx->saRecord_base;
+	dma_addr_t saState_base;
+	unsigned int remainin, remainout;
+	int offsetout = 0;
+	u32 n, len;
+	dma_addr_t saddr, daddr;
+	u32 srcAddr, dstAddr;
+	bool nextin = false;
+	bool nextout = false;
+	struct eip93_descriptor_s cdesc;
+	int ndesc_cdr = 0, err;
+
+	if (complete)
+		saState_base = rctx->saState_base;
+	else
+		saState_base = rctx->saState_base_ctr;
+
+	cdesc.peCrtlStat.word = 0;
+	cdesc.peCrtlStat.bits.hostReady = 1;
+	cdesc.peCrtlStat.bits.prngMode = 0;
+	cdesc.peCrtlStat.bits.hashFinal = 1;
+	cdesc.peCrtlStat.bits.padCrtlStat = 0;
+	cdesc.peCrtlStat.bits.peReady = 0;
+	cdesc.saAddr = saRecord_base;
+	cdesc.stateAddr = saState_base;
+	cdesc.arc4Addr = (u32)areq;
+	if (IS_HMAC(rctx->flags))
+		cdesc.userId = MTK_DESC_AEAD;
+	else
+		cdesc.userId = MTK_DESC_SKCIPHER;
+	cdesc.peLength.word = 0;
+	cdesc.peLength.bits.byPass = 0;
+	cdesc.peLength.bits.hostReady = 1;
+
+	n = datalen;
+	remainin = min(sg_dma_len(sgsrc), n);
+	remainout = min(sg_dma_len(sgdst), n);
+	saddr = sg_dma_address(sgsrc);
+	daddr = sg_dma_address(sgdst);
+
+	do {
+		if (nextin) {
+			sgsrc = sg_next(sgsrc);
+			remainin = min(sg_dma_len(sgsrc), n);
+			if (remainin == 0)
+				continue;
+
+			saddr = sg_dma_address(sgsrc);
+			offsetin = 0;
+			nextin = false;
+		}
+
+		if (nextout) {
+			sgdst = sg_next(sgdst);
+			remainout = min(sg_dma_len(sgdst), n);
+			if (remainout == 0)
+				continue;
+
+			daddr = sg_dma_address(sgdst);
+			offsetout = 0;
+			nextout = false;
+		}
+		srcAddr = saddr + offsetin;
+		dstAddr = daddr + offsetout;
+
+		if (remainin == remainout) {
+			len = remainin;
+				nextin = true;
+				nextout = true;
+		} else if (remainin < remainout) {
+			len = remainin;
+				offsetout += len;
+				remainout -= len;
+				nextin = true;
+		} else {
+			len = remainout;
+				offsetin += len;
+				remainin -= len;
+				nextout = true;
+		}
+		n -= len;
+
+		cdesc.srcAddr = srcAddr;
+		cdesc.dstAddr = dstAddr;
+		cdesc.peLength.bits.length = len;
+
+		if (n == 0)
+			if (complete == true) {
+				cdesc.userId |= MTK_DESC_LAST;
+				cdesc.userId |= MTK_DESC_FINISH;
+				}
+
+		err = mtk_put_descriptor(mtk, cdesc);
+		if (err)
+			dev_err(mtk->dev, "No empty Descriptor space");
+
+		ndesc_cdr++;
+	} while (n);
+
+	return ndesc_cdr;
+}
+
+int mtk_send_req(struct crypto_async_request *base,
+		const struct mtk_cipher_ctx *ctx,
+		struct scatterlist *reqsrc, struct scatterlist *reqdst,
+		const u8 *reqiv, struct mtk_cipher_reqctx *rctx)
+{
+	struct mtk_device *mtk = ctx->mtk;
+	int ndesc_cdr = 0, ctr_cdr = 0;
+	int offset = 0, err;
+	int src_nents, dst_nents;
+	u32 aad = rctx->assoclen;
+	u32 textsize = rctx->textsize;
+	u32 authsize = rctx->authsize;
+	u32 datalen = aad + textsize;
+	u32 totlen_src = datalen;
+	u32 totlen_dst = datalen;
+	struct scatterlist *src, *src_ctr;
+	struct scatterlist *dst, *dst_ctr;
+	struct saRecord_s *saRecord;
+	struct saState_s *saState;
+	u32 start, end, ctr, blocks;
+	unsigned long flags = rctx->flags;
+	bool overflow;
+	bool complete = true;
+	bool src_align = true, dst_align = true;
+	u32 iv[AES_BLOCK_SIZE / sizeof(u32)], *esph;
+	int blksize = 1, offsetin = 0;
+
+	switch ((flags & MTK_ALG_MASK))	{
+	case MTK_ALG_AES:
+		blksize = AES_BLOCK_SIZE;
+		break;
+	case MTK_ALG_DES:
+		blksize = DES_BLOCK_SIZE;
+		break;
+	case MTK_ALG_3DES:
+		blksize = DES3_EDE_BLOCK_SIZE;
+		break;
+	}
+
+	if (!IS_CTR(rctx->flags)) {
+		if (IS_GENIV(rctx->flags))
+			textsize -= rctx->ivsize;
+		if (!IS_ALIGNED(textsize, blksize))
+			return -EINVAL;
+	}
+
+	rctx->sg_src = reqsrc;
+	src = reqsrc;
+	rctx->sg_dst = reqdst;
+	dst = reqdst;
+
+	if (ctx->aead) {
+		if (IS_ENCRYPT(flags))
+			totlen_dst += authsize;
+		else
+			totlen_src += authsize;
+	}
+
+	src_nents = sg_nents_for_len(src, totlen_src);
+	dst_nents = sg_nents_for_len(dst, totlen_dst);
+
+	if (src == dst) {
+		src_nents = max(src_nents, dst_nents);
+		dst_nents = src_nents;
+		if (unlikely((totlen_src || totlen_dst) &&
+		    (src_nents <= 0))) {
+			dev_err(mtk->dev, "In-place buffer not large enough (need %d bytes)!",
+				max(totlen_src, totlen_dst));
+			return -EINVAL;
+		}
+	} else {
+		if (unlikely(totlen_src && (src_nents <= 0))) {
+			dev_err(mtk->dev, "Source buffer not large enough (need %d bytes)!",
+				totlen_src);
+			return -EINVAL;
+		}
+
+		if (unlikely(totlen_dst && (dst_nents <= 0))) {
+			dev_err(mtk->dev, "Dest buffer not large enough (need %d bytes)!",
+				totlen_dst);
+			return -EINVAL;
+		}
+	}
+
+	if (ctx->aead) {
+		if (dst_nents == 1 && src_nents == 1) {
+			src_align = mtk_is_sg_aligned(src, totlen_src, blksize);
+			if (src ==  dst)
+				dst_align = src_align;
+			else
+				dst_align = mtk_is_sg_aligned(reqdst,
+							totlen_dst, blksize);
+		} else {
+			src_align = false;
+			dst_align = false;
+		}
+	} else {
+		src_align = mtk_is_sg_aligned(src, totlen_src, blksize);
+		if (src == dst)
+			dst_align = src_align;
+		else
+			dst_align = mtk_is_sg_aligned(reqdst, totlen_dst,
+								blksize);
+	}
+
+	if (!src_align) {
+		err = mtk_make_sg_cpy(mtk, rctx->sg_src, &rctx->sg_src,
+					totlen_src, rctx, true);
+		if (err)
+			return err;
+		src = rctx->sg_src;
+	}
+
+	if (!dst_align) {
+		err = mtk_make_sg_cpy(mtk, rctx->sg_dst, &rctx->sg_dst,
+					totlen_dst, rctx, false);
+		if (err)
+			return err;
+
+		dst = rctx->sg_dst;
+	}
+
+	rctx->saState_ctr = NULL;
+	rctx->saState = NULL;
+
+	if ((IS_ECB(flags)) || (IS_GENIV(flags))) {
+		rctx->iv_dma = false;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0)
+		rctx->saState_base = 0;
+#else
+		rctx->saState_base = NULL;
+#endif
+		goto skip_iv;
+	}
+
+	/* make sure IV is DMA-able */
+	if (!IS_ALIGNED((u32)reqiv, 16))
+			rctx->iv_dma = false;
+	memcpy(iv, reqiv, rctx->ivsize);
+
+	overflow = (IS_CTR(rctx->flags) && (!IS_RFC3686(rctx->flags)));
+
+	if (overflow) {
+		/* Compute data length. */
+		blocks = DIV_ROUND_UP(totlen_src, AES_BLOCK_SIZE);
+		ctr = be32_to_cpu(iv[3]);
+		/* Check 32bit counter overflow. */
+		start = ctr;
+		end = start + blocks - 1;
+		if (end < start) {
+			offset = AES_BLOCK_SIZE * -start;
+			/*
+			 * Increment the counter manually to cope with
+			 * the hardware counter overflow.
+			 */
+			iv[3] = 0xffffffff;
+			crypto_inc((u8 *)iv, AES_BLOCK_SIZE);
+			complete = false;
+			rctx->saState_ctr = dma_pool_zalloc(mtk->saState_pool,
+				GFP_KERNEL, &rctx->saState_base_ctr);
+			if (!rctx->saState_ctr)
+				dev_err(mtk->dev, "No State_ctr DMA memory\n");
+
+			memcpy(rctx->saState_ctr->stateIv, reqiv, rctx->ivsize);
+		}
+	}
+
+	if (rctx->iv_dma) {
+		rctx->saState = (void *)reqiv;
+	} else {
+		rctx->saState = dma_pool_zalloc(mtk->saState_pool,
+					GFP_KERNEL, &rctx->saState_base);
+		if (!rctx->saState)
+			dev_err(mtk->dev, "No saState DMA memory\n");
+	}
+
+	saState = rctx->saState;
+
+	if (rctx->saState_ctr)
+		memcpy(saState->stateIv, iv, rctx->ivsize);
+
+	if (IS_RFC3686(flags)) {
+		saState->stateIv[0] = ctx->sa->saNonce;
+		saState->stateIv[1] = iv[0];
+		saState->stateIv[2] = iv[1];
+		saState->stateIv[3] = cpu_to_be32(1);
+	}
+
+	if (rctx->iv_dma)
+		rctx->saState_base = dma_map_single(mtk->dev, (void *)reqiv,
+						rctx->ivsize,	DMA_TO_DEVICE);
+	else if (IS_CBC(flags) || overflow)
+			memcpy(saState->stateIv, iv, rctx->ivsize);
+
+skip_iv:
+	rctx->saRecord = dma_pool_zalloc(mtk->saRecord_pool, GFP_KERNEL,
+					&rctx->saRecord_base);
+	if (!rctx->saRecord)
+		dev_err(mtk->dev, "No saRecord DMA memory\n");
+
+	saRecord = rctx->saRecord;
+
+	memcpy(saRecord, ctx->sa, sizeof(struct saRecord_s));
+
+	if (IS_DECRYPT(flags))
+		saRecord->saCmd0.bits.direction = 1;
+
+	if ((IS_ECB(flags)) || (IS_GENIV(flags)))
+		saRecord->saCmd0.bits.saveIv = 0;
+
+	if (IS_HMAC(flags)) {
+		saRecord->saCmd1.bits.byteOffset = 0;
+		saRecord->saCmd1.bits.hashCryptOffset = (aad / 4);
+		saRecord->saCmd0.bits.digestLength = (authsize / 4);
+	}
+
+	if (ctx->aead) {
+		saRecord->saCmd0.bits.opCode = 1;
+		if (IS_DECRYPT(flags))
+			saRecord->saCmd1.bits.copyDigest = 0;
+	}
+
+	if (IS_GENIV(flags)) {
+		saRecord->saCmd0.bits.opCode = 0;
+		saRecord->saCmd0.bits.opGroup = 1;
+		saRecord->saCmd1.bits.seqNumCheck = 1;
+
+		if (IS_ENCRYPT(flags)) {
+			datalen = rctx->textsize - rctx->ivsize;
+			/* seems EIP93 needs to process the header itself
+			 * So get the spi and sequence number from orginal
+			 * header for now
+			 */
+			esph = sg_virt(rctx->sg_src);
+			saRecord->saSpi = ntohl(esph[0]);
+			saRecord->saSeqNum[0] = ntohl(esph[1]) - 1;
+			offsetin = rctx->assoclen + rctx->ivsize;
+			saRecord->saCmd1.bits.copyHeader = 0;
+			saRecord->saCmd0.bits.hdrProc = 1;
+			saRecord->saCmd0.bits.ivSource = 3;
+		} else {
+			esph = sg_virt(rctx->sg_src);
+			saRecord->saSpi = ntohl(esph[0]);
+			saRecord->saSeqNum[0] = ntohl(esph[1]);
+			saRecord->saCmd1.bits.copyHeader = 1;
+			saRecord->saCmd0.bits.hdrProc = 1;
+			saRecord->saCmd0.bits.ivSource = 1;
+			datalen += rctx->authsize;
+		}
+	}
+
+	/* map DMA_BIDIRECTIONAL to invalidate cache on destination
+	 * implies __dma_cache_wback_inv
+	 */
+	dma_map_sg(mtk->dev, dst, sg_nents(dst), DMA_BIDIRECTIONAL);
+	if (src != dst)
+		dma_map_sg(mtk->dev, src, sg_nents(src), DMA_TO_DEVICE);
+
+
+	if (unlikely(complete == false)) {
+		src_ctr = src;
+		dst_ctr = dst;
+		/* process until offset of the counter overflow */
+		ctr_cdr = mtk_scatter_combine(mtk, rctx, src, dst, offset,
+						complete, (void *)base, 0);
+		/* Jump to offset. */
+		src = scatterwalk_ffwd(rctx->ctr_src, src_ctr, offset);
+		dst = ((src_ctr == dst_ctr) ? src :
+			scatterwalk_ffwd(rctx->ctr_dst, dst_ctr, offset));
+
+		datalen -= offset;
+		complete = true;
+		/* map DMA_BIDIRECTIONAL to invalidate cache on destination */
+		dma_map_sg(mtk->dev, dst, sg_nents(dst), DMA_BIDIRECTIONAL);
+		if (src != dst)
+			dma_map_sg(mtk->dev, src, sg_nents(src), DMA_TO_DEVICE);
+	}
+
+	ndesc_cdr = mtk_scatter_combine(mtk, rctx, src, dst, datalen, complete,
+			(void *)base, offsetin);
+
+	return ndesc_cdr + ctr_cdr;
+}
+
+static void mtk_unmap_dma(struct mtk_device *mtk, struct mtk_cipher_reqctx *rctx,
+			struct scatterlist *reqsrc, struct scatterlist *reqdst)
+{
+	u32 len = rctx->assoclen + rctx->textsize;
+	u32 *otag;
+	int i;
+
+	if (rctx->sg_src == rctx->sg_dst) {
+		dma_unmap_sg(mtk->dev, rctx->sg_dst, sg_nents(rctx->sg_dst),
+							DMA_FROM_DEVICE);
+		goto process_tag;
+	}
+
+	dma_unmap_sg(mtk->dev, rctx->sg_src, sg_nents(rctx->sg_src),
+							DMA_TO_DEVICE);
+
+	if (rctx->sg_src != reqsrc)
+		mtk_free_sg_cpy(len +  rctx->authsize, &rctx->sg_src);
+
+	dma_unmap_sg(mtk->dev, rctx->sg_dst, sg_nents(rctx->sg_dst),
+							DMA_FROM_DEVICE);
+
+	/* SHA tags need convertion from net-to-host */
+process_tag:
+	if (rctx->authsize) {
+		if ((IS_ENCRYPT(rctx->flags)) && (!IS_GENIV(rctx->flags))) {
+			if (!IS_HASH_MD5(rctx->flags)) {
+				otag = sg_virt(rctx->sg_dst) + len;
+				for (i = 0; i < (rctx->authsize / 4); i++)
+					otag[i] = ntohl(otag[i]);
+			}
+		}
+	}
+
+	if (rctx->sg_dst != reqdst) {
+		sg_copy_from_buffer(reqdst, sg_nents(reqdst),
+				sg_virt(rctx->sg_dst), len + rctx->authsize);
+		mtk_free_sg_cpy(len + rctx->authsize, &rctx->sg_dst);
+	}
+}
+
+void mtk_handle_result(struct mtk_device *mtk,
+	struct crypto_async_request *async, struct mtk_cipher_reqctx *rctx,
+	struct scatterlist *reqsrc, struct scatterlist *reqdst,	u8 *reqiv,
+	bool complete, int err)
+{
+	mtk_unmap_dma(mtk, rctx, reqsrc, reqdst);
+
+	if (IS_BUSY(rctx->flags)) {
+		local_bh_disable();
+		async->complete(async, -EINPROGRESS);
+		local_bh_enable();
+	}
+
+	if (!complete)
+		return;
+
+	if (rctx->iv_dma) {
+		dma_unmap_single(mtk->dev, rctx->saState_base, rctx->ivsize,
+						DMA_BIDIRECTIONAL);
+	} else {
+		if ((!IS_ECB(rctx->flags)) || (!IS_GENIV(rctx->flags)))  {
+			memcpy(reqiv, rctx->saState->stateIv, rctx->ivsize);
+			if (rctx->saState)
+				dma_pool_free(mtk->saState_pool, rctx->saState,
+							rctx->saState_base);
+		}
+	}
+
+	if (rctx->saState_ctr)
+		dma_pool_free(mtk->saState_pool, rctx->saState_ctr,
+						rctx->saState_base_ctr);
+
+	dma_pool_free(mtk->saRecord_pool, rctx->saRecord, rctx->saRecord_base);
+
+	local_bh_disable();
+	async->complete(async, err);
+	local_bh_enable();
+}
+
+void mtk_skcipher_handle_result(struct mtk_device *mtk,
+				struct crypto_async_request *async,
+				bool complete, int err)
+{
+	struct skcipher_request *req = skcipher_request_cast(async);
+	struct mtk_cipher_reqctx *rctx = skcipher_request_ctx(req);
+
+	mtk_handle_result(mtk, async, rctx, req->src, req->dst, req->iv,
+				complete, err);
+}
+
+void mtk_aead_handle_result(struct mtk_device *mtk,
+				struct crypto_async_request *async,
+				bool complete,  int err)
+{
+	struct aead_request *req = aead_request_cast(async);
+	struct mtk_cipher_reqctx *rctx = aead_request_ctx(req);
+
+	mtk_handle_result(mtk, async, rctx, req->src, req->dst, req->iv,
+				complete, err);
+}
+
+/* Crypto skcipher API functions */
+static int mtk_skcipher_cra_init(struct crypto_tfm *tfm)
+{
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);
+	struct mtk_alg_template *tmpl = container_of(tfm->__crt_alg,
+				struct mtk_alg_template, alg.skcipher.base);
+
+	memset(ctx, 0, sizeof(*ctx));
+
+	ctx->fallback = NULL;
+
+	if (IS_AES(tmpl->flags)) {
+		ctx->fallback = crypto_alloc_skcipher(crypto_tfm_alg_name(tfm),
+				0, CRYPTO_ALG_NEED_FALLBACK);
+		if (IS_ERR(ctx->fallback))
+			ctx->fallback = NULL;
+	}
+
+	if (IS_AES(tmpl->flags) && (ctx->fallback))
+		crypto_skcipher_set_reqsize(__crypto_skcipher_cast(tfm),
+					sizeof(struct mtk_cipher_reqctx) +
+					crypto_skcipher_reqsize(ctx->fallback));
+	else
+		crypto_skcipher_set_reqsize(__crypto_skcipher_cast(tfm),
+			offsetof(struct mtk_cipher_reqctx, fallback_req));
+
+	ctx->mtk = tmpl->mtk;
+	ctx->aead = false;
+	ctx->sa = kzalloc(sizeof(struct saRecord_s), GFP_KERNEL);
+	if (!ctx->sa)
+		printk("!! no sa memory\n");
+
+	return 0;
+}
+
+static void mtk_skcipher_cra_exit(struct crypto_tfm *tfm)
+{
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);
+
+	kfree(ctx->sa);
+
+	if (ctx->fallback)
+		crypto_free_skcipher(ctx->fallback);
+}
+
+static int mtk_skcipher_setkey(struct crypto_skcipher *ctfm, const u8 *key,
+				 unsigned int len)
+{
+	struct crypto_tfm *tfm = crypto_skcipher_tfm(ctfm);
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);
+	struct mtk_alg_template *tmpl = container_of(tfm->__crt_alg,
+				struct mtk_alg_template, alg.skcipher.base);
+	unsigned long flags = tmpl->flags;
+	struct crypto_aes_ctx aes;
+	unsigned int keylen = len;
+	u32 nonce = 0;
+	int ret = 0;
+
+	if (!key || !keylen)
+		return -EINVAL;
+
+	if (IS_RFC3686(flags)) {
+		/* last 4 bytes of key are the nonce! */
+		keylen -= CTR_RFC3686_NONCE_SIZE;
+		memcpy(&nonce, key + keylen, CTR_RFC3686_NONCE_SIZE);
+	}
+
+	switch ((flags & MTK_ALG_MASK)) {
+	case MTK_ALG_AES:
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0)
+		ret = crypto_aes_expand_key(&aes, key, keylen);
+#else
+		ret = aes_expandkey(&aes, key, keylen);
+#endif
+		break;
+	case MTK_ALG_DES:
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 4, 0)
+		if (len != DES_KEY_SIZE) {
+			ret = -EINVAL;
+			break;
+		}
+#else
+		ret = verify_skcipher_des_key(ctfm, key);
+#endif
+		break;
+	case MTK_ALG_3DES:
+		if (keylen != DES3_EDE_KEY_SIZE) {
+			ret = -EINVAL;
+			break;
+		}
+#if LINUX_VERSION_CODE > KERNEL_VERSION(5, 3, 0)
+		ret = verify_skcipher_des3_key(ctfm, key);
+#endif
+	}
+
+	if (ret) {
+		crypto_skcipher_set_flags(ctfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		return ret;
+	}
+
+	mtk_ctx_saRecord(ctx, key, nonce, keylen, flags);
+
+	if (ctx->fallback)
+		ret = crypto_skcipher_setkey(ctx->fallback, key, len);
+
+	return ret;
+}
+
+static int mtk_skcipher_crypt(struct skcipher_request *req)
+{
+	struct mtk_cipher_reqctx *rctx = skcipher_request_ctx(req);
+	struct crypto_async_request *base = &req->base;
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
+	struct mtk_device *mtk = ctx->mtk;
+	int ret;
+	int DescriptorCountDone = MTK_RING_SIZE - 1;
+	int DescriptorDoneTimeout = 3;
+	int DescriptorPendingCount = 0;
+	struct crypto_skcipher *skcipher = crypto_skcipher_reqtfm(req);
+	u32 ivsize = crypto_skcipher_ivsize(skcipher);
+
+	if (!req->cryptlen)
+		return 0;
+
+	if ((req->cryptlen <= aes_sw) && (ctx->fallback)) {
+		skcipher_request_set_tfm(&rctx->fallback_req, ctx->fallback);
+		skcipher_request_set_callback(&rctx->fallback_req,
+					req->base.flags,
+					req->base.complete,
+					req->base.data);
+		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
+					req->dst, req->cryptlen, req->iv);
+		if (IS_ENCRYPT(rctx->flags))
+			ret = crypto_skcipher_encrypt(&rctx->fallback_req);
+		else
+			ret = crypto_skcipher_decrypt(&rctx->fallback_req);
+
+		return ret;
+	}
+
+	if (mtk->ring->requests > MTK_RING_BUSY)
+		return -EAGAIN;
+
+	rctx->textsize = req->cryptlen;
+	rctx->authsize = 0;
+	rctx->assoclen = 0;
+	rctx->iv_dma = true;
+	rctx->ivsize = ivsize;
+
+	ret = mtk_send_req(base, ctx, req->src, req->dst, req->iv,
+				rctx);
+
+	if (ret < 0) {
+		base->complete(base, ret);
+		return ret;
+	}
+
+	if (ret == 0)
+		return 0;
+
+	spin_lock_bh(&mtk->ring->lock);
+	mtk->ring->requests += ret;
+
+	if (!mtk->ring->busy) {
+		DescriptorPendingCount = min_t(int, mtk->ring->requests, 32);
+		writel(BIT(31) | (DescriptorCountDone & GENMASK(10, 0)) |
+			(((DescriptorPendingCount - 1) & GENMASK(10, 0)) << 16) |
+			((DescriptorDoneTimeout  & GENMASK(4, 0)) << 26),
+			mtk->base + EIP93_REG_PE_RING_THRESH);
+		mtk->ring->busy = true;
+	}
+	spin_unlock_bh(&mtk->ring->lock);
+	/* Writing new descriptor count starts DMA action */
+	writel(ret, mtk->base + EIP93_REG_PE_CD_COUNT);
+
+	if (mtk->ring->requests > MTK_RING_BUSY) {
+		rctx->flags |= MTK_BUSY;
+		return -EBUSY;
+	}
+
+	return -EINPROGRESS;
+}
+
+static int mtk_skcipher_encrypt(struct skcipher_request *req)
+{
+	struct mtk_cipher_reqctx *rctx = skcipher_request_ctx(req);
+	struct crypto_async_request *base = &req->base;
+	struct mtk_alg_template *tmpl = container_of(base->tfm->__crt_alg,
+				struct mtk_alg_template, alg.skcipher.base);
+
+	rctx->flags = tmpl->flags;
+	rctx->flags |= MTK_ENCRYPT;
+
+	return mtk_skcipher_crypt(req);
+}
+
+static int mtk_skcipher_decrypt(struct skcipher_request *req)
+{
+	struct mtk_cipher_reqctx *rctx = skcipher_request_ctx(req);
+	struct crypto_async_request *base = &req->base;
+	struct mtk_alg_template *tmpl = container_of(base->tfm->__crt_alg,
+				struct mtk_alg_template, alg.skcipher.base);
+
+	rctx->flags = tmpl->flags;
+	rctx->flags |= MTK_DECRYPT;
+
+	return mtk_skcipher_crypt(req);
+}
+/* Crypto aead API functions */
+static int mtk_aead_cra_init(struct crypto_tfm *tfm)
+{
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);
+	struct mtk_alg_template *tmpl = container_of(tfm->__crt_alg,
+				struct mtk_alg_template, alg.aead.base);
+	unsigned long flags = tmpl->flags;
+	char *alg_base;
+
+	memset(ctx, 0, sizeof(*ctx));
+
+	crypto_aead_set_reqsize(__crypto_aead_cast(tfm),
+			sizeof(struct mtk_cipher_reqctx));
+
+	ctx->mtk = tmpl->mtk;
+	ctx->aead = true;
+	ctx->fallback = NULL;
+
+	ctx->sa = kzalloc(sizeof(struct saRecord_s), GFP_KERNEL);
+	if (!ctx->sa)
+		printk("!! no sa memory\n");
+
+	/* software workaround for now */
+	if (IS_HASH_MD5(flags))
+		alg_base = "md5";
+	if (IS_HASH_SHA1(flags))
+		alg_base = "sha1";
+	if (IS_HASH_SHA224(flags))
+		alg_base = "sha224";
+	if (IS_HASH_SHA256(flags))
+		alg_base = "sha256";
+
+	ctx->shash = crypto_alloc_shash(alg_base, 0, CRYPTO_ALG_NEED_FALLBACK);
+
+	if (IS_ERR(ctx->shash)) {
+		dev_err(ctx->mtk->dev, "base driver %s could not be loaded.\n",
+				alg_base);
+		return PTR_ERR(ctx->shash);
+	}
+
+	return 0;
+}
+
+static void mtk_aead_cra_exit(struct crypto_tfm *tfm)
+{
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);
+
+	if (ctx->shash)
+		crypto_free_shash(ctx->shash);
+
+	kfree(ctx->sa);
+}
+
+static int mtk_aead_setkey(struct crypto_aead *ctfm, const u8 *key,
+			unsigned int keylen)
+{
+	struct crypto_tfm *tfm = crypto_aead_tfm(ctfm);
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);
+	struct mtk_alg_template *tmpl = container_of(tfm->__crt_alg,
+				struct mtk_alg_template, alg.skcipher.base);
+	unsigned long flags = tmpl->flags;
+	struct crypto_authenc_keys keys;
+	int bs = crypto_shash_blocksize(ctx->shash);
+	int ds = crypto_shash_digestsize(ctx->shash);
+	u8 *ipad, *opad;
+	unsigned int i, err;
+	u32 nonce;
+
+	SHASH_DESC_ON_STACK(shash, ctx->shash);
+
+	if (crypto_authenc_extractkeys(&keys, key, keylen) != 0)
+		goto badkey;
+
+	if (IS_RFC3686(flags)) {
+		if (keylen < CTR_RFC3686_NONCE_SIZE)
+			return -EINVAL;
+
+		keylen -= CTR_RFC3686_NONCE_SIZE;
+		memcpy(&nonce, key + keylen, CTR_RFC3686_NONCE_SIZE);
+	}
+
+	if (keys.enckeylen > AES_MAX_KEY_SIZE)
+		goto badkey;
+
+	/* auth key
+	 *
+	 * EIP93 can only authenticate with hash of the key
+	 * do software shash until EIP93 hash function complete.
+	 */
+	ipad = kcalloc(2, SHA512_BLOCK_SIZE, GFP_KERNEL);
+	if (!ipad)
+		return -ENOMEM;
+
+	opad = ipad + SHA512_BLOCK_SIZE;
+
+	shash->tfm = ctx->shash;
+
+	if (keys.authkeylen > bs) {
+		err = crypto_shash_digest(shash, keys.authkey,
+					keys.authkeylen, ipad);
+		if (err)
+			return err;
+
+		keys.authkeylen = ds;
+	} else
+		memcpy(ipad, keys.authkey, keys.authkeylen);
+
+	memset(ipad + keys.authkeylen, 0, bs - keys.authkeylen);
+	memcpy(opad, ipad, bs);
+
+	for (i = 0; i < bs; i++) {
+		ipad[i] ^= HMAC_IPAD_VALUE;
+		opad[i] ^= HMAC_OPAD_VALUE;
+	}
+
+	err = crypto_shash_init(shash) ?:
+				 crypto_shash_update(shash, ipad, bs) ?:
+				 crypto_shash_export(shash, ipad) ?:
+				 crypto_shash_init(shash) ?:
+				 crypto_shash_update(shash, opad, bs) ?:
+				 crypto_shash_export(shash, opad);
+
+	if (err)
+		return err;
+
+	/* Encryption key */
+	mtk_ctx_saRecord(ctx, keys.enckey, nonce, keys.enckeylen, flags);
+	/* add auth key */
+	memcpy(&ctx->sa->saIDigest, ipad, SHA256_DIGEST_SIZE);
+	memcpy(&ctx->sa->saODigest, opad, SHA256_DIGEST_SIZE);
+
+	kfree(ipad);
+	return err;
+
+badkey:
+	crypto_aead_set_flags(ctfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+	return -EINVAL;
+}
+
+static int mtk_aead_setauthsize(struct crypto_aead *ctfm,
+				unsigned int authsize)
+{
+	struct crypto_tfm *tfm = crypto_aead_tfm(ctfm);
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(tfm);
+	/* might be needed for IPSec SHA1 (3 Words vs 5 Words)
+	u32 maxauth = crypto_aead_maxauthsize(ctfm);
+	*/
+
+	ctx->authsize = authsize;
+
+	return 0;
+}
+
+static int mtk_aead_crypt(struct aead_request *req)
+{
+	struct mtk_cipher_reqctx *rctx = aead_request_ctx(req);
+	struct crypto_async_request *base = &req->base;
+	struct mtk_cipher_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
+	struct mtk_device *mtk = ctx->mtk;
+	struct crypto_aead *aead = crypto_aead_reqtfm(req);
+	u32 ivsize = crypto_aead_ivsize(aead);
+	int ret;
+	int DescriptorCountDone = MTK_RING_SIZE - 1;
+	int DescriptorDoneTimeout = 3;
+	int DescriptorPendingCount = 0;
+
+	rctx->textsize = req->cryptlen;
+	rctx->assoclen = req->assoclen;
+	rctx->authsize = ctx->authsize;
+	rctx->iv_dma = false;
+	rctx->ivsize = ivsize;
+
+	if IS_DECRYPT(rctx->flags)
+		rctx->textsize -= rctx->authsize;
+
+	if (!rctx->textsize)
+		return 0;
+
+	if (mtk->ring->requests > MTK_RING_BUSY)
+		return -EAGAIN;
+
+	ret = mtk_send_req(base, ctx, req->src, req->dst, req->iv,
+				rctx);
+
+	if (ret < 0) {
+		base->complete(base, ret);
+		return ret;
+	}
+
+	if (ret == 0)
+		return 0;
+
+	spin_lock_bh(&mtk->ring->lock);
+	mtk->ring->requests += ret;
+
+	if (!mtk->ring->busy) {
+		DescriptorPendingCount = min_t(int, mtk->ring->requests, 32);
+		writel(BIT(31) | (DescriptorCountDone & GENMASK(10, 0)) |
+			(((DescriptorPendingCount - 1) & GENMASK(10, 0)) << 16) |
+			((DescriptorDoneTimeout  & GENMASK(4, 0)) << 26),
+			mtk->base + EIP93_REG_PE_RING_THRESH);
+		mtk->ring->busy = true;
+	}
+	spin_unlock_bh(&mtk->ring->lock);
+
+	/* Writing new descriptor count starts DMA action */
+	writel(ret, mtk->base + EIP93_REG_PE_CD_COUNT);
+
+	if (mtk->ring->requests > MTK_RING_BUSY) {
+		rctx->flags |= MTK_BUSY;
+		return -EBUSY;
+	}
+
+	return -EINPROGRESS;
+}
+
+static int mtk_aead_encrypt(struct aead_request *req)
+{
+	struct mtk_cipher_reqctx *rctx = aead_request_ctx(req);
+	struct crypto_async_request *base = &req->base;
+	struct mtk_alg_template *tmpl = container_of(base->tfm->__crt_alg,
+				struct mtk_alg_template, alg.aead.base);
+
+	rctx->flags = tmpl->flags;
+	rctx->flags |= MTK_ENCRYPT;
+
+	return mtk_aead_crypt(req);
+}
+
+static int mtk_aead_decrypt(struct aead_request *req)
+{
+	struct mtk_cipher_reqctx *rctx = aead_request_ctx(req);
+	struct crypto_async_request *base = &req->base;
+	struct mtk_alg_template *tmpl = container_of(base->tfm->__crt_alg,
+				struct mtk_alg_template, alg.aead.base);
+
+	rctx->flags = tmpl->flags;
+	rctx->flags |= MTK_DECRYPT;
+
+	return mtk_aead_crypt(req);
+}
+
+/* Available algorithms in this module */
+
+struct mtk_alg_template mtk_alg_ecb_des = {
+	.type = MTK_ALG_TYPE_SKCIPHER,
+	.flags = MTK_MODE_ECB | MTK_ALG_DES,
+	.alg.skcipher = {
+		.setkey = mtk_skcipher_setkey,
+		.encrypt = mtk_skcipher_encrypt,
+		.decrypt = mtk_skcipher_decrypt,
+		.min_keysize = DES_KEY_SIZE,
+		.max_keysize = DES_KEY_SIZE,
+		.ivsize	= 0,
+		.base = {
+			.cra_name = "ecb(des)",
+			.cra_driver_name = "ebc(des-eip93)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_skcipher_cra_init,
+			.cra_exit = mtk_skcipher_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_cbc_des = {
+	.type = MTK_ALG_TYPE_SKCIPHER,
+	.flags = MTK_MODE_CBC | MTK_ALG_DES,
+	.alg.skcipher = {
+		.setkey = mtk_skcipher_setkey,
+		.encrypt = mtk_skcipher_encrypt,
+		.decrypt = mtk_skcipher_decrypt,
+		.min_keysize = DES_KEY_SIZE,
+		.max_keysize = DES_KEY_SIZE,
+		.ivsize	= DES_BLOCK_SIZE,
+		.base = {
+			.cra_name = "cbc(des)",
+			.cra_driver_name = "cbc(des-eip93)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_skcipher_cra_init,
+			.cra_exit = mtk_skcipher_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_ecb_des3_ede = {
+	.type = MTK_ALG_TYPE_SKCIPHER,
+	.flags = MTK_MODE_ECB | MTK_ALG_3DES,
+	.alg.skcipher = {
+		.setkey = mtk_skcipher_setkey,
+		.encrypt = mtk_skcipher_encrypt,
+		.decrypt = mtk_skcipher_decrypt,
+		.min_keysize = DES3_EDE_KEY_SIZE,
+		.max_keysize = DES3_EDE_KEY_SIZE,
+		.ivsize	= 0,
+		.base = {
+			.cra_name = "ecb(des3_ede)",
+			.cra_driver_name = "ecb(des3_ede-eip93)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_skcipher_cra_init,
+			.cra_exit = mtk_skcipher_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_cbc_des3_ede = {
+	.type = MTK_ALG_TYPE_SKCIPHER,
+	.flags = MTK_MODE_CBC | MTK_ALG_3DES,
+	.alg.skcipher = {
+		.setkey = mtk_skcipher_setkey,
+		.encrypt = mtk_skcipher_encrypt,
+		.decrypt = mtk_skcipher_decrypt,
+		.min_keysize = DES3_EDE_KEY_SIZE,
+		.max_keysize = DES3_EDE_KEY_SIZE,
+		.ivsize	= DES3_EDE_BLOCK_SIZE,
+		.base = {
+			.cra_name = "cbc(des3_ede)",
+			.cra_driver_name = "cbc(des3_ede-eip93)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_skcipher_cra_init,
+			.cra_exit = mtk_skcipher_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_ecb_aes = {
+	.type = MTK_ALG_TYPE_SKCIPHER,
+	.flags = MTK_MODE_ECB | MTK_ALG_AES,
+	.alg.skcipher = {
+		.setkey = mtk_skcipher_setkey,
+		.encrypt = mtk_skcipher_encrypt,
+		.decrypt = mtk_skcipher_decrypt,
+		.min_keysize = AES_MIN_KEY_SIZE,
+		.max_keysize = AES_MAX_KEY_SIZE,
+		.ivsize	= 0,
+		.base = {
+			.cra_name = "ecb(aes)",
+			.cra_driver_name = "ecb(aes-eip93)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_NEED_FALLBACK |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0xf,
+			.cra_init = mtk_skcipher_cra_init,
+			.cra_exit = mtk_skcipher_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_cbc_aes = {
+	.type = MTK_ALG_TYPE_SKCIPHER,
+	.flags = MTK_MODE_CBC | MTK_ALG_AES,
+	.alg.skcipher = {
+		.setkey = mtk_skcipher_setkey,
+		.encrypt = mtk_skcipher_encrypt,
+		.decrypt = mtk_skcipher_decrypt,
+		.min_keysize = AES_MIN_KEY_SIZE,
+		.max_keysize = AES_MAX_KEY_SIZE,
+		.ivsize	= AES_BLOCK_SIZE,
+		.base = {
+			.cra_name = "cbc(aes)",
+			.cra_driver_name = "cbc(aes-eip93)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_NEED_FALLBACK |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0xf,
+			.cra_init = mtk_skcipher_cra_init,
+			.cra_exit = mtk_skcipher_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_ctr_aes = {
+	.type = MTK_ALG_TYPE_SKCIPHER,
+	.flags = MTK_MODE_CTR | MTK_ALG_AES,
+	.alg.skcipher = {
+		.setkey = mtk_skcipher_setkey,
+		.encrypt = mtk_skcipher_encrypt,
+		.decrypt = mtk_skcipher_decrypt,
+		.min_keysize = AES_MIN_KEY_SIZE,
+		.max_keysize = AES_MAX_KEY_SIZE,
+		.ivsize	= AES_BLOCK_SIZE,
+		.base = {
+			.cra_name = "ctr(aes)",
+			.cra_driver_name = "ctr(aes-eip93)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+				     CRYPTO_ALG_NEED_FALLBACK |
+				     CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = 1,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0xf,
+			.cra_init = mtk_skcipher_cra_init,
+			.cra_exit = mtk_skcipher_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_rfc3686_aes = {
+	.type = MTK_ALG_TYPE_SKCIPHER,
+	.flags = MTK_MODE_CTR | MTK_MODE_RFC3686 | MTK_ALG_AES,
+	.alg.skcipher = {
+		.setkey = mtk_skcipher_setkey,
+		.encrypt = mtk_skcipher_encrypt,
+		.decrypt = mtk_skcipher_decrypt,
+		.min_keysize = AES_MIN_KEY_SIZE + CTR_RFC3686_NONCE_SIZE,
+		.max_keysize = AES_MAX_KEY_SIZE + CTR_RFC3686_NONCE_SIZE,
+		.ivsize	= CTR_RFC3686_IV_SIZE,
+		.base = {
+			.cra_name = "rfc3686(ctr(aes))",
+			.cra_driver_name = "rfc3686(ctr(aes-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_NEED_FALLBACK |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = 1,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0xf,
+			.cra_init = mtk_skcipher_cra_init,
+			.cra_exit = mtk_skcipher_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+/* Available authenc algorithms in this module */
+
+struct mtk_alg_template mtk_alg_authenc_hmac_md5_cbc_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_MD5 | MTK_MODE_CBC | MTK_ALG_AES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= AES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = MD5_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(md5),cbc(aes))",
+			.cra_driver_name =
+				"authenc(hmac(md5-eip93), cbc(aes-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha1_cbc_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA1 | MTK_MODE_CBC | MTK_ALG_AES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= AES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA1_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha1),cbc(aes))",
+			.cra_driver_name =
+				"authenc(hmac(sha1-eip93),cbc(aes-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha224_cbc_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA224 | MTK_MODE_CBC | MTK_ALG_AES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= AES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA224_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha224),cbc(aes))",
+			.cra_driver_name =
+				"authenc(hmac(sha224-eip93),cbc(aes-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha256_cbc_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA256 | MTK_MODE_CBC | MTK_ALG_AES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= AES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA256_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha256),cbc(aes))",
+			.cra_driver_name =
+				"authenc(hmac(sha256-eip93),cbc(aes-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_md5_rfc3686_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_MD5 |
+			MTK_MODE_CTR | MTK_MODE_RFC3686 | MTK_ALG_AES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= CTR_RFC3686_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = MD5_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(md5),rfc3686(ctr(aes)))",
+			.cra_driver_name =
+			"authenc(hmac(md5-eip93),rfc3686(ctr(aes-eip93)))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = 1,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha1_rfc3686_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA1 |
+			MTK_MODE_CTR | MTK_MODE_RFC3686 | MTK_ALG_AES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= CTR_RFC3686_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA1_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha1),rfc3686(ctr(aes)))",
+			.cra_driver_name =
+			"authenc(hmac(sha1-eip93),rfc3686(ctr(aes-eip93)))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = 1,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha224_rfc3686_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA224 |
+			MTK_MODE_CTR | MTK_MODE_RFC3686 | MTK_ALG_AES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= CTR_RFC3686_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA224_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha224),rfc3686(ctr(aes)))",
+			.cra_driver_name =
+			"authenc(hmac(sha224-eip93),rfc3686(ctr(aes-eip93)))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = 1,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha256_rfc3686_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA256 |
+			MTK_MODE_CTR | MTK_MODE_RFC3686 | MTK_ALG_AES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= CTR_RFC3686_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA256_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha256),rfc3686(ctr(aes)))",
+			.cra_driver_name =
+			"authenc(hmac(sha256-eip93),rfc3686(ctr(aes-eip93)))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = 1,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_md5_cbc_des = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_MD5 | MTK_MODE_CBC | MTK_ALG_DES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = MD5_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(md5),cbc(des))",
+			.cra_driver_name =
+				"authenc(hmac(md5-eip93),cbc(des-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha1_cbc_des = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA1 | MTK_MODE_CBC | MTK_ALG_DES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA1_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha1),cbc(des))",
+			.cra_driver_name =
+				"authenc(hmac(sha1-eip93),cbc(des-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha224_cbc_des = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA224 | MTK_MODE_CBC | MTK_ALG_DES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA224_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha224),cbc(des))",
+			.cra_driver_name =
+				"authenc(hmac(sha224-eip93),cbc(des-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha256_cbc_des = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA256 | MTK_MODE_CBC | MTK_ALG_DES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA256_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha256),cbc(des))",
+			.cra_driver_name =
+				"authenc(hmac(sha256-eip93),cbc(des-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_md5_cbc_des3_ede = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_MD5 | MTK_MODE_CBC | MTK_ALG_3DES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES3_EDE_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = MD5_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(md5),cbc(des3_ede))",
+			.cra_driver_name =
+				"authenc(hmac(md5-eip93),cbc(des3_ede-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0x0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha1_cbc_des3_ede = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA1 | MTK_MODE_CBC | MTK_ALG_3DES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES3_EDE_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA1_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha1),cbc(des3_ede))",
+			.cra_driver_name =
+				"authenc(hmac(sha1-eip93),cbc(des3_ede-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0x0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha224_cbc_des3_ede = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA224 | MTK_MODE_CBC | MTK_ALG_3DES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES3_EDE_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA224_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha224),cbc(des3_ede))",
+			.cra_driver_name =
+			"authenc(hmac(sha224-eip93),cbc(des3_ede-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0x0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha256_cbc_des3_ede = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA256 | MTK_MODE_CBC | MTK_ALG_3DES,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES3_EDE_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA256_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha256),cbc(des3_ede))",
+			.cra_driver_name =
+			"authenc(hmac(sha256-eip93),cbc(des3_ede-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0x0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+/* Single pass IPSEC ESP descriptor */
+struct mtk_alg_template mtk_alg_authenc_hmac_md5_ecb_null = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_MD5,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= NULL_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = MD5_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(md5),ecb(cipher_null))",
+			.cra_driver_name = "authenc(hmac(md5-eip93),"
+						"ecb(cipher_null)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = NULL_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0x0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha1_ecb_null = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA1,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= NULL_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA1_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha1),ecb(cipher_null))",
+			.cra_driver_name = "authenc(hmac(sha1-eip93),"
+						"ecb(cipher_null)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = NULL_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0x0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha224_ecb_null = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA224,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= NULL_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA224_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha224),ecb(cipher_null))",
+			.cra_driver_name = "authenc(hmac(sha224-eip93),"
+						"ecb(cipher_null)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = NULL_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0x0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_authenc_hmac_sha256_ecb_null = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA256,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= NULL_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA256_DIGEST_SIZE,
+		.base = {
+			.cra_name = "authenc(hmac(sha256),ecb(cipher_null))",
+			.cra_driver_name = "authenc(hmac(sha256-eip93),"
+						"ecb(cipher_null)",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = NULL_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0x0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_echainiv_authenc_hmac_md5_cbc_des = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_MD5 | MTK_MODE_CBC |
+			MTK_ALG_DES | MTK_GENIV,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= DES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = MD5_DIGEST_SIZE,
+		.base = {
+			.cra_name = "echainiv(authenc(hmac(md5),cbc(des)))",
+			.cra_driver_name = "echainiv(authenc(hmac(md5-eip93)"
+					",cbc(des-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = DES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_echainiv_authenc_hmac_sha1_cbc_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA1 | MTK_MODE_CBC |
+			MTK_ALG_AES | MTK_GENIV,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= AES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA1_DIGEST_SIZE,
+		.base = {
+			.cra_name = "echainiv(authenc(hmac(sha1),cbc(aes)))",
+			.cra_driver_name = "echainiv(authenc(hmac(sha1-eip93)"
+					",cbc(aes-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_echainiv_authenc_hmac_sha256_cbc_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA256 | MTK_MODE_CBC |
+			MTK_ALG_AES | MTK_GENIV,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= AES_BLOCK_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA256_DIGEST_SIZE,
+		.base = {
+			.cra_name = "echainiv(authenc(hmac(sha256),cbc(aes)))",
+			.cra_driver_name = "echainiv(authenc(hmac(sha256-eip93)"
+				",cbc(aes-eip93))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = AES_BLOCK_SIZE,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_seqiv_authenc_hmac_sha1_rfc3686_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA1 | MTK_ALG_AES |
+			MTK_MODE_CTR | MTK_MODE_RFC3686 | MTK_GENIV,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= CTR_RFC3686_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA1_DIGEST_SIZE,
+		.base = {
+			.cra_name = "seqiv(authenc(hmac(sha1),rfc3686(ctr(aes))))",
+			.cra_driver_name = "seqiv(authenc(hmac(sha1-eip93),"
+				"rfc3686(ctr(aes-eip93)))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = 1,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
+
+struct mtk_alg_template mtk_alg_seqiv_authenc_hmac_sha256_rfc3686_aes = {
+	.type = MTK_ALG_TYPE_AEAD,
+	.flags = MTK_HASH_HMAC | MTK_HASH_SHA256 | MTK_ALG_AES |
+			MTK_MODE_CTR | MTK_MODE_RFC3686 | MTK_GENIV,
+	.alg.aead = {
+		.setkey = mtk_aead_setkey,
+		.encrypt = mtk_aead_encrypt,
+		.decrypt = mtk_aead_decrypt,
+		.ivsize	= CTR_RFC3686_IV_SIZE,
+		.setauthsize = mtk_aead_setauthsize,
+		.maxauthsize = SHA256_DIGEST_SIZE,
+		.base = {
+			.cra_name = "seqiv(authenc(hmac(sha256),rfc3686(ctr(aes))))",
+			.cra_driver_name = "seqiv(authenc(hmac(sha256-eip93),"
+				"rfc3686(ctr(aes-eip93)))",
+			.cra_priority = MTK_CRA_PRIORITY,
+			.cra_flags = CRYPTO_ALG_ASYNC |
+					CRYPTO_ALG_KERN_DRIVER_ONLY,
+			.cra_blocksize = 1,
+			.cra_ctxsize = sizeof(struct mtk_cipher_ctx),
+			.cra_alignmask = 0,
+			.cra_init = mtk_aead_cra_init,
+			.cra_exit = mtk_aead_cra_exit,
+			.cra_module = THIS_MODULE,
+		},
+	},
+};
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-cipher.h b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-cipher.h
new file mode 100644
index 000000000..fdeeaf630
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-cipher.h
@@ -0,0 +1,89 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+#ifndef _CIPHER_H_
+#define _CIPHER_H_
+
+extern struct mtk_alg_template mtk_alg_ecb_aes;
+extern struct mtk_alg_template mtk_alg_cbc_aes;
+extern struct mtk_alg_template mtk_alg_ctr_aes;
+extern struct mtk_alg_template mtk_alg_rfc3686_aes;
+extern struct mtk_alg_template mtk_alg_ecb_des;
+extern struct mtk_alg_template mtk_alg_cbc_des;
+extern struct mtk_alg_template mtk_alg_ecb_des3_ede;
+extern struct mtk_alg_template mtk_alg_cbc_des3_ede;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_md5_cbc_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha1_cbc_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha224_cbc_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha256_cbc_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_md5_ctr_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha1_ctr_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha224_ctr_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha256_ctr_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_md5_rfc3686_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha1_rfc3686_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha224_rfc3686_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha256_rfc3686_aes;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_md5_cbc_des;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha1_cbc_des;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha224_cbc_des;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha256_cbc_des;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_md5_cbc_des3_ede;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha1_cbc_des3_ede;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha224_cbc_des3_ede;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha256_cbc_des3_ede;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_md5_ecb_null;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha1_ecb_null;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha224_ecb_null;
+extern struct mtk_alg_template mtk_alg_authenc_hmac_sha256_ecb_null;
+extern struct mtk_alg_template mtk_alg_echainiv_authenc_hmac_md5_cbc_des;
+extern struct mtk_alg_template mtk_alg_echainiv_authenc_hmac_sha1_cbc_aes;
+extern struct mtk_alg_template mtk_alg_echainiv_authenc_hmac_sha256_cbc_aes;
+extern struct mtk_alg_template mtk_alg_seqiv_authenc_hmac_sha1_rfc3686_aes;
+extern struct mtk_alg_template mtk_alg_seqiv_authenc_hmac_sha256_rfc3686_aes;
+
+struct mtk_cipher_ctx {
+	struct mtk_device		*mtk;
+	struct saRecord_s		*sa;
+	struct crypto_skcipher		*fallback;
+	/* AEAD specific */
+	unsigned int			authsize;
+	struct crypto_shash		*shash;
+	bool				aead;
+};
+
+struct mtk_cipher_reqctx {
+	unsigned long			flags;
+	u32				textsize;
+	u32				ivsize;
+	bool				iv_dma;
+	struct saRecord_s		*saRecord;
+	dma_addr_t			saRecord_base;
+	struct saState_s		*saState;
+	dma_addr_t			saState_base;
+	/* copy in case of mis-alignment or AEAD if no-consecutive blocks */
+	struct scatterlist		*sg_src;
+	struct scatterlist		*sg_dst;
+	/* AES-CTR in case of counter overflow */
+	struct saState_s		*saState_ctr;
+	dma_addr_t			saState_base_ctr;
+	struct scatterlist		ctr_src[2];
+	struct scatterlist		ctr_dst[2];
+	/* AEAD */
+	u32				assoclen;
+	u32				authsize;
+	/* request fallback, keep at the end */
+	struct skcipher_request		fallback_req;
+};
+
+void mtk_skcipher_handle_result(struct mtk_device *mtk,
+				struct crypto_async_request *async,
+				bool complete, int err);
+
+void mtk_aead_handle_result(struct mtk_device *mtk,
+			struct crypto_async_request *async,
+			bool complete,  int err);
+#endif /* _CIPHER_H_ */
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-common.h b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-common.h
new file mode 100644
index 000000000..5781494ae
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-common.h
@@ -0,0 +1,202 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+
+#ifndef _COMMON_H_
+#define _COMMON_H_
+
+#include <linux/bits.h>
+
+#define MTK_RING_SIZE			256
+#define MTK_RING_BUSY			224
+#define NUM_AES_BYPASS			256
+#define MTK_QUEUE_LENGTH		128
+#define MTK_CRA_PRIORITY		1500
+
+#define MTK_DESC_ASYNC			BIT(0)
+#define MTK_DESC_SKCIPHER		BIT(1)
+#define MTK_DESC_AEAD			BIT(2)
+#define MTK_DESC_AHASH			BIT(3)
+#define MTK_DESC_PRNG			BIT(4)
+#define MTK_DESC_FAKE_HMAC		BIT(5)
+#define MTK_DESC_LAST			BIT(6)
+#define MTK_DESC_FINISH			BIT(7)
+
+/* cipher algorithms */
+#define MTK_ALG_DES			BIT(0)
+#define MTK_ALG_3DES			BIT(1)
+#define MTK_ALG_AES			BIT(2)
+#define MTK_ALG_MASK			GENMASK(2, 0)
+/* hash and hmac algorithms */
+#define MTK_HASH_MD5			BIT(3)
+#define MTK_HASH_SHA1			BIT(4)
+#define MTK_HASH_SHA224			BIT(5)
+#define MTK_HASH_SHA256			BIT(6)
+#define MTK_HASH_HMAC			BIT(7)
+#define MTK_HASH_MASK			GENMASK(6, 3)
+/* cipher modes */
+#define MTK_MODE_CBC			BIT(8)
+#define MTK_MODE_ECB			BIT(9)
+#define MTK_MODE_CTR			BIT(10)
+#define MTK_MODE_RFC3686		BIT(11)
+#define MTK_MODE_MASK			GENMASK(10, 8)
+
+/* cipher encryption/decryption operations */
+#define MTK_ENCRYPT			BIT(12)
+#define MTK_DECRYPT			BIT(13)
+
+#define MTK_GENIV			BIT(14)
+#define MTK_BUSY			BIT(15)
+
+#define IS_DES(flags)			(flags & MTK_ALG_DES)
+#define IS_3DES(flags)			(flags & MTK_ALG_3DES)
+#define IS_AES(flags)			(flags & MTK_ALG_AES)
+
+#define IS_HASH_MD5(flags)		(flags & MTK_HASH_MD5)
+#define IS_HASH_SHA1(flags)		(flags & MTK_HASH_SHA1)
+#define IS_HASH_SHA224(flags)		(flags & MTK_HASH_SHA224)
+#define IS_HASH_SHA256(flags)		(flags & MTK_HASH_SHA256)
+#define IS_HMAC(flags)			(flags & MTK_HASH_HMAC)
+
+#define IS_CBC(mode)			(mode & MTK_MODE_CBC)
+#define IS_ECB(mode)			(mode & MTK_MODE_ECB)
+#define IS_CTR(mode)			(mode & MTK_MODE_CTR)
+#define IS_RFC3686(mode)		(mode & MTK_MODE_RFC3686)
+#define IS_GENIV(flags)			(flags & MTK_GENIV)
+
+#define IS_BUSY(flags)			(flags & MTK_BUSY)
+
+#define IS_ENCRYPT(dir)			(dir & MTK_ENCRYPT)
+#define IS_DECRYPT(dir)			(dir & MTK_DECRYPT)
+
+#define IS_CIPHER(flags)		(flags & (MTK_ALG_DES || \
+						MTK_ALG_3DES ||  \
+						MTK_ALG_AES))
+
+#define IS_HASH(flags)			(flags & (MTK_HASH_MD5 ||  \
+						MTK_HASH_SHA1 ||   \
+						MTK_HASH_SHA224 || \
+						MTK_HASH_SHA256))
+
+/*
+ * Interrupts of EIP93
+ */
+
+typedef enum {
+	EIP93_INT_PE_CDRTHRESH_REQ =	BIT(0),
+	EIP93_INT_PE_RDRTHRESH_REQ =	BIT(1),
+	EIP93_INT_PE_OPERATION_DONE =	BIT(9),
+	EIP93_INT_PE_INBUFTHRESH_REQ =	BIT(10),
+	EIP93_INT_PE_OUTBURTHRSH_REQ =	BIT(11),
+	EIP93_INT_PE_PRNG_IRQ =		BIT(12),
+	EIP93_INT_PE_ERR_REG =		BIT(13),
+	EIP93_INT_PE_RD_DONE_IRQ =	BIT(16),
+} EIP93_InterruptSource_t;
+
+typedef union {
+	struct {
+		unsigned int opCode		:3;
+		unsigned int direction		:1;
+		unsigned int opGroup		:2;
+		unsigned int padType		:2;
+		unsigned int cipher		:4;
+		unsigned int hash		:4;
+		unsigned int reserved2		:1;
+		unsigned int scPad		:1;
+		unsigned int extPad		:1;
+		unsigned int hdrProc		:1;
+		unsigned int digestLength	:4;
+		unsigned int ivSource		:2;
+		unsigned int hashSource		:2;
+		unsigned int saveIv		:1;
+		unsigned int saveHash		:1;
+		unsigned int reserved1		:2;
+	} bits;
+	unsigned int word;
+
+} saCmd0_t;
+
+typedef union {
+	struct {
+		unsigned int copyDigest		:1;
+		unsigned int copyHeader		:1;
+		unsigned int copyPayload	:1;
+		unsigned int copyPad		:1;
+		unsigned int reserved4		:4;
+		unsigned int cipherMode		:2;
+		unsigned int reserved3		:1;
+		unsigned int sslMac		:1;
+		unsigned int hmac		:1;
+		unsigned int byteOffset		:1;
+		unsigned int reserved2		:2;
+		unsigned int hashCryptOffset	:8;
+		unsigned int aesKeyLen		:3;
+		unsigned int reserved1		:1;
+		unsigned int aesDecKey		:1;
+		unsigned int seqNumCheck	:1;
+		unsigned int reserved0		:2;
+	} bits;
+	unsigned int word;
+
+} saCmd1_t;
+
+typedef struct saRecord_s {
+	saCmd0_t	saCmd0;
+	saCmd1_t	saCmd1;
+	unsigned int	saKey[8];
+	unsigned int	saIDigest[8];
+	unsigned int	saODigest[8];
+	unsigned int	saSpi;
+	unsigned int	saSeqNum[2];
+	unsigned int	saSeqNumMask[2];
+	unsigned int	saNonce;
+} saRecord_t;
+
+typedef struct saState_s {
+	unsigned int	stateIv[4];
+	unsigned int	stateByteCnt[2];
+	unsigned int	stateIDigest[8];
+} saState_t;
+
+typedef union {
+	struct {
+		unsigned int hostReady		:1;
+		unsigned int peReady		:1;
+		unsigned int reserved		:1;
+		unsigned int initArc4		:1;
+		unsigned int hashFinal		:1;
+		unsigned int haltMode		:1;
+		unsigned int prngMode		:2;
+		unsigned int padValue		:8;
+		unsigned int errStatus		:8;
+		unsigned int padCrtlStat	:8;
+	} bits;
+	unsigned int word;
+} peCrtlStat_t;
+
+typedef union {
+	struct {
+		unsigned int length		:20;
+		unsigned int reserved		:2;
+		unsigned int hostReady		:1;
+		unsigned int peReady		:1;
+		unsigned int byPass		:8;
+	} bits;
+	unsigned int word;
+} peLength_t;
+
+typedef struct eip93_descriptor_s {
+	peCrtlStat_t		peCrtlStat;
+	unsigned int		srcAddr;
+	unsigned int		dstAddr;
+	unsigned int		saAddr;
+	unsigned int		stateAddr;
+	unsigned int		arc4Addr;
+	unsigned int		userId;
+	peLength_t		peLength;
+} eip93_descriptor_t;
+
+#endif /* _COMMON_H_ */
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-core.c b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-core.c
new file mode 100644
index 000000000..257c5ca4f
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-core.c
@@ -0,0 +1,566 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+//#define DEBUG 1
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/dmapool.h>
+#include <linux/interrupt.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/spinlock.h>
+#include <linux/types.h>
+
+#include <crypto/internal/aead.h>
+#include <crypto/internal/skcipher.h>
+#include <crypto/internal/hash.h>
+
+#include "eip93-regs.h"
+#include "eip93-common.h"
+#include "eip93-core.h"
+#include "eip93-ring.h"
+#include "eip93-cipher.h"
+#include "eip93-prng.h"
+
+static struct mtk_alg_template *mtk_algs[] = {
+	&mtk_alg_ecb_des,
+	&mtk_alg_cbc_des,
+	&mtk_alg_ecb_des3_ede,
+	&mtk_alg_cbc_des3_ede,
+	&mtk_alg_ecb_aes,
+	&mtk_alg_cbc_aes,
+	&mtk_alg_ctr_aes,
+	&mtk_alg_rfc3686_aes,
+	&mtk_alg_authenc_hmac_md5_cbc_des,
+	&mtk_alg_authenc_hmac_sha1_cbc_des,
+	&mtk_alg_authenc_hmac_sha224_cbc_des,
+	&mtk_alg_authenc_hmac_sha256_cbc_des,
+	&mtk_alg_authenc_hmac_md5_cbc_des3_ede,
+	&mtk_alg_authenc_hmac_sha1_cbc_des3_ede,
+	&mtk_alg_authenc_hmac_sha224_cbc_des3_ede,
+	&mtk_alg_authenc_hmac_sha256_cbc_des3_ede,
+	&mtk_alg_authenc_hmac_md5_cbc_aes,
+	&mtk_alg_authenc_hmac_sha1_cbc_aes,
+	&mtk_alg_authenc_hmac_sha224_cbc_aes,
+	&mtk_alg_authenc_hmac_sha256_cbc_aes,
+	&mtk_alg_authenc_hmac_md5_rfc3686_aes,
+	&mtk_alg_authenc_hmac_sha1_rfc3686_aes,
+	&mtk_alg_authenc_hmac_sha224_rfc3686_aes,
+	&mtk_alg_authenc_hmac_sha256_rfc3686_aes,
+	&mtk_alg_authenc_hmac_md5_ecb_null,
+	&mtk_alg_authenc_hmac_sha1_ecb_null,
+	&mtk_alg_authenc_hmac_sha224_ecb_null,
+	&mtk_alg_authenc_hmac_sha256_ecb_null,
+	&mtk_alg_echainiv_authenc_hmac_md5_cbc_des,
+	&mtk_alg_echainiv_authenc_hmac_sha1_cbc_aes,
+	&mtk_alg_echainiv_authenc_hmac_sha256_cbc_aes,
+//	&mtk_alg_seqiv_authenc_hmac_sha1_rfc3686_aes,
+//	&mtk_alg_seqiv_authenc_hmac_sha256_rfc3686_aes,
+//	&mtk_alg_prng,
+//	&mtk_alg_cprng,
+};
+
+static void mtk_unregister_algs(struct mtk_device *mtk, int i)
+{
+	int j;
+
+	for (j = 0; j < i; j++) {
+		switch (mtk_algs[j]->type) {
+		case MTK_ALG_TYPE_SKCIPHER:
+			dev_dbg(mtk->dev, "unregistering: %s",
+				mtk_algs[j]->alg.skcipher.base.cra_name);
+			crypto_unregister_skcipher(&mtk_algs[j]->alg.skcipher);
+			break;
+		case MTK_ALG_TYPE_AEAD:
+			dev_dbg(mtk->dev, "unregistering: %s",
+				mtk_algs[j]->alg.aead.base.cra_name);
+			crypto_unregister_aead(&mtk_algs[j]->alg.aead);
+			break;
+		case MTK_ALG_TYPE_AHASH:
+			dev_dbg(mtk->dev, "unregistering: %s",
+				mtk_algs[j]->alg.ahash.halg.base.cra_name);
+			crypto_unregister_ahash(&mtk_algs[j]->alg.ahash);
+			break;
+		case MTK_ALG_TYPE_PRNG:
+			dev_dbg(mtk->dev, "unregistering: %s",
+				mtk_algs[j]->alg.rng.base.cra_name);
+			crypto_unregister_rng(&mtk_algs[j]->alg.rng);
+		}
+	}
+}
+
+static int mtk_register_algs(struct mtk_device *mtk)
+{
+	int i, ret = 0;
+
+	for (i = 0; i < ARRAY_SIZE(mtk_algs); i++) {
+		mtk_algs[i]->mtk = mtk;
+
+		switch (mtk_algs[i]->type) {
+		case MTK_ALG_TYPE_SKCIPHER:
+			dev_dbg(mtk->dev, "registering: %s",
+				mtk_algs[i]->alg.skcipher.base.cra_name);
+			ret = crypto_register_skcipher(&mtk_algs[i]->alg.skcipher);
+			break;
+		case MTK_ALG_TYPE_AEAD:
+			dev_dbg(mtk->dev, "registering: %s",
+				mtk_algs[i]->alg.aead.base.cra_name);
+			ret = crypto_register_aead(&mtk_algs[i]->alg.aead);
+			break;
+		case MTK_ALG_TYPE_AHASH:
+			dev_dbg(mtk->dev, "registering: %s",
+				mtk_algs[i]->alg.ahash.halg.base.cra_name);
+			ret = crypto_register_ahash(&mtk_algs[i]->alg.ahash);
+			break;
+		case MTK_ALG_TYPE_PRNG:
+			dev_dbg(mtk->dev, "registering: %s",
+				mtk_algs[i]->alg.rng.base.cra_name);
+			ret = crypto_register_rng(&mtk_algs[i]->alg.rng);
+		}
+		if (ret)
+			goto fail;
+	}
+
+	return 0;
+
+fail:
+	mtk_unregister_algs(mtk, i);
+
+	return ret;
+}
+
+static inline void mtk_irq_disable(struct mtk_device *mtk, u32 mask)
+{
+	__raw_writel(mask, mtk->base + EIP93_REG_MASK_DISABLE);
+	__raw_readl(mtk->base + EIP93_REG_MASK_DISABLE);
+}
+
+static inline void mtk_irq_enable(struct mtk_device *mtk, u32 mask)
+{
+	__raw_writel(mask, mtk->base + EIP93_REG_MASK_ENABLE);
+	__raw_readl(mtk->base + EIP93_REG_MASK_ENABLE);
+}
+
+static inline void mtk_irq_clear(struct mtk_device *mtk, u32 mask)
+{
+	__raw_writel(mask, mtk->base + EIP93_REG_INT_CLR);
+	__raw_readl(mtk->base + EIP93_REG_INT_CLR);
+}
+
+inline void mtk_push_request(struct mtk_device *mtk, int DescriptorPendingCount)
+{
+	int DescriptorCountDone = MTK_RING_SIZE - 1;
+	int DescriptorDoneTimeout = 3;
+
+	DescriptorPendingCount = min_t(int, mtk->ring->requests, 32);
+
+	if (!DescriptorPendingCount)
+		return;
+
+	writel(BIT(31) | (DescriptorCountDone & GENMASK(10, 0)) |
+		(((DescriptorPendingCount - 1) & GENMASK(10, 0)) << 16) |
+		((DescriptorDoneTimeout  & GENMASK(4, 0)) << 26),
+		mtk->base + EIP93_REG_PE_RING_THRESH);
+}
+
+static void mtk_handle_result_descriptor(struct mtk_device *mtk)
+{
+	struct crypto_async_request *async = NULL;
+	struct eip93_descriptor_s *rdesc;
+	int handled = 0, nreq;
+	int try, ret, err = 0;
+	volatile int done1, done2;
+	bool last_entry = false;
+	bool complete = false;
+	u32 flags;
+
+get_more:
+	nreq = readl(mtk->base + EIP93_REG_PE_RD_COUNT) & GENMASK(10, 0);
+
+	while (nreq) {
+		rdesc = mtk_get_descriptor(mtk);
+		if (IS_ERR(rdesc)) {
+			dev_err(mtk->dev, "Ndesc: %d nreq: %d\n", handled, nreq);
+			ret = -EIO;
+			break;
+		}
+		/* make sure EIP93 finished writing all data
+		 * (volatile int) used since bits will be updated via DMA
+		*/
+		try = 0;
+		while (try < 1000) {
+			done1 = (volatile int)rdesc->peCrtlStat.bits.peReady;
+			done2 = (volatile int)rdesc->peLength.bits.peReady;
+			if ((!done1) || (!done2)) {
+					try++;
+					cpu_relax();
+					continue;
+			}
+			break;
+		}
+		/*
+		if (try)
+			dev_err(mtk->dev, "EIP93 try-count: %d", try);
+		*/
+		err = rdesc->peCrtlStat.bits.errStatus;
+		if (err) {
+			dev_err(mtk->dev, "Err: %02x\n", err);
+		}
+
+		handled++;
+
+		flags = rdesc->userId;
+		if (flags & MTK_DESC_FINISH)
+			complete = true;
+
+		if (flags & MTK_DESC_LAST) {
+			last_entry = true;
+			break;
+		}
+		nreq--;
+	}
+
+	if (last_entry) {
+		last_entry = false;
+		if (flags & MTK_DESC_PRNG)
+			mtk_prng_done(mtk, err);
+
+		if (flags & MTK_DESC_SKCIPHER) {
+			async = (struct crypto_async_request *)rdesc->arc4Addr;
+			mtk_skcipher_handle_result(mtk, async, complete, err);
+		}
+
+		if (flags & MTK_DESC_AEAD) {
+			async = (struct crypto_async_request *)rdesc->arc4Addr;
+			mtk_aead_handle_result(mtk, async, complete, err);
+		}
+
+	}
+
+	if (handled) {
+		writel(handled, mtk->base + EIP93_REG_PE_RD_COUNT);
+		spin_lock(&mtk->ring->lock);
+		mtk->ring->requests -= handled;
+		if (!mtk->ring->requests) {
+			mtk->ring->busy = false;
+			spin_unlock(&mtk->ring->lock);
+			goto queue_done;
+		}
+		spin_unlock(&mtk->ring->lock);
+		handled = 0;
+		goto get_more;
+	}
+
+	spin_lock(&mtk->ring->lock);
+	if (mtk->ring->requests)
+		mtk_push_request(mtk, mtk->ring->requests);
+	else
+		mtk->ring->busy = false;
+
+	spin_unlock(&mtk->ring->lock);
+queue_done:
+	mtk_irq_enable(mtk, BIT(1));
+}
+
+static irqreturn_t mtk_irq_handler(int irq, void *dev_id)
+{
+	struct mtk_device *mtk = (struct mtk_device *)dev_id;
+	u32 irq_status;
+
+	irq_status = readl(mtk->base + EIP93_REG_INT_MASK_STAT);
+
+	if (irq_status & BIT(1)) {
+		mtk_irq_clear(mtk, BIT(1));
+		mtk_irq_disable(mtk, BIT(1));
+		tasklet_hi_schedule(&mtk->done);
+		return IRQ_HANDLED;
+	}
+
+/* TODO: error handler; for now just clear ALL */
+	dev_err(mtk->dev, "IRQ: %08x\n", irq_status);
+	mtk_irq_clear(mtk, irq_status);
+	if (irq_status) {
+		printk("disable irq\n");
+		mtk_irq_disable(mtk, irq_status);
+	}
+	return IRQ_NONE;
+}
+
+static void mtk_done_tasklet(unsigned long data)
+{
+	struct mtk_device *mtk = (struct mtk_device *)data;
+
+	mtk_handle_result_descriptor(mtk);
+}
+
+void mtk_initialize(struct mtk_device *mtk)
+{
+	uint8_t fRstPacketEngine = 1;
+	uint8_t fResetRing = 1;
+	uint8_t PE_Mode = 3;
+	uint8_t fBO_PD_en = 0;
+	uint8_t fBO_SA_en = 0;
+	uint8_t fBO_Data_en = 0;
+	uint8_t fBO_TD_en = 0;
+	uint8_t fEnablePDRUpdate = 1;
+	int InputThreshold = 128;
+	int OutputThreshold = 128;
+	int DescriptorCountDone = MTK_RING_SIZE - 1;
+	int DescriptorPendingCount = 1;
+	int DescriptorDoneTimeout = 3;
+	u32 regVal;
+
+	writel((fRstPacketEngine & 1) |
+		((fResetRing & 1) << 1) |
+		((PE_Mode & GENMASK(2, 0)) << 8) |
+		((fBO_PD_en & 1) << 16) |
+		((fBO_SA_en & 1) << 17) |
+		((fBO_Data_en  & 1) << 18) |
+		((fBO_TD_en & 1) << 20) |
+		((fEnablePDRUpdate & 1) << 10),
+		mtk->base + EIP93_REG_PE_CONFIG);
+
+	udelay(10);
+
+	fRstPacketEngine = 0;
+	fResetRing = 0;
+
+	writel((fRstPacketEngine & 1) |
+		((fResetRing & 1) << 1) |
+		((PE_Mode & GENMASK(2, 0)) << 8) |
+		((fBO_PD_en & 1) << 16) |
+		((fBO_SA_en & 1) << 17) |
+		((fBO_Data_en  & 1) << 18) |
+		((fBO_TD_en & 1) << 20) |
+		((fEnablePDRUpdate & 1) << 10),
+		mtk->base + EIP93_REG_PE_CONFIG);
+
+	/* Initialize the BYTE_ORDER_CFG register */
+	writel((EIP93_BYTE_ORDER_PD & GENMASK(4, 0)) |
+		((EIP93_BYTE_ORDER_SA & GENMASK(4, 0)) << 4) |
+		((EIP93_BYTE_ORDER_DATA & GENMASK(4, 0)) << 8) |
+		((EIP93_BYTE_ORDER_TD & GENMASK(2, 0)) << 16),
+		mtk->base + EIP93_REG_PE_ENDIAN_CONFIG);
+	/* Initialize the INT_CFG register */
+	writel((EIP93_INT_HOST_OUTPUT_TYPE & 1) |
+		((EIP93_INT_PULSE_CLEAR << 1) & 1),
+		mtk->base + EIP93_REG_INT_CFG);
+	/* Clock Control, must for DHM, optional for ARM
+	 * 0x1 Only enable Packet Engine Clock
+	 *     AES, DES and HASH clocks on demand
+	 * Activating all clocks per performance
+	 */
+	regVal = BIT(0) | BIT(1) | BIT(2) | BIT(4);
+	writel(regVal, mtk->base + EIP93_REG_PE_CLOCK_CTRL);
+
+	writel(BIT(31) | (InputThreshold & GENMASK(10, 0)) |
+		((OutputThreshold & GENMASK(10, 0)) << 16),
+		mtk->base + EIP93_REG_PE_BUF_THRESH);
+
+	/* Clear/ack all interrupts before disable all */
+	mtk_irq_clear(mtk, 0xFFFFFFFF);
+	mtk_irq_disable(mtk, 0xFFFFFFFF);
+
+	writel((DescriptorCountDone & GENMASK(10, 0)) |
+		(((DescriptorPendingCount - 1) & GENMASK(10, 0)) << 16) |
+		((DescriptorDoneTimeout  & GENMASK(4, 0)) << 26),
+		mtk->base + EIP93_REG_PE_RING_THRESH);
+
+	regVal = readl(mtk->base + EIP93_REG_PE_REVISION);
+	dev_dbg(mtk->dev, "Rev: %08x", regVal);
+	regVal = readl(mtk->base + EIP93_REG_PE_OPTION_1);
+	dev_dbg(mtk->dev, "Opt1: %08x", regVal);
+	regVal = readl(mtk->base + EIP93_REG_PE_OPTION_0);
+	dev_dbg(mtk->dev, "Opt0: %08x", regVal);
+
+}
+
+static void mtk_desc_free(struct mtk_device *mtk,
+				struct mtk_desc_ring *cdr,
+				struct mtk_desc_ring *rdr)
+{
+	writel(0, mtk->base + EIP93_REG_PE_RING_CONFIG);
+	writel(0, mtk->base + EIP93_REG_PE_CDR_BASE);
+	writel(0, mtk->base + EIP93_REG_PE_RDR_BASE);
+}
+
+static int mtk_desc_init(struct mtk_device *mtk,
+			struct mtk_desc_ring *cdr,
+			struct mtk_desc_ring *rdr)
+{
+	int RingOffset, RingSize;
+
+	cdr->offset = sizeof(struct eip93_descriptor_s);
+	cdr->base = dmam_alloc_coherent(mtk->dev, cdr->offset * MTK_RING_SIZE,
+					&cdr->base_dma, GFP_KERNEL);
+	if (!cdr->base)
+		return -ENOMEM;
+
+	cdr->write = cdr->base;
+	cdr->base_end = cdr->base + cdr->offset * (MTK_RING_SIZE - 1);
+	cdr->read  = cdr->base;
+
+	dev_dbg(mtk->dev, "CD Ring : %08X\n", cdr->base_dma);
+
+	rdr->offset = sizeof(struct eip93_descriptor_s);
+	rdr->base = dmam_alloc_coherent(mtk->dev, rdr->offset * MTK_RING_SIZE,
+					&rdr->base_dma, GFP_KERNEL);
+	if (!rdr->base)
+		return -ENOMEM;
+
+	rdr->write = rdr->base;
+	rdr->base_end = rdr->base + rdr->offset * (MTK_RING_SIZE - 1);
+	rdr->read  = rdr->base;
+
+	dev_dbg(mtk->dev, "RD Ring : %08X\n", rdr->base_dma);
+
+	writel((u32)cdr->base_dma, mtk->base + EIP93_REG_PE_CDR_BASE);
+	writel((u32)rdr->base_dma, mtk->base + EIP93_REG_PE_RDR_BASE);
+
+	RingOffset = 8; /* 8 words per descriptor */
+	RingSize = MTK_RING_SIZE - 1;
+
+	writel(((RingOffset & GENMASK(8, 0)) << 16) |
+		(RingSize & GENMASK(10, 0)),
+		mtk->base + EIP93_REG_PE_RING_CONFIG);
+
+	/* Create Sa and State record DMA pool */
+
+	mtk->saRecord_pool = dmam_pool_create("eip93-saRecord",
+				mtk->dev, sizeof(struct saRecord_s), 32, 0);
+
+	if (!mtk->saRecord_pool) {
+		dev_err(mtk->dev, "Unable to allocate saRecord DMA pool\n");
+		return -ENOMEM;
+	}
+
+	mtk->saState_pool = dmam_pool_create("eip93-saState",
+				mtk->dev, sizeof(struct saState_s), 32, 0);
+
+	if (!mtk->saState_pool) {
+		dev_err(mtk->dev, "Unable to allocate saState DMA pool\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static int mtk_crypto_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct mtk_device *mtk;
+	struct resource *res;
+	int ret;
+
+	mtk = devm_kzalloc(dev, sizeof(*mtk), GFP_KERNEL);
+	if (!mtk)
+		return -ENOMEM;
+
+	mtk->dev = dev;
+	platform_set_drvdata(pdev, mtk);
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	mtk->base = devm_ioremap_resource(&pdev->dev, res);
+
+	if (IS_ERR(mtk->base))
+		return PTR_ERR(mtk->base);
+
+	mtk->irq = platform_get_irq(pdev, 0);
+
+	if (mtk->irq < 0) {
+		dev_err(mtk->dev, "Cannot get IRQ resource\n");
+		return mtk->irq;
+	}
+	dev_dbg(mtk->dev, "Assigning IRQ: %d", mtk->irq);
+
+	ret = devm_request_irq(mtk->dev, mtk->irq, mtk_irq_handler,
+				IRQF_TRIGGER_HIGH, dev_name(mtk->dev), mtk);
+
+	mtk->ring = devm_kcalloc(mtk->dev, 1, sizeof(*mtk->ring), GFP_KERNEL);
+
+	if (!mtk->ring) {
+		dev_err(mtk->dev, "Can't allocate Ring memory\n");
+	}
+
+	ret = mtk_desc_init(mtk, &mtk->ring->cdr, &mtk->ring->rdr);
+
+	if (ret == -ENOMEM)
+		return -ENOMEM;
+
+	mtk->prng = devm_kcalloc(mtk->dev, 1, sizeof(*mtk->prng), GFP_KERNEL);
+	if (!mtk->prng) {
+		dev_err(mtk->dev, "Can't allocate PRNG memory\n");
+		return -ENOMEM;
+	}
+
+	mtk->ring->requests = 0;
+	mtk->ring->busy = false;
+
+	spin_lock_init(&mtk->ring->lock);
+	spin_lock_init(&mtk->ring->read_lock);
+	spin_lock_init(&mtk->ring->write_lock);
+
+	/* Init tasklet for bottom half processing */
+	tasklet_init(&mtk->done, mtk_done_tasklet, (unsigned long)mtk);
+
+	mtk_initialize(mtk);
+	/* Init. finished, enable RDR interupt */
+	mtk_irq_enable(mtk, BIT(1));
+
+	ret = mtk_prng_init(mtk, true);
+	if (ret)
+		dev_info(mtk->dev, "PRNG initialized");
+	else
+		dev_err(mtk->dev, "Could not initialize PRNG");
+
+	ret = mtk_register_algs(mtk);
+
+	dev_info(mtk->dev, "EIP93 initialized succesfull\n");
+
+	return 0;
+}
+
+static int mtk_crypto_remove(struct platform_device *pdev)
+{
+	struct mtk_device *mtk = platform_get_drvdata(pdev);
+
+	mtk_unregister_algs(mtk, ARRAY_SIZE(mtk_algs));
+
+	/* Clear/ack all interrupts before disable all */
+	mtk_irq_clear(mtk, 0xFFFFFFFF);
+	mtk_irq_disable(mtk, 0xFFFFFFFF);
+
+	writel(0, mtk->base + EIP93_REG_PE_CLOCK_CTRL);
+
+	tasklet_kill(&mtk->done);
+
+	mtk_desc_free(mtk, &mtk->ring->cdr, &mtk->ring->rdr);
+	dev_info(mtk->dev, "EIP93 removed.\n");
+
+	return 0;
+}
+
+static const struct of_device_id mtk_crypto_of_match[] = {
+	{ .compatible = "mediatek,mtk-eip93", },
+	{}
+};
+MODULE_DEVICE_TABLE(of, mtk_crypto_of_match);
+
+static struct platform_driver mtk_crypto_driver = {
+	.probe = mtk_crypto_probe,
+	.remove = mtk_crypto_remove,
+	.driver = {
+		.name = "mtk-eip93",
+		.of_match_table = mtk_crypto_of_match,
+	},
+};
+module_platform_driver(mtk_crypto_driver);
+
+MODULE_AUTHOR("Richard van Schagen <vschagen@cs.com>");
+MODULE_ALIAS("platform:" KBUILD_MODNAME);
+MODULE_DESCRIPTION("Mediatek EIP-93 crypto engine driver");
+MODULE_LICENSE("GPL v2");
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-core.h b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-core.h
new file mode 100644
index 000000000..c39156591
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-core.h
@@ -0,0 +1,91 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+#ifndef _CORE_H_
+#define _CORE_H_
+
+#include <linux/atomic.h>
+#include <linux/completion.h>
+#include <linux/dmapool.h>
+#include <crypto/aead.h>
+#include <crypto/internal/hash.h>
+#include <crypto/internal/rng.h>
+#include <crypto/internal/skcipher.h>
+
+/**
+ * struct mtk_device - crypto engine device structure
+ */
+struct mtk_device {
+	void __iomem		*base;
+	struct device		*dev;
+	struct clk		*clk;
+	int			irq;
+
+	struct tasklet_struct	dequeue;
+	struct tasklet_struct	done;
+
+	struct mtk_ring		*ring;
+
+	struct dma_pool		*saRecord_pool;
+	struct dma_pool		*saState_pool;
+
+	struct mtk_prng_device	*prng;
+};
+
+struct mtk_prng_device {
+	struct saRecord_s	*PRNGSaRecord;
+	dma_addr_t		PRNGSaRecord_dma;
+	void			*PRNGBuffer[2];
+	dma_addr_t		PRNGBuffer_dma[2];
+	uint32_t		cur_buf;
+	struct completion	Filled;
+	atomic_t		State;
+};
+
+struct mtk_desc_ring {
+	void			*base;
+	void			*base_end;
+	dma_addr_t		base_dma;
+	/* write and read pointers */
+	void			*read;
+	void			*write;
+	/* descriptor element offset */
+	u32			offset;
+};
+
+struct mtk_ring {
+	spinlock_t			lock;
+	/* command/result rings */
+	struct mtk_desc_ring		cdr;
+	struct mtk_desc_ring		rdr;
+	spinlock_t			write_lock;
+	spinlock_t			read_lock;
+	/* Number of request in the engine. */
+	int				requests;
+	/* The rings is handling at least one request */
+	bool				busy;
+};
+
+enum mtk_alg_type {
+	MTK_ALG_TYPE_SKCIPHER,
+	MTK_ALG_TYPE_AEAD,
+	MTK_ALG_TYPE_AHASH,
+	MTK_ALG_TYPE_PRNG,
+};
+
+struct mtk_alg_template {
+	struct mtk_device	*mtk;
+	enum mtk_alg_type	type;
+	unsigned long		flags;
+	union {
+		struct skcipher_alg	skcipher;
+		struct aead_alg		aead;
+		struct ahash_alg	ahash;
+		struct rng_alg		rng;
+	} alg;
+};
+
+#endif /* _CORE_H_ */
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-prng.c b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-prng.c
new file mode 100644
index 000000000..559d2e706
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-prng.c
@@ -0,0 +1,363 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+
+#include "eip93-common.h"
+#include "eip93-core.h"
+#include "eip93-regs.h"
+#include "eip93-ring.h"
+#include "eip93-prng.h"
+
+static int mtk_prng_push_job(struct mtk_device *mtk, bool reset)
+{
+	struct mtk_prng_device *prng = mtk->prng;
+	struct eip93_descriptor_s cdesc;
+	int cur = prng->cur_buf;
+	int len, mode, err;
+
+	if (reset) {
+		len = 0;
+		mode = 1;
+	} else {
+		len = 4080;
+		mode = 2;
+	}
+
+	init_completion(&prng->Filled);
+	atomic_set(&prng->State, BUF_EMPTY);
+
+	memset(&cdesc, 0, sizeof(struct eip93_descriptor_s));
+	cdesc.peCrtlStat.bits.hostReady = 1;
+	cdesc.peCrtlStat.bits.prngMode = mode;
+	cdesc.peCrtlStat.bits.hashFinal = 0;
+	cdesc.peCrtlStat.bits.padCrtlStat = 0;
+	cdesc.peCrtlStat.bits.peReady = 0;
+	cdesc.srcAddr = 0;
+	cdesc.dstAddr = (u32)prng->PRNGBuffer_dma[cur];
+	cdesc.saAddr = (u32)prng->PRNGSaRecord_dma;
+	cdesc.stateAddr = 0;
+	cdesc.arc4Addr = 0;
+	cdesc.userId = MTK_DESC_PRNG | MTK_DESC_LAST | MTK_DESC_FINISH;
+	cdesc.peLength.bits.byPass = 0;
+	cdesc.peLength.bits.length = 4080;
+	cdesc.peLength.bits.hostReady = 1;
+
+	err = mtk_put_descriptor(mtk, cdesc);
+	if (err)
+		dev_err(mtk->dev, "PRNG: No Descriptor space");
+
+	/*   */
+	spin_lock(&mtk->ring->lock);
+	mtk->ring[0].requests += 1;
+	mtk->ring[0].busy = true;
+	spin_unlock(&mtk->ring->lock);
+
+	writel(1, mtk->base + EIP93_REG_PE_CD_COUNT);
+
+	wait_for_completion(&prng->Filled);
+
+	if (atomic_read(&prng->State) == PRNG_NEED_RESET)
+		return false;
+
+	return true;
+}
+
+/*----------------------------------------------------------------------------
+ * mtk_prng_init
+ *
+ * This function initializes the PE PRNG for the ARM mode.
+ *
+ * Return Value
+ *      true: PRNG is initialized
+ *     false: PRNG initialization failed
+ */
+bool mtk_prng_init(struct mtk_device *mtk, bool fLongSA)
+{
+	struct mtk_prng_device *prng = mtk->prng;
+	int i;
+	struct saRecord_s *saRecord;
+	const uint32_t PRNGKey[]  = {0xe0fc631d, 0xcbb9fb9a,
+					0x869285cb, 0xcbb9fb9a};
+	const uint32_t PRNGSeed[]  = {0x758bac03, 0xf20ab39e,
+					0xa569f104, 0x95dfaea6};
+	const uint32_t PRNGDateTime[] = {0, 0, 0, 0};
+
+	if (!mtk)
+		return -ENODEV;
+
+	prng->cur_buf = 0;
+	prng->PRNGBuffer[0] = devm_kzalloc(mtk->dev, 4080, GFP_KERNEL);
+	prng->PRNGBuffer_dma[0] = (u32)dma_map_single(mtk->dev,
+				(void *)prng->PRNGBuffer[0],
+				4080, DMA_FROM_DEVICE);
+
+	prng->PRNGBuffer[1] = devm_kzalloc(mtk->dev, 4080, GFP_KERNEL);
+	prng->PRNGBuffer_dma[1] = (u32)dma_map_single(mtk->dev,
+				(void *)prng->PRNGBuffer[1],
+				4080, DMA_FROM_DEVICE);
+
+	prng->PRNGSaRecord = dmam_alloc_coherent(mtk->dev,
+				sizeof(struct saRecord_s),
+				&prng->PRNGSaRecord_dma, GFP_KERNEL);
+
+	if (!prng->PRNGSaRecord) {
+		dev_err(mtk->dev, "PRNG dma_alloc for saRecord failed\n");
+		return -ENOMEM;
+	}
+
+	saRecord = &prng->PRNGSaRecord[0];
+
+	saRecord->saCmd0.word = 0x00001307;
+	saRecord->saCmd1.word = 0x02000000;
+
+	for (i = 0; i < 4; i++) {
+		saRecord->saKey[i] = PRNGKey[i];
+		saRecord->saIDigest[i] = PRNGSeed[i];
+		saRecord->saODigest[i] = PRNGDateTime[i];
+	}
+
+	return mtk_prng_push_job(mtk, true);
+}
+
+void mtk_prng_done(struct mtk_device *mtk, u32 err)
+{
+	struct mtk_prng_device *prng = mtk->prng;
+	int cur = prng->cur_buf;
+
+	if (err) {
+		dev_err(mtk->dev, "PRNG error: %d\n", err);
+		atomic_set(&prng->State, PRNG_NEED_RESET);
+	}
+
+	/* Buffer refilled, invalidate cache */
+	dma_unmap_single(mtk->dev, prng->PRNGBuffer_dma[cur],
+							4080, DMA_FROM_DEVICE);
+
+	complete(&prng->Filled);
+}
+
+static int get_prng_bytes(char *buf, size_t nbytes, struct mtk_prng_ctx *ctx,
+				int do_cont_test)
+{
+	int err;
+
+	spin_lock_bh(&ctx->prng_lock);
+
+	err = -EINVAL;
+	if (ctx->flags & PRNG_NEED_RESET)
+		goto done;
+
+done:
+	spin_unlock_bh(&ctx->prng_lock);
+	return err;
+}
+
+static int mtk_prng_generate(struct crypto_rng *tfm, const u8 *src,
+			   unsigned int slen, u8 *dst, unsigned int dlen)
+{
+	struct mtk_prng_ctx *prng = crypto_rng_ctx(tfm);
+
+	return get_prng_bytes(dst, dlen, prng, 1);
+}
+
+static int mtk_prng_seed(struct crypto_rng *tfm, const u8 *seed,
+		       unsigned int slen)
+{
+#if LINUX_VERSION_CODE > KERNEL_VERSION(4, 19, 0)
+	struct rng_alg *alg = crypto_rng_alg(tfm);
+	struct mtk_alg_template *tmpl = container_of(alg,
+				struct mtk_alg_template, alg.rng);
+	struct mtk_device *mtk = tmpl->mtk;
+#endif
+	return 0;
+}
+
+#if 0
+static bool mtk_prng_fill_buffer(struct mtk_device *mtk)
+{
+	struct mtk_prng_device *prng = mtk->prng;
+	int cur = prng->cur_buf;
+	int ret;
+
+	if (!mtk)
+		return -ENODEV;
+
+	/* add logic for 2 buffers and swap */
+	prng->PRNGBuffer_dma[cur] = (u32)dma_map_single(mtk->dev,
+					(void *)prng->PRNGBuffer[cur],
+					4080, DMA_FROM_DEVICE);
+
+	ret = mtk_prng_push_job(mtk, false);
+
+	return ret;
+}
+#endif
+
+static int reset_prng_context(struct mtk_prng_ctx *ctx,
+				const unsigned char *key,
+				const unsigned char *V,
+				const unsigned char *DT)
+{
+	spin_lock_bh(&ctx->prng_lock);
+	ctx->flags |= PRNG_NEED_RESET;
+
+	if (key)
+		memcpy(ctx->PRNGKey, key, DEFAULT_PRNG_KSZ);
+	else
+		memcpy(ctx->PRNGKey, DEFAULT_PRNG_KEY, DEFAULT_PRNG_KSZ);
+
+
+	if (V)
+		memcpy(ctx->PRNGSeed, V, DEFAULT_BLK_SZ);
+	else
+		memcpy(ctx->PRNGSeed, DEFAULT_V_SEED, DEFAULT_BLK_SZ);
+
+	if (DT)
+		memcpy(ctx->PRNGDateTime, DT, DEFAULT_BLK_SZ);
+	else
+		memset(ctx->PRNGDateTime, 0, DEFAULT_BLK_SZ);
+
+	memset(ctx->rand_data, 0, DEFAULT_BLK_SZ);
+	memset(ctx->last_rand_data, 0, DEFAULT_BLK_SZ);
+
+	ctx->rand_data_valid = DEFAULT_BLK_SZ;
+
+	ctx->flags &= ~PRNG_NEED_RESET;
+	spin_unlock_bh(&ctx->prng_lock);
+	return 0;
+}
+
+/*
+ *  This is the cprng_registered reset method the seed value is
+ *  interpreted as the tuple { V KEY DT}
+ *  V and KEY are required during reset, and DT is optional, detected
+ *  as being present by testing the length of the seed
+ */
+static int cprng_reset(struct crypto_rng *tfm,
+		       const u8 *seed, unsigned int slen)
+{
+	struct mtk_prng_ctx *prng = crypto_rng_ctx(tfm);
+	const u8 *key = seed + DEFAULT_BLK_SZ;
+	const u8 *dt = NULL;
+
+	if (slen < DEFAULT_PRNG_KSZ + DEFAULT_BLK_SZ)
+		return -EINVAL;
+
+	if (slen >= (2 * DEFAULT_BLK_SZ + DEFAULT_PRNG_KSZ))
+		dt = key + DEFAULT_PRNG_KSZ;
+
+	reset_prng_context(prng, key, seed, dt);
+
+	if (prng->flags & PRNG_NEED_RESET)
+		return -EINVAL;
+	return 0;
+}
+
+
+static void free_prng_context(struct mtk_prng_ctx *ctx)
+{
+	crypto_free_cipher(ctx->tfm);
+}
+
+static int cprng_init(struct crypto_tfm *tfm)
+{
+	struct mtk_prng_ctx *ctx = crypto_tfm_ctx(tfm);
+
+	spin_lock_init(&ctx->prng_lock);
+
+	if (reset_prng_context(ctx, NULL, NULL, NULL) < 0)
+		return -EINVAL;
+
+	/*
+	 * after allocation, we should always force the user to reset
+	 * so they don't inadvertently use the insecure default values
+	 * without specifying them intentially
+	 */
+	ctx->flags |= PRNG_NEED_RESET;
+	return 0;
+}
+
+static void cprng_exit(struct crypto_tfm *tfm)
+{
+	free_prng_context(crypto_tfm_ctx(tfm));
+}
+
+struct mtk_alg_template mtk_alg_prng = {
+	.type = MTK_ALG_TYPE_PRNG,
+	.flags = 0,
+	.alg.rng = {
+		.generate = mtk_prng_generate,
+		.seed = mtk_prng_seed,
+		.seedsize = 0,
+		.base = {
+			.cra_name = "stdrng",
+			.cra_driver_name = "eip93-prng",
+			.cra_priority = 200,
+			.cra_ctxsize = sizeof(struct mtk_prng_ctx),
+			.cra_module = THIS_MODULE,
+			.cra_init = cprng_init,
+			.cra_exit = cprng_exit,
+		},
+	},
+};
+
+//#ifdef CONFIG_CRYPTO_FIPS
+static int fips_cprng_get_random(struct crypto_rng *tfm,
+				 const u8 *src, unsigned int slen,
+				 u8 *rdata, unsigned int dlen)
+{
+	struct mtk_prng_ctx *prng = crypto_rng_ctx(tfm);
+
+	return get_prng_bytes(rdata, dlen, prng, 1);
+}
+
+static int fips_cprng_reset(struct crypto_rng *tfm,
+			    const u8 *seed, unsigned int slen)
+{
+	struct mtk_prng_ctx *prng = crypto_rng_ctx(tfm);
+	u8 rdata[DEFAULT_BLK_SZ];
+	const u8 *key = seed + DEFAULT_BLK_SZ;
+	int rc;
+
+	if (slen < DEFAULT_PRNG_KSZ + DEFAULT_BLK_SZ)
+		return -EINVAL;
+
+	/* fips strictly requires seed != key */
+	if (!memcmp(seed, key, DEFAULT_PRNG_KSZ))
+		return -EINVAL;
+
+	rc = cprng_reset(tfm, seed, slen);
+
+	if (!rc)
+		goto out;
+
+	/* this primes our continuity test */
+	rc = get_prng_bytes(rdata, DEFAULT_BLK_SZ, prng, 0);
+	prng->rand_data_valid = DEFAULT_BLK_SZ;
+
+out:
+	return rc;
+}
+
+struct mtk_alg_template mtk_alg_cprng = {
+	.type = MTK_ALG_TYPE_PRNG,
+	.flags = 0,
+	.alg.rng = {
+		.generate = fips_cprng_get_random,
+		.seed = fips_cprng_reset,
+		.seedsize = DEFAULT_PRNG_KSZ + 2 * DEFAULT_BLK_SZ,
+		.base = {
+			.cra_name = "fips(ansi_cprng)",
+			.cra_driver_name = "eip93-fips_ansi_cprng",
+			.cra_priority = 300,
+			.cra_ctxsize = sizeof(struct mtk_prng_ctx),
+			.cra_module = THIS_MODULE,
+			.cra_init = cprng_init,
+			.cra_exit = cprng_exit,
+		},
+	},
+};
+//#endif
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-prng.h b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-prng.h
new file mode 100644
index 000000000..944a0d377
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-prng.h
@@ -0,0 +1,34 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+#define DEFAULT_PRNG_KEY "0123456789abcdef"
+#define DEFAULT_PRNG_KSZ 16
+#define DEFAULT_BLK_SZ 16
+#define DEFAULT_V_SEED "zaybxcwdveuftgsh"
+
+#define BUF_NOT_EMPTY 0
+#define BUF_EMPTY 1
+#define BUF_PENDING 2
+#define PRNG_NEED_RESET 3
+
+extern struct mtk_alg_template mtk_alg_prng;
+extern struct mtk_alg_template mtk_alg_cprng;
+
+bool mtk_prng_init(struct mtk_device *mtk, bool fLongSA);
+
+void mtk_prng_done(struct mtk_device *mtk, u32 err);
+
+struct mtk_prng_ctx {
+	spinlock_t 		prng_lock;
+	unsigned char		rand_data[DEFAULT_BLK_SZ];
+	unsigned char		last_rand_data[DEFAULT_BLK_SZ];
+	uint32_t		PRNGKey[4];
+	uint32_t		PRNGSeed[4];
+	uint32_t		PRNGDateTime[4];
+	struct crypto_cipher	*tfm;
+	uint32_t		rand_data_valid;
+	uint32_t		flags;
+};
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-regs.h b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-regs.h
new file mode 100644
index 000000000..28cccb106
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-regs.h
@@ -0,0 +1,190 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+#ifndef REG_EIP93_H
+#define REG_EIP93_H
+
+#define EIP93_REG_WIDTH			4
+/*-----------------------------------------------------------------------------
+ * Register Map
+ */
+#define DESP_BASE			0x0000000
+#define EIP93_REG_PE_CTRL_STAT		((DESP_BASE)+(0x00 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_SOURCE_ADDR	((DESP_BASE)+(0x01 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_DEST_ADDR		((DESP_BASE)+(0x02 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_SA_ADDR		((DESP_BASE)+(0x03 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_ADDR		((DESP_BASE)+(0x04 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_USER_ID		((DESP_BASE)+(0x06 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_LENGTH		((DESP_BASE)+(0x07 * EIP93_REG_WIDTH))
+
+//PACKET ENGINE RING configuartion registers
+#define PE_RNG_BASE			0x0000080
+
+#define EIP93_REG_PE_CDR_BASE		((PE_RNG_BASE)+(0x00 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_RDR_BASE		((PE_RNG_BASE)+(0x01 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_RING_CONFIG	((PE_RNG_BASE)+(0x02 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_RING_THRESH	((PE_RNG_BASE)+(0x03 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_CD_COUNT		((PE_RNG_BASE)+(0x04 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_RD_COUNT		((PE_RNG_BASE)+(0x05 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_RING_RW_PNTR	((PE_RNG_BASE)+(0x06 * EIP93_REG_WIDTH))
+
+//PACKET ENGINE  configuartion registers
+#define PE_CFG_BASE			0x0000100
+#define EIP93_REG_PE_CONFIG		((PE_CFG_BASE)+(0x00 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_STATUS		((PE_CFG_BASE)+(0x01 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_BUF_THRESH		((PE_CFG_BASE)+(0x03 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_INBUF_COUNT	((PE_CFG_BASE)+(0x04 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_OUTBUF_COUNT	((PE_CFG_BASE)+(0x05 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_BUF_RW_PNTR	((PE_CFG_BASE)+(0x06 * EIP93_REG_WIDTH))
+
+//PACKET ENGINE endian config
+#define EN_CFG_BASE			0x00001CC
+#define EIP93_REG_PE_ENDIAN_CONFIG	((EN_CFG_BASE)+(0x00 * EIP93_REG_WIDTH))
+
+//EIP93 CLOCK control registers
+#define CLOCK_BASE			0x01E8
+#define EIP93_REG_PE_CLOCK_CTRL		((CLOCK_BASE)+(0x00 * EIP93_REG_WIDTH))
+
+//EIP93 Device Option and Revision Register
+#define REV_BASE			0x01F4
+#define EIP93_REG_PE_OPTION_1		((REV_BASE)+(0x00 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_OPTION_0		((REV_BASE)+(0x01 * EIP93_REG_WIDTH))
+#define EIP93_REG_PE_REVISION		((REV_BASE)+(0x02 * EIP93_REG_WIDTH))
+
+//EIP93 Interrupt Control Register
+#define INT_BASE			0x0200
+#define EIP93_REG_INT_UNMASK_STAT	((INT_BASE)+(0x00 * EIP93_REG_WIDTH))
+#define EIP93_REG_INT_MASK_STAT		((INT_BASE)+(0x01 * EIP93_REG_WIDTH))
+#define EIP93_REG_INT_CLR		((INT_BASE)+(0x01 * EIP93_REG_WIDTH))
+#define EIP93_REG_INT_MASK		((INT_BASE)+(0x02 * EIP93_REG_WIDTH))
+#define EIP93_REG_INT_CFG		((INT_BASE)+(0x03 * EIP93_REG_WIDTH))
+#define EIP93_REG_MASK_ENABLE		((INT_BASE)+(0X04 * EIP93_REG_WIDTH))
+#define EIP93_REG_MASK_DISABLE		((INT_BASE)+(0X05 * EIP93_REG_WIDTH))
+
+//EIP93 SA Record register
+#define SA_BASE				0x0400
+#define EIP93_REG_SA_CMD_0		((SA_BASE)+(0x00 * EIP93_REG_WIDTH))
+#define EIP93_REG_SA_CMD_1		((SA_BASE)+(0x01 * EIP93_REG_WIDTH))
+
+//#define EIP93_REG_SA_READY		((SA_BASE)+(31 * EIP93_REG_WIDTH))
+
+//State save register
+#define STATE_BASE			0x0500
+#define EIP93_REG_STATE_IV_0		((STATE_BASE)+(0x00 * EIP93_REG_WIDTH))
+#define EIP93_REG_STATE_IV_1		((STATE_BASE)+(0x01 * EIP93_REG_WIDTH))
+
+#define EIP93_PE_ARC4STATE_BASEADDR_REG	0x0700
+
+//RAM buffer start address
+#define EIP93_INPUT_BUFFER		0x0800
+#define EIP93_OUTPUT_BUFFER		0x0800
+
+//EIP93 PRNG Configuration Register
+#define PRNG_BASE			0x0300
+#define EIP93_REG_PRNG_STAT		((PRNG_BASE)+(0x00 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_CTRL		((PRNG_BASE)+(0x01 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_SEED_0		((PRNG_BASE)+(0x02 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_SEED_1		((PRNG_BASE)+(0x03 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_SEED_2		((PRNG_BASE)+(0x04 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_SEED_3		((PRNG_BASE)+(0x05 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_KEY_0		((PRNG_BASE)+(0x06 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_KEY_1		((PRNG_BASE)+(0x07 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_KEY_2		((PRNG_BASE)+(0x08 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_KEY_3		((PRNG_BASE)+(0x09 * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_RES_0		((PRNG_BASE)+(0x0A * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_RES_1		((PRNG_BASE)+(0x0B * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_RES_2		((PRNG_BASE)+(0x0C * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_RES_3		((PRNG_BASE)+(0x0D * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_LFSR_0		((PRNG_BASE)+(0x0E * EIP93_REG_WIDTH))
+#define EIP93_REG_PRNG_LFSR_1		((PRNG_BASE)+(0x0F * EIP93_REG_WIDTH))
+
+/*-----------------------------------------------------------------------------
+ * Constants & masks
+ */
+
+#define EIP93_SUPPORTED_INTERRUPTS_MASK	0xffff7f00
+#define EIP93_PRNG_DT_TEXT_LOWERHALF	0xDEAD
+#define EIP93_PRNG_DT_TEXT_UPPERHALF	0xC0DE
+#define EIP93_10BITS_MASK		0X3FF
+#define EIP93_12BITS_MASK		0XFFF
+#define EIP93_4BITS_MASK		0X04
+#define EIP93_20BITS_MASK		0xFFFFF
+
+#define EIP93_MIN_DESC_DONE_COUNT	0
+#define EIP93_MAX_DESC_DONE_COUNT	15
+
+#define EIP93_MIN_DESC_PENDING_COUNT	0
+#define EIP93_MAX_DESC_PENDING_COUNT	1023
+
+#define EIP93_MIN_TIMEOUT_COUNT		0
+#define EIP93_MAX_TIMEOUT_COUNT		15
+
+#define EIP93_MIN_PE_INPUT_THRESHOLD	1
+#define EIP93_MAX_PE_INPUT_THRESHOLD	511
+
+#define EIP93_MIN_PE_OUTPUT_THRESHOLD	1
+#define EIP93_MAX_PE_OUTPUT_THRESHOLD	432
+
+#define EIP93_MIN_PE_RING_SIZE		1
+#define EIP93_MAX_PE_RING_SIZE		1023
+
+#define EIP93_MIN_PE_DESCRIPTOR_SIZE	7
+#define EIP93_MAX_PE_DESCRIPTOR_SIZE	15
+
+//3DES keys,seed,known data and its result
+#define EIP93_KEY_0			0x133b3454
+#define EIP93_KEY_1			0x5e5b890b
+#define EIP93_KEY_2			0x5eb30757
+#define EIP93_KEY_3			0x93ab15f7
+#define EIP93_SEED_0			0x62c4bf5e
+#define EIP93_SEED_1			0x972667c8
+#define EIP93_SEED_2			0x6345bf67
+#define EIP93_SEED_3			0xcb3482bf
+#define EIP93_LFSR_0			0xDEADC0DE
+#define EIP93_LFSR_1			0xBEEFF00D
+
+/*-----------------------------------------------------------------------------
+ * EIP93 device initialization specifics
+ */
+
+/*----------------------------------------------------------------------------
+ * Byte Order Reversal Mechanisms Supported in EIP93
+ * EIP93_BO_REVERSE_HALF_WORD : reverse the byte order within a half-word
+ * EIP93_BO_REVERSE_WORD :  reverse the byte order within a word
+ * EIP93_BO_REVERSE_DUAL_WORD : reverse the byte order within a dual-word
+ * EIP93_BO_REVERSE_QUAD_WORD : reverse the byte order within a quad-word
+ */
+typedef enum
+{
+    EIP93_BO_REVERSE_HALF_WORD = 1,
+    EIP93_BO_REVERSE_WORD = 2,
+    EIP93_BO_REVERSE_DUAL_WORD = 4,
+    EIP93_BO_REVERSE_QUAD_WORD = 8,
+} EIP93_Byte_Order_Value_t;
+
+/*----------------------------------------------------------------------------
+ * Byte Order Reversal Mechanisms Supported in EIP93 for Target Data
+ * EIP93_BO_REVERSE_HALF_WORD : reverse the byte order within a half-word
+ * EIP93_BO_REVERSE_WORD :  reverse the byte order within a word
+ */
+typedef enum
+{
+    EIP93_BO_REVERSE_HALF_WORD_TD = 1,
+    EIP93_BO_REVERSE_WORD_TD = 2,
+} EIP93_Byte_Order_Value_TD_t;
+
+
+// BYTE_ORDER_CFG register values
+#define EIP93_BYTE_ORDER_PD		EIP93_BO_REVERSE_WORD
+#define EIP93_BYTE_ORDER_SA		EIP93_BO_REVERSE_WORD
+#define EIP93_BYTE_ORDER_DATA		EIP93_BO_REVERSE_WORD
+#define EIP93_BYTE_ORDER_TD		EIP93_BO_REVERSE_WORD_TD
+
+// INT_CFG register values
+#define EIP93_INT_HOST_OUTPUT_TYPE	0	// 0 = Level
+#define EIP93_INT_PULSE_CLEAR		0	// 0 = Manual clear
+
+#endif
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-ring.c b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-ring.c
new file mode 100644
index 000000000..fff5c0b87
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-ring.c
@@ -0,0 +1,82 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+
+#include "eip93-common.h"
+#include "eip93-core.h"
+
+inline void *mtk_ring_next_wptr(struct mtk_device *mtk,
+						struct mtk_desc_ring *ring)
+{
+	void *ptr = ring->write;
+
+	if ((ring->write == ring->read - ring->offset) ||
+		(ring->read == ring->base && ring->write == ring->base_end))
+		return ERR_PTR(-ENOMEM);
+
+	if (ring->write == ring->base_end)
+		ring->write = ring->base;
+	else
+		ring->write += ring->offset;
+
+	return ptr;
+}
+
+inline void *mtk_ring_next_rptr(struct mtk_device *mtk,
+						struct mtk_desc_ring *ring)
+{
+	void *ptr = ring->read;
+
+	if (ring->write == ring->read)
+		return ERR_PTR(-ENOENT);
+
+	if (ring->read == ring->base_end)
+		ring->read = ring->base;
+	else
+		ring->read += ring->offset;
+
+	return ptr;
+}
+
+inline int mtk_put_descriptor(struct mtk_device *mtk,
+					struct eip93_descriptor_s desc)
+{
+	struct eip93_descriptor_s *cdesc;
+	struct eip93_descriptor_s *rdesc;
+
+	spin_lock(&mtk->ring->write_lock);
+	cdesc = mtk_ring_next_wptr(mtk, &mtk->ring->cdr);
+
+	if (IS_ERR(cdesc))
+		return -ENOENT;
+
+	rdesc = mtk_ring_next_wptr(mtk, &mtk->ring->rdr);
+
+	if (IS_ERR(rdesc)) {
+		spin_lock(&mtk->ring->write_lock);
+		return -ENOENT;
+	}
+
+	memset(rdesc, 0, sizeof(struct eip93_descriptor_s));
+	memcpy(cdesc, &desc, sizeof(struct eip93_descriptor_s));
+
+	spin_unlock(&mtk->ring->write_lock);
+
+	return 0;
+}
+
+inline void *mtk_get_descriptor(struct mtk_device *mtk)
+{
+	struct eip93_descriptor_s *cdesc;
+
+	cdesc = mtk_ring_next_rptr(mtk, &mtk->ring->cdr);
+	if (IS_ERR(cdesc)) {
+		dev_err(mtk->dev, "Cant get Cdesc");
+		return cdesc;
+	}
+
+	return mtk_ring_next_rptr(mtk, &mtk->ring->rdr);
+}
diff --git a/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-ring.h b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-ring.h
new file mode 100644
index 000000000..c26d436e6
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/crypto/mtk-eip93/eip93-ring.h
@@ -0,0 +1,11 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (C) 2019 - 2020
+ *
+ * Richard van Schagen <vschagen@cs.com>
+ */
+
+inline int mtk_put_descriptor(struct mtk_device *mtk,
+					struct eip93_descriptor_s desc);
+
+inline void *mtk_get_descriptor(struct mtk_device *mtk);
diff --git a/trunk/linux-4.4.x/drivers/gpio/Makefile b/trunk/linux-4.4.x/drivers/gpio/Makefile
index 37bbe7967..e8bbab20e 100644
--- a/trunk/linux-4.4.x/drivers/gpio/Makefile
+++ b/trunk/linux-4.4.x/drivers/gpio/Makefile
@@ -121,4 +121,4 @@ obj-$(CONFIG_GPIO_XTENSA)	+= gpio-xtensa.o
 obj-$(CONFIG_GPIO_ZEVIO)	+= gpio-zevio.o
 obj-$(CONFIG_GPIO_ZYNQ)		+= gpio-zynq.o
 obj-$(CONFIG_GPIO_ZX)		+= gpio-zx.o
-obj-y += gpio-button-hotplug.o
+#obj-y += gpio-button-hotplug.o
diff --git a/trunk/linux-4.4.x/drivers/gpio/gpio-sx150x.c b/trunk/linux-4.4.x/drivers/gpio/gpio-sx150x.c
index 76f920173..8216d8ed1 100644
--- a/trunk/linux-4.4.x/drivers/gpio/gpio-sx150x.c
+++ b/trunk/linux-4.4.x/drivers/gpio/gpio-sx150x.c
@@ -32,8 +32,19 @@
 #define NO_UPDATE_PENDING	-1
 
 /* The chip models of sx150x */
-#define SX150X_456 0
-#define SX150X_789 1
+#define SX150X_123 0
+#define SX150X_456 1
+#define SX150X_789 2
+
+struct sx150x_123_pri {
+	u8 reg_pld_mode;
+	u8 reg_pld_table0;
+	u8 reg_pld_table1;
+	u8 reg_pld_table2;
+	u8 reg_pld_table3;
+	u8 reg_pld_table4;
+	u8 reg_advance;
+};
 
 struct sx150x_456_pri {
 	u8 reg_pld_mode;
@@ -65,6 +76,7 @@ struct sx150x_device_data {
 	u8 reg_sense;
 	u8 ngpios;
 	union {
+		struct sx150x_123_pri x123;
 		struct sx150x_456_pri x456;
 		struct sx150x_789_pri x789;
 	} pri;
@@ -142,12 +154,33 @@ static const struct sx150x_device_data sx150x_devices[] = {
 		},
 		.ngpios	= 16
 	},
+	[3] = { /* sx1503q */
+		.model = SX150X_123,
+		.reg_pullup	= 0x04,
+		.reg_pulldn	= 0x06,
+		.reg_dir	= 0x02,
+		.reg_data	= 0x00,
+		.reg_irq_mask	= 0x08,
+		.reg_irq_src	= 0x0e,
+		.reg_sense	= 0x0a,
+		.pri.x123 = {
+			.reg_pld_mode	= 0x20,
+			.reg_pld_table0	= 0x22,
+			.reg_pld_table1	= 0x24,
+			.reg_pld_table2	= 0x26,
+			.reg_pld_table3	= 0x28,
+			.reg_pld_table4	= 0x2a,
+			.reg_advance	= 0xad,
+		},
+		.ngpios	= 16
+	},
 };
 
 static const struct i2c_device_id sx150x_id[] = {
 	{"sx1508q", 0},
 	{"sx1509q", 1},
 	{"sx1506q", 2},
+	{"sx1503q", 3},
 	{}
 };
 MODULE_DEVICE_TABLE(i2c, sx150x_id);
@@ -156,6 +189,7 @@ static const struct of_device_id sx150x_of_match[] = {
 	{ .compatible = "semtech,sx1508q" },
 	{ .compatible = "semtech,sx1509q" },
 	{ .compatible = "semtech,sx1506q" },
+	{ .compatible = "semtech,sx1503q" },
 	{},
 };
 MODULE_DEVICE_TABLE(of, sx150x_of_match);
@@ -545,6 +579,10 @@ static int sx150x_init_hw(struct sx150x_chip *chip,
 		err = sx150x_i2c_write(chip->client,
 				chip->dev_cfg->pri.x789.reg_misc,
 				0x01);
+	else if (chip->dev_cfg->model == SX150X_123)
+		err = sx150x_i2c_write(chip->client,
+				chip->dev_cfg->pri.x123.reg_advance,
+				0x04);
 	else
 		err = sx150x_i2c_write(chip->client,
 				chip->dev_cfg->pri.x456.reg_advance,
@@ -574,6 +612,13 @@ static int sx150x_init_hw(struct sx150x_chip *chip,
 				pdata->io_polarity);
 		if (err < 0)
 			return err;
+	}else if (chip->dev_cfg->model == SX150X_123) {
+		/* Set all pins to work in normal mode */
+		err = sx150x_init_io(chip,
+				chip->dev_cfg->pri.x123.reg_pld_mode,
+				0);
+		if (err < 0)
+			return err;
 	} else {
 		/* Set all pins to work in normal mode */
 		err = sx150x_init_io(chip,
diff --git a/trunk/linux-4.4.x/drivers/leds/Makefile b/trunk/linux-4.4.x/drivers/leds/Makefile
index b641578f5..43a152ea6 100644
--- a/trunk/linux-4.4.x/drivers/leds/Makefile
+++ b/trunk/linux-4.4.x/drivers/leds/Makefile
@@ -76,3 +76,5 @@ obj-$(CONFIG_LEDS_USER)			+= uleds.o
 
 # LED Triggers
 obj-$(CONFIG_LEDS_TRIGGERS)		+= trigger/
+obj-$(CONFIG_LEDS_TRIGGER_NETDEV)	+= ledtrig-netdev.o
+obj-$(CONFIG_LEDS_TRIGGER_USBDEV)	+= ledtrig-usbdev.o
diff --git a/trunk/linux-4.4.x/drivers/leds/ledtrig-usbdev.c b/trunk/linux-4.4.x/drivers/leds/ledtrig-usbdev.c
new file mode 100644
index 000000000..0309aa47a
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/leds/ledtrig-usbdev.c
@@ -0,0 +1,347 @@
+/*
+ * LED USB device Trigger
+ *
+ * Toggles the LED to reflect the presence and activity of an USB device
+ * Copyright (C) Gabor Juhos <juhosg@openwrt.org>
+ *
+ * derived from ledtrig-netdev.c:
+ *	Copyright 2007 Oliver Jowett <oliver@opencloud.com>
+ *
+ * ledtrig-netdev.c derived from ledtrig-timer.c:
+ *	Copyright 2005-2006 Openedhand Ltd.
+ *	Author: Richard Purdie <rpurdie@openedhand.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/jiffies.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/spinlock.h>
+#include <linux/device.h>
+#include <linux/timer.h>
+#include <linux/ctype.h>
+#include <linux/slab.h>
+#include <linux/leds.h>
+#include <linux/usb.h>
+
+#include "leds.h"
+
+#define DEV_BUS_ID_SIZE		32
+
+/*
+ * Configurable sysfs attributes:
+ *
+ * device_name - name of the USB device to monitor
+ * activity_interval - duration of LED blink, in milliseconds
+ */
+
+struct usbdev_trig_data {
+	rwlock_t lock;
+
+	struct timer_list timer;
+	struct notifier_block notifier;
+
+	struct led_classdev *led_cdev;
+	struct usb_device *usb_dev;
+
+	char device_name[DEV_BUS_ID_SIZE];
+	unsigned interval;
+	int last_urbnum;
+};
+
+static void usbdev_trig_update_state(struct usbdev_trig_data *td)
+{
+	if (td->usb_dev)
+		led_set_brightness(td->led_cdev, LED_FULL);
+	else
+		led_set_brightness(td->led_cdev, LED_OFF);
+
+	if (td->interval && td->usb_dev)
+		mod_timer(&td->timer, jiffies + td->interval);
+	else
+		del_timer(&td->timer);
+}
+
+static ssize_t usbdev_trig_name_show(struct device *dev,
+				     struct device_attribute *attr,
+				     char *buf)
+{
+	struct led_classdev *led_cdev = dev_get_drvdata(dev);
+	struct usbdev_trig_data *td = led_cdev->trigger_data;
+
+	read_lock(&td->lock);
+	sprintf(buf, "%s\n", td->device_name);
+	read_unlock(&td->lock);
+
+	return strlen(buf) + 1;
+}
+
+static ssize_t usbdev_trig_name_store(struct device *dev,
+				      struct device_attribute *attr,
+				      const char *buf,
+				      size_t size)
+{
+	struct led_classdev *led_cdev = dev_get_drvdata(dev);
+	struct usbdev_trig_data *td = led_cdev->trigger_data;
+
+	if (size < 0 || size >= DEV_BUS_ID_SIZE)
+		return -EINVAL;
+
+	write_lock(&td->lock);
+
+	strcpy(td->device_name, buf);
+	if (size > 0 && td->device_name[size - 1] == '\n')
+		td->device_name[size - 1] = 0;
+
+	if (td->device_name[0] != 0) {
+		struct usb_device *usb_dev;
+
+		/* check for existing device to update from */
+		usb_dev = usb_find_device_by_name(td->device_name);
+		if (usb_dev) {
+			if (td->usb_dev)
+				usb_put_dev(td->usb_dev);
+
+			td->usb_dev = usb_dev;
+			td->last_urbnum = atomic_read(&usb_dev->urbnum);
+		}
+
+		/* updates LEDs, may start timers */
+		usbdev_trig_update_state(td);
+	}
+
+	write_unlock(&td->lock);
+	return size;
+}
+
+static DEVICE_ATTR(device_name, 0644, usbdev_trig_name_show,
+		   usbdev_trig_name_store);
+
+static ssize_t usbdev_trig_interval_show(struct device *dev,
+				 	 struct device_attribute *attr,
+					 char *buf)
+{
+	struct led_classdev *led_cdev = dev_get_drvdata(dev);
+	struct usbdev_trig_data *td = led_cdev->trigger_data;
+
+	read_lock(&td->lock);
+	sprintf(buf, "%u\n", jiffies_to_msecs(td->interval));
+	read_unlock(&td->lock);
+
+	return strlen(buf) + 1;
+}
+
+static ssize_t usbdev_trig_interval_store(struct device *dev,
+					  struct device_attribute *attr,
+					  const char *buf,
+					  size_t size)
+{
+	struct led_classdev *led_cdev = dev_get_drvdata(dev);
+	struct usbdev_trig_data *td = led_cdev->trigger_data;
+	int ret = -EINVAL;
+	char *after;
+	unsigned long value = simple_strtoul(buf, &after, 10);
+	size_t count = after - buf;
+
+	if (*after && isspace(*after))
+		count++;
+
+	if (count == size && value <= 10000) {
+		write_lock(&td->lock);
+		td->interval = msecs_to_jiffies(value);
+		usbdev_trig_update_state(td); /* resets timer */
+		write_unlock(&td->lock);
+		ret = count;
+	}
+
+	return ret;
+}
+
+static DEVICE_ATTR(activity_interval, 0644, usbdev_trig_interval_show,
+		   usbdev_trig_interval_store);
+
+static int usbdev_trig_notify(struct notifier_block *nb,
+			      unsigned long evt,
+			      void *data)
+{
+	struct usb_device *usb_dev;
+	struct usbdev_trig_data *td;
+
+	if (evt != USB_DEVICE_ADD && evt != USB_DEVICE_REMOVE)
+		return NOTIFY_DONE;
+
+	usb_dev = data;
+	td = container_of(nb, struct usbdev_trig_data, notifier);
+
+	write_lock(&td->lock);
+
+	if (strcmp(dev_name(&usb_dev->dev), td->device_name))
+		goto done;
+
+	if (evt == USB_DEVICE_ADD) {
+		usb_get_dev(usb_dev);
+		if (td->usb_dev != NULL)
+			usb_put_dev(td->usb_dev);
+		td->usb_dev = usb_dev;
+		td->last_urbnum = atomic_read(&usb_dev->urbnum);
+	} else if (evt == USB_DEVICE_REMOVE) {
+		if (td->usb_dev != NULL) {
+			usb_put_dev(td->usb_dev);
+			td->usb_dev = NULL;
+		}
+	}
+
+	usbdev_trig_update_state(td);
+
+done:
+	write_unlock(&td->lock);
+	return NOTIFY_DONE;
+}
+
+/* here's the real work! */
+static void usbdev_trig_timer(unsigned long arg)
+{
+	struct usbdev_trig_data *td = (struct usbdev_trig_data *)arg;
+	int new_urbnum;
+
+	write_lock(&td->lock);
+
+	if (!td->usb_dev || td->interval == 0) {
+		/*
+		 * we don't need to do timer work, just reflect device presence
+		 */
+		if (td->usb_dev)
+			led_set_brightness(td->led_cdev, LED_FULL);
+		else
+			led_set_brightness(td->led_cdev, LED_OFF);
+
+		goto no_restart;
+	}
+
+	if (td->interval)
+		new_urbnum = atomic_read(&td->usb_dev->urbnum);
+	else
+		new_urbnum = 0;
+
+	if (td->usb_dev) {
+		/*
+		 * Base state is ON (device is present). If there's no device,
+		 * we don't get this far and the LED is off.
+		 * OFF -> ON always
+		 * ON -> OFF on activity
+		 */
+		if (td->led_cdev->brightness == LED_OFF)
+			led_set_brightness(td->led_cdev, LED_FULL);
+		else if (td->last_urbnum != new_urbnum)
+			led_set_brightness(td->led_cdev, LED_OFF);
+	} else {
+		/*
+		 * base state is OFF
+		 * ON -> OFF always
+		 * OFF -> ON on activity
+		 */
+		if (td->led_cdev->brightness == LED_FULL)
+			led_set_brightness(td->led_cdev, LED_OFF);
+		else if (td->last_urbnum != new_urbnum)
+			led_set_brightness(td->led_cdev, LED_FULL);
+	}
+
+	td->last_urbnum = new_urbnum;
+	mod_timer(&td->timer, jiffies + td->interval);
+
+no_restart:
+	write_unlock(&td->lock);
+}
+
+static void usbdev_trig_activate(struct led_classdev *led_cdev)
+{
+	struct usbdev_trig_data *td;
+	int rc;
+
+	td = kzalloc(sizeof(struct usbdev_trig_data), GFP_KERNEL);
+	if (!td)
+		return;
+
+	rwlock_init(&td->lock);
+
+	td->notifier.notifier_call = usbdev_trig_notify;
+	td->notifier.priority = 10;
+
+	setup_timer(&td->timer, usbdev_trig_timer, (unsigned long) td);
+
+	td->led_cdev = led_cdev;
+	td->interval = msecs_to_jiffies(50);
+
+	led_cdev->trigger_data = td;
+
+	rc = device_create_file(led_cdev->dev, &dev_attr_device_name);
+	if (rc)
+		goto err_out;
+
+	rc = device_create_file(led_cdev->dev, &dev_attr_activity_interval);
+	if (rc)
+		goto err_out_device_name;
+
+	usb_register_notify(&td->notifier);
+	return;
+
+err_out_device_name:
+	device_remove_file(led_cdev->dev, &dev_attr_device_name);
+err_out:
+	led_cdev->trigger_data = NULL;
+	kfree(td);
+}
+
+static void usbdev_trig_deactivate(struct led_classdev *led_cdev)
+{
+	struct usbdev_trig_data *td = led_cdev->trigger_data;
+
+	if (td) {
+		usb_unregister_notify(&td->notifier);
+
+		device_remove_file(led_cdev->dev, &dev_attr_device_name);
+		device_remove_file(led_cdev->dev, &dev_attr_activity_interval);
+
+		write_lock(&td->lock);
+
+		if (td->usb_dev) {
+			usb_put_dev(td->usb_dev);
+			td->usb_dev = NULL;
+		}
+
+		write_unlock(&td->lock);
+
+		del_timer_sync(&td->timer);
+
+		kfree(td);
+	}
+}
+
+static struct led_trigger usbdev_led_trigger = {
+	.name		= "usbdev",
+	.activate	= usbdev_trig_activate,
+	.deactivate	= usbdev_trig_deactivate,
+};
+
+static int __init usbdev_trig_init(void)
+{
+	return led_trigger_register(&usbdev_led_trigger);
+}
+
+static void __exit usbdev_trig_exit(void)
+{
+	led_trigger_unregister(&usbdev_led_trigger);
+}
+
+module_init(usbdev_trig_init);
+module_exit(usbdev_trig_exit);
+
+MODULE_AUTHOR("Gabor Juhos <juhosg@openwrt.org>");
+MODULE_DESCRIPTION("USB device LED trigger");
+MODULE_LICENSE("GPL v2");
diff --git a/trunk/linux-4.4.x/drivers/leds/trigger/Kconfig b/trunk/linux-4.4.x/drivers/leds/trigger/Kconfig
index 3f9ddb9fa..51ed59fc1 100644
--- a/trunk/linux-4.4.x/drivers/leds/trigger/Kconfig
+++ b/trunk/linux-4.4.x/drivers/leds/trigger/Kconfig
@@ -126,4 +126,18 @@ config LEDS_TRIGGER_PANIC
 	  a different trigger.
 	  If unsure, say Y.
 
+config LEDS_TRIGGER_NETDEV
+	tristate "LED Netdev Trigger"
+	depends on NET && LEDS_TRIGGERS
+	help
+	  This allows LEDs to be controlled by network device activity.
+	  If unsure, say Y.
+
+config LEDS_TRIGGER_USBDEV
+	tristate "LED USB device Trigger"
+	depends on USB && LEDS_TRIGGERS
+	help
+	  This allows LEDs to be controlled by the presence/activity of
+	  an USB device. If unsure, say N.
+
 endif # LEDS_TRIGGERS
diff --git a/trunk/linux-4.4.x/drivers/mtd/Kconfig b/trunk/linux-4.4.x/drivers/mtd/Kconfig
index 63b6dbd8f..84626d614 100644
--- a/trunk/linux-4.4.x/drivers/mtd/Kconfig
+++ b/trunk/linux-4.4.x/drivers/mtd/Kconfig
@@ -373,4 +373,8 @@ source "drivers/mtd/spi-nor/Kconfig"
 
 source "drivers/mtd/ubi/Kconfig"
 
+source "drivers/mtd/nmbm/Kconfig"
+
+source "drivers/mtd/mtk-snand/Kconfig"
+
 endif # MTD
diff --git a/trunk/linux-4.4.x/drivers/mtd/Makefile b/trunk/linux-4.4.x/drivers/mtd/Makefile
index 8d8d3d6aa..cc0ae82e8 100644
--- a/trunk/linux-4.4.x/drivers/mtd/Makefile
+++ b/trunk/linux-4.4.x/drivers/mtd/Makefile
@@ -37,3 +37,7 @@ obj-y		+= chips/ lpddr/ maps/ devices/ nand/ onenand/ tests/
 
 obj-$(CONFIG_MTD_SPI_NOR)	+= spi-nor/
 obj-$(CONFIG_MTD_UBI)		+= ubi/
+
+obj-$(CONFIG_NMBM)		+= nmbm/
+
+obj-$(CONFIG_MTK_SPI_NAND)	+= mtk-snand/
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtdcore.c b/trunk/linux-4.4.x/drivers/mtd/mtdcore.c
index 3a2c15d8c..0ebaeff6e 100644
--- a/trunk/linux-4.4.x/drivers/mtd/mtdcore.c
+++ b/trunk/linux-4.4.x/drivers/mtd/mtdcore.c
@@ -826,6 +826,44 @@ out_unlock:
 }
 EXPORT_SYMBOL_GPL(get_mtd_device_nm);
 
+/**
+ *	get_mtd_device_by_node - obtain a validated handle for an MTD device
+ *	by of_node
+ *	@of_node: OF node of MTD device to open
+ *
+ *	This function returns an MTD device structure in case of success,
+ *	an error code otherwise.
+ */
+struct mtd_info *get_mtd_device_by_node(const struct device_node *of_node)
+{
+	struct mtd_info *mtd;
+	bool found = false;
+	int ret;
+
+	mutex_lock(&mtd_table_mutex);
+
+	mtd_for_each_device(mtd) {
+		if (of_node == mtd->dev.of_node) {
+			found = true;
+			break;
+		}
+	}
+
+	if (found)
+		ret = __get_mtd_device(mtd);
+
+	mutex_unlock(&mtd_table_mutex);
+
+	if (!found)
+		return ERR_PTR(-ENODEV);
+
+	if (ret)
+		return ERR_PTR(ret);
+
+	return mtd;
+}
+EXPORT_SYMBOL_GPL(get_mtd_device_by_node);
+
 void put_mtd_device(struct mtd_info *mtd)
 {
 	mutex_lock(&mtd_table_mutex);
@@ -919,6 +957,40 @@ unsigned long mtd_get_unmapped_area(struct mtd_info *mtd, unsigned long len,
 }
 EXPORT_SYMBOL_GPL(mtd_get_unmapped_area);
 
+/*
+ * LEDE OpenWRT split rootfs from Kernel partition, to split rootfs,
+ * nand check bad is necessary, to read bad block marker, nfc has to
+ * read the data and mark swap, this take a lot of time, to reduce
+ * nand flash access, use a table to store the result of bad blocks.
+ */
+static int lede_split_isbad(struct mtd_info *mtd, loff_t ofs)
+{
+	static unsigned int split_isbad_init;
+	static u_char *tbl;
+	static unsigned int kofs;
+	unsigned int size, index;
+	int ret;
+
+	if (!split_isbad_init) {
+		kofs = (unsigned int) mtdpart_get_offset(mtd);
+		split_isbad_init = 1;
+		size = (unsigned int)mtd->size >> mtd->erasesize_shift;
+		tbl = kmalloc(size, GFP_KERNEL);
+		memset(tbl, 0xff, size);
+	}
+
+	index = (unsigned int)(ofs + mtdpart_get_offset(mtd) - kofs)
+			      >> mtd->erasesize_shift;
+	if (tbl[index] == 0xff) {
+		ret = mtd_block_isbad(mtd, ofs);
+		tbl[index] = (u_char)ret;
+	} else {
+		ret = (int) tbl[index];
+	}
+
+	return ret;
+}
+
 /* Learn total bad block number before access offs+len */
 int mtd_countbad(struct mtd_info *mtd, loff_t offs, unsigned int len)
 {
@@ -926,10 +998,10 @@ int mtd_countbad(struct mtd_info *mtd, loff_t offs, unsigned int len)
 	loff_t offset = 0;
 
 	while ((offs + len) > offset) {
-		if (mtd_block_isbad(mtd, offset) > 0) {
+		if (lede_split_isbad(mtd, offset) > 0) {
 			bad++;
 			offs += mtd->erasesize;
-		} else if (mtd_block_isbad(mtd, offset) < 0) {
+		} else if (lede_split_isbad(mtd, offset) < 0) {
 			pr_err("len should not be over partition end\n");
 			return bad;
 		}
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtdsplit/Kconfig b/trunk/linux-4.4.x/drivers/mtd/mtdsplit/Kconfig
index 7e653e78a..122ec3bc2 100644
--- a/trunk/linux-4.4.x/drivers/mtd/mtdsplit/Kconfig
+++ b/trunk/linux-4.4.x/drivers/mtd/mtdsplit/Kconfig
@@ -64,3 +64,9 @@ config MTD_SPLIT_EVA_FW
 	bool "EVA image based firmware partition parser"
 	depends on MTD_SPLIT_SUPPORT
 	select MTD_SPLIT
+
+config MTD_SPLIT_ASUS_FW
+	bool "ASUS image based firmware partition parser"
+	depends on MTD_SPLIT_SUPPORT
+	select MTD_SPLIT
+
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtdsplit/Makefile b/trunk/linux-4.4.x/drivers/mtd/mtdsplit/Makefile
index c843025ff..c9e748f73 100644
--- a/trunk/linux-4.4.x/drivers/mtd/mtdsplit/Makefile
+++ b/trunk/linux-4.4.x/drivers/mtd/mtdsplit/Makefile
@@ -9,3 +9,4 @@ obj-$(CONFIG_MTD_SPLIT_TRX_FW) += mtdsplit_trx.o
 obj-$(CONFIG_MTD_SPLIT_BRNIMAGE_FW) += mtdsplit_brnimage.o
 obj-$(CONFIG_MTD_SPLIT_EVA_FW) += mtdsplit_eva.o
 obj-$(CONFIG_MTD_SPLIT_WRGG_FW) += mtdsplit_wrgg.o
+obj-$(CONFIG_MTD_SPLIT_ASUS_FW) += mtdsplit_asus.o
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtdsplit/mtdsplit_asus.c b/trunk/linux-4.4.x/drivers/mtd/mtdsplit/mtdsplit_asus.c
new file mode 100644
index 000000000..d8597b593
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtdsplit/mtdsplit_asus.c
@@ -0,0 +1,201 @@
+/*
+ *  Copyright (C) 2022 Zhaowei Xu <paldier@hotmail.com>
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ *
+ */
+
+#define pr_fmt(fmt)	KBUILD_MODNAME ": " fmt
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/byteorder/generic.h>
+
+#include "mtdsplit.h"
+
+#define IH_MAGIC			0x27051956	/* Image Magic Number		*/
+#define MAX_HEADER_LEN		64
+#define MAX_STRING			12
+#define MAX_VER				4
+#define IH_NMLEN		32	/* Image Name Length		*/
+
+/* If hw[i].kernel == ROOTFS_OFFSET_MAGIC,
+ * rootfilesystem offset (uImage header size + kernel size)
+ * can be calculated by following equation:
+ * (hw[i].minor << 16) | (hw[i+1].major << 8) | (hw[i+1].minor)
+ */
+#define ROOTFS_OFFSET_MAGIC	0xA9	/* Occupy two version_t		*/
+
+typedef struct {
+	uint8_t major;
+	uint8_t minor; 
+} version_t;
+
+typedef struct {
+	version_t kernel;
+	version_t fs;
+	char	  productid[MAX_STRING];
+	uint16_t  sn;
+	uint16_t  en;
+	uint8_t   pkey;
+	uint8_t   key;
+	version_t hw[MAX_VER];
+} TAIL;
+
+typedef struct image_header {
+	uint32_t	ih_magic;	/* Image Header Magic Number	*/
+	uint32_t	ih_hcrc;	/* Image Header CRC Checksum	*/
+	uint32_t	ih_time;	/* Image Creation Timestamp	*/
+	uint32_t	ih_size;	/* Image Data Size		*/
+	uint32_t	ih_load;	/* Data	 Load  Address		*/
+	uint32_t	ih_ep;		/* Entry Point Address		*/
+	uint32_t	ih_dcrc;	/* Image Data CRC Checksum	*/
+	uint8_t		ih_os;		/* Operating System		*/
+	uint8_t		ih_arch;	/* CPU architecture		*/
+	uint8_t		ih_type;	/* Image Type			*/
+	uint8_t		ih_comp;	/* Compression Type		*/
+	union {
+		uint8_t		ih_name[IH_NMLEN];	/* Image Name		*/
+		TAIL		tail;		/* ASUS firmware infomation	*/
+	} u;
+} image_header_t;
+
+static int
+read_asus_header(struct mtd_info *mtd, size_t offset,u_char *buf,
+		   size_t header_len)
+{
+	size_t retlen;
+	int ret;
+
+	ret = mtd_read(mtd, offset, header_len, &retlen, buf);
+	if (ret) {
+		printk("read error in \"%s\"\n", mtd->name);
+		return ret;
+	}
+
+	if (retlen != header_len) {
+		printk("short read in \"%s\"\n", mtd->name);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static int
+mtdsplit_parse_asus(struct mtd_info *master,
+				   struct mtd_partition **pparts,
+				   struct mtd_part_parser_data *data)
+{
+	struct mtd_partition *parts;
+	u_char *buf;
+	int nr_parts;
+	size_t offset;
+	size_t kernel_offset;
+	size_t kernel_size = 0;
+	size_t rootfs_offset = 0;
+	size_t rootfs_size = 0;
+	int ret;
+
+	nr_parts = 2;
+	parts = kzalloc(nr_parts * sizeof(*parts), GFP_KERNEL);
+	if (!parts)
+		return -ENOMEM;
+
+	buf = vmalloc(MAX_HEADER_LEN);
+	if (!buf) {
+		ret = -ENOMEM;
+		goto err;
+	}
+
+	/* find asus image on erase block boundaries */
+	for (offset = 0; offset < master->size; offset += master->erasesize) {
+		image_header_t *hdr;
+		kernel_size = 0;
+
+		ret = read_asus_header(master, offset, buf, MAX_HEADER_LEN);
+		if (ret)
+			continue;
+
+		hdr = (image_header_t *)buf;
+		if (be32_to_cpu(hdr->ih_magic) != IH_MAGIC) {
+			printk("no valid asus header found in \"%s\" at offset %llx\n",
+				 master->name, (unsigned long long) offset);
+			continue;
+		}
+		if(hdr->u.tail.hw[3].major == ROOTFS_OFFSET_MAGIC){
+			rootfs_offset = (hdr->u.tail.hw[3].minor << 16) | (hdr->u.tail.hw[4].major << 8) | (hdr->u.tail.hw[4].minor);
+		}
+		if(be32_to_cpu(hdr->ih_size) < 0x400000){//uImage header:only kernel
+			rootfs_offset = 0x400000;
+			rootfs_size = master->size - rootfs_offset;
+			kernel_size = rootfs_offset;
+		} else {// asus header:kernel+rootfs
+			rootfs_size = master->size - rootfs_offset;
+			kernel_size = rootfs_offset;
+		}
+
+		if ((offset + kernel_size) > master->size) {
+			printk("asus image exceeds MTD device \"%s\"\n",
+				 master->name);
+			continue;
+		}
+		break;
+	}
+
+	if (kernel_size == 0) {
+		printk("no asus header found in \"%s\"\n", master->name);
+		ret = -ENODEV;
+		goto err_free_buf;
+	}
+
+	kernel_offset = offset;
+
+	if (rootfs_size == 0) {
+		printk("no rootfs found in \"%s\"\n", master->name);
+		ret = -ENODEV;
+		goto err_free_buf;
+	}
+
+	parts[0].name = KERNEL_PART_NAME;
+	parts[0].offset = kernel_offset;
+	parts[0].size = kernel_size;
+
+	parts[1].name = ROOTFS_PART_NAME;
+	parts[1].offset = rootfs_offset;
+	parts[1].size = rootfs_size;
+
+	vfree(buf);
+
+	*pparts = parts;
+	return nr_parts;
+
+err_free_buf:
+	vfree(buf);
+
+err:
+	kfree(parts);
+	return ret;
+}
+
+static struct mtd_part_parser asus_parser = {
+	.owner = THIS_MODULE,
+	.name = "asus-fw",
+	.parse_fn = mtdsplit_parse_asus,
+	.type = MTD_PARSER_TYPE_FIRMWARE,
+};
+
+static int __init mtdsplit_asus_init(void)
+{
+	register_mtd_parser(&asus_parser);
+
+	return 0;
+}
+
+module_init(mtdsplit_asus_init);
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtdsplit/mtdsplit_squashfs.c b/trunk/linux-4.4.x/drivers/mtd/mtdsplit/mtdsplit_squashfs.c
index 1e14c95d7..245ee320a 100644
--- a/trunk/linux-4.4.x/drivers/mtd/mtdsplit/mtdsplit_squashfs.c
+++ b/trunk/linux-4.4.x/drivers/mtd/mtdsplit/mtdsplit_squashfs.c
@@ -30,6 +30,9 @@ mtdsplit_parse_squashfs(struct mtd_info *master,
 	struct mtd_info *parent_mtd;
 	size_t part_offset;
 	size_t squashfs_len;
+	size_t dm_off, dm_len;
+	size_t retlen;
+	char verity[7];
 	int err;
 
 	err = mtd_get_squashfs_len(master, 0, &squashfs_len);
@@ -39,6 +42,25 @@ mtdsplit_parse_squashfs(struct mtd_info *master,
 	parent_mtd = mtdpart_get_master(master);
 	part_offset = mtdpart_get_offset(master);
 
+#define DM_VERITY_STR		"verity"
+#define DM_VERITY_BLK_SZ	4096
+	/* Try to find DM-verity */
+	dm_off = roundup(squashfs_len, DM_VERITY_BLK_SZ);
+	dm_len = 7;
+	err = mtd_read(master, dm_off, dm_len, &retlen, (void *)&verity);
+	if (err || (retlen != dm_len)) {
+		pr_alert("error occured while reading from \"%s\"\n",
+			 master->name);
+		return -EIO;
+	}
+	if (!strcmp(verity, DM_VERITY_STR)) {
+		int dm_sz;
+
+		dm_sz = roundup(squashfs_len / 128, DM_VERITY_BLK_SZ);
+		dm_sz += DM_VERITY_BLK_SZ * 2;
+		squashfs_len += dm_sz;
+	}
+
 	part = kzalloc(sizeof(*part), GFP_KERNEL);
 	if (!part) {
 		pr_alert("unable to allocate memory for \"%s\" partition\n",
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/Kconfig b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/Kconfig
new file mode 100644
index 000000000..138b93957
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/Kconfig
@@ -0,0 +1,14 @@
+#
+# Copyright (C) 2020 MediaTek Inc. All rights reserved.
+# Author: Weijie Gao <weijie.gao@mediatek.com>
+#
+# SPDX-License-Identifier: GPL-2.0
+#
+
+config MTK_SPI_NAND
+	tristate "MediaTek SPI NAND flash controller driver"
+	depends on MTD
+	default n
+	help
+	  This option enables access to SPI-NAND flashes through the
+	  MTD interface of MediaTek SPI NAND Flash Controller
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/Makefile b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/Makefile
new file mode 100644
index 000000000..a39f1cade
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/Makefile
@@ -0,0 +1,11 @@
+#
+# Copyright (C) 2020 MediaTek Inc. All rights reserved.
+# Author: Weijie Gao <weijie.gao@mediatek.com>
+#
+# SPDX-License-Identifier: GPL-2.0
+#
+
+obj-y += mtk-snand.o mtk-snand-ecc.o mtk-snand-ids.o mtk-snand-os.o \
+	 mtk-snand-mtd.o
+
+ccflags-y += -DPRIVATE_MTK_SNAND_HEADER
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-def.h b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-def.h
new file mode 100644
index 000000000..95c4bb30c
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-def.h
@@ -0,0 +1,266 @@
+/* SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause */
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#ifndef _MTK_SNAND_DEF_H_
+#define _MTK_SNAND_DEF_H_
+
+#include "mtk-snand-os.h"
+
+#ifdef PRIVATE_MTK_SNAND_HEADER
+#include "mtk-snand.h"
+#else
+#include <mtk-snand.h>
+#endif
+
+struct mtk_snand_plat_dev;
+
+enum snand_flash_io {
+	SNAND_IO_1_1_1,
+	SNAND_IO_1_1_2,
+	SNAND_IO_1_2_2,
+	SNAND_IO_1_1_4,
+	SNAND_IO_1_4_4,
+
+	__SNAND_IO_MAX
+};
+
+#define SPI_IO_1_1_1			BIT(SNAND_IO_1_1_1)
+#define SPI_IO_1_1_2			BIT(SNAND_IO_1_1_2)
+#define SPI_IO_1_2_2			BIT(SNAND_IO_1_2_2)
+#define SPI_IO_1_1_4			BIT(SNAND_IO_1_1_4)
+#define SPI_IO_1_4_4			BIT(SNAND_IO_1_4_4)
+
+struct snand_opcode {
+	uint8_t opcode;
+	uint8_t dummy;
+};
+
+struct snand_io_cap {
+	uint8_t caps;
+	struct snand_opcode opcodes[__SNAND_IO_MAX];
+};
+
+#define SNAND_OP(_io, _opcode, _dummy) [_io] = { .opcode = (_opcode), \
+						 .dummy = (_dummy) }
+
+#define SNAND_IO_CAP(_name, _caps, ...) \
+	struct snand_io_cap _name = { .caps = (_caps), \
+				      .opcodes = { __VA_ARGS__ } }
+
+#define SNAND_MAX_ID_LEN		4
+
+enum snand_id_type {
+	SNAND_ID_DYMMY,
+	SNAND_ID_ADDR = SNAND_ID_DYMMY,
+	SNAND_ID_DIRECT,
+
+	__SNAND_ID_TYPE_MAX
+};
+
+struct snand_id {
+	uint8_t type;	/* enum snand_id_type */
+	uint8_t len;
+	uint8_t id[SNAND_MAX_ID_LEN];
+};
+
+#define SNAND_ID(_type, ...) \
+	{ .type = (_type), .id = { __VA_ARGS__ }, \
+	  .len = sizeof((uint8_t[]) { __VA_ARGS__ }) }
+
+struct snand_mem_org {
+	uint16_t pagesize;
+	uint16_t sparesize;
+	uint16_t pages_per_block;
+	uint16_t blocks_per_die;
+	uint16_t planes_per_die;
+	uint16_t ndies;
+};
+
+#define SNAND_MEMORG(_ps, _ss, _ppb, _bpd, _ppd, _nd) \
+	{ .pagesize = (_ps), .sparesize = (_ss), .pages_per_block = (_ppb), \
+	  .blocks_per_die = (_bpd), .planes_per_die = (_ppd), .ndies = (_nd) }
+
+typedef int (*snand_select_die_t)(struct mtk_snand *snf, uint32_t dieidx);
+
+struct snand_flash_info {
+	const char *model;
+	struct snand_id id;
+	const struct snand_mem_org memorg;
+	const struct snand_io_cap *cap_rd;
+	const struct snand_io_cap *cap_pl;
+	snand_select_die_t select_die;
+};
+
+#define SNAND_INFO(_model, _id, _memorg, _cap_rd, _cap_pl, ...) \
+	{ .model = (_model), .id = _id, .memorg = _memorg, \
+	  .cap_rd = (_cap_rd), .cap_pl = (_cap_pl), __VA_ARGS__ }
+
+const struct snand_flash_info *snand_flash_id_lookup(enum snand_id_type type,
+						     const uint8_t *id);
+
+struct mtk_snand_soc_data {
+	uint16_t sector_size;
+	uint16_t max_sectors;
+	uint16_t fdm_size;
+	uint16_t fdm_ecc_size;
+	uint16_t fifo_size;
+
+	bool bbm_swap;
+	bool empty_page_check;
+	uint32_t mastersta_mask;
+
+	const uint8_t *spare_sizes;
+	uint32_t num_spare_size;
+};
+
+enum mtk_ecc_regs {
+	ECC_DECDONE,
+};
+
+struct mtk_ecc_soc_data {
+	const uint8_t *ecc_caps;
+	uint32_t num_ecc_cap;
+	const uint32_t *regs;
+	uint16_t mode_shift;
+	uint8_t errnum_bits;
+	uint8_t errnum_shift;
+};
+
+struct mtk_snand {
+	struct mtk_snand_plat_dev *pdev;
+
+	void __iomem *nfi_base;
+	void __iomem *ecc_base;
+
+	enum mtk_snand_soc soc;
+	const struct mtk_snand_soc_data *nfi_soc;
+	const struct mtk_ecc_soc_data *ecc_soc;
+	bool snfi_quad_spi;
+	bool quad_spi_op;
+
+	const char *model;
+	uint64_t size;
+	uint64_t die_size;
+	uint32_t erasesize;
+	uint32_t writesize;
+	uint32_t oobsize;
+
+	uint32_t num_dies;
+	snand_select_die_t select_die;
+
+	uint8_t opcode_rfc;
+	uint8_t opcode_pl;
+	uint8_t dummy_rfc;
+	uint8_t mode_rfc;
+	uint8_t mode_pl;
+
+	uint32_t writesize_mask;
+	uint32_t writesize_shift;
+	uint32_t erasesize_mask;
+	uint32_t erasesize_shift;
+	uint64_t die_mask;
+	uint32_t die_shift;
+
+	uint32_t spare_per_sector;
+	uint32_t raw_sector_size;
+	uint32_t ecc_strength;
+	uint32_t ecc_steps;
+	uint32_t ecc_bytes;
+	uint32_t ecc_parity_bits;
+
+	uint8_t *page_cache;	/* Used by read/write page */
+	uint8_t *buf_cache;	/* Used by block bad/markbad & auto_oob */
+};
+
+enum mtk_snand_log_category {
+	SNAND_LOG_NFI,
+	SNAND_LOG_SNFI,
+	SNAND_LOG_ECC,
+	SNAND_LOG_CHIP,
+
+	__SNAND_LOG_CAT_MAX
+};
+
+int mtk_ecc_setup(struct mtk_snand *snf, void *fmdaddr, uint32_t max_ecc_bytes,
+		  uint32_t msg_size);
+int mtk_snand_ecc_encoder_start(struct mtk_snand *snf);
+void mtk_snand_ecc_encoder_stop(struct mtk_snand *snf);
+int mtk_snand_ecc_decoder_start(struct mtk_snand *snf);
+void mtk_snand_ecc_decoder_stop(struct mtk_snand *snf);
+int mtk_ecc_wait_decoder_done(struct mtk_snand *snf);
+int mtk_ecc_check_decode_error(struct mtk_snand *snf, uint32_t page);
+
+int mtk_snand_mac_io(struct mtk_snand *snf, const uint8_t *out, uint32_t outlen,
+		     uint8_t *in, uint32_t inlen);
+int mtk_snand_set_feature(struct mtk_snand *snf, uint32_t addr, uint32_t val);
+
+int mtk_snand_log(struct mtk_snand_plat_dev *pdev,
+		  enum mtk_snand_log_category cat, const char *fmt, ...);
+
+#define snand_log_nfi(pdev, fmt, ...) \
+	mtk_snand_log(pdev, SNAND_LOG_NFI, fmt, ##__VA_ARGS__)
+
+#define snand_log_snfi(pdev, fmt, ...) \
+	mtk_snand_log(pdev, SNAND_LOG_SNFI, fmt, ##__VA_ARGS__)
+
+#define snand_log_ecc(pdev, fmt, ...) \
+	mtk_snand_log(pdev, SNAND_LOG_ECC, fmt, ##__VA_ARGS__)
+
+#define snand_log_chip(pdev, fmt, ...) \
+	mtk_snand_log(pdev, SNAND_LOG_CHIP, fmt, ##__VA_ARGS__)
+
+/* ffs64 */
+static inline int mtk_snand_ffs64(uint64_t x)
+{
+	if (!x)
+		return 0;
+
+	if (!(x & 0xffffffff))
+		return ffs((uint32_t)(x >> 32)) + 32;
+
+	return ffs((uint32_t)(x & 0xffffffff));
+}
+
+/* NFI dummy commands */
+#define NFI_CMD_DUMMY_READ		0x00
+#define NFI_CMD_DUMMY_WRITE		0x80
+
+/* SPI-NAND opcodes */
+#define SNAND_CMD_RESET			0xff
+#define SNAND_CMD_BLOCK_ERASE		0xd8
+#define SNAND_CMD_READ_FROM_CACHE_QUAD	0xeb
+#define SNAND_CMD_WINBOND_SELECT_DIE	0xc2
+#define SNAND_CMD_READ_FROM_CACHE_DUAL	0xbb
+#define SNAND_CMD_READID		0x9f
+#define SNAND_CMD_READ_FROM_CACHE_X4	0x6b
+#define SNAND_CMD_READ_FROM_CACHE_X2	0x3b
+#define SNAND_CMD_PROGRAM_LOAD_X4	0x32
+#define SNAND_CMD_SET_FEATURE		0x1f
+#define SNAND_CMD_READ_TO_CACHE		0x13
+#define SNAND_CMD_PROGRAM_EXECUTE	0x10
+#define SNAND_CMD_GET_FEATURE		0x0f
+#define SNAND_CMD_READ_FROM_CACHE	0x0b
+#define SNAND_CMD_WRITE_ENABLE		0x06
+#define SNAND_CMD_PROGRAM_LOAD		0x02
+
+/* SPI-NAND feature addresses */
+#define SNAND_FEATURE_MICRON_DIE_ADDR	0xd0
+#define SNAND_MICRON_DIE_SEL_1		BIT(6)
+
+#define SNAND_FEATURE_STATUS_ADDR	0xc0
+#define SNAND_STATUS_OIP		BIT(0)
+#define SNAND_STATUS_WEL		BIT(1)
+#define SNAND_STATUS_ERASE_FAIL		BIT(2)
+#define SNAND_STATUS_PROGRAM_FAIL	BIT(3)
+
+#define SNAND_FEATURE_CONFIG_ADDR	0xb0
+#define SNAND_FEATURE_QUAD_ENABLE	BIT(0)
+#define SNAND_FEATURE_ECC_EN		BIT(4)
+
+#define SNAND_FEATURE_PROTECT_ADDR	0xa0
+
+#endif /* _MTK_SNAND_DEF_H_ */
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-ecc.c b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-ecc.c
new file mode 100644
index 000000000..57ba611cf
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-ecc.c
@@ -0,0 +1,264 @@
+// SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#include "mtk-snand-def.h"
+
+/* ECC registers */
+#define ECC_ENCCON			0x000
+#define ENC_EN				BIT(0)
+
+#define ECC_ENCCNFG			0x004
+#define ENC_MS_S			16
+#define ENC_BURST_EN			BIT(8)
+#define ENC_TNUM_S			0
+
+#define ECC_ENCIDLE			0x00c
+#define ENC_IDLE			BIT(0)
+
+#define ECC_DECCON			0x100
+#define DEC_EN				BIT(0)
+
+#define ECC_DECCNFG			0x104
+#define DEC_EMPTY_EN			BIT(31)
+#define DEC_CS_S			16
+#define DEC_CON_S			12
+#define   DEC_CON_CORRECT		3
+#define DEC_BURST_EN			BIT(8)
+#define DEC_TNUM_S			0
+
+#define ECC_DECIDLE			0x10c
+#define DEC_IDLE			BIT(0)
+
+#define ECC_DECENUM0			0x114
+#define ECC_DECENUM(n)			(ECC_DECENUM0 + (n) * 4)
+
+/* ECC_ENCIDLE & ECC_DECIDLE */
+#define ECC_IDLE			BIT(0)
+
+/* ENC_MODE & DEC_MODE */
+#define ECC_MODE_NFI			1
+
+#define ECC_TIMEOUT			500000
+
+static const uint8_t mt7622_ecc_caps[] = { 4, 6, 8, 10, 12 };
+
+static const uint8_t mt7986_ecc_caps[] = {
+	4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24
+};
+
+static const uint32_t mt7622_ecc_regs[] = {
+	[ECC_DECDONE] = 0x11c,
+};
+
+static const uint32_t mt7986_ecc_regs[] = {
+	[ECC_DECDONE] = 0x124,
+};
+
+static const struct mtk_ecc_soc_data mtk_ecc_socs[__SNAND_SOC_MAX] = {
+	[SNAND_SOC_MT7622] = {
+		.ecc_caps = mt7622_ecc_caps,
+		.num_ecc_cap = ARRAY_SIZE(mt7622_ecc_caps),
+		.regs = mt7622_ecc_regs,
+		.mode_shift = 4,
+		.errnum_bits = 5,
+		.errnum_shift = 5,
+	},
+	[SNAND_SOC_MT7629] = {
+		.ecc_caps = mt7622_ecc_caps,
+		.num_ecc_cap = ARRAY_SIZE(mt7622_ecc_caps),
+		.regs = mt7622_ecc_regs,
+		.mode_shift = 4,
+		.errnum_bits = 5,
+		.errnum_shift = 5,
+	},
+	[SNAND_SOC_MT7986] = {
+		.ecc_caps = mt7986_ecc_caps,
+		.num_ecc_cap = ARRAY_SIZE(mt7986_ecc_caps),
+		.regs = mt7986_ecc_regs,
+		.mode_shift = 5,
+		.errnum_bits = 5,
+		.errnum_shift = 8,
+	},
+};
+
+static inline uint32_t ecc_read32(struct mtk_snand *snf, uint32_t reg)
+{
+	return readl(snf->ecc_base + reg);
+}
+
+static inline void ecc_write32(struct mtk_snand *snf, uint32_t reg,
+			       uint32_t val)
+{
+	writel(val, snf->ecc_base + reg);
+}
+
+static inline void ecc_write16(struct mtk_snand *snf, uint32_t reg,
+			       uint16_t val)
+{
+	writew(val, snf->ecc_base + reg);
+}
+
+static int mtk_ecc_poll(struct mtk_snand *snf, uint32_t reg, uint32_t bits)
+{
+	uint32_t val;
+
+	return read16_poll_timeout(snf->ecc_base + reg, val, (val & bits), 0,
+				   ECC_TIMEOUT);
+}
+
+static int mtk_ecc_wait_idle(struct mtk_snand *snf, uint32_t reg)
+{
+	int ret;
+
+	ret = mtk_ecc_poll(snf, reg, ECC_IDLE);
+	if (ret) {
+		snand_log_ecc(snf->pdev, "ECC engine is busy\n");
+		return -EBUSY;
+	}
+
+	return 0;
+}
+
+int mtk_ecc_setup(struct mtk_snand *snf, void *fmdaddr, uint32_t max_ecc_bytes,
+		  uint32_t msg_size)
+{
+	uint32_t i, val, ecc_msg_bits, ecc_strength;
+	int ret;
+
+	snf->ecc_soc = &mtk_ecc_socs[snf->soc];
+
+	snf->ecc_parity_bits = fls(1 + 8 * msg_size);
+	ecc_strength = max_ecc_bytes * 8 / snf->ecc_parity_bits;
+
+	for (i = snf->ecc_soc->num_ecc_cap - 1; i >= 0; i--) {
+		if (snf->ecc_soc->ecc_caps[i] <= ecc_strength)
+			break;
+	}
+
+	if (unlikely(i < 0)) {
+		snand_log_ecc(snf->pdev, "Page size %u+%u is not supported\n",
+			      snf->writesize, snf->oobsize);
+		return -ENOTSUPP;
+	}
+
+	snf->ecc_strength = snf->ecc_soc->ecc_caps[i];
+	snf->ecc_bytes = DIV_ROUND_UP(snf->ecc_strength * snf->ecc_parity_bits,
+				      8);
+
+	/* Encoder config */
+	ecc_write16(snf, ECC_ENCCON, 0);
+	ret = mtk_ecc_wait_idle(snf, ECC_ENCIDLE);
+	if (ret)
+		return ret;
+
+	ecc_msg_bits = msg_size * 8;
+	val = (ecc_msg_bits << ENC_MS_S) |
+	      (ECC_MODE_NFI << snf->ecc_soc->mode_shift) | i;
+	ecc_write32(snf, ECC_ENCCNFG, val);
+
+	/* Decoder config */
+	ecc_write16(snf, ECC_DECCON, 0);
+	ret = mtk_ecc_wait_idle(snf, ECC_DECIDLE);
+	if (ret)
+		return ret;
+
+	ecc_msg_bits += snf->ecc_strength * snf->ecc_parity_bits;
+	val = DEC_EMPTY_EN | (ecc_msg_bits << DEC_CS_S) |
+	      (DEC_CON_CORRECT << DEC_CON_S) |
+	      (ECC_MODE_NFI << snf->ecc_soc->mode_shift) | i;
+	ecc_write32(snf, ECC_DECCNFG, val);
+
+	return 0;
+}
+
+int mtk_snand_ecc_encoder_start(struct mtk_snand *snf)
+{
+	int ret;
+
+	ret = mtk_ecc_wait_idle(snf, ECC_ENCIDLE);
+	if (ret) {
+		ecc_write16(snf, ECC_ENCCON, 0);
+		mtk_ecc_wait_idle(snf, ECC_ENCIDLE);
+	}
+
+	ecc_write16(snf, ECC_ENCCON, ENC_EN);
+
+	return 0;
+}
+
+void mtk_snand_ecc_encoder_stop(struct mtk_snand *snf)
+{
+	mtk_ecc_wait_idle(snf, ECC_ENCIDLE);
+	ecc_write16(snf, ECC_ENCCON, 0);
+}
+
+int mtk_snand_ecc_decoder_start(struct mtk_snand *snf)
+{
+	int ret;
+
+	ret = mtk_ecc_wait_idle(snf, ECC_DECIDLE);
+	if (ret) {
+		ecc_write16(snf, ECC_DECCON, 0);
+		mtk_ecc_wait_idle(snf, ECC_DECIDLE);
+	}
+
+	ecc_write16(snf, ECC_DECCON, DEC_EN);
+
+	return 0;
+}
+
+void mtk_snand_ecc_decoder_stop(struct mtk_snand *snf)
+{
+	mtk_ecc_wait_idle(snf, ECC_DECIDLE);
+	ecc_write16(snf, ECC_DECCON, 0);
+}
+
+int mtk_ecc_wait_decoder_done(struct mtk_snand *snf)
+{
+	uint16_t val, step_mask = (1 << snf->ecc_steps) - 1;
+	uint32_t reg = snf->ecc_soc->regs[ECC_DECDONE];
+	int ret;
+
+	ret = read16_poll_timeout(snf->ecc_base + reg, val,
+				  (val & step_mask) == step_mask, 0,
+				  ECC_TIMEOUT);
+	if (ret)
+		snand_log_ecc(snf->pdev, "ECC decoder is busy\n");
+
+	return ret;
+}
+
+int mtk_ecc_check_decode_error(struct mtk_snand *snf, uint32_t page)
+{
+	uint32_t i, regi, fi, errnum;
+	uint32_t errnum_shift = snf->ecc_soc->errnum_shift;
+	uint32_t errnum_mask = (1 << snf->ecc_soc->errnum_bits) - 1;
+	int ret = 0;
+
+	for (i = 0; i < snf->ecc_steps; i++) {
+		regi = i / 4;
+		fi = i % 4;
+
+		errnum = ecc_read32(snf, ECC_DECENUM(regi));
+		errnum = (errnum >> (fi * errnum_shift)) & errnum_mask;
+		if (!errnum)
+			continue;
+
+		if (errnum <= snf->ecc_strength) {
+			if (ret >= 0)
+				ret += errnum;
+			continue;
+		}
+
+		snand_log_ecc(snf->pdev,
+			      "Uncorrectable bitflips in page %u sect %u\n",
+			      page, i);
+		ret = -EBADMSG;
+	}
+
+	return ret;
+}
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-ids.c b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-ids.c
new file mode 100644
index 000000000..05e5b25d6
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-ids.c
@@ -0,0 +1,511 @@
+// SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#include "mtk-snand-def.h"
+
+static int mtk_snand_winbond_select_die(struct mtk_snand *snf, uint32_t dieidx);
+static int mtk_snand_micron_select_die(struct mtk_snand *snf, uint32_t dieidx);
+
+#define SNAND_MEMORG_512M_2K_64		SNAND_MEMORG(2048, 64, 64, 512, 1, 1)
+#define SNAND_MEMORG_1G_2K_64		SNAND_MEMORG(2048, 64, 64, 1024, 1, 1)
+#define SNAND_MEMORG_2G_2K_64		SNAND_MEMORG(2048, 64, 64, 2048, 1, 1)
+#define SNAND_MEMORG_2G_2K_120		SNAND_MEMORG(2048, 120, 64, 2048, 1, 1)
+#define SNAND_MEMORG_4G_2K_64		SNAND_MEMORG(2048, 64, 64, 4096, 1, 1)
+#define SNAND_MEMORG_1G_2K_120		SNAND_MEMORG(2048, 120, 64, 1024, 1, 1)
+#define SNAND_MEMORG_1G_2K_128		SNAND_MEMORG(2048, 128, 64, 1024, 1, 1)
+#define SNAND_MEMORG_2G_2K_128		SNAND_MEMORG(2048, 128, 64, 2048, 1, 1)
+#define SNAND_MEMORG_4G_2K_128		SNAND_MEMORG(2048, 128, 64, 4096, 1, 1)
+#define SNAND_MEMORG_4G_4K_240		SNAND_MEMORG(4096, 240, 64, 2048, 1, 1)
+#define SNAND_MEMORG_4G_4K_256		SNAND_MEMORG(4096, 256, 64, 2048, 1, 1)
+#define SNAND_MEMORG_8G_4K_256		SNAND_MEMORG(4096, 256, 64, 4096, 1, 1)
+#define SNAND_MEMORG_2G_2K_64_2P	SNAND_MEMORG(2048, 64, 64, 2048, 2, 1)
+#define SNAND_MEMORG_2G_2K_64_2D	SNAND_MEMORG(2048, 64, 64, 1024, 1, 2)
+#define SNAND_MEMORG_2G_2K_128_2P	SNAND_MEMORG(2048, 128, 64, 2048, 2, 1)
+#define SNAND_MEMORG_4G_2K_64_2P	SNAND_MEMORG(2048, 64, 64, 4096, 2, 1)
+#define SNAND_MEMORG_4G_2K_128_2P_2D	SNAND_MEMORG(2048, 128, 64, 2048, 2, 2)
+#define SNAND_MEMORG_8G_4K_256_2D	SNAND_MEMORG(4096, 256, 64, 2048, 1, 2)
+
+static const SNAND_IO_CAP(snand_cap_read_from_cache_quad,
+	SPI_IO_1_1_1 | SPI_IO_1_1_2 | SPI_IO_1_2_2 | SPI_IO_1_1_4 |
+	SPI_IO_1_4_4,
+	SNAND_OP(SNAND_IO_1_1_1, SNAND_CMD_READ_FROM_CACHE, 8),
+	SNAND_OP(SNAND_IO_1_1_2, SNAND_CMD_READ_FROM_CACHE_X2, 8),
+	SNAND_OP(SNAND_IO_1_2_2, SNAND_CMD_READ_FROM_CACHE_DUAL, 4),
+	SNAND_OP(SNAND_IO_1_1_4, SNAND_CMD_READ_FROM_CACHE_X4, 8),
+	SNAND_OP(SNAND_IO_1_4_4, SNAND_CMD_READ_FROM_CACHE_QUAD, 4));
+
+static const SNAND_IO_CAP(snand_cap_read_from_cache_quad_q2d,
+	SPI_IO_1_1_1 | SPI_IO_1_1_2 | SPI_IO_1_2_2 | SPI_IO_1_1_4 |
+	SPI_IO_1_4_4,
+	SNAND_OP(SNAND_IO_1_1_1, SNAND_CMD_READ_FROM_CACHE, 8),
+	SNAND_OP(SNAND_IO_1_1_2, SNAND_CMD_READ_FROM_CACHE_X2, 8),
+	SNAND_OP(SNAND_IO_1_2_2, SNAND_CMD_READ_FROM_CACHE_DUAL, 4),
+	SNAND_OP(SNAND_IO_1_1_4, SNAND_CMD_READ_FROM_CACHE_X4, 8),
+	SNAND_OP(SNAND_IO_1_4_4, SNAND_CMD_READ_FROM_CACHE_QUAD, 2));
+
+static const SNAND_IO_CAP(snand_cap_read_from_cache_quad_a8d,
+	SPI_IO_1_1_1 | SPI_IO_1_1_2 | SPI_IO_1_2_2 | SPI_IO_1_1_4 |
+	SPI_IO_1_4_4,
+	SNAND_OP(SNAND_IO_1_1_1, SNAND_CMD_READ_FROM_CACHE, 8),
+	SNAND_OP(SNAND_IO_1_1_2, SNAND_CMD_READ_FROM_CACHE_X2, 8),
+	SNAND_OP(SNAND_IO_1_2_2, SNAND_CMD_READ_FROM_CACHE_DUAL, 8),
+	SNAND_OP(SNAND_IO_1_1_4, SNAND_CMD_READ_FROM_CACHE_X4, 8),
+	SNAND_OP(SNAND_IO_1_4_4, SNAND_CMD_READ_FROM_CACHE_QUAD, 8));
+
+static const SNAND_IO_CAP(snand_cap_read_from_cache_x4,
+	SPI_IO_1_1_1 | SPI_IO_1_1_2 | SPI_IO_1_1_4,
+	SNAND_OP(SNAND_IO_1_1_1, SNAND_CMD_READ_FROM_CACHE, 8),
+	SNAND_OP(SNAND_IO_1_1_2, SNAND_CMD_READ_FROM_CACHE_X2, 8),
+	SNAND_OP(SNAND_IO_1_1_4, SNAND_CMD_READ_FROM_CACHE_X4, 8));
+
+static const SNAND_IO_CAP(snand_cap_read_from_cache_x4_only,
+	SPI_IO_1_1_1 | SPI_IO_1_1_4,
+	SNAND_OP(SNAND_IO_1_1_1, SNAND_CMD_READ_FROM_CACHE, 8),
+	SNAND_OP(SNAND_IO_1_1_4, SNAND_CMD_READ_FROM_CACHE_X4, 8));
+
+static const SNAND_IO_CAP(snand_cap_program_load_x1,
+	SPI_IO_1_1_1,
+	SNAND_OP(SNAND_IO_1_1_1, SNAND_CMD_PROGRAM_LOAD, 0));
+
+static const SNAND_IO_CAP(snand_cap_program_load_x4,
+	SPI_IO_1_1_1 | SPI_IO_1_1_4,
+	SNAND_OP(SNAND_IO_1_1_1, SNAND_CMD_PROGRAM_LOAD, 0),
+	SNAND_OP(SNAND_IO_1_1_4, SNAND_CMD_PROGRAM_LOAD_X4, 0));
+
+static const struct snand_flash_info snand_flash_ids[] = {
+	SNAND_INFO("W25N512GV", SNAND_ID(SNAND_ID_DYMMY, 0xef, 0xaa, 0x20),
+		   SNAND_MEMORG_512M_2K_64,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("W25N01GV", SNAND_ID(SNAND_ID_DYMMY, 0xef, 0xaa, 0x21),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("W25M02GV", SNAND_ID(SNAND_ID_DYMMY, 0xef, 0xab, 0x21),
+		   SNAND_MEMORG_2G_2K_64_2D,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4,
+		   mtk_snand_winbond_select_die),
+	SNAND_INFO("W25N02KV", SNAND_ID(SNAND_ID_DYMMY, 0xef, 0xaa, 0x22),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("GD5F1GQ4UAWxx", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0x10),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F1GQ4UExIG", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0xd1),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F1GQ4UExxH", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0xd9),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F1GQ4xAYIG", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0xf1),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F2GQ4UExIG", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0xd2),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F2GQ5UExxH", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0x32),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_a8d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F2GQ4xAYIG", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0xf2),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F4GQ4UBxIG", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0xd4),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F4GQ4xAYIG", SNAND_ID(SNAND_ID_ADDR, 0xc8, 0xf4),
+		   SNAND_MEMORG_4G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F2GQ5UExxG", SNAND_ID(SNAND_ID_DYMMY, 0xc8, 0x52),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("GD5F4GQ4UCxIG", SNAND_ID(SNAND_ID_DYMMY, 0xc8, 0xb4),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("MX35LF1GE4AB", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x12),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MX35LF1G24AD", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x14),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MX31LF1GE4BC", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x1e),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MX35LF2GE4AB", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x22),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MX35LF2G24AD", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x24),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MX35LF2GE4AD", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x26),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MX35LF2G14AC", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x20),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MX35LF4G24AD", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x35),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MX35LF4GE4AD", SNAND_ID(SNAND_ID_DYMMY, 0xc2, 0x37),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("MT29F1G01AAADD", SNAND_ID(SNAND_ID_DYMMY, 0x2c, 0x12),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x1),
+	SNAND_INFO("MT29F1G01ABAFD", SNAND_ID(SNAND_ID_DYMMY, 0x2c, 0x14),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MT29F2G01AAAED", SNAND_ID(SNAND_ID_DYMMY, 0x2c, 0x9f),
+		   SNAND_MEMORG_2G_2K_64_2P,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x1),
+	SNAND_INFO("MT29F2G01ABAGD", SNAND_ID(SNAND_ID_DYMMY, 0x2c, 0x24),
+		   SNAND_MEMORG_2G_2K_128_2P,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MT29F4G01AAADD", SNAND_ID(SNAND_ID_DYMMY, 0x2c, 0x32),
+		   SNAND_MEMORG_4G_2K_64_2P,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x1),
+	SNAND_INFO("MT29F4G01ABAFD", SNAND_ID(SNAND_ID_DYMMY, 0x2c, 0x34),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("MT29F4G01ADAGD", SNAND_ID(SNAND_ID_DYMMY, 0x2c, 0x36),
+		   SNAND_MEMORG_4G_2K_128_2P_2D,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4,
+		   mtk_snand_micron_select_die),
+	SNAND_INFO("MT29F8G01ADAFD", SNAND_ID(SNAND_ID_DYMMY, 0x2c, 0x46),
+		   SNAND_MEMORG_8G_4K_256_2D,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4,
+		   mtk_snand_micron_select_die),
+
+	SNAND_INFO("TC58CVG0S3HRAIG", SNAND_ID(SNAND_ID_DYMMY, 0x98, 0xc2),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x1),
+	SNAND_INFO("TC58CVG1S3HRAIG", SNAND_ID(SNAND_ID_DYMMY, 0x98, 0xcb),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x1),
+	SNAND_INFO("TC58CVG2S0HRAIG", SNAND_ID(SNAND_ID_DYMMY, 0x98, 0xcd),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x1),
+	SNAND_INFO("TC58CVG0S3HRAIJ", SNAND_ID(SNAND_ID_DYMMY, 0x98, 0xe2),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("TC58CVG1S3HRAIJ", SNAND_ID(SNAND_ID_DYMMY, 0x98, 0xeb),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("TC58CVG2S0HRAIJ", SNAND_ID(SNAND_ID_DYMMY, 0x98, 0xed),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("TH58CVG3S0HRAIJ", SNAND_ID(SNAND_ID_DYMMY, 0x98, 0xe4),
+		   SNAND_MEMORG_8G_4K_256,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("F50L512M41A", SNAND_ID(SNAND_ID_DYMMY, 0xc8, 0x20),
+		   SNAND_MEMORG_512M_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("F50L1G41A", SNAND_ID(SNAND_ID_DYMMY, 0xc8, 0x21),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("F50L1G41LB", SNAND_ID(SNAND_ID_DYMMY, 0xc8, 0x01),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("F50L2G41LB", SNAND_ID(SNAND_ID_DYMMY, 0xc8, 0x0a),
+		   SNAND_MEMORG_2G_2K_64_2D,
+		   &snand_cap_read_from_cache_quad,
+		   &snand_cap_program_load_x4,
+		   mtk_snand_winbond_select_die),
+
+	SNAND_INFO("CS11G0T0A0AA", SNAND_ID(SNAND_ID_DYMMY, 0x6b, 0x00),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("CS11G0G0A0AA", SNAND_ID(SNAND_ID_DYMMY, 0x6b, 0x10),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("CS11G0S0A0AA", SNAND_ID(SNAND_ID_DYMMY, 0x6b, 0x20),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("CS11G1T0A0AA", SNAND_ID(SNAND_ID_DYMMY, 0x6b, 0x01),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("CS11G1S0A0AA", SNAND_ID(SNAND_ID_DYMMY, 0x6b, 0x21),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("CS11G2T0A0AA", SNAND_ID(SNAND_ID_DYMMY, 0x6b, 0x02),
+		   SNAND_MEMORG_4G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("CS11G2S0A0AA", SNAND_ID(SNAND_ID_DYMMY, 0x6b, 0x22),
+		   SNAND_MEMORG_4G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("EM73B044VCA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x01),
+		   SNAND_MEMORG_512M_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044SNB", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x11),
+		   SNAND_MEMORG_1G_2K_120,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044SNF", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x09),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044VCA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x18),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044SNA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x19),
+		   SNAND_MEMORG(2048, 64, 128, 512, 1, 1),
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044VCD", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x1c),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044SND", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x1d),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044SND", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x1e),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044VCC", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x22),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044VCF", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x25),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044SNC", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x31),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044SNC", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x0a),
+		   SNAND_MEMORG_2G_2K_120,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044SNA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x12),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044SNF", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x10),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044VCA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x13),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044VCB", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x14),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044VCD", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x17),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044VCH", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x1b),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044SND", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x1d),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044VCG", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x1f),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044VCE", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x20),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044VCL", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x2e),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044SNB", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x32),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73E044SNA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x03),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73E044SND", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x0b),
+		   SNAND_MEMORG_4G_4K_240,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73E044SNB", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x23),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73E044VCA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x2c),
+		   SNAND_MEMORG_4G_4K_256,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73E044VCB", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x2f),
+		   SNAND_MEMORG_4G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73F044SNA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x24),
+		   SNAND_MEMORG_8G_4K_256,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73F044VCA", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x2d),
+		   SNAND_MEMORG_8G_4K_256,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73E044SNE", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x0e),
+		   SNAND_MEMORG_8G_4K_256,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73C044SNG", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x0c),
+		   SNAND_MEMORG_1G_2K_120,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("EM73D044VCN", SNAND_ID(SNAND_ID_DYMMY, 0xd5, 0x0f),
+		   SNAND_MEMORG_2G_2K_64,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("FM35Q1GA", SNAND_ID(SNAND_ID_DYMMY, 0xe5, 0x71),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("PN26G01A", SNAND_ID(SNAND_ID_DYMMY, 0xa1, 0xe1),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("PN26G02A", SNAND_ID(SNAND_ID_DYMMY, 0xa1, 0xe2),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("IS37SML01G1", SNAND_ID(SNAND_ID_DYMMY, 0xc8, 0x21),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_x4,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("ATO25D1GA", SNAND_ID(SNAND_ID_DYMMY, 0x9b, 0x12),
+		   SNAND_MEMORG_1G_2K_64,
+		   &snand_cap_read_from_cache_x4_only,
+		   &snand_cap_program_load_x4),
+
+	SNAND_INFO("HYF1GQ4U", SNAND_ID(SNAND_ID_DYMMY, 0xc9, 0x51),
+		   SNAND_MEMORG_1G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+	SNAND_INFO("HYF2GQ4U", SNAND_ID(SNAND_ID_DYMMY, 0xc9, 0x52),
+		   SNAND_MEMORG_2G_2K_128,
+		   &snand_cap_read_from_cache_quad_q2d,
+		   &snand_cap_program_load_x4),
+};
+
+static int mtk_snand_winbond_select_die(struct mtk_snand *snf, uint32_t dieidx)
+{
+	uint8_t op[2];
+
+	if (dieidx > 1) {
+		snand_log_chip(snf->pdev, "Invalid die index %u\n", dieidx);
+		return -EINVAL;
+	}
+
+	op[0] = SNAND_CMD_WINBOND_SELECT_DIE;
+	op[1] = (uint8_t)dieidx;
+
+	return mtk_snand_mac_io(snf, op, sizeof(op), NULL, 0);
+}
+
+static int mtk_snand_micron_select_die(struct mtk_snand *snf, uint32_t dieidx)
+{
+	int ret;
+
+	if (dieidx > 1) {
+		snand_log_chip(snf->pdev, "Invalid die index %u\n", dieidx);
+		return -EINVAL;
+	}
+
+	ret = mtk_snand_set_feature(snf, SNAND_FEATURE_MICRON_DIE_ADDR,
+				    SNAND_MICRON_DIE_SEL_1);
+	if (ret) {
+		snand_log_chip(snf->pdev,
+			       "Failed to set die selection feature\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+const struct snand_flash_info *snand_flash_id_lookup(enum snand_id_type type,
+						     const uint8_t *id)
+{
+	const struct snand_id *fid;
+	uint32_t i;
+
+	for (i = 0; i < ARRAY_SIZE(snand_flash_ids); i++) {
+		if (snand_flash_ids[i].id.type != type)
+			continue;
+
+		fid = &snand_flash_ids[i].id;
+		if (memcmp(fid->id, id, fid->len))
+			continue;
+
+		return &snand_flash_ids[i];
+	}
+
+	return NULL;
+}
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-mtd.c b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-mtd.c
new file mode 100644
index 000000000..acf9f1420
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-mtd.c
@@ -0,0 +1,730 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/mutex.h>
+#include <linux/clk.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <linux/wait.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/of_platform.h>
+
+#include "mtk-snand.h"
+#include "mtk-snand-os.h"
+
+struct mtk_snand_of_id {
+	enum mtk_snand_soc soc;
+};
+
+struct mtk_snand_mtd {
+	struct mtk_snand_plat_dev pdev;
+
+	struct clk *nfi_clk;
+	struct clk *pad_clk;
+	struct clk *ecc_clk;
+
+	void __iomem *nfi_regs;
+	void __iomem *ecc_regs;
+
+	int irq;
+
+	bool quad_spi;
+	enum mtk_snand_soc soc;
+
+	struct mtd_info mtd;
+	struct mtk_snand *snf;
+	struct mtk_snand_chip_info cinfo;
+	uint8_t *page_cache;
+	struct mutex lock;
+};
+
+#define mtd_to_msm(mtd) container_of(mtd, struct mtk_snand_mtd, mtd)
+
+static int mtk_snand_mtd_erase(struct mtd_info *mtd, struct erase_info *instr)
+{
+	struct mtk_snand_mtd *msm = mtd_to_msm(mtd);
+	u64 start_addr, end_addr;
+	int ret;
+
+	/* Do not allow write past end of device */
+	if ((instr->addr + instr->len) > mtd->size) {
+		dev_err(msm->pdev.dev,
+			"attempt to erase beyond end of device\n");
+		return -EINVAL;
+	}
+
+	start_addr = instr->addr & (~mtd->erasesize_mask);
+	end_addr = instr->addr + instr->len;
+	if (end_addr & mtd->erasesize_mask) {
+		end_addr = (end_addr + mtd->erasesize_mask) &
+			   (~mtd->erasesize_mask);
+	}
+
+	instr->state = MTD_ERASING;
+
+	mutex_lock(&msm->lock);
+
+	while (start_addr < end_addr) {
+		if (mtk_snand_block_isbad(msm->snf, start_addr)) {
+			instr->fail_addr = start_addr;
+			ret = -EIO;
+			break;
+		}
+
+		ret = mtk_snand_erase_block(msm->snf, start_addr);
+		if (ret) {
+			instr->fail_addr = start_addr;
+			break;
+		}
+
+		start_addr += mtd->erasesize;
+	}
+
+	mutex_unlock(&msm->lock);
+
+	if (ret)
+		instr->state = MTD_ERASE_FAILED;
+	else
+		instr->state = MTD_ERASE_DONE;
+
+	if (!ret)
+		mtd_erase_callback(instr);
+	else
+		ret = -EIO;
+
+	return ret;
+}
+
+static int mtk_snand_mtd_read_data(struct mtk_snand_mtd *msm, uint64_t addr,
+				   struct mtd_oob_ops *ops)
+{
+	struct mtd_info *mtd = &msm->mtd;
+	size_t len, ooblen, maxooblen, chklen;
+	uint32_t col, ooboffs;
+	uint8_t *datcache, *oobcache;
+	bool raw = ops->mode == MTD_OPS_RAW ? true : false;
+	int ret;
+
+	col = addr & mtd->writesize_mask;
+	addr &= ~mtd->writesize_mask;
+	maxooblen = mtd_oobavail(mtd, ops);
+	ooboffs = ops->ooboffs;
+	ooblen = ops->ooblen;
+	len = ops->len;
+
+	datcache = len ? msm->page_cache : NULL;
+	oobcache = ooblen ? msm->page_cache + mtd->writesize : NULL;
+
+	ops->oobretlen = 0;
+	ops->retlen = 0;
+
+	while (len || ooblen) {
+		if (ops->mode == MTD_OPS_AUTO_OOB)
+			ret = mtk_snand_read_page_auto_oob(msm->snf, addr,
+				datcache, oobcache, maxooblen, NULL, raw);
+		else
+			ret = mtk_snand_read_page(msm->snf, addr, datcache,
+				oobcache, raw);
+
+		if (ret < 0)
+			return ret;
+
+		if (len) {
+			/* Move data */
+			chklen = mtd->writesize - col;
+			if (chklen > len)
+				chklen = len;
+
+			memcpy(ops->datbuf + ops->retlen, datcache + col,
+			       chklen);
+			len -= chklen;
+			col = 0; /* (col + chklen) %  */
+			ops->retlen += chklen;
+		}
+
+		if (ooblen) {
+			/* Move oob */
+			chklen = maxooblen - ooboffs;
+			if (chklen > ooblen)
+				chklen = ooblen;
+
+			memcpy(ops->oobbuf + ops->oobretlen, oobcache + ooboffs,
+			       chklen);
+			ooblen -= chklen;
+			ooboffs = 0; /* (ooboffs + chklen) % maxooblen; */
+			ops->oobretlen += chklen;
+		}
+
+		addr += mtd->writesize;
+	}
+
+	return 0;
+}
+
+static int mtk_snand_mtd_read_oob(struct mtd_info *mtd, loff_t from,
+				  struct mtd_oob_ops *ops)
+{
+	struct mtk_snand_mtd *msm = mtd_to_msm(mtd);
+	uint32_t maxooblen;
+	int ret;
+
+	if (!ops->oobbuf && !ops->datbuf) {
+		if (ops->ooblen || ops->len)
+			return -EINVAL;
+
+		return 0;
+	}
+
+	switch (ops->mode) {
+	case MTD_OPS_PLACE_OOB:
+	case MTD_OPS_AUTO_OOB:
+	case MTD_OPS_RAW:
+		break;
+	default:
+		dev_err(msm->pdev.dev, "unsupported oob mode: %u\n", ops->mode);
+		return -EINVAL;
+	}
+
+	maxooblen = mtd_oobavail(mtd, ops);
+
+	/* Do not allow read past end of device */
+	if (ops->datbuf && (from + ops->len) > mtd->size) {
+		dev_err(msm->pdev.dev,
+			"attempt to read beyond end of device\n");
+		return -EINVAL;
+	}
+
+	if (unlikely(ops->ooboffs >= maxooblen)) {
+		dev_err(msm->pdev.dev, "attempt to start read outside oob\n");
+		return -EINVAL;
+	}
+
+	if (unlikely(from >= mtd->size ||
+	    ops->ooboffs + ops->ooblen > ((mtd->size >> mtd->writesize_shift) -
+	    (from >> mtd->writesize_shift)) * maxooblen)) {
+		dev_err(msm->pdev.dev,
+			"attempt to read beyond end of device\n");
+		return -EINVAL;
+	}
+
+	mutex_lock(&msm->lock);
+	ret = mtk_snand_mtd_read_data(msm, from, ops);
+	mutex_unlock(&msm->lock);
+
+	return ret;
+}
+
+static int mtk_snand_mtd_write_data(struct mtk_snand_mtd *msm, uint64_t addr,
+				    struct mtd_oob_ops *ops)
+{
+	struct mtd_info *mtd = &msm->mtd;
+	size_t len, ooblen, maxooblen, chklen, oobwrlen;
+	uint32_t col, ooboffs;
+	uint8_t *datcache, *oobcache;
+	bool raw = ops->mode == MTD_OPS_RAW ? true : false;
+	int ret;
+
+	col = addr & mtd->writesize_mask;
+	addr &= ~mtd->writesize_mask;
+	maxooblen = mtd_oobavail(mtd, ops);
+	ooboffs = ops->ooboffs;
+	ooblen = ops->ooblen;
+	len = ops->len;
+
+	datcache = len ? msm->page_cache : NULL;
+	oobcache = ooblen ? msm->page_cache + mtd->writesize : NULL;
+
+	ops->oobretlen = 0;
+	ops->retlen = 0;
+
+	while (len || ooblen) {
+		if (len) {
+			/* Move data */
+			chklen = mtd->writesize - col;
+			if (chklen > len)
+				chklen = len;
+
+			memset(datcache, 0xff, col);
+			memcpy(datcache + col, ops->datbuf + ops->retlen,
+			       chklen);
+			memset(datcache + col + chklen, 0xff,
+			       mtd->writesize - col - chklen);
+			len -= chklen;
+			col = 0; /* (col + chklen) %  */
+			ops->retlen += chklen;
+		}
+
+		oobwrlen = 0;
+		if (ooblen) {
+			/* Move oob */
+			chklen = maxooblen - ooboffs;
+			if (chklen > ooblen)
+				chklen = ooblen;
+
+			memset(oobcache, 0xff, ooboffs);
+			memcpy(oobcache + ooboffs,
+			       ops->oobbuf + ops->oobretlen, chklen);
+			memset(oobcache + ooboffs + chklen, 0xff,
+			       mtd->oobsize - ooboffs - chklen);
+			oobwrlen = chklen + ooboffs;
+			ooblen -= chklen;
+			ooboffs = 0; /* (ooboffs + chklen) % maxooblen; */
+			ops->oobretlen += chklen;
+		}
+
+		if (ops->mode == MTD_OPS_AUTO_OOB)
+			ret = mtk_snand_write_page_auto_oob(msm->snf, addr,
+				datcache, oobcache, oobwrlen, NULL, raw);
+		else
+			ret = mtk_snand_write_page(msm->snf, addr, datcache,
+				oobcache, raw);
+
+		if (ret)
+			return ret;
+
+		addr += mtd->writesize;
+	}
+
+	return 0;
+}
+
+static int mtk_snand_mtd_write_oob(struct mtd_info *mtd, loff_t to,
+				   struct mtd_oob_ops *ops)
+{
+	struct mtk_snand_mtd *msm = mtd_to_msm(mtd);
+	uint32_t maxooblen;
+	int ret;
+
+	if (!ops->oobbuf && !ops->datbuf) {
+		if (ops->ooblen || ops->len)
+			return -EINVAL;
+
+		return 0;
+	}
+
+	switch (ops->mode) {
+	case MTD_OPS_PLACE_OOB:
+	case MTD_OPS_AUTO_OOB:
+	case MTD_OPS_RAW:
+		break;
+	default:
+		dev_err(msm->pdev.dev, "unsupported oob mode: %u\n", ops->mode);
+		return -EINVAL;
+	}
+
+	maxooblen = mtd_oobavail(mtd, ops);
+
+	/* Do not allow write past end of device */
+	if (ops->datbuf && (to + ops->len) > mtd->size) {
+		dev_err(msm->pdev.dev,
+			"attempt to write beyond end of device\n");
+		return -EINVAL;
+	}
+
+	if (unlikely(ops->ooboffs >= maxooblen)) {
+		dev_err(msm->pdev.dev,
+			"attempt to start write outside oob\n");
+		return -EINVAL;
+	}
+
+	if (unlikely(to >= mtd->size ||
+	    ops->ooboffs + ops->ooblen > ((mtd->size >> mtd->writesize_shift) -
+	    (to >> mtd->writesize_shift)) * maxooblen)) {
+		dev_err(msm->pdev.dev,
+			"attempt to write beyond end of device\n");
+		return -EINVAL;
+	}
+
+	mutex_lock(&msm->lock);
+	ret = mtk_snand_mtd_write_data(msm, to, ops);
+	mutex_unlock(&msm->lock);
+
+	return ret;
+}
+
+static int mtk_snand_mtd_read(struct mtd_info *mtd, loff_t from, size_t len,
+			      size_t *retlen, u_char *buf)
+{
+	struct mtd_oob_ops ops = {
+		.mode = MTD_OPS_PLACE_OOB,
+		.datbuf = buf,
+		.len = len,
+	};
+	int ret;
+
+	ret = mtk_snand_mtd_read_oob(mtd, from, &ops);
+
+	if (retlen)
+		*retlen = ops.retlen;
+
+	return ret;
+}
+
+static int mtk_snand_mtd_write(struct mtd_info *mtd, loff_t to, size_t len,
+			       size_t *retlen, const u_char *buf)
+{
+	struct mtd_oob_ops ops = {
+		.mode = MTD_OPS_PLACE_OOB,
+		.datbuf = (void *)buf,
+		.len = len,
+	};
+	int ret;
+
+	ret = mtk_snand_mtd_write_oob(mtd, to, &ops);
+
+	if (retlen)
+		*retlen = ops.retlen;
+
+	return ret;
+}
+
+static int mtk_snand_mtd_block_isbad(struct mtd_info *mtd, loff_t offs)
+{
+	struct mtk_snand_mtd *msm = mtd_to_msm(mtd);
+	int ret;
+
+	mutex_lock(&msm->lock);
+	ret = mtk_snand_block_isbad(msm->snf, offs);
+	mutex_unlock(&msm->lock);
+
+	return ret;
+}
+
+static int mtk_snand_mtd_block_markbad(struct mtd_info *mtd, loff_t offs)
+{
+	struct mtk_snand_mtd *msm = mtd_to_msm(mtd);
+	int ret;
+
+	mutex_lock(&msm->lock);
+	ret = mtk_snand_block_markbad(msm->snf, offs);
+	mutex_unlock(&msm->lock);
+
+	return ret;
+}
+
+static int mtk_snand_ooblayout_ecc(struct mtd_info *mtd, int section,
+				   struct mtd_oob_region *oobecc)
+{
+	struct mtk_snand_mtd *msm = mtd_to_msm(mtd);
+
+	if (section)
+		return -ERANGE;
+
+	oobecc->offset = msm->cinfo.fdm_size * msm->cinfo.num_sectors;
+	oobecc->length = mtd->oobsize - oobecc->offset;
+
+	return 0;
+}
+
+static int mtk_snand_ooblayout_free(struct mtd_info *mtd, int section,
+				    struct mtd_oob_region *oobfree)
+{
+	struct mtk_snand_mtd *msm = mtd_to_msm(mtd);
+
+	if (section >= msm->cinfo.num_sectors)
+		return -ERANGE;
+
+	oobfree->length = msm->cinfo.fdm_size - 1;
+	oobfree->offset = section * msm->cinfo.fdm_size + 1;
+
+	return 0;
+}
+
+static irqreturn_t mtk_snand_irq(int irq, void *id)
+{
+	struct mtk_snand_mtd *msm = id;
+	int ret;
+
+	ret = mtk_snand_irq_process(msm->snf);
+	if (ret > 0)
+		return IRQ_HANDLED;
+
+	return IRQ_NONE;
+}
+
+static int mtk_snand_enable_clk(struct mtk_snand_mtd *msm)
+{
+	int ret;
+
+	ret = clk_prepare_enable(msm->nfi_clk);
+	if (ret) {
+		dev_err(msm->pdev.dev, "unable to enable nfi clk\n");
+		return ret;
+	}
+
+	ret = clk_prepare_enable(msm->pad_clk);
+	if (ret) {
+		dev_err(msm->pdev.dev, "unable to enable pad clk\n");
+		clk_disable_unprepare(msm->nfi_clk);
+		return ret;
+	}
+
+	ret = clk_prepare_enable(msm->ecc_clk);
+	if (ret) {
+		dev_err(msm->pdev.dev, "unable to enable ecc clk\n");
+		clk_disable_unprepare(msm->nfi_clk);
+		clk_disable_unprepare(msm->pad_clk);
+		return ret;
+	}
+
+	return 0;
+}
+
+static void mtk_snand_disable_clk(struct mtk_snand_mtd *msm)
+{
+	clk_disable_unprepare(msm->nfi_clk);
+	clk_disable_unprepare(msm->pad_clk);
+	clk_disable_unprepare(msm->ecc_clk);
+}
+
+static const struct mtd_ooblayout_ops mtk_snand_ooblayout = {
+	.ecc = mtk_snand_ooblayout_ecc,
+	.free = mtk_snand_ooblayout_free,
+};
+
+static struct mtk_snand_of_id mt7622_soc_id = { .soc = SNAND_SOC_MT7622 };
+static struct mtk_snand_of_id mt7629_soc_id = { .soc = SNAND_SOC_MT7629 };
+static struct mtk_snand_of_id mt7986_soc_id = { .soc = SNAND_SOC_MT7986 };
+
+static const struct of_device_id mtk_snand_ids[] = {
+	{ .compatible = "mediatek,mt7622-snand", .data = &mt7622_soc_id },
+	{ .compatible = "mediatek,mt7629-snand", .data = &mt7629_soc_id },
+	{ .compatible = "mediatek,mt7986-snand", .data = &mt7986_soc_id },
+	{ },
+};
+
+MODULE_DEVICE_TABLE(of, mtk_snand_ids);
+
+static int mtk_snand_probe(struct platform_device *pdev)
+{
+	struct mtk_snand_platdata mtk_snand_pdata = {};
+	struct device_node *np = pdev->dev.of_node;
+	const struct of_device_id *of_soc_id;
+	const struct mtk_snand_of_id *soc_id;
+	struct mtd_part_parser_data ppdata;
+	struct device_node *ofpart_node;
+	struct mtk_snand_mtd *msm;
+	struct mtd_info *mtd;
+	struct resource *r;
+	uint32_t size;
+	int ret;
+
+	of_soc_id = of_match_node(mtk_snand_ids, np);
+	if (!of_soc_id)
+		return -EINVAL;
+
+	soc_id = of_soc_id->data;
+
+	msm = devm_kzalloc(&pdev->dev, sizeof(*msm), GFP_KERNEL);
+	if (!msm)
+		return -ENOMEM;
+
+	r = platform_get_resource_byname(pdev, IORESOURCE_MEM, "nfi");
+	msm->nfi_regs = devm_ioremap_resource(&pdev->dev, r);
+	if (IS_ERR(msm->nfi_regs)) {
+		ret = PTR_ERR(msm->nfi_regs);
+		goto errout1;
+	}
+
+	r = platform_get_resource_byname(pdev, IORESOURCE_MEM, "ecc");
+	msm->ecc_regs = devm_ioremap_resource(&pdev->dev, r);
+	if (IS_ERR(msm->ecc_regs)) {
+		ret = PTR_ERR(msm->ecc_regs);
+		goto errout1;
+	}
+
+	msm->pdev.dev = &pdev->dev;
+	msm->quad_spi = of_property_read_bool(np, "mediatek,quad-spi");
+	msm->soc = soc_id->soc;
+
+	msm->nfi_clk = devm_clk_get(msm->pdev.dev, "nfi_clk");
+	if (IS_ERR(msm->nfi_clk)) {
+		ret = PTR_ERR(msm->nfi_clk);
+		dev_err(msm->pdev.dev, "unable to get nfi_clk, err = %d\n",
+			ret);
+		goto errout1;
+	}
+
+	msm->ecc_clk = devm_clk_get(msm->pdev.dev, "ecc_clk");
+	if (IS_ERR(msm->ecc_clk)) {
+		ret = PTR_ERR(msm->ecc_clk);
+		dev_err(msm->pdev.dev, "unable to get ecc_clk, err = %d\n",
+			ret);
+		goto errout1;
+	}
+
+	msm->pad_clk = devm_clk_get(msm->pdev.dev, "pad_clk");
+	if (IS_ERR(msm->pad_clk)) {
+		ret = PTR_ERR(msm->pad_clk);
+		dev_err(msm->pdev.dev, "unable to get pad_clk, err = %d\n",
+			ret);
+		goto errout1;
+	}
+
+	ret = mtk_snand_enable_clk(msm);
+	if (ret)
+		goto errout1;
+
+	/* Probe SPI-NAND Flash */
+	mtk_snand_pdata.soc = msm->soc;
+	mtk_snand_pdata.quad_spi = msm->quad_spi;
+	mtk_snand_pdata.nfi_base = msm->nfi_regs;
+	mtk_snand_pdata.ecc_base = msm->ecc_regs;
+
+	ret = mtk_snand_init(&msm->pdev, &mtk_snand_pdata, &msm->snf);
+	if (ret)
+		goto errout1;
+
+	msm->irq = platform_get_irq(pdev, 0);
+	if (msm->irq >= 0) {
+		ret = devm_request_irq(msm->pdev.dev, msm->irq, mtk_snand_irq,
+				       0x0, "mtk-snand", msm);
+		if (ret) {
+			dev_err(msm->pdev.dev, "failed to request snfi irq\n");
+			goto errout2;
+		}
+
+		ret = dma_set_mask(msm->pdev.dev, DMA_BIT_MASK(32));
+		if (ret) {
+			dev_err(msm->pdev.dev, "failed to set dma mask\n");
+			goto errout3;
+		}
+	}
+
+	mtk_snand_get_chip_info(msm->snf, &msm->cinfo);
+
+	size = msm->cinfo.pagesize + msm->cinfo.sparesize;
+	msm->page_cache = devm_kmalloc(msm->pdev.dev, size, GFP_KERNEL);
+	if (!msm->page_cache) {
+		dev_err(msm->pdev.dev, "failed to allocate page cache\n");
+		ret = -ENOMEM;
+		goto errout3;
+	}
+
+	mutex_init(&msm->lock);
+
+	dev_info(msm->pdev.dev,
+		 "chip is %s, size %lluMB, page size %u, oob size %u\n",
+		 msm->cinfo.model, msm->cinfo.chipsize >> 20,
+		 msm->cinfo.pagesize, msm->cinfo.sparesize);
+
+	/* Initialize mtd for SPI-NAND */
+	mtd = &msm->mtd;
+
+	mtd->owner = THIS_MODULE;
+	mtd->dev.parent = &pdev->dev;
+	mtd->type = MTD_NANDFLASH;
+	mtd->flags = MTD_CAP_NANDFLASH;
+
+	mtd_set_of_node(mtd, np);
+
+	mtd->size = msm->cinfo.chipsize;
+	mtd->erasesize = msm->cinfo.blocksize;
+	mtd->writesize = msm->cinfo.pagesize;
+	mtd->writebufsize = mtd->writesize;
+	mtd->oobsize = msm->cinfo.sparesize;
+	mtd->oobavail = msm->cinfo.num_sectors * (msm->cinfo.fdm_size - 1);
+
+	mtd->erasesize_shift = ffs(mtd->erasesize) - 1;
+	mtd->writesize_shift = ffs(mtd->writesize) - 1;
+	mtd->erasesize_mask = (1 << mtd->erasesize_shift) - 1;
+	mtd->writesize_mask = (1 << mtd->writesize_shift) - 1;
+
+	mtd->ooblayout = &mtk_snand_ooblayout;
+
+	mtd->ecc_strength = msm->cinfo.ecc_strength * msm->cinfo.num_sectors;
+	mtd->bitflip_threshold = (mtd->ecc_strength * 3) / 4;
+	mtd->ecc_step_size = msm->cinfo.sector_size;
+
+	mtd->_read = mtk_snand_mtd_read;
+	mtd->_write = mtk_snand_mtd_write;
+	mtd->_erase = mtk_snand_mtd_erase;
+	mtd->_read_oob = mtk_snand_mtd_read_oob;
+	mtd->_write_oob = mtk_snand_mtd_write_oob;
+	mtd->_block_isbad = mtk_snand_mtd_block_isbad;
+	mtd->_block_markbad = mtk_snand_mtd_block_markbad;
+
+	ppdata.of_node = pdev->dev.of_node;
+
+	ofpart_node = of_get_child_by_name(ppdata.of_node, "partitions");
+	if (ofpart_node) {
+		static const char *const probes[] = {"ofpart", NULL};
+
+		ret = mtd_device_parse_register(mtd, probes, &ppdata, NULL, 0);
+		if (ret) {
+			dev_err(msm->pdev.dev, "mtd partition parsing error\n");
+			goto errout4;
+		}
+	}
+
+	platform_set_drvdata(pdev, msm);
+
+	return 0;
+
+errout4:
+	devm_kfree(msm->pdev.dev, msm->page_cache);
+
+errout3:
+	if (msm->irq >= 0)
+		devm_free_irq(msm->pdev.dev, msm->irq, msm);
+
+errout2:
+	mtk_snand_cleanup(msm->snf);
+
+errout1:
+	devm_kfree(msm->pdev.dev, msm);
+
+	platform_set_drvdata(pdev, NULL);
+
+	return ret;
+}
+
+static int mtk_snand_remove(struct platform_device *pdev)
+{
+	struct mtk_snand_mtd *msm = platform_get_drvdata(pdev);
+	struct mtd_info *mtd = &msm->mtd;
+	int ret;
+
+	ret = mtd_device_unregister(mtd);
+	if (ret)
+		return ret;
+
+	mtk_snand_cleanup(msm->snf);
+
+	if (msm->irq >= 0)
+		devm_free_irq(msm->pdev.dev, msm->irq, msm);
+
+	mtk_snand_disable_clk(msm);
+
+	devm_kfree(msm->pdev.dev, msm->page_cache);
+	devm_kfree(msm->pdev.dev, msm);
+
+	platform_set_drvdata(pdev, NULL);
+
+	return 0;
+}
+
+static struct platform_driver mtk_snand_driver = {
+	.probe = mtk_snand_probe,
+	.remove = mtk_snand_remove,
+	.driver = {
+		.name = "mtk-snand",
+		.of_match_table = mtk_snand_ids,
+	},
+};
+
+module_platform_driver(mtk_snand_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Weijie Gao <weijie.gao@mediatek.com>");
+MODULE_DESCRIPTION("MeidaTek SPI-NAND Flash Controller Driver");
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-os.c b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-os.c
new file mode 100644
index 000000000..0c3ffec8b
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-os.c
@@ -0,0 +1,48 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#include "mtk-snand-def.h"
+
+int mtk_snand_log(struct mtk_snand_plat_dev *pdev,
+		  enum mtk_snand_log_category cat, const char *fmt, ...)
+{
+	const char *catname = "";
+	va_list ap;
+	char *msg;
+
+	switch (cat) {
+	case SNAND_LOG_NFI:
+		catname = "NFI";
+		break;
+	case SNAND_LOG_SNFI:
+		catname = "SNFI";
+		break;
+	case SNAND_LOG_ECC:
+		catname = "ECC";
+		break;
+	default:
+		break;
+	}
+
+	va_start(ap, fmt);
+	msg = kvasprintf(GFP_KERNEL, fmt, ap);
+	va_end(ap);
+
+	if (!msg) {
+		dev_warn(pdev->dev, "unable to print log\n");
+		return -1;
+	}
+
+	if (*catname)
+		dev_warn(pdev->dev, "%s: %s", catname, msg);
+	else
+		dev_warn(pdev->dev, "%s", msg);
+
+	kfree(msg);
+
+	return 0;
+}
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-os.h b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-os.h
new file mode 100644
index 000000000..223f73f73
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand-os.h
@@ -0,0 +1,133 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#ifndef _MTK_SNAND_OS_H_
+#define _MTK_SNAND_OS_H_
+
+#include <linux/slab.h>
+#include <linux/kernel.h>
+#include <linux/limits.h>
+#include <linux/types.h>
+#include <linux/bitops.h>
+#include <linux/sizes.h>
+#include <linux/iopoll.h>
+#include <linux/hrtimer.h>
+#include <linux/device.h>
+#include <linux/dma-mapping.h>
+#include <linux/io.h>
+#include <asm/div64.h>
+
+struct mtk_snand_plat_dev {
+	struct device *dev;
+	struct completion done;
+};
+
+/* Polling helpers */
+#define read16_poll_timeout(addr, val, cond, sleep_us, timeout_us) \
+	readw_poll_timeout((addr), (val), (cond), (sleep_us), (timeout_us))
+
+#define read32_poll_timeout(addr, val, cond, sleep_us, timeout_us) \
+	readl_poll_timeout((addr), (val), (cond), (sleep_us), (timeout_us))
+
+/* Timer helpers */
+#define mtk_snand_time_t ktime_t
+
+static inline mtk_snand_time_t timer_get_ticks(void)
+{
+	return ktime_get();
+}
+
+static inline mtk_snand_time_t timer_time_to_tick(uint32_t timeout_us)
+{
+	return ktime_add_us(ktime_set(0, 0), timeout_us);
+}
+
+static inline bool timer_is_timeout(mtk_snand_time_t start_tick,
+				    mtk_snand_time_t timeout_tick)
+{
+	ktime_t tmo = ktime_add(start_tick, timeout_tick);
+
+	return ktime_compare(ktime_get(), tmo) > 0;
+}
+
+/* Memory helpers */
+static inline void *generic_mem_alloc(struct mtk_snand_plat_dev *pdev,
+				      size_t size)
+{
+	return devm_kzalloc(pdev->dev, size, GFP_KERNEL);
+}
+static inline void generic_mem_free(struct mtk_snand_plat_dev *pdev, void *ptr)
+{
+	devm_kfree(pdev->dev, ptr);
+}
+
+static inline void *dma_mem_alloc(struct mtk_snand_plat_dev *pdev, size_t size)
+{
+	return kzalloc(size, GFP_KERNEL);
+}
+static inline void dma_mem_free(struct mtk_snand_plat_dev *pdev, void *ptr)
+{
+	kfree(ptr);
+}
+
+static inline int dma_mem_map(struct mtk_snand_plat_dev *pdev, void *vaddr,
+			      uintptr_t *dma_addr, size_t size, bool to_device)
+{
+	dma_addr_t addr;
+	int ret;
+
+	addr = dma_map_single(pdev->dev, vaddr, size,
+			      to_device ? DMA_TO_DEVICE : DMA_FROM_DEVICE);
+	ret = dma_mapping_error(pdev->dev, addr);
+	if (ret)
+		return ret;
+
+	*dma_addr = (uintptr_t)addr;
+
+	return 0;
+}
+
+static inline void dma_mem_unmap(struct mtk_snand_plat_dev *pdev,
+				 uintptr_t dma_addr, size_t size,
+				 bool to_device)
+{
+	dma_unmap_single(pdev->dev, dma_addr, size,
+			 to_device ? DMA_TO_DEVICE : DMA_FROM_DEVICE);
+}
+
+/* Interrupt helpers */
+static inline void irq_completion_done(struct mtk_snand_plat_dev *pdev)
+{
+	complete(&pdev->done);
+}
+
+static inline void irq_completion_init(struct mtk_snand_plat_dev *pdev)
+{
+	init_completion(&pdev->done);
+}
+
+static inline int irq_completion_wait(struct mtk_snand_plat_dev *pdev,
+				       void __iomem *reg, uint32_t bit,
+				       uint32_t timeout_us)
+{
+#if 0
+	uint32_t val;
+
+	return read32_poll_timeout(reg, val, val & bit, 0, timeout_us);
+#else
+	int ret;
+
+	ret = wait_for_completion_timeout(&pdev->done,
+					  usecs_to_jiffies(timeout_us));
+	if (!ret)
+		return -ETIMEDOUT;
+
+	return 0;
+#endif
+}
+
+#endif /* _MTK_SNAND_OS_H_ */
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand.c b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand.c
new file mode 100644
index 000000000..26dde9504
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand.c
@@ -0,0 +1,1776 @@
+// SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#include "mtk-snand-def.h"
+
+/* NFI registers */
+#define NFI_CNFG			0x000
+#define CNFG_OP_MODE_S			12
+#define   CNFG_OP_MODE_CUST		6
+#define   CNFG_OP_MODE_PROGRAM		3
+#define CNFG_AUTO_FMT_EN		BIT(9)
+#define CNFG_HW_ECC_EN			BIT(8)
+#define CNFG_DMA_BURST_EN		BIT(2)
+#define CNFG_READ_MODE			BIT(1)
+#define CNFG_DMA_MODE			BIT(0)
+
+#define NFI_PAGEFMT			0x0004
+#define NFI_SPARE_SIZE_LS_S		16
+#define NFI_FDM_ECC_NUM_S		12
+#define NFI_FDM_NUM_S			8
+#define NFI_SPARE_SIZE_S		4
+#define NFI_SEC_SEL_512			BIT(2)
+#define NFI_PAGE_SIZE_S			0
+#define   NFI_PAGE_SIZE_512_2K		0
+#define   NFI_PAGE_SIZE_2K_4K		1
+#define   NFI_PAGE_SIZE_4K_8K		2
+#define   NFI_PAGE_SIZE_8K_16K		3
+
+#define NFI_CON				0x008
+#define CON_SEC_NUM_S			12
+#define CON_BWR				BIT(9)
+#define CON_BRD				BIT(8)
+#define CON_NFI_RST			BIT(1)
+#define CON_FIFO_FLUSH			BIT(0)
+
+#define NFI_INTR_EN			0x010
+#define NFI_INTR_STA			0x014
+#define NFI_IRQ_INTR_EN			BIT(31)
+#define NFI_IRQ_CUS_READ		BIT(8)
+#define NFI_IRQ_CUS_PG			BIT(7)
+
+#define NFI_CMD				0x020
+
+#define NFI_STRDATA			0x040
+#define STR_DATA			BIT(0)
+
+#define NFI_STA				0x060
+#define NFI_NAND_FSM			GENMASK(28, 24)
+#define NFI_FSM				GENMASK(19, 16)
+#define READ_EMPTY			BIT(12)
+
+#define NFI_FIFOSTA			0x064
+#define FIFO_WR_REMAIN_S		8
+#define FIFO_RD_REMAIN_S		0
+
+#define NFI_STRADDR			0x080
+
+#define NFI_FDM0L			0x0a0
+#define NFI_FDM0M			0x0a4
+#define NFI_FDML(n)			(NFI_FDM0L + (n) * 8)
+#define NFI_FDMM(n)			(NFI_FDM0M + (n) * 8)
+
+#define NFI_DEBUG_CON1			0x220
+#define WBUF_EN				BIT(2)
+
+#define NFI_MASTERSTA			0x224
+#define MAS_ADDR			GENMASK(11, 9)
+#define MAS_RD				GENMASK(8, 6)
+#define MAS_WR				GENMASK(5, 3)
+#define MAS_RDDLY			GENMASK(2, 0)
+#define NFI_MASTERSTA_MASK_7622		(MAS_ADDR | MAS_RD | MAS_WR | MAS_RDDLY)
+#define AHB_BUS_BUSY			BIT(1)
+#define BUS_BUSY			BIT(0)
+#define NFI_MASTERSTA_MASK_7986		(AHB_BUS_BUSY | BUS_BUSY)
+
+/* SNFI registers */
+#define SNF_MAC_CTL			0x500
+#define MAC_XIO_SEL			BIT(4)
+#define SF_MAC_EN			BIT(3)
+#define SF_TRIG				BIT(2)
+#define WIP_READY			BIT(1)
+#define WIP				BIT(0)
+
+#define SNF_MAC_OUTL			0x504
+#define SNF_MAC_INL			0x508
+
+#define SNF_RD_CTL2			0x510
+#define DATA_READ_DUMMY_S		8
+#define DATA_READ_CMD_S			0
+
+#define SNF_RD_CTL3			0x514
+
+#define SNF_PG_CTL1			0x524
+#define PG_LOAD_CMD_S			8
+
+#define SNF_PG_CTL2			0x528
+
+#define SNF_MISC_CTL			0x538
+#define SW_RST				BIT(28)
+#define FIFO_RD_LTC_S			25
+#define PG_LOAD_X4_EN			BIT(20)
+#define DATA_READ_MODE_S		16
+#define DATA_READ_MODE			GENMASK(18, 16)
+#define   DATA_READ_MODE_X1		0
+#define   DATA_READ_MODE_X2		1
+#define   DATA_READ_MODE_X4		2
+#define   DATA_READ_MODE_DUAL		5
+#define   DATA_READ_MODE_QUAD		6
+#define PG_LOAD_CUSTOM_EN		BIT(7)
+#define DATARD_CUSTOM_EN		BIT(6)
+#define CS_DESELECT_CYC_S		0
+
+#define SNF_MISC_CTL2			0x53c
+#define PROGRAM_LOAD_BYTE_NUM_S		16
+#define READ_DATA_BYTE_NUM_S		11
+
+#define SNF_DLY_CTL3			0x548
+#define SFCK_SAM_DLY_S			0
+
+#define SNF_STA_CTL1			0x550
+#define CUS_PG_DONE			BIT(28)
+#define CUS_READ_DONE			BIT(27)
+#define SPI_STATE_S			0
+#define SPI_STATE			GENMASK(3, 0)
+
+#define SNF_CFG				0x55c
+#define SPI_MODE			BIT(0)
+
+#define SNF_GPRAM			0x800
+#define SNF_GPRAM_SIZE			0xa0
+
+#define SNFI_POLL_INTERVAL		1000000
+
+static const uint8_t mt7622_spare_sizes[] = { 16, 26, 27, 28 };
+
+static const uint8_t mt7986_spare_sizes[] = {
+	16, 26, 27, 28, 32, 36, 40, 44, 48, 49, 50, 51, 52, 62, 61, 63, 64,
+	67, 74
+};
+
+static const struct mtk_snand_soc_data mtk_snand_socs[__SNAND_SOC_MAX] = {
+	[SNAND_SOC_MT7622] = {
+		.sector_size = 512,
+		.max_sectors = 8,
+		.fdm_size = 8,
+		.fdm_ecc_size = 1,
+		.fifo_size = 32,
+		.bbm_swap = false,
+		.empty_page_check = false,
+		.mastersta_mask = NFI_MASTERSTA_MASK_7622,
+		.spare_sizes = mt7622_spare_sizes,
+		.num_spare_size = ARRAY_SIZE(mt7622_spare_sizes)
+	},
+	[SNAND_SOC_MT7629] = {
+		.sector_size = 512,
+		.max_sectors = 8,
+		.fdm_size = 8,
+		.fdm_ecc_size = 1,
+		.fifo_size = 32,
+		.bbm_swap = true,
+		.empty_page_check = false,
+		.mastersta_mask = NFI_MASTERSTA_MASK_7622,
+		.spare_sizes = mt7622_spare_sizes,
+		.num_spare_size = ARRAY_SIZE(mt7622_spare_sizes)
+	},
+	[SNAND_SOC_MT7986] = {
+		.sector_size = 1024,
+		.max_sectors = 16,
+		.fdm_size = 8,
+		.fdm_ecc_size = 1,
+		.fifo_size = 64,
+		.bbm_swap = true,
+		.empty_page_check = true,
+		.mastersta_mask = NFI_MASTERSTA_MASK_7986,
+		.spare_sizes = mt7986_spare_sizes,
+		.num_spare_size = ARRAY_SIZE(mt7986_spare_sizes)
+	},
+};
+
+static inline uint32_t nfi_read32(struct mtk_snand *snf, uint32_t reg)
+{
+	return readl(snf->nfi_base + reg);
+}
+
+static inline void nfi_write32(struct mtk_snand *snf, uint32_t reg,
+			       uint32_t val)
+{
+	writel(val, snf->nfi_base + reg);
+}
+
+static inline void nfi_write16(struct mtk_snand *snf, uint32_t reg,
+			       uint16_t val)
+{
+	writew(val, snf->nfi_base + reg);
+}
+
+static inline void nfi_rmw32(struct mtk_snand *snf, uint32_t reg, uint32_t clr,
+			     uint32_t set)
+{
+	uint32_t val;
+
+	val = readl(snf->nfi_base + reg);
+	val &= ~clr;
+	val |= set;
+	writel(val, snf->nfi_base + reg);
+}
+
+static void nfi_write_data(struct mtk_snand *snf, uint32_t reg,
+			   const uint8_t *data, uint32_t len)
+{
+	uint32_t i, val = 0, es = sizeof(uint32_t);
+
+	for (i = reg; i < reg + len; i++) {
+		val |= ((uint32_t)*data++) << (8 * (i % es));
+
+		if (i % es == es - 1 || i == reg + len - 1) {
+			nfi_write32(snf, i & ~(es - 1), val);
+			val = 0;
+		}
+	}
+}
+
+static void nfi_read_data(struct mtk_snand *snf, uint32_t reg, uint8_t *data,
+			  uint32_t len)
+{
+	uint32_t i, val = 0, es = sizeof(uint32_t);
+
+	for (i = reg; i < reg + len; i++) {
+		if (i == reg || i % es == 0)
+			val = nfi_read32(snf, i & ~(es - 1));
+
+		*data++ = (uint8_t)(val >> (8 * (i % es)));
+	}
+}
+
+static inline void do_bm_swap(uint8_t *bm1, uint8_t *bm2)
+{
+	uint8_t tmp = *bm1;
+	*bm1 = *bm2;
+	*bm2 = tmp;
+}
+
+static void mtk_snand_bm_swap_raw(struct mtk_snand *snf)
+{
+	uint32_t fdm_bbm_pos;
+
+	if (!snf->nfi_soc->bbm_swap || snf->ecc_steps == 1)
+		return;
+
+	fdm_bbm_pos = (snf->ecc_steps - 1) * snf->raw_sector_size +
+		      snf->nfi_soc->sector_size;
+	do_bm_swap(&snf->page_cache[fdm_bbm_pos],
+		   &snf->page_cache[snf->writesize]);
+}
+
+static void mtk_snand_bm_swap(struct mtk_snand *snf)
+{
+	uint32_t buf_bbm_pos, fdm_bbm_pos;
+
+	if (!snf->nfi_soc->bbm_swap || snf->ecc_steps == 1)
+		return;
+
+	buf_bbm_pos = snf->writesize -
+		      (snf->ecc_steps - 1) * snf->spare_per_sector;
+	fdm_bbm_pos = snf->writesize +
+		      (snf->ecc_steps - 1) * snf->nfi_soc->fdm_size;
+	do_bm_swap(&snf->page_cache[fdm_bbm_pos],
+		   &snf->page_cache[buf_bbm_pos]);
+}
+
+static void mtk_snand_fdm_bm_swap_raw(struct mtk_snand *snf)
+{
+	uint32_t fdm_bbm_pos1, fdm_bbm_pos2;
+
+	if (!snf->nfi_soc->bbm_swap || snf->ecc_steps == 1)
+		return;
+
+	fdm_bbm_pos1 = snf->nfi_soc->sector_size;
+	fdm_bbm_pos2 = (snf->ecc_steps - 1) * snf->raw_sector_size +
+		       snf->nfi_soc->sector_size;
+	do_bm_swap(&snf->page_cache[fdm_bbm_pos1],
+		   &snf->page_cache[fdm_bbm_pos2]);
+}
+
+static void mtk_snand_fdm_bm_swap(struct mtk_snand *snf)
+{
+	uint32_t fdm_bbm_pos1, fdm_bbm_pos2;
+
+	if (!snf->nfi_soc->bbm_swap || snf->ecc_steps == 1)
+		return;
+
+	fdm_bbm_pos1 = snf->writesize;
+	fdm_bbm_pos2 = snf->writesize +
+		       (snf->ecc_steps - 1) * snf->nfi_soc->fdm_size;
+	do_bm_swap(&snf->page_cache[fdm_bbm_pos1],
+		   &snf->page_cache[fdm_bbm_pos2]);
+}
+
+static int mtk_nfi_reset(struct mtk_snand *snf)
+{
+	uint32_t val, fifo_mask;
+	int ret;
+
+	nfi_write32(snf, NFI_CON, CON_FIFO_FLUSH | CON_NFI_RST);
+
+	ret = read16_poll_timeout(snf->nfi_base + NFI_MASTERSTA, val,
+				  !(val & snf->nfi_soc->mastersta_mask), 0,
+				  SNFI_POLL_INTERVAL);
+	if (ret) {
+		snand_log_nfi(snf->pdev,
+			      "NFI master is still busy after reset\n");
+		return ret;
+	}
+
+	ret = read32_poll_timeout(snf->nfi_base + NFI_STA, val,
+				  !(val & (NFI_FSM | NFI_NAND_FSM)), 0,
+				  SNFI_POLL_INTERVAL);
+	if (ret) {
+		snand_log_nfi(snf->pdev, "Failed to reset NFI\n");
+		return ret;
+	}
+
+	fifo_mask = ((snf->nfi_soc->fifo_size - 1) << FIFO_RD_REMAIN_S) |
+		    ((snf->nfi_soc->fifo_size - 1) << FIFO_WR_REMAIN_S);
+	ret = read16_poll_timeout(snf->nfi_base + NFI_FIFOSTA, val,
+				  !(val & fifo_mask), 0, SNFI_POLL_INTERVAL);
+	if (ret) {
+		snand_log_nfi(snf->pdev, "NFI FIFOs are not empty\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+static int mtk_snand_mac_reset(struct mtk_snand *snf)
+{
+	int ret;
+	uint32_t val;
+
+	nfi_rmw32(snf, SNF_MISC_CTL, 0, SW_RST);
+
+	ret = read32_poll_timeout(snf->nfi_base + SNF_STA_CTL1, val,
+				  !(val & SPI_STATE), 0, SNFI_POLL_INTERVAL);
+	if (ret)
+		snand_log_snfi(snf->pdev, "Failed to reset SNFI MAC\n");
+
+	nfi_write32(snf, SNF_MISC_CTL, (2 << FIFO_RD_LTC_S) |
+		    (10 << CS_DESELECT_CYC_S));
+
+	return ret;
+}
+
+static int mtk_snand_mac_trigger(struct mtk_snand *snf, uint32_t outlen,
+				 uint32_t inlen)
+{
+	int ret;
+	uint32_t val;
+
+	nfi_write32(snf, SNF_MAC_CTL, SF_MAC_EN);
+	nfi_write32(snf, SNF_MAC_OUTL, outlen);
+	nfi_write32(snf, SNF_MAC_INL, inlen);
+
+	nfi_write32(snf, SNF_MAC_CTL, SF_MAC_EN | SF_TRIG);
+
+	ret = read32_poll_timeout(snf->nfi_base + SNF_MAC_CTL, val,
+				  val & WIP_READY, 0, SNFI_POLL_INTERVAL);
+	if (ret) {
+		snand_log_snfi(snf->pdev, "Timed out waiting for WIP_READY\n");
+		goto cleanup;
+	}
+
+	ret = read32_poll_timeout(snf->nfi_base + SNF_MAC_CTL, val,
+				  !(val & WIP), 0, SNFI_POLL_INTERVAL);
+	if (ret) {
+		snand_log_snfi(snf->pdev,
+			       "Timed out waiting for WIP cleared\n");
+	}
+
+cleanup:
+	nfi_write32(snf, SNF_MAC_CTL, 0);
+
+	return ret;
+}
+
+int mtk_snand_mac_io(struct mtk_snand *snf, const uint8_t *out, uint32_t outlen,
+		     uint8_t *in, uint32_t inlen)
+{
+	int ret;
+
+	if (outlen + inlen > SNF_GPRAM_SIZE)
+		return -EINVAL;
+
+	mtk_snand_mac_reset(snf);
+
+	nfi_write_data(snf, SNF_GPRAM, out, outlen);
+
+	ret = mtk_snand_mac_trigger(snf, outlen, inlen);
+	if (ret)
+		return ret;
+
+	if (!inlen)
+		return 0;
+
+	nfi_read_data(snf, SNF_GPRAM + outlen, in, inlen);
+
+	return 0;
+}
+
+static int mtk_snand_get_feature(struct mtk_snand *snf, uint32_t addr)
+{
+	uint8_t op[2], val;
+	int ret;
+
+	op[0] = SNAND_CMD_GET_FEATURE;
+	op[1] = (uint8_t)addr;
+
+	ret = mtk_snand_mac_io(snf, op, sizeof(op), &val, 1);
+	if (ret)
+		return ret;
+
+	return val;
+}
+
+int mtk_snand_set_feature(struct mtk_snand *snf, uint32_t addr, uint32_t val)
+{
+	uint8_t op[3];
+
+	op[0] = SNAND_CMD_SET_FEATURE;
+	op[1] = (uint8_t)addr;
+	op[2] = (uint8_t)val;
+
+	return mtk_snand_mac_io(snf, op, sizeof(op), NULL, 0);
+}
+
+static int mtk_snand_poll_status(struct mtk_snand *snf, uint32_t wait_us)
+{
+	int val;
+	mtk_snand_time_t time_start, tmo;
+
+	time_start = timer_get_ticks();
+	tmo = timer_time_to_tick(wait_us);
+
+	do {
+		val = mtk_snand_get_feature(snf, SNAND_FEATURE_STATUS_ADDR);
+		if (!(val & SNAND_STATUS_OIP))
+			return val & (SNAND_STATUS_ERASE_FAIL |
+				      SNAND_STATUS_PROGRAM_FAIL);
+	} while (!timer_is_timeout(time_start, tmo));
+
+	return -ETIMEDOUT;
+}
+
+int mtk_snand_chip_reset(struct mtk_snand *snf)
+{
+	uint8_t op = SNAND_CMD_RESET;
+	int ret;
+
+	ret = mtk_snand_mac_io(snf, &op, 1, NULL, 0);
+	if (ret)
+		return ret;
+
+	ret = mtk_snand_poll_status(snf, SNFI_POLL_INTERVAL);
+	if (ret < 0)
+		return ret;
+
+	return 0;
+}
+
+static int mtk_snand_config_feature(struct mtk_snand *snf, uint8_t clr,
+				    uint8_t set)
+{
+	int val, newval;
+	int ret;
+
+	val = mtk_snand_get_feature(snf, SNAND_FEATURE_CONFIG_ADDR);
+	if (val < 0) {
+		snand_log_chip(snf->pdev,
+			       "Failed to get configuration feature\n");
+		return val;
+	}
+
+	newval = (val & (~clr)) | set;
+
+	if (newval == val)
+		return 0;
+
+	ret = mtk_snand_set_feature(snf, SNAND_FEATURE_CONFIG_ADDR,
+				    (uint8_t)newval);
+	if (val < 0) {
+		snand_log_chip(snf->pdev,
+			       "Failed to set configuration feature\n");
+		return ret;
+	}
+
+	val = mtk_snand_get_feature(snf, SNAND_FEATURE_CONFIG_ADDR);
+	if (val < 0) {
+		snand_log_chip(snf->pdev,
+			       "Failed to get configuration feature\n");
+		return val;
+	}
+
+	if (newval != val)
+		return -ENOTSUPP;
+
+	return 0;
+}
+
+static int mtk_snand_ondie_ecc_control(struct mtk_snand *snf, bool enable)
+{
+	int ret;
+
+	if (enable)
+		ret = mtk_snand_config_feature(snf, 0, SNAND_FEATURE_ECC_EN);
+	else
+		ret = mtk_snand_config_feature(snf, SNAND_FEATURE_ECC_EN, 0);
+
+	if (ret) {
+		snand_log_chip(snf->pdev, "Failed to %s On-Die ECC engine\n",
+			       enable ? "enable" : "disable");
+	}
+
+	return ret;
+}
+
+static int mtk_snand_qspi_control(struct mtk_snand *snf, bool enable)
+{
+	int ret;
+
+	if (enable) {
+		ret = mtk_snand_config_feature(snf, 0,
+					       SNAND_FEATURE_QUAD_ENABLE);
+	} else {
+		ret = mtk_snand_config_feature(snf,
+					       SNAND_FEATURE_QUAD_ENABLE, 0);
+	}
+
+	if (ret) {
+		snand_log_chip(snf->pdev, "Failed to %s quad spi\n",
+			       enable ? "enable" : "disable");
+	}
+
+	return ret;
+}
+
+static int mtk_snand_unlock(struct mtk_snand *snf)
+{
+	int ret;
+
+	ret = mtk_snand_set_feature(snf, SNAND_FEATURE_PROTECT_ADDR, 0);
+	if (ret) {
+		snand_log_chip(snf->pdev, "Failed to set protection feature\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+static int mtk_snand_write_enable(struct mtk_snand *snf)
+{
+	uint8_t op = SNAND_CMD_WRITE_ENABLE;
+	int ret, val;
+
+	ret = mtk_snand_mac_io(snf, &op, 1, NULL, 0);
+	if (ret)
+		return ret;
+
+	val = mtk_snand_get_feature(snf, SNAND_FEATURE_STATUS_ADDR);
+	if (val < 0)
+		return ret;
+
+	if (val & SNAND_STATUS_WEL)
+		return 0;
+
+	snand_log_chip(snf->pdev, "Failed to send write-enable command\n");
+
+	return -ENOTSUPP;
+}
+
+static int mtk_snand_select_die(struct mtk_snand *snf, uint32_t dieidx)
+{
+	if (!snf->select_die)
+		return 0;
+
+	return snf->select_die(snf, dieidx);
+}
+
+static uint64_t mtk_snand_select_die_address(struct mtk_snand *snf,
+					     uint64_t addr)
+{
+	uint32_t dieidx;
+
+	if (!snf->select_die)
+		return addr;
+
+	dieidx = addr >> snf->die_shift;
+
+	mtk_snand_select_die(snf, dieidx);
+
+	return addr & snf->die_mask;
+}
+
+static uint32_t mtk_snand_get_plane_address(struct mtk_snand *snf,
+					    uint32_t page)
+{
+	uint32_t pages_per_block;
+
+	pages_per_block = 1 << (snf->erasesize_shift - snf->writesize_shift);
+
+	if (page & pages_per_block)
+		return 1 << (snf->writesize_shift + 1);
+
+	return 0;
+}
+
+static int mtk_snand_page_op(struct mtk_snand *snf, uint32_t page, uint8_t cmd)
+{
+	uint8_t op[4];
+
+	op[0] = cmd;
+	op[1] = (page >> 16) & 0xff;
+	op[2] = (page >> 8) & 0xff;
+	op[3] = page & 0xff;
+
+	return mtk_snand_mac_io(snf, op, sizeof(op), NULL, 0);
+}
+
+static void mtk_snand_read_fdm(struct mtk_snand *snf, uint8_t *buf)
+{
+	uint32_t vall, valm;
+	uint8_t *oobptr = buf;
+	int i, j;
+
+	for (i = 0; i < snf->ecc_steps; i++) {
+		vall = nfi_read32(snf, NFI_FDML(i));
+		valm = nfi_read32(snf, NFI_FDMM(i));
+
+		for (j = 0; j < snf->nfi_soc->fdm_size; j++)
+			oobptr[j] = (j >= 4 ? valm : vall) >> ((j % 4) * 8);
+
+		oobptr += snf->nfi_soc->fdm_size;
+	}
+}
+
+static int mtk_snand_read_cache(struct mtk_snand *snf, uint32_t page, bool raw)
+{
+	uint32_t coladdr, rwbytes, mode, len;
+	uintptr_t dma_addr;
+	int ret;
+
+	/* Column address with plane bit */
+	coladdr = mtk_snand_get_plane_address(snf, page);
+
+	mtk_snand_mac_reset(snf);
+	mtk_nfi_reset(snf);
+
+	/* Command and dummy cycles */
+	nfi_write32(snf, SNF_RD_CTL2,
+		    ((uint32_t)snf->dummy_rfc << DATA_READ_DUMMY_S) |
+		    (snf->opcode_rfc << DATA_READ_CMD_S));
+
+	/* Column address */
+	nfi_write32(snf, SNF_RD_CTL3, coladdr);
+
+	/* Set read mode */
+	mode = (uint32_t)snf->mode_rfc << DATA_READ_MODE_S;
+	nfi_rmw32(snf, SNF_MISC_CTL, DATA_READ_MODE, mode | DATARD_CUSTOM_EN);
+
+	/* Set bytes to read */
+	rwbytes = snf->ecc_steps * snf->raw_sector_size;
+	nfi_write32(snf, SNF_MISC_CTL2, (rwbytes << PROGRAM_LOAD_BYTE_NUM_S) |
+		    rwbytes);
+
+	/* NFI read prepare */
+	mode = raw ? 0 : CNFG_HW_ECC_EN | CNFG_AUTO_FMT_EN;
+	nfi_write16(snf, NFI_CNFG, (CNFG_OP_MODE_CUST << CNFG_OP_MODE_S) |
+		    CNFG_DMA_BURST_EN | CNFG_READ_MODE | CNFG_DMA_MODE | mode);
+
+	nfi_write32(snf, NFI_CON, (snf->ecc_steps << CON_SEC_NUM_S));
+
+	/* Prepare for DMA read */
+	len = snf->writesize + snf->oobsize;
+	ret = dma_mem_map(snf->pdev, snf->page_cache, &dma_addr, len, false);
+	if (ret) {
+		snand_log_nfi(snf->pdev,
+			      "DMA map from device failed with %d\n", ret);
+		return ret;
+	}
+
+	nfi_write32(snf, NFI_STRADDR, (uint32_t)dma_addr);
+
+	if (!raw)
+		mtk_snand_ecc_decoder_start(snf);
+
+	/* Prepare for custom read interrupt */
+	nfi_write32(snf, NFI_INTR_EN, NFI_IRQ_INTR_EN | NFI_IRQ_CUS_READ);
+	irq_completion_init(snf->pdev);
+
+	/* Trigger NFI into custom mode */
+	nfi_write16(snf, NFI_CMD, NFI_CMD_DUMMY_READ);
+
+	/* Start DMA read */
+	nfi_rmw32(snf, NFI_CON, 0, CON_BRD);
+	nfi_write16(snf, NFI_STRDATA, STR_DATA);
+
+	/* Wait for operation finished */
+	ret = irq_completion_wait(snf->pdev, snf->nfi_base + SNF_STA_CTL1,
+				  CUS_READ_DONE, SNFI_POLL_INTERVAL);
+	if (ret) {
+		snand_log_nfi(snf->pdev,
+			      "DMA timed out for reading from cache\n");
+		goto cleanup;
+	}
+
+	if (!raw) {
+		ret = mtk_ecc_wait_decoder_done(snf);
+		if (ret)
+			goto cleanup;
+
+		mtk_snand_read_fdm(snf, snf->page_cache + snf->writesize);
+
+		/*
+		 * For new IPs, ecc error may occur on empty pages.
+		 * Use an specific indication bit to check empty page.
+		 */
+		if (snf->nfi_soc->empty_page_check &&
+		    (nfi_read32(snf, NFI_STA) & READ_EMPTY))
+			ret = 0;
+		else
+			ret = mtk_ecc_check_decode_error(snf, page);
+
+		mtk_snand_ecc_decoder_stop(snf);
+	}
+
+cleanup:
+	/* DMA cleanup */
+	dma_mem_unmap(snf->pdev, dma_addr, len, false);
+
+	/* Stop read */
+	nfi_write32(snf, NFI_CON, 0);
+
+	/* Clear SNF done flag */
+	nfi_rmw32(snf, SNF_STA_CTL1, 0, CUS_READ_DONE);
+	nfi_write32(snf, SNF_STA_CTL1, 0);
+
+	/* Disable interrupt */
+	nfi_read32(snf, NFI_INTR_STA);
+	nfi_write32(snf, NFI_INTR_EN, 0);
+
+	nfi_rmw32(snf, SNF_MISC_CTL, DATARD_CUSTOM_EN, 0);
+
+	return ret;
+}
+
+static void mtk_snand_from_raw_page(struct mtk_snand *snf, void *buf, void *oob)
+{
+	uint32_t i, ecc_bytes = snf->spare_per_sector - snf->nfi_soc->fdm_size;
+	uint8_t *eccptr = oob + snf->ecc_steps * snf->nfi_soc->fdm_size;
+	uint8_t *bufptr = buf, *oobptr = oob, *raw_sector;
+
+	for (i = 0; i < snf->ecc_steps; i++) {
+		raw_sector = snf->page_cache + i * snf->raw_sector_size;
+
+		if (buf) {
+			memcpy(bufptr, raw_sector, snf->nfi_soc->sector_size);
+			bufptr += snf->nfi_soc->sector_size;
+		}
+
+		raw_sector += snf->nfi_soc->sector_size;
+
+		if (oob) {
+			memcpy(oobptr, raw_sector, snf->nfi_soc->fdm_size);
+			oobptr += snf->nfi_soc->fdm_size;
+			raw_sector += snf->nfi_soc->fdm_size;
+
+			memcpy(eccptr, raw_sector, ecc_bytes);
+			eccptr += ecc_bytes;
+		}
+	}
+}
+
+static int mtk_snand_do_read_page(struct mtk_snand *snf, uint64_t addr,
+				  void *buf, void *oob, bool raw, bool format)
+{
+	uint64_t die_addr;
+	uint32_t page;
+	int ret;
+
+	die_addr = mtk_snand_select_die_address(snf, addr);
+	page = die_addr >> snf->writesize_shift;
+
+	ret = mtk_snand_page_op(snf, page, SNAND_CMD_READ_TO_CACHE);
+	if (ret)
+		return ret;
+
+	ret = mtk_snand_poll_status(snf, SNFI_POLL_INTERVAL);
+	if (ret < 0) {
+		snand_log_chip(snf->pdev, "Read to cache command timed out\n");
+		return ret;
+	}
+
+	ret = mtk_snand_read_cache(snf, page, raw);
+	if (ret < 0 && ret != -EBADMSG)
+		return ret;
+
+	if (raw) {
+		if (format) {
+			mtk_snand_bm_swap_raw(snf);
+			mtk_snand_fdm_bm_swap_raw(snf);
+			mtk_snand_from_raw_page(snf, buf, oob);
+		} else {
+			if (buf)
+				memcpy(buf, snf->page_cache, snf->writesize);
+
+			if (oob) {
+				memset(oob, 0xff, snf->oobsize);
+				memcpy(oob, snf->page_cache + snf->writesize,
+				       snf->ecc_steps * snf->spare_per_sector);
+			}
+		}
+	} else {
+		mtk_snand_bm_swap(snf);
+		mtk_snand_fdm_bm_swap(snf);
+
+		if (buf)
+			memcpy(buf, snf->page_cache, snf->writesize);
+
+		if (oob) {
+			memset(oob, 0xff, snf->oobsize);
+			memcpy(oob, snf->page_cache + snf->writesize,
+			       snf->ecc_steps * snf->nfi_soc->fdm_size);
+		}
+	}
+
+	return ret;
+}
+
+int mtk_snand_read_page(struct mtk_snand *snf, uint64_t addr, void *buf,
+			void *oob, bool raw)
+{
+	if (!snf || (!buf && !oob))
+		return -EINVAL;
+
+	if (addr >= snf->size)
+		return -EINVAL;
+
+	return mtk_snand_do_read_page(snf, addr, buf, oob, raw, true);
+}
+
+static void mtk_snand_write_fdm(struct mtk_snand *snf, const uint8_t *buf)
+{
+	uint32_t vall, valm, fdm_size = snf->nfi_soc->fdm_size;
+	const uint8_t *oobptr = buf;
+	int i, j;
+
+	for (i = 0; i < snf->ecc_steps; i++) {
+		vall = 0;
+		valm = 0;
+
+		for (j = 0; j < 8; j++) {
+			if (j < 4)
+				vall |= (j < fdm_size ? oobptr[j] : 0xff)
+						<< (j * 8);
+			else
+				valm |= (j < fdm_size ? oobptr[j] : 0xff)
+						<< ((j - 4) * 8);
+		}
+
+		nfi_write32(snf, NFI_FDML(i), vall);
+		nfi_write32(snf, NFI_FDMM(i), valm);
+
+		oobptr += fdm_size;
+	}
+}
+
+static int mtk_snand_program_load(struct mtk_snand *snf, uint32_t page,
+				  bool raw)
+{
+	uint32_t coladdr, rwbytes, mode, len;
+	uintptr_t dma_addr;
+	int ret;
+
+	/* Column address with plane bit */
+	coladdr = mtk_snand_get_plane_address(snf, page);
+
+	mtk_snand_mac_reset(snf);
+	mtk_nfi_reset(snf);
+
+	/* Write FDM registers if necessary */
+	if (!raw)
+		mtk_snand_write_fdm(snf, snf->page_cache + snf->writesize);
+
+	/* Command */
+	nfi_write32(snf, SNF_PG_CTL1, (snf->opcode_pl << PG_LOAD_CMD_S));
+
+	/* Column address */
+	nfi_write32(snf, SNF_PG_CTL2, coladdr);
+
+	/* Set write mode */
+	mode = snf->mode_pl ? PG_LOAD_X4_EN : 0;
+	nfi_rmw32(snf, SNF_MISC_CTL, PG_LOAD_X4_EN, mode | PG_LOAD_CUSTOM_EN);
+
+	/* Set bytes to write */
+	rwbytes = snf->ecc_steps * snf->raw_sector_size;
+	nfi_write32(snf, SNF_MISC_CTL2, (rwbytes << PROGRAM_LOAD_BYTE_NUM_S) |
+		    rwbytes);
+
+	/* NFI write prepare */
+	mode = raw ? 0 : CNFG_HW_ECC_EN | CNFG_AUTO_FMT_EN;
+	nfi_write16(snf, NFI_CNFG, (CNFG_OP_MODE_PROGRAM << CNFG_OP_MODE_S) |
+		    CNFG_DMA_BURST_EN | CNFG_DMA_MODE | mode);
+
+	nfi_write32(snf, NFI_CON, (snf->ecc_steps << CON_SEC_NUM_S));
+
+	/* Prepare for DMA write */
+	len = snf->writesize + snf->oobsize;
+	ret = dma_mem_map(snf->pdev, snf->page_cache, &dma_addr, len, true);
+	if (ret) {
+		snand_log_nfi(snf->pdev,
+			      "DMA map to device failed with %d\n", ret);
+		return ret;
+	}
+
+	nfi_write32(snf, NFI_STRADDR, (uint32_t)dma_addr);
+
+	if (!raw)
+		mtk_snand_ecc_encoder_start(snf);
+
+	/* Prepare for custom write interrupt */
+	nfi_write32(snf, NFI_INTR_EN, NFI_IRQ_INTR_EN | NFI_IRQ_CUS_PG);
+	irq_completion_init(snf->pdev);
+
+	/* Trigger NFI into custom mode */
+	nfi_write16(snf, NFI_CMD, NFI_CMD_DUMMY_WRITE);
+
+	/* Start DMA write */
+	nfi_rmw32(snf, NFI_CON, 0, CON_BWR);
+	nfi_write16(snf, NFI_STRDATA, STR_DATA);
+
+	/* Wait for operation finished */
+	ret = irq_completion_wait(snf->pdev, snf->nfi_base + SNF_STA_CTL1,
+				  CUS_PG_DONE, SNFI_POLL_INTERVAL);
+	if (ret) {
+		snand_log_nfi(snf->pdev,
+			      "DMA timed out for program load\n");
+		goto cleanup;
+	}
+
+	if (!raw)
+		mtk_snand_ecc_encoder_stop(snf);
+
+cleanup:
+	/* DMA cleanup */
+	dma_mem_unmap(snf->pdev, dma_addr, len, true);
+
+	/* Stop write */
+	nfi_write16(snf, NFI_CON, 0);
+
+	/* Clear SNF done flag */
+	nfi_rmw32(snf, SNF_STA_CTL1, 0, CUS_PG_DONE);
+	nfi_write32(snf, SNF_STA_CTL1, 0);
+
+	/* Disable interrupt */
+	nfi_read32(snf, NFI_INTR_STA);
+	nfi_write32(snf, NFI_INTR_EN, 0);
+
+	nfi_rmw32(snf, SNF_MISC_CTL, PG_LOAD_CUSTOM_EN, 0);
+
+	return ret;
+}
+
+static void mtk_snand_to_raw_page(struct mtk_snand *snf,
+				  const void *buf, const void *oob,
+				  bool empty_ecc)
+{
+	uint32_t i, ecc_bytes = snf->spare_per_sector - snf->nfi_soc->fdm_size;
+	const uint8_t *eccptr = oob + snf->ecc_steps * snf->nfi_soc->fdm_size;
+	const uint8_t *bufptr = buf, *oobptr = oob;
+	uint8_t *raw_sector;
+
+	memset(snf->page_cache, 0xff, snf->writesize + snf->oobsize);
+	for (i = 0; i < snf->ecc_steps; i++) {
+		raw_sector = snf->page_cache + i * snf->raw_sector_size;
+
+		if (buf) {
+			memcpy(raw_sector, bufptr, snf->nfi_soc->sector_size);
+			bufptr += snf->nfi_soc->sector_size;
+		}
+
+		raw_sector += snf->nfi_soc->sector_size;
+
+		if (oob) {
+			memcpy(raw_sector, oobptr, snf->nfi_soc->fdm_size);
+			oobptr += snf->nfi_soc->fdm_size;
+			raw_sector += snf->nfi_soc->fdm_size;
+
+			if (empty_ecc)
+				memset(raw_sector, 0xff, ecc_bytes);
+			else
+				memcpy(raw_sector, eccptr, ecc_bytes);
+			eccptr += ecc_bytes;
+		}
+	}
+}
+
+static bool mtk_snand_is_empty_page(struct mtk_snand *snf, const void *buf,
+				    const void *oob)
+{
+	const uint8_t *p = buf;
+	uint32_t i, j;
+
+	if (buf) {
+		for (i = 0; i < snf->writesize; i++) {
+			if (p[i] != 0xff)
+				return false;
+		}
+	}
+
+	if (oob) {
+		for (j = 0; j < snf->ecc_steps; j++) {
+			p = oob + j * snf->nfi_soc->fdm_size;
+
+			for (i = 0; i < snf->nfi_soc->fdm_ecc_size; i++) {
+				if (p[i] != 0xff)
+					return false;
+			}
+		}
+	}
+
+	return true;
+}
+
+static int mtk_snand_do_write_page(struct mtk_snand *snf, uint64_t addr,
+				   const void *buf, const void *oob,
+				   bool raw, bool format)
+{
+	uint64_t die_addr;
+	bool empty_ecc = false;
+	uint32_t page;
+	int ret;
+
+	die_addr = mtk_snand_select_die_address(snf, addr);
+	page = die_addr >> snf->writesize_shift;
+
+	if (!raw && mtk_snand_is_empty_page(snf, buf, oob)) {
+		/*
+		 * If the data in the page to be ecc-ed is full 0xff,
+		 * change to raw write mode
+		 */
+		raw = true;
+		format = true;
+
+		/* fill ecc parity code region with 0xff */
+		empty_ecc = true;
+	}
+
+	if (raw) {
+		if (format) {
+			mtk_snand_to_raw_page(snf, buf, oob, empty_ecc);
+			mtk_snand_fdm_bm_swap_raw(snf);
+			mtk_snand_bm_swap_raw(snf);
+		} else {
+			memset(snf->page_cache, 0xff,
+			       snf->writesize + snf->oobsize);
+
+			if (buf)
+				memcpy(snf->page_cache, buf, snf->writesize);
+
+			if (oob) {
+				memcpy(snf->page_cache + snf->writesize, oob,
+				       snf->ecc_steps * snf->spare_per_sector);
+			}
+		}
+	} else {
+		memset(snf->page_cache, 0xff, snf->writesize + snf->oobsize);
+		if (buf)
+			memcpy(snf->page_cache, buf, snf->writesize);
+
+		if (oob) {
+			memcpy(snf->page_cache + snf->writesize, oob,
+			       snf->ecc_steps * snf->nfi_soc->fdm_size);
+		}
+
+		mtk_snand_fdm_bm_swap(snf);
+		mtk_snand_bm_swap(snf);
+	}
+
+	ret = mtk_snand_write_enable(snf);
+	if (ret)
+		return ret;
+
+	ret = mtk_snand_program_load(snf, page, raw);
+	if (ret)
+		return ret;
+
+	ret = mtk_snand_page_op(snf, page, SNAND_CMD_PROGRAM_EXECUTE);
+	if (ret)
+		return ret;
+
+	ret = mtk_snand_poll_status(snf, SNFI_POLL_INTERVAL);
+	if (ret < 0) {
+		snand_log_chip(snf->pdev,
+			       "Page program command timed out on page %u\n",
+			       page);
+		return ret;
+	}
+
+	if (ret & SNAND_STATUS_PROGRAM_FAIL) {
+		snand_log_chip(snf->pdev,
+			       "Page program failed on page %u\n", page);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+int mtk_snand_write_page(struct mtk_snand *snf, uint64_t addr, const void *buf,
+			 const void *oob, bool raw)
+{
+	if (!snf || (!buf && !oob))
+		return -EINVAL;
+
+	if (addr >= snf->size)
+		return -EINVAL;
+
+	return mtk_snand_do_write_page(snf, addr, buf, oob, raw, true);
+}
+
+int mtk_snand_erase_block(struct mtk_snand *snf, uint64_t addr)
+{
+	uint64_t die_addr;
+	uint32_t page, block;
+	int ret;
+
+	if (!snf)
+		return -EINVAL;
+
+	if (addr >= snf->size)
+		return -EINVAL;
+
+	die_addr = mtk_snand_select_die_address(snf, addr);
+	block = die_addr >> snf->erasesize_shift;
+	page = block << (snf->erasesize_shift - snf->writesize_shift);
+
+	ret = mtk_snand_write_enable(snf);
+	if (ret)
+		return ret;
+
+	ret = mtk_snand_page_op(snf, page, SNAND_CMD_BLOCK_ERASE);
+	if (ret)
+		return ret;
+
+	ret = mtk_snand_poll_status(snf, SNFI_POLL_INTERVAL);
+	if (ret < 0) {
+		snand_log_chip(snf->pdev,
+			       "Block erase command timed out on block %u\n",
+			       block);
+		return ret;
+	}
+
+	if (ret & SNAND_STATUS_ERASE_FAIL) {
+		snand_log_chip(snf->pdev,
+			       "Block erase failed on block %u\n", block);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static int mtk_snand_block_isbad_std(struct mtk_snand *snf, uint64_t addr)
+{
+	int ret;
+
+	ret = mtk_snand_do_read_page(snf, addr, NULL, snf->buf_cache, true,
+				     false);
+	if (ret && ret != -EBADMSG)
+		return ret;
+
+	return snf->buf_cache[0] != 0xff;
+}
+
+static int mtk_snand_block_isbad_mtk(struct mtk_snand *snf, uint64_t addr)
+{
+	int ret;
+
+	ret = mtk_snand_do_read_page(snf, addr, NULL, snf->buf_cache, true,
+				     true);
+	if (ret && ret != -EBADMSG)
+		return ret;
+
+	return snf->buf_cache[0] != 0xff;
+}
+
+int mtk_snand_block_isbad(struct mtk_snand *snf, uint64_t addr)
+{
+	if (!snf)
+		return -EINVAL;
+
+	if (addr >= snf->size)
+		return -EINVAL;
+
+	addr &= ~snf->erasesize_mask;
+
+	if (snf->nfi_soc->bbm_swap)
+		return mtk_snand_block_isbad_std(snf, addr);
+
+	return mtk_snand_block_isbad_mtk(snf, addr);
+}
+
+static int mtk_snand_block_markbad_std(struct mtk_snand *snf, uint64_t addr)
+{
+	/* Standard BBM position */
+	memset(snf->buf_cache, 0xff, snf->oobsize);
+	snf->buf_cache[0] = 0;
+
+	return mtk_snand_do_write_page(snf, addr, NULL, snf->buf_cache, true,
+				       false);
+}
+
+static int mtk_snand_block_markbad_mtk(struct mtk_snand *snf, uint64_t addr)
+{
+	/* Write the whole page with zeros */
+	memset(snf->buf_cache, 0, snf->writesize + snf->oobsize);
+
+	return mtk_snand_do_write_page(snf, addr, snf->buf_cache,
+				       snf->buf_cache + snf->writesize, true,
+				       true);
+}
+
+int mtk_snand_block_markbad(struct mtk_snand *snf, uint64_t addr)
+{
+	if (!snf)
+		return -EINVAL;
+
+	if (addr >= snf->size)
+		return -EINVAL;
+
+	addr &= ~snf->erasesize_mask;
+
+	if (snf->nfi_soc->bbm_swap)
+		return mtk_snand_block_markbad_std(snf, addr);
+
+	return mtk_snand_block_markbad_mtk(snf, addr);
+}
+
+int mtk_snand_fill_oob(struct mtk_snand *snf, uint8_t *oobraw,
+		       const uint8_t *oobbuf, size_t ooblen)
+{
+	size_t len = ooblen, sect_fdm_len;
+	const uint8_t *oob = oobbuf;
+	uint32_t step = 0;
+
+	if (!snf || !oobraw || !oob)
+		return -EINVAL;
+
+	while (len && step < snf->ecc_steps) {
+		sect_fdm_len = snf->nfi_soc->fdm_size - 1;
+		if (sect_fdm_len > len)
+			sect_fdm_len = len;
+
+		memcpy(oobraw + step * snf->nfi_soc->fdm_size + 1, oob,
+		       sect_fdm_len);
+
+		len -= sect_fdm_len;
+		oob += sect_fdm_len;
+		step++;
+	}
+
+	return len;
+}
+
+int mtk_snand_transfer_oob(struct mtk_snand *snf, uint8_t *oobbuf,
+			   size_t ooblen, const uint8_t *oobraw)
+{
+	size_t len = ooblen, sect_fdm_len;
+	uint8_t *oob = oobbuf;
+	uint32_t step = 0;
+
+	if (!snf || !oobraw || !oob)
+		return -EINVAL;
+
+	while (len && step < snf->ecc_steps) {
+		sect_fdm_len = snf->nfi_soc->fdm_size - 1;
+		if (sect_fdm_len > len)
+			sect_fdm_len = len;
+
+		memcpy(oob, oobraw + step * snf->nfi_soc->fdm_size + 1,
+		       sect_fdm_len);
+
+		len -= sect_fdm_len;
+		oob += sect_fdm_len;
+		step++;
+	}
+
+	return len;
+}
+
+int mtk_snand_read_page_auto_oob(struct mtk_snand *snf, uint64_t addr,
+				 void *buf, void *oob, size_t ooblen,
+				 size_t *actualooblen, bool raw)
+{
+	int ret, oobremain;
+
+	if (!snf)
+		return -EINVAL;
+
+	if (!oob)
+		return mtk_snand_read_page(snf, addr, buf, NULL, raw);
+
+	ret = mtk_snand_read_page(snf, addr, buf, snf->buf_cache, raw);
+	if (ret && ret != -EBADMSG) {
+		if (actualooblen)
+			*actualooblen = 0;
+		return ret;
+	}
+
+	oobremain = mtk_snand_transfer_oob(snf, oob, ooblen, snf->buf_cache);
+	if (actualooblen)
+		*actualooblen = ooblen - oobremain;
+
+	return ret;
+}
+
+int mtk_snand_write_page_auto_oob(struct mtk_snand *snf, uint64_t addr,
+				  const void *buf, const void *oob,
+				  size_t ooblen, size_t *actualooblen, bool raw)
+{
+	int oobremain;
+
+	if (!snf)
+		return -EINVAL;
+
+	if (!oob)
+		return mtk_snand_write_page(snf, addr, buf, NULL, raw);
+
+	memset(snf->buf_cache, 0xff, snf->oobsize);
+	oobremain = mtk_snand_fill_oob(snf, snf->buf_cache, oob, ooblen);
+	if (actualooblen)
+		*actualooblen = ooblen - oobremain;
+
+	return mtk_snand_write_page(snf, addr, buf, snf->buf_cache, raw);
+}
+
+int mtk_snand_get_chip_info(struct mtk_snand *snf,
+			    struct mtk_snand_chip_info *info)
+{
+	if (!snf || !info)
+		return -EINVAL;
+
+	info->model = snf->model;
+	info->chipsize = snf->size;
+	info->blocksize = snf->erasesize;
+	info->pagesize = snf->writesize;
+	info->sparesize = snf->oobsize;
+	info->spare_per_sector = snf->spare_per_sector;
+	info->fdm_size = snf->nfi_soc->fdm_size;
+	info->fdm_ecc_size = snf->nfi_soc->fdm_ecc_size;
+	info->num_sectors = snf->ecc_steps;
+	info->sector_size = snf->nfi_soc->sector_size;
+	info->ecc_strength = snf->ecc_strength;
+	info->ecc_bytes = snf->ecc_bytes;
+
+	return 0;
+}
+
+int mtk_snand_irq_process(struct mtk_snand *snf)
+{
+	uint32_t sta, ien;
+
+	if (!snf)
+		return -EINVAL;
+
+	sta = nfi_read32(snf, NFI_INTR_STA);
+	ien = nfi_read32(snf, NFI_INTR_EN);
+
+	if (!(sta & ien))
+		return 0;
+
+	nfi_write32(snf, NFI_INTR_EN, 0);
+	irq_completion_done(snf->pdev);
+
+	return 1;
+}
+
+static int mtk_snand_select_spare_per_sector(struct mtk_snand *snf)
+{
+	uint32_t spare_per_step = snf->oobsize / snf->ecc_steps;
+	int i, mul = 1;
+
+	/*
+	 * If we're using the 1KB sector size, HW will automatically
+	 * double the spare size. So we should only use half of the value.
+	 */
+	if (snf->nfi_soc->sector_size == 1024)
+		mul = 2;
+
+	spare_per_step /= mul;
+
+	for (i = snf->nfi_soc->num_spare_size - 1; i >= 0; i--) {
+		if (snf->nfi_soc->spare_sizes[i] <= spare_per_step) {
+			snf->spare_per_sector = snf->nfi_soc->spare_sizes[i];
+			snf->spare_per_sector *= mul;
+			return i;
+		}
+	}
+
+	snand_log_nfi(snf->pdev,
+		      "Page size %u+%u is not supported\n", snf->writesize,
+		      snf->oobsize);
+
+	return -1;
+}
+
+static int mtk_snand_pagefmt_setup(struct mtk_snand *snf)
+{
+	uint32_t spare_size_idx, spare_size_shift, pagesize_idx;
+	uint32_t sector_size_512;
+
+	if (snf->nfi_soc->sector_size == 512) {
+		sector_size_512 = NFI_SEC_SEL_512;
+		spare_size_shift = NFI_SPARE_SIZE_S;
+	} else {
+		sector_size_512 = 0;
+		spare_size_shift = NFI_SPARE_SIZE_LS_S;
+	}
+
+	switch (snf->writesize) {
+	case SZ_512:
+		pagesize_idx = NFI_PAGE_SIZE_512_2K;
+		break;
+	case SZ_2K:
+		if (snf->nfi_soc->sector_size == 512)
+			pagesize_idx = NFI_PAGE_SIZE_2K_4K;
+		else
+			pagesize_idx = NFI_PAGE_SIZE_512_2K;
+		break;
+	case SZ_4K:
+		if (snf->nfi_soc->sector_size == 512)
+			pagesize_idx = NFI_PAGE_SIZE_4K_8K;
+		else
+			pagesize_idx = NFI_PAGE_SIZE_2K_4K;
+		break;
+	case SZ_8K:
+		if (snf->nfi_soc->sector_size == 512)
+			pagesize_idx = NFI_PAGE_SIZE_8K_16K;
+		else
+			pagesize_idx = NFI_PAGE_SIZE_4K_8K;
+		break;
+	case SZ_16K:
+		pagesize_idx = NFI_PAGE_SIZE_8K_16K;
+		break;
+	default:
+		snand_log_nfi(snf->pdev, "Page size %u is not supported\n",
+			      snf->writesize);
+		return -ENOTSUPP;
+	}
+
+	spare_size_idx = mtk_snand_select_spare_per_sector(snf);
+	if (unlikely(spare_size_idx < 0))
+		return -ENOTSUPP;
+
+	snf->raw_sector_size = snf->nfi_soc->sector_size +
+			       snf->spare_per_sector;
+
+	/* Setup page format */
+	nfi_write32(snf, NFI_PAGEFMT,
+		    (snf->nfi_soc->fdm_ecc_size << NFI_FDM_ECC_NUM_S) |
+		    (snf->nfi_soc->fdm_size << NFI_FDM_NUM_S) |
+		    (spare_size_idx << spare_size_shift) |
+		    (pagesize_idx << NFI_PAGE_SIZE_S) |
+		    sector_size_512);
+
+	return 0;
+}
+
+static enum snand_flash_io mtk_snand_select_opcode(struct mtk_snand *snf,
+				   uint32_t snfi_caps, uint8_t *opcode,
+				   uint8_t *dummy,
+				   const struct snand_io_cap *op_cap)
+{
+	uint32_t i, caps;
+
+	caps = snfi_caps & op_cap->caps;
+
+	i = fls(caps);
+	if (i > 0) {
+		*opcode = op_cap->opcodes[i - 1].opcode;
+		if (dummy)
+			*dummy = op_cap->opcodes[i - 1].dummy;
+		return i - 1;
+	}
+
+	return __SNAND_IO_MAX;
+}
+
+static int mtk_snand_select_opcode_rfc(struct mtk_snand *snf,
+				       uint32_t snfi_caps,
+				       const struct snand_io_cap *op_cap)
+{
+	enum snand_flash_io idx;
+
+	static const uint8_t rfc_modes[__SNAND_IO_MAX] = {
+		[SNAND_IO_1_1_1] = DATA_READ_MODE_X1,
+		[SNAND_IO_1_1_2] = DATA_READ_MODE_X2,
+		[SNAND_IO_1_2_2] = DATA_READ_MODE_DUAL,
+		[SNAND_IO_1_1_4] = DATA_READ_MODE_X4,
+		[SNAND_IO_1_4_4] = DATA_READ_MODE_QUAD,
+	};
+
+	idx = mtk_snand_select_opcode(snf, snfi_caps, &snf->opcode_rfc,
+				      &snf->dummy_rfc, op_cap);
+	if (idx >= __SNAND_IO_MAX) {
+		snand_log_snfi(snf->pdev,
+			       "No capable opcode for read from cache\n");
+		return -ENOTSUPP;
+	}
+
+	snf->mode_rfc = rfc_modes[idx];
+
+	if (idx == SNAND_IO_1_1_4 || idx == SNAND_IO_1_4_4)
+		snf->quad_spi_op = true;
+
+	return 0;
+}
+
+static int mtk_snand_select_opcode_pl(struct mtk_snand *snf, uint32_t snfi_caps,
+				      const struct snand_io_cap *op_cap)
+{
+	enum snand_flash_io idx;
+
+	static const uint8_t pl_modes[__SNAND_IO_MAX] = {
+		[SNAND_IO_1_1_1] = 0,
+		[SNAND_IO_1_1_4] = 1,
+	};
+
+	idx = mtk_snand_select_opcode(snf, snfi_caps, &snf->opcode_pl,
+				      NULL, op_cap);
+	if (idx >= __SNAND_IO_MAX) {
+		snand_log_snfi(snf->pdev,
+			       "No capable opcode for program load\n");
+		return -ENOTSUPP;
+	}
+
+	snf->mode_pl = pl_modes[idx];
+
+	if (idx == SNAND_IO_1_1_4)
+		snf->quad_spi_op = true;
+
+	return 0;
+}
+
+static int mtk_snand_setup(struct mtk_snand *snf,
+			   const struct snand_flash_info *snand_info)
+{
+	const struct snand_mem_org *memorg = &snand_info->memorg;
+	uint32_t i, msg_size, snfi_caps;
+	int ret;
+
+	/* Calculate flash memory organization */
+	snf->model = snand_info->model;
+	snf->writesize = memorg->pagesize;
+	snf->oobsize = memorg->sparesize;
+	snf->erasesize = snf->writesize * memorg->pages_per_block;
+	snf->die_size = (uint64_t)snf->erasesize * memorg->blocks_per_die;
+	snf->size = snf->die_size * memorg->ndies;
+	snf->num_dies = memorg->ndies;
+
+	snf->writesize_mask = snf->writesize - 1;
+	snf->erasesize_mask = snf->erasesize - 1;
+	snf->die_mask = snf->die_size - 1;
+
+	snf->writesize_shift = ffs(snf->writesize) - 1;
+	snf->erasesize_shift = ffs(snf->erasesize) - 1;
+	snf->die_shift = mtk_snand_ffs64(snf->die_size) - 1;
+
+	snf->select_die = snand_info->select_die;
+
+	/* Determine opcodes for read from cache/program load */
+	snfi_caps = SPI_IO_1_1_1 | SPI_IO_1_1_2 | SPI_IO_1_2_2;
+	if (snf->snfi_quad_spi)
+		snfi_caps |= SPI_IO_1_1_4 | SPI_IO_1_4_4;
+
+	ret = mtk_snand_select_opcode_rfc(snf, snfi_caps, snand_info->cap_rd);
+	if (ret)
+		return ret;
+
+	ret = mtk_snand_select_opcode_pl(snf, snfi_caps, snand_info->cap_pl);
+	if (ret)
+		return ret;
+
+	/* ECC and page format */
+	snf->ecc_steps = snf->writesize / snf->nfi_soc->sector_size;
+	if (snf->ecc_steps > snf->nfi_soc->max_sectors) {
+		snand_log_nfi(snf->pdev, "Page size %u is not supported\n",
+			      snf->writesize);
+		return -ENOTSUPP;
+	}
+
+	ret = mtk_snand_pagefmt_setup(snf);
+	if (ret)
+		return ret;
+
+	msg_size = snf->nfi_soc->sector_size + snf->nfi_soc->fdm_ecc_size;
+	ret = mtk_ecc_setup(snf, snf->nfi_base + NFI_FDM0L,
+			    snf->spare_per_sector - snf->nfi_soc->fdm_size,
+			    msg_size);
+	if (ret)
+		return ret;
+
+	nfi_write16(snf, NFI_CNFG, 0);
+
+	/* Tuning options */
+	nfi_write16(snf, NFI_DEBUG_CON1, WBUF_EN);
+	nfi_write32(snf, SNF_DLY_CTL3, (40 << SFCK_SAM_DLY_S));
+
+	/* Interrupts */
+	nfi_read32(snf, NFI_INTR_STA);
+	nfi_write32(snf, NFI_INTR_EN, 0);
+
+	/* Clear SNF done flag */
+	nfi_rmw32(snf, SNF_STA_CTL1, 0, CUS_READ_DONE | CUS_PG_DONE);
+	nfi_write32(snf, SNF_STA_CTL1, 0);
+
+	/* Initialization on all dies */
+	for (i = 0; i < snf->num_dies; i++) {
+		mtk_snand_select_die(snf, i);
+
+		/* Disable On-Die ECC engine */
+		ret = mtk_snand_ondie_ecc_control(snf, false);
+		if (ret)
+			return ret;
+
+		/* Disable block protection */
+		mtk_snand_unlock(snf);
+
+		/* Enable/disable quad-spi */
+		mtk_snand_qspi_control(snf, snf->quad_spi_op);
+	}
+
+	mtk_snand_select_die(snf, 0);
+
+	return 0;
+}
+
+static int mtk_snand_id_probe(struct mtk_snand *snf,
+			      const struct snand_flash_info **snand_info)
+{
+	uint8_t id[4], op[2];
+	int ret;
+
+	/* Read SPI-NAND JEDEC ID, OP + dummy/addr + ID */
+	op[0] = SNAND_CMD_READID;
+	op[1] = 0;
+	ret = mtk_snand_mac_io(snf, op, 2, id, sizeof(id));
+	if (ret)
+		return ret;
+
+	*snand_info = snand_flash_id_lookup(SNAND_ID_DYMMY, id);
+	if (*snand_info)
+		return 0;
+
+	/* Read SPI-NAND JEDEC ID, OP + ID */
+	op[0] = SNAND_CMD_READID;
+	ret = mtk_snand_mac_io(snf, op, 1, id, sizeof(id));
+	if (ret)
+		return ret;
+
+	*snand_info = snand_flash_id_lookup(SNAND_ID_DYMMY, id);
+	if (*snand_info)
+		return 0;
+
+	snand_log_chip(snf->pdev,
+		       "Unrecognized SPI-NAND ID: %02x %02x %02x %02x\n",
+		       id[0], id[1], id[2], id[3]);
+
+	return -EINVAL;
+}
+
+int mtk_snand_init(void *dev, const struct mtk_snand_platdata *pdata,
+		   struct mtk_snand **psnf)
+{
+	const struct snand_flash_info *snand_info;
+	struct mtk_snand tmpsnf, *snf;
+	uint32_t rawpage_size;
+	int ret;
+
+	if (!pdata || !psnf)
+		return -EINVAL;
+
+	if (pdata->soc >= __SNAND_SOC_MAX) {
+		snand_log_chip(dev, "Invalid SOC %u for MTK-SNAND\n",
+			       pdata->soc);
+		return -EINVAL;
+	}
+
+	/* Dummy instance only for initial reset and id probe */
+	tmpsnf.nfi_base = pdata->nfi_base;
+	tmpsnf.ecc_base = pdata->ecc_base;
+	tmpsnf.soc = pdata->soc;
+	tmpsnf.nfi_soc = &mtk_snand_socs[pdata->soc];
+	tmpsnf.pdev = dev;
+
+	/* Switch to SNFI mode */
+	writel(SPI_MODE, tmpsnf.nfi_base + SNF_CFG);
+
+	/* Reset SNFI & NFI */
+	mtk_snand_mac_reset(&tmpsnf);
+	mtk_nfi_reset(&tmpsnf);
+
+	/* Reset SPI-NAND chip */
+	ret = mtk_snand_chip_reset(&tmpsnf);
+	if (ret) {
+		snand_log_chip(dev, "Failed to reset SPI-NAND chip\n");
+		return ret;
+	}
+
+	/* Probe SPI-NAND flash by JEDEC ID */
+	ret = mtk_snand_id_probe(&tmpsnf, &snand_info);
+	if (ret)
+		return ret;
+
+	rawpage_size = snand_info->memorg.pagesize +
+		       snand_info->memorg.sparesize;
+
+	/* Allocate memory for instance and cache */
+	snf = generic_mem_alloc(dev, sizeof(*snf) + rawpage_size);
+	if (!snf) {
+		snand_log_chip(dev, "Failed to allocate memory for instance\n");
+		return -ENOMEM;
+	}
+
+	snf->buf_cache = (uint8_t *)((uintptr_t)snf + sizeof(*snf));
+
+	/* Allocate memory for DMA buffer */
+	snf->page_cache = dma_mem_alloc(dev, rawpage_size);
+	if (!snf->page_cache) {
+		generic_mem_free(dev, snf);
+		snand_log_chip(dev,
+			       "Failed to allocate memory for DMA buffer\n");
+		return -ENOMEM;
+	}
+
+	/* Fill up instance */
+	snf->pdev = dev;
+	snf->nfi_base = pdata->nfi_base;
+	snf->ecc_base = pdata->ecc_base;
+	snf->soc = pdata->soc;
+	snf->nfi_soc = &mtk_snand_socs[pdata->soc];
+	snf->snfi_quad_spi = pdata->quad_spi;
+
+	/* Initialize SNFI & ECC engine */
+	ret = mtk_snand_setup(snf, snand_info);
+	if (ret) {
+		dma_mem_free(dev, snf->page_cache);
+		generic_mem_free(dev, snf);
+		return ret;
+	}
+
+	*psnf = snf;
+
+	return 0;
+}
+
+int mtk_snand_cleanup(struct mtk_snand *snf)
+{
+	if (!snf)
+		return 0;
+
+	dma_mem_free(snf->pdev, snf->page_cache);
+	generic_mem_free(snf->pdev, snf);
+
+	return 0;
+}
diff --git a/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand.h b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand.h
new file mode 100644
index 000000000..382f80c25
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/mtk-snand/mtk-snand.h
@@ -0,0 +1,77 @@
+/* SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause */
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#ifndef _MTK_SNAND_H_
+#define _MTK_SNAND_H_
+
+#ifndef PRIVATE_MTK_SNAND_HEADER
+#include <stddef.h>
+#include <stdint.h>
+#include <stdbool.h>
+#endif
+
+enum mtk_snand_soc {
+	SNAND_SOC_MT7622,
+	SNAND_SOC_MT7629,
+	SNAND_SOC_MT7986,
+
+	__SNAND_SOC_MAX
+};
+
+struct mtk_snand_platdata {
+	void *nfi_base;
+	void *ecc_base;
+	enum mtk_snand_soc soc;
+	bool quad_spi;
+};
+
+struct mtk_snand_chip_info {
+	const char *model;
+	uint64_t chipsize;
+	uint32_t blocksize;
+	uint32_t pagesize;
+	uint32_t sparesize;
+	uint32_t spare_per_sector;
+	uint32_t fdm_size;
+	uint32_t fdm_ecc_size;
+	uint32_t num_sectors;
+	uint32_t sector_size;
+	uint32_t ecc_strength;
+	uint32_t ecc_bytes;
+};
+
+struct mtk_snand;
+struct snand_flash_info;
+
+int mtk_snand_init(void *dev, const struct mtk_snand_platdata *pdata,
+		   struct mtk_snand **psnf);
+int mtk_snand_cleanup(struct mtk_snand *snf);
+
+int mtk_snand_chip_reset(struct mtk_snand *snf);
+int mtk_snand_read_page(struct mtk_snand *snf, uint64_t addr, void *buf,
+			void *oob, bool raw);
+int mtk_snand_write_page(struct mtk_snand *snf, uint64_t addr, const void *buf,
+			 const void *oob, bool raw);
+int mtk_snand_erase_block(struct mtk_snand *snf, uint64_t addr);
+int mtk_snand_block_isbad(struct mtk_snand *snf, uint64_t addr);
+int mtk_snand_block_markbad(struct mtk_snand *snf, uint64_t addr);
+int mtk_snand_fill_oob(struct mtk_snand *snf, uint8_t *oobraw,
+		       const uint8_t *oobbuf, size_t ooblen);
+int mtk_snand_transfer_oob(struct mtk_snand *snf, uint8_t *oobbuf,
+			   size_t ooblen, const uint8_t *oobraw);
+int mtk_snand_read_page_auto_oob(struct mtk_snand *snf, uint64_t addr,
+				 void *buf, void *oob, size_t ooblen,
+				 size_t *actualooblen, bool raw);
+int mtk_snand_write_page_auto_oob(struct mtk_snand *snf, uint64_t addr,
+				  const void *buf, const void *oob,
+				  size_t ooblen, size_t *actualooblen,
+				  bool raw);
+int mtk_snand_get_chip_info(struct mtk_snand *snf,
+			    struct mtk_snand_chip_info *info);
+int mtk_snand_irq_process(struct mtk_snand *snf);
+
+#endif /* _MTK_SNAND_H_ */
diff --git a/trunk/linux-4.4.x/drivers/mtd/nand/mtk_nand.c b/trunk/linux-4.4.x/drivers/mtd/nand/mtk_nand.c
index d4b15a207..96c0a1253 100644
--- a/trunk/linux-4.4.x/drivers/mtd/nand/mtk_nand.c
+++ b/trunk/linux-4.4.x/drivers/mtd/nand/mtk_nand.c
@@ -773,6 +773,7 @@ static int mtk_nfc_write_subpage_hwecc(struct mtd_info *mtd,
 static int mtk_nfc_write_oob_std(struct mtd_info *mtd, struct nand_chip *chip,
 				 int page)
 {
+#ifndef CONFIG_MACH_MT7623 
 	int ret;
 
 	chip->cmdfunc(mtd, NAND_CMD_SEQIN, 0x00, page);
@@ -785,6 +786,9 @@ static int mtk_nfc_write_oob_std(struct mtd_info *mtd, struct nand_chip *chip,
 	ret = chip->waitfunc(mtd, chip);
 
 	return ret & NAND_STATUS_FAIL ? -EIO : 0;
+#else 
+	return 0;
+#endif
 }
 
 static int mtk_nfc_update_ecc_stats(struct mtd_info *mtd, u8 *buf, u32 sectors)
diff --git a/trunk/linux-4.4.x/drivers/mtd/nand/mtk_snand.c b/trunk/linux-4.4.x/drivers/mtd/nand/mtk_snand.c
index 3e0d5c5ec..4218c8dd9 100644
--- a/trunk/linux-4.4.x/drivers/mtd/nand/mtk_snand.c
+++ b/trunk/linux-4.4.x/drivers/mtd/nand/mtk_snand.c
@@ -538,6 +538,8 @@ struct mtk_snfc {
 	struct completion done;
 	struct list_head chips;
 
+	int use_bmt;
+
 	u8 *buffer;
 };
 
@@ -2895,7 +2897,7 @@ static int mtk_snand_write_page(struct mtd_info *mtd, struct nand_chip *chip,
 	int mapped_block;
 	struct timeval stimer, etimer;
 
-	if (!snfc->chip_data->use_bmt)
+	if (!snfc->use_bmt)
 		mapped_block = block;
 	else
 		mapped_block = get_mapping_block_index(block);
@@ -2918,7 +2920,7 @@ static int mtk_snand_write_page(struct mtd_info *mtd, struct nand_chip *chip,
 				     (u8 *) buf, local_oob_buf, 0)) {
 		pr_warn("write fail at: 0x%x, page: 0x%x\n",
 				     mapped_block, page_in_block);
-		if (snfc->chip_data->use_bmt) {
+		if (snfc->use_bmt) {
 			if (update_bmt((page_in_block + mapped_block * page_per_block)
 					<< chip->page_shift, UPDATE_WRITE_FAIL,
 					(u8 *) buf, local_oob_buf))
@@ -3264,7 +3266,7 @@ static int mtk_snand_read_page_hwecc(struct mtd_info *mtd,
 	u16 page_in_block = pkCMD->u4RowAddr % page_per_block;
 	int mapped_block;
 
-	if (!snfc->chip_data->use_bmt)
+	if (!snfc->use_bmt)
 		mapped_block = block;
 	else
 		mapped_block = get_mapping_block_index(block);
@@ -3379,7 +3381,7 @@ static int mtk_nand_erase(struct mtd_info *mtd, int page)
 	int mapped_block;
 	int status;
 
-	if (!snfc->chip_data->use_bmt)
+	if (!snfc->use_bmt)
 		mapped_block = block;
 	else
 		mapped_block = get_mapping_block_index(block);
@@ -3388,7 +3390,7 @@ static int mtk_nand_erase(struct mtd_info *mtd, int page)
 				   * mapped_block);
 
 	if (status & NAND_STATUS_FAIL) {
-		if (snfc->chip_data->use_bmt) {
+		if (snfc->use_bmt) {
 			if (update_bmt((page_in_block + mapped_block * page_per_block)
 				<< chip->page_shift, UPDATE_ERASE_FAIL, NULL, NULL))
 				return 0;
@@ -3525,7 +3527,7 @@ static int mtk_snand_write_oob(struct mtd_info *mtd, struct nand_chip *chip,
 	u16 page_in_block = page % page_per_block;
 	int mapped_block;
 
-	if (!snfc->chip_data->use_bmt)
+	if (!snfc->use_bmt)
 		mapped_block = block;
 	else
 		mapped_block = get_mapping_block_index(block);
@@ -3540,7 +3542,7 @@ static int mtk_snand_write_oob(struct mtd_info *mtd, struct nand_chip *chip,
 				   * page_per_block)) {
 		memset(local_oob_buf, 0xFF, mtd->oobsize);
 		mtk_snand_transfer_oob(chip, local_oob_buf);
-		if (snfc->chip_data->use_bmt) {
+		if (snfc->use_bmt) {
 			if (update_bmt((page_in_block + mapped_block * page_per_block)
 					<< chip->page_shift, UPDATE_WRITE_FAIL, NULL,
 					local_oob_buf))
@@ -3579,7 +3581,7 @@ static int mtk_snand_block_markbad(struct mtd_info *mtd, loff_t offset)
 	int block = (int)offset >> chip->phys_erase_shift;
 	int mapped_block;
 
-	if (!snfc->chip_data->use_bmt)
+	if (!snfc->use_bmt)
 		mapped_block = block;
 	else
 		mapped_block = get_mapping_block_index(block);
@@ -3619,7 +3621,7 @@ static int mtk_snand_read_oob(struct mtd_info *mtd, struct nand_chip *chip,
 	u16 page_in_block = page % page_per_block;
 	int mapped_block;
 
-	if (!snfc->chip_data->use_bmt)
+	if (!snfc->use_bmt)
 		mapped_block = block;
 	else
 		mapped_block = get_mapping_block_index(block);
@@ -3671,7 +3673,7 @@ static int mtk_snand_block_bad(struct mtd_info *mtd, loff_t ofs)
 	int mapped_block;
 	int ret;
 
-	if (!snfc->chip_data->use_bmt)
+	if (!snfc->use_bmt)
 		mapped_block = block;
 	else
 		mapped_block = get_mapping_block_index(block);
@@ -3680,7 +3682,7 @@ static int mtk_snand_block_bad(struct mtd_info *mtd, loff_t ofs)
 				    << chip->phys_erase_shift);
 
 	if (ret) {
-		if (snfc->chip_data->use_bmt) {
+		if (snfc->use_bmt) {
 			pr_debug("Unmapped bad block: 0x%x\n", mapped_block);
 			if (update_bmt(mapped_block << chip->phys_erase_shift,
 				       UPDATE_UNMAPPED_BLOCK, NULL, NULL)) {
@@ -4085,17 +4087,24 @@ static int mtk_snand_probe(struct platform_device *pdev)
 		goto out;
 	}
 
+	snfc->use_bmt = snfc->chip_data->use_bmt;
+
+	if (of_property_read_bool(np, "disable-bmt"))
+		snfc->use_bmt = 0;
+
+	if (snfc->use_bmt) {
 	#if defined(MTK_COMBO_NAND_SUPPORT)
-	nand_chip->chipsize -= (PART_SIZE_BMTPOOL);
+		nand_chip->chipsize -= (PART_SIZE_BMTPOOL);
 	#else
-	nand_chip->chipsize -= (BMT_POOL_SIZE) << nand_chip->phys_erase_shift;
+		nand_chip->chipsize -= (BMT_POOL_SIZE) << nand_chip->phys_erase_shift;
 	#endif
+	}
 	mtd->size = nand_chip->chipsize;
 
 	/* config read empty threshold for MTK ECC */
 	snfi_writel(snfc, 1, NFI_EMPTY_THRESH);
 
-	if (snfc->chip_data->use_bmt)
+	if (snfc->use_bmt) {
 		if (init_bmt(host,
 			1 << (nand_chip->chip_shift - nand_chip->phys_erase_shift),
 			(nand_chip->chipsize >> nand_chip->phys_erase_shift) - 2) != 0) {
@@ -4103,7 +4112,8 @@ static int mtk_snand_probe(struct platform_device *pdev)
 			return 0;
 		}
 
-	nand_chip->chipsize -= (PMT_POOL_SIZE) << nand_chip->phys_erase_shift;
+		nand_chip->chipsize -= (PMT_POOL_SIZE) << nand_chip->phys_erase_shift;
+	}
 	mtd->size = nand_chip->chipsize;
 
 	np = of_get_next_available_child(pdev->dev.of_node, NULL);
diff --git a/trunk/linux-4.4.x/drivers/mtd/nand/nand_ids.c b/trunk/linux-4.4.x/drivers/mtd/nand/nand_ids.c
index 2d3b82b90..f455f5bdb 100644
--- a/trunk/linux-4.4.x/drivers/mtd/nand/nand_ids.c
+++ b/trunk/linux-4.4.x/drivers/mtd/nand/nand_ids.c
@@ -33,6 +33,12 @@ struct nand_flash_dev nand_flash_ids[] = {
 		{ .id = {0x98, 0xd1, 0x90, 0x15, 0x76, 0x14, 0x01, 0x00} },
 		  SZ_2K, SZ_128, SZ_128K, 0, 8, 64, NAND_ECC_INFO(1, SZ_512),
 		  2 },
+	{"TC58BVG0S3H 1G 3.3V 8-bit",
+		{ .id = {0x98, 0xf1, 0x80, 0x15, 0xf2, 0x16, 0x08, 0x00} },
+		  SZ_2K, SZ_128, SZ_128K, 0, 8, 64, NAND_ECC_INFO(8, SZ_512) },
+	{"TC58NVG0S3H 1G 3.3V 8-bit",
+		{ .id = {0x98, 0xf1, 0x80, 0x15, 0x72, 0x16, 0x08, 0x00} },
+		  SZ_2K, SZ_128, SZ_128K, 0, 8, 64, NAND_ECC_INFO(8, SZ_512) },
 	{"TC58NVG2S0F 4G 3.3V 8-bit",
 		{ .id = {0x98, 0xdc, 0x90, 0x26, 0x76, 0x15, 0x01, 0x08} },
 		  SZ_4K, SZ_512, SZ_256K, 0, 8, 224, NAND_ECC_INFO(4, SZ_512) },
diff --git a/trunk/linux-4.4.x/drivers/mtd/nmbm/Kconfig b/trunk/linux-4.4.x/drivers/mtd/nmbm/Kconfig
new file mode 100644
index 000000000..98df30572
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/nmbm/Kconfig
@@ -0,0 +1,35 @@
+
+config NMBM
+	bool "Enable NAND mapping block management"
+	default n
+	select CRC32
+
+choice
+	prompt "Default log level"
+	depends on NMBM
+	default NMBM_LOG_LEVEL_INFO
+
+config NMBM_LOG_LEVEL_DEBUG
+	bool "0 - Debug"
+
+config NMBM_LOG_LEVEL_INFO
+	bool "1 - Info"
+
+config NMBM_LOG_LEVEL_WARN
+	bool "2 - Warn"
+
+config NMBM_LOG_LEVEL_ERR
+	bool "3 - Error"
+
+config NMBM_LOG_LEVEL_EMERG
+	bool "4 - Emergency"
+
+config NMBM_LOG_LEVEL_NONE
+	bool "5 - None"
+
+endchoice
+
+config NMBM_MTD
+	bool "Enable MTD based NAND mapping block management"
+	default n
+	depends on NMBM
diff --git a/trunk/linux-4.4.x/drivers/mtd/nmbm/Makefile b/trunk/linux-4.4.x/drivers/mtd/nmbm/Makefile
new file mode 100644
index 000000000..46e6d50a8
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/nmbm/Makefile
@@ -0,0 +1,6 @@
+# SPDX-License-Identifier: GPL-2.0
+#
+# (C) Copyright 2020 MediaTek Inc. All rights reserved.
+
+obj-$(CONFIG_NMBM) += nmbm-core.o
+obj-$(CONFIG_NMBM_MTD) += nmbm-mtd.o
diff --git a/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-core.c b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-core.c
new file mode 100644
index 000000000..018243009
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-core.c
@@ -0,0 +1,2814 @@
+// SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#include "nmbm-private.h"
+
+#include "nmbm-debug.h"
+
+#define NMBM_VER_MAJOR			1
+#define NMBM_VER_MINOR			0
+#define NMBM_VER			NMBM_VERSION_MAKE(NMBM_VER_MAJOR, \
+							  NMBM_VER_MINOR)
+
+#define NMBM_ALIGN(v, a)		(((v) + (a) - 1) & ~((a) - 1))
+
+/*****************************************************************************/
+/* Logging related functions */
+/*****************************************************************************/
+
+/*
+ * nmbm_log_lower - Print log using OS specific routine
+ * @nld: NMBM lower device structure
+ * @level: log level
+ * @fmt: format string
+ */
+static void nmbm_log_lower(struct nmbm_lower_device *nld,
+			   enum nmbm_log_category level, const char *fmt, ...)
+{
+	va_list ap;
+
+	if (!nld->logprint)
+		return;
+
+	va_start(ap, fmt);
+	nld->logprint(nld->arg, level, fmt, ap);
+	va_end(ap);
+}
+
+/*
+ * nmbm_log - Print log using OS specific routine
+ * @ni: NMBM instance structure
+ * @level: log level
+ * @fmt: format string
+ */
+static void nmbm_log(struct nmbm_instance *ni, enum nmbm_log_category level,
+		     const char *fmt, ...)
+{
+	va_list ap;
+
+	if (!ni)
+		return;
+
+	if (!ni->lower.logprint || level < ni->log_display_level)
+		return;
+
+	va_start(ap, fmt);
+	ni->lower.logprint(ni->lower.arg, level, fmt, ap);
+	va_end(ap);
+}
+
+/*
+ * nmbm_set_log_level - Set log display level
+ * @ni: NMBM instance structure
+ * @level: log display level
+ */
+enum nmbm_log_category nmbm_set_log_level(struct nmbm_instance *ni,
+					  enum nmbm_log_category level)
+{
+	enum nmbm_log_category old;
+
+	if (!ni)
+		return __NMBM_LOG_MAX;
+
+	old = ni->log_display_level;
+	ni->log_display_level = level;
+	return old;
+}
+
+/*
+ * nlog_table_creation - Print log of table creation event
+ * @ni: NMBM instance structure
+ * @main_table: whether the table is main info table
+ * @start_ba: start block address of the table
+ * @end_ba: block address after the end of the table
+ */
+static void nlog_table_creation(struct nmbm_instance *ni, bool main_table,
+			       uint32_t start_ba, uint32_t end_ba)
+{
+	if (start_ba == end_ba - 1)
+		nlog_info(ni, "%s info table has been written to block %u\n",
+			 main_table ? "Main" : "Backup", start_ba);
+	else
+		nlog_info(ni, "%s info table has been written to block %u-%u\n",
+			 main_table ? "Main" : "Backup", start_ba, end_ba - 1);
+
+	nmbm_mark_block_color_info_table(ni, start_ba, end_ba - 1);
+}
+
+/*
+ * nlog_table_update - Print log of table update event
+ * @ni: NMBM instance structure
+ * @main_table: whether the table is main info table
+ * @start_ba: start block address of the table
+ * @end_ba: block address after the end of the table
+ */
+static void nlog_table_update(struct nmbm_instance *ni, bool main_table,
+			     uint32_t start_ba, uint32_t end_ba)
+{
+	if (start_ba == end_ba - 1)
+		nlog_debug(ni, "%s info table has been updated in block %u\n",
+			  main_table ? "Main" : "Backup", start_ba);
+	else
+		nlog_debug(ni, "%s info table has been updated in block %u-%u\n",
+			  main_table ? "Main" : "Backup", start_ba, end_ba - 1);
+
+	nmbm_mark_block_color_info_table(ni, start_ba, end_ba - 1);
+}
+
+/*
+ * nlog_table_found - Print log of table found event
+ * @ni: NMBM instance structure
+ * @first_table: whether the table is first found info table
+ * @write_count: write count of the info table
+ * @start_ba: start block address of the table
+ * @end_ba: block address after the end of the table
+ */
+static void nlog_table_found(struct nmbm_instance *ni, bool first_table,
+			    uint32_t write_count, uint32_t start_ba,
+			    uint32_t end_ba)
+{
+	if (start_ba == end_ba - 1)
+		nlog_info(ni, "%s info table with writecount %u found in block %u\n",
+			 first_table ? "First" : "Second", write_count,
+			 start_ba);
+	else
+		nlog_info(ni, "%s info table with writecount %u found in block %u-%u\n",
+			 first_table ? "First" : "Second", write_count,
+			 start_ba, end_ba - 1);
+
+	nmbm_mark_block_color_info_table(ni, start_ba, end_ba - 1);
+}
+
+/*****************************************************************************/
+/* Address conversion functions */
+/*****************************************************************************/
+
+/*
+ * addr2ba - Convert a linear address to block address
+ * @ni: NMBM instance structure
+ * @addr: Linear address
+ */
+static uint32_t addr2ba(struct nmbm_instance *ni, uint64_t addr)
+{
+	return addr >> ni->erasesize_shift;
+}
+
+/*
+ * ba2addr - Convert a block address to linear address
+ * @ni: NMBM instance structure
+ * @ba: Block address
+ */
+static uint64_t ba2addr(struct nmbm_instance *ni, uint32_t ba)
+{
+	return (uint64_t)ba << ni->erasesize_shift;
+}
+/*
+ * size2blk - Get minimum required blocks for storing specific size of data
+ * @ni: NMBM instance structure
+ * @size: size for storing
+ */
+static uint32_t size2blk(struct nmbm_instance *ni, uint64_t size)
+{
+	return (size + ni->lower.erasesize - 1) >> ni->erasesize_shift;
+}
+
+/*****************************************************************************/
+/* High level NAND chip APIs */
+/*****************************************************************************/
+
+/*
+ * nmbm_reset_chip - Reset NAND device
+ * @nld: Lower NAND chip structure
+ */
+static void nmbm_reset_chip(struct nmbm_instance *ni)
+{
+	if (ni->lower.reset_chip)
+		ni->lower.reset_chip(ni->lower.arg);
+}
+
+/*
+ * nmbm_read_phys_page - Read page with retry
+ * @ni: NMBM instance structure
+ * @addr: linear address where the data will be read from
+ * @data: the main data to be read
+ * @oob: the oob data to be read
+ * @mode: mode for processing oob data
+ *
+ * Read a page for at most NMBM_TRY_COUNT times.
+ *
+ * Return 0 for success, positive value for ecc error,
+ * negative value for other errors
+ */
+static int nmbm_read_phys_page(struct nmbm_instance *ni, uint64_t addr,
+			       void *data, void *oob, enum nmbm_oob_mode mode)
+{
+	int tries, ret;
+
+	for (tries = 0; tries < NMBM_TRY_COUNT; tries++) {
+		ret = ni->lower.read_page(ni->lower.arg, addr, data, oob, mode);
+		if (!ret)
+			return 0;
+
+		nmbm_reset_chip(ni);
+	}
+
+	if (ret < 0)
+		nlog_err(ni, "Page read failed at address 0x%08llx\n", addr);
+
+	return ret;
+}
+
+/*
+ * nmbm_write_phys_page - Write page with retry
+ * @ni: NMBM instance structure
+ * @addr: linear address where the data will be written to
+ * @data: the main data to be written
+ * @oob: the oob data to be written
+ * @mode: mode for processing oob data
+ *
+ * Write a page for at most NMBM_TRY_COUNT times.
+ */
+static bool nmbm_write_phys_page(struct nmbm_instance *ni, uint64_t addr,
+				 const void *data, const void *oob,
+				 enum nmbm_oob_mode mode)
+{
+	int tries, ret;
+
+	for (tries = 0; tries < NMBM_TRY_COUNT; tries++) {
+		ret = ni->lower.write_page(ni->lower.arg, addr, data, oob, mode);
+		if (!ret)
+			return true;
+
+		nmbm_reset_chip(ni);
+	}
+
+	nlog_err(ni, "Page write failed at address 0x%08llx\n", addr);
+
+	return false;
+}
+
+/*
+ * nmbm_erase_phys_block - Erase a block with retry
+ * @ni: NMBM instance structure
+ * @addr: Linear address
+ *
+ * Erase a block for at most NMBM_TRY_COUNT times.
+ */
+static bool nmbm_erase_phys_block(struct nmbm_instance *ni, uint64_t addr)
+{
+	int tries, ret;
+
+	for (tries = 0; tries < NMBM_TRY_COUNT; tries++) {
+		ret = ni->lower.erase_block(ni->lower.arg, addr);
+		if (!ret)
+			return true;
+
+		nmbm_reset_chip(ni);
+	}
+
+	nlog_err(ni, "Block erasure failed at address 0x%08llx\n", addr);
+
+	return false;
+}
+
+/*
+ * nmbm_check_bad_phys_block - Check whether a block is marked bad in OOB
+ * @ni: NMBM instance structure
+ * @ba: block address
+ */
+static bool nmbm_check_bad_phys_block(struct nmbm_instance *ni, uint32_t ba)
+{
+	uint64_t addr = ba2addr(ni, ba);
+	int ret;
+
+	if (ni->lower.is_bad_block)
+		return ni->lower.is_bad_block(ni->lower.arg, addr);
+
+	/* Treat ECC error as read success */
+	ret = nmbm_read_phys_page(ni, addr, NULL,
+				  ni->page_cache + ni->lower.writesize,
+				  NMBM_MODE_PLACE_OOB);
+	if (ret < 0)
+		return true;
+
+	return ni->page_cache[ni->lower.writesize] != 0xff;
+}
+
+/*
+ * nmbm_mark_phys_bad_block - Mark a block bad
+ * @ni: NMBM instance structure
+ * @addr: Linear address
+ */
+static int nmbm_mark_phys_bad_block(struct nmbm_instance *ni, uint32_t ba)
+{
+	uint64_t addr = ba2addr(ni, ba);
+	enum nmbm_log_category level;
+	uint32_t off;
+
+	nlog_info(ni, "Block %u [0x%08llx] will be marked bad\n", ba, addr);
+
+	if (ni->lower.mark_bad_block)
+		return ni->lower.mark_bad_block(ni->lower.arg, addr);
+
+	/* Whole page set to 0x00 */
+	memset(ni->page_cache, 0, ni->rawpage_size);
+
+	/* Write to all pages within this block, disable all errors */
+	level = nmbm_set_log_level(ni, __NMBM_LOG_MAX);
+
+	for (off = 0; off < ni->lower.erasesize; off += ni->lower.writesize) {
+		nmbm_write_phys_page(ni, addr + off, ni->page_cache,
+				     ni->page_cache + ni->lower.writesize,
+				     NMBM_MODE_RAW);
+	}
+
+	nmbm_set_log_level(ni, level);
+
+	return 0;
+}
+
+/*****************************************************************************/
+/* NMBM related functions */
+/*****************************************************************************/
+
+/*
+ * nmbm_check_header - Check whether a NMBM structure is valid
+ * @data: pointer to a NMBM structure with a NMBM header at beginning
+ * @size: Size of the buffer pointed by @header
+ *
+ * The size of the NMBM structure may be larger than NMBM header,
+ * e.g. block mapping table and block state table.
+ */
+static bool nmbm_check_header(const void *data, uint32_t size)
+{
+	const struct nmbm_header *header = data;
+	struct nmbm_header nhdr;
+	uint32_t new_checksum;
+
+	/*
+	 * Make sure expected structure size is equal or smaller than
+	 * buffer size.
+	 */
+	if (header->size > size)
+		return false;
+
+	memcpy(&nhdr, data, sizeof(nhdr));
+
+	nhdr.checksum = 0;
+	new_checksum = nmbm_crc32(0, &nhdr, sizeof(nhdr));
+	if (header->size > sizeof(nhdr))
+		new_checksum = nmbm_crc32(new_checksum,
+			(const uint8_t *)data + sizeof(nhdr),
+			header->size - sizeof(nhdr));
+
+	if (header->checksum != new_checksum)
+		return false;
+
+	return true;
+}
+
+/*
+ * nmbm_update_checksum - Update checksum of a NMBM structure
+ * @header: pointer to a NMBM structure with a NMBM header at beginning
+ *
+ * The size of the NMBM structure must be specified by @header->size
+ */
+static void nmbm_update_checksum(struct nmbm_header *header)
+{
+	header->checksum = 0;
+	header->checksum = nmbm_crc32(0, header, header->size);
+}
+
+/*
+ * nmbm_get_spare_block_count - Calculate number of blocks should be reserved
+ * @block_count: number of blocks of data
+ *
+ * Calculate number of blocks should be reserved for data
+ */
+static uint32_t nmbm_get_spare_block_count(uint32_t block_count)
+{
+	uint32_t val;
+
+	val = (block_count + NMBM_SPARE_BLOCK_DIV / 2) / NMBM_SPARE_BLOCK_DIV;
+	val *= NMBM_SPARE_BLOCK_MULTI;
+
+	if (val < NMBM_SPARE_BLOCK_MIN)
+		val = NMBM_SPARE_BLOCK_MIN;
+
+	return val;
+}
+
+/*
+ * nmbm_get_block_state_raw - Get state of a block from raw block state table
+ * @block_state: pointer to raw block state table (bitmap)
+ * @ba: block address
+ */
+static uint32_t nmbm_get_block_state_raw(nmbm_bitmap_t *block_state,
+					 uint32_t ba)
+{
+	uint32_t unit, shift;
+
+	unit = ba / NMBM_BITMAP_BLOCKS_PER_UNIT;
+	shift = (ba % NMBM_BITMAP_BLOCKS_PER_UNIT) * NMBM_BITMAP_BITS_PER_BLOCK;
+
+	return (block_state[unit] >> shift) & BLOCK_ST_MASK;
+}
+
+/*
+ * nmbm_get_block_state - Get state of a block from block state table
+ * @ni: NMBM instance structure
+ * @ba: block address
+ */
+static uint32_t nmbm_get_block_state(struct nmbm_instance *ni, uint32_t ba)
+{
+	return nmbm_get_block_state_raw(ni->block_state, ba);
+}
+
+/*
+ * nmbm_set_block_state - Set state of a block to block state table
+ * @ni: NMBM instance structure
+ * @ba: block address
+ * @state: block state
+ *
+ * Set state of a block. If the block state changed, ni->block_state_changed
+ * will be increased.
+ */
+static bool nmbm_set_block_state(struct nmbm_instance *ni, uint32_t ba,
+				 uint32_t state)
+{
+	uint32_t unit, shift, orig;
+	nmbm_bitmap_t uv;
+
+	unit = ba / NMBM_BITMAP_BLOCKS_PER_UNIT;
+	shift = (ba % NMBM_BITMAP_BLOCKS_PER_UNIT) * NMBM_BITMAP_BITS_PER_BLOCK;
+
+	orig = (ni->block_state[unit] >> shift) & BLOCK_ST_MASK;
+	state &= BLOCK_ST_MASK;
+
+	uv = ni->block_state[unit] & (~(BLOCK_ST_MASK << shift));
+	uv |= state << shift;
+	ni->block_state[unit] = uv;
+
+	if (state == BLOCK_ST_BAD)
+		nmbm_mark_block_color_bad(ni, ba);
+
+	if (orig != state) {
+		ni->block_state_changed++;
+		return true;
+	}
+
+	return false;
+}
+
+/*
+ * nmbm_block_walk_asc - Skip specified number of good blocks, ascending addr.
+ * @ni: NMBM instance structure
+ * @ba: start physical block address
+ * @nba: return physical block address after walk
+ * @count: number of good blocks to be skipped
+ * @limit: highest block address allowed for walking
+ *
+ * Start from @ba, skipping any bad blocks, counting @count good blocks, and
+ * return the next good block address.
+ *
+ * If no enough good blocks counted while @limit reached, false will be returned.
+ *
+ * If @count == 0, nearest good block address will be returned.
+ * @limit is not counted in walking.
+ */
+static bool nmbm_block_walk_asc(struct nmbm_instance *ni, uint32_t ba,
+				uint32_t *nba, uint32_t count,
+				uint32_t limit)
+{
+	int32_t nblock = count;
+
+	if (limit >= ni->block_count)
+		limit = ni->block_count - 1;
+
+	while (ba < limit) {
+		if (nmbm_get_block_state(ni, ba) == BLOCK_ST_GOOD)
+			nblock--;
+
+		if (nblock < 0) {
+			*nba = ba;
+			return true;
+		}
+
+		ba++;
+	}
+
+	return false;
+}
+
+/*
+ * nmbm_block_walk_desc - Skip specified number of good blocks, descending addr
+ * @ni: NMBM instance structure
+ * @ba: start physical block address
+ * @nba: return physical block address after walk
+ * @count: number of good blocks to be skipped
+ * @limit: lowest block address allowed for walking
+ *
+ * Start from @ba, skipping any bad blocks, counting @count good blocks, and
+ * return the next good block address.
+ *
+ * If no enough good blocks counted while @limit reached, false will be returned.
+ *
+ * If @count == 0, nearest good block address will be returned.
+ * @limit is not counted in walking.
+ */
+static bool nmbm_block_walk_desc(struct nmbm_instance *ni, uint32_t ba,
+				 uint32_t *nba, uint32_t count, uint32_t limit)
+{
+	int32_t nblock = count;
+
+	if (limit >= ni->block_count)
+		limit = ni->block_count - 1;
+
+	while (ba > limit) {
+		if (nmbm_get_block_state(ni, ba) == BLOCK_ST_GOOD)
+			nblock--;
+
+		if (nblock < 0) {
+			*nba = ba;
+			return true;
+		}
+
+		ba--;
+	}
+
+	return false;
+}
+
+/*
+ * nmbm_block_walk - Skip specified number of good blocks from curr. block addr
+ * @ni: NMBM instance structure
+ * @ascending: whether to walk ascending
+ * @ba: start physical block address
+ * @nba: return physical block address after walk
+ * @count: number of good blocks to be skipped
+ * @limit: highest/lowest block address allowed for walking
+ *
+ * Start from @ba, skipping any bad blocks, counting @count good blocks, and
+ * return the next good block address.
+ *
+ * If no enough good blocks counted while @limit reached, false will be returned.
+ *
+ * If @count == 0, nearest good block address will be returned.
+ * @limit can be set to negative if no limit required.
+ * @limit is not counted in walking.
+ */
+static bool nmbm_block_walk(struct nmbm_instance *ni, bool ascending,
+			    uint32_t ba, uint32_t *nba, int32_t count,
+			    int32_t limit)
+{
+	if (ascending)
+		return nmbm_block_walk_asc(ni, ba, nba, count, limit);
+
+	return nmbm_block_walk_desc(ni, ba, nba, count, limit);
+}
+
+/*
+ * nmbm_scan_badblocks - Scan and record all bad blocks
+ * @ni: NMBM instance structure
+ *
+ * Scan the entire lower NAND chip and record all bad blocks in to block state
+ * table.
+ */
+static void nmbm_scan_badblocks(struct nmbm_instance *ni)
+{
+	uint32_t ba;
+
+	for (ba = 0; ba < ni->block_count; ba++) {
+		if (nmbm_check_bad_phys_block(ni, ba)) {
+			nmbm_set_block_state(ni, ba, BLOCK_ST_BAD);
+			nlog_info(ni, "Bad block %u [0x%08llx]\n", ba,
+				 ba2addr(ni, ba));
+		}
+	}
+}
+
+/*
+ * nmbm_build_mapping_table - Build initial block mapping table
+ * @ni: NMBM instance structure
+ *
+ * The initial mapping table will be compatible with the stratage of
+ * factory production.
+ */
+static void nmbm_build_mapping_table(struct nmbm_instance *ni)
+{
+	uint32_t pb, lb;
+
+	for (pb = 0, lb = 0; pb < ni->mgmt_start_ba; pb++) {
+		if (nmbm_get_block_state(ni, pb) == BLOCK_ST_BAD)
+			continue;
+
+		/* Always map to the next good block */
+		ni->block_mapping[lb++] = pb;
+	}
+
+	ni->data_block_count = lb;
+
+	/* Unusable/Management blocks */
+	for (pb = lb; pb < ni->block_count; pb++)
+		ni->block_mapping[pb] = -1;
+}
+
+/*
+ * nmbm_erase_range - Erase a range of blocks
+ * @ni: NMBM instance structure
+ * @ba: block address where the erasure will start
+ * @limit: top block address allowed for erasure
+ *
+ * Erase blocks within the specific range. Newly-found bad blocks will be
+ * marked.
+ *
+ * @limit is not counted into the allowed erasure address.
+ */
+static void nmbm_erase_range(struct nmbm_instance *ni, uint32_t ba,
+			     uint32_t limit)
+{
+	bool success;
+
+	while (ba < limit) {
+		WATCHDOG_RESET();
+
+		if (nmbm_get_block_state(ni, ba) != BLOCK_ST_GOOD)
+			goto next_block;
+
+		success = nmbm_erase_phys_block(ni, ba2addr(ni, ba));
+		if (success)
+			goto next_block;
+
+		nmbm_mark_phys_bad_block(ni, ba);
+		nmbm_set_block_state(ni, ba, BLOCK_ST_BAD);
+
+	next_block:
+		ba++;
+	}
+}
+
+/*
+ * nmbm_write_repeated_data - Write critical data to a block with retry
+ * @ni: NMBM instance structure
+ * @ba: block address where the data will be written to
+ * @data: the data to be written
+ * @size: size of the data
+ *
+ * Write data to every page of the block. Success only if all pages within
+ * this block have been successfully written.
+ *
+ * Make sure data size is not bigger than one page.
+ *
+ * This function will write and verify every page for at most
+ * NMBM_TRY_COUNT times.
+ */
+static bool nmbm_write_repeated_data(struct nmbm_instance *ni, uint32_t ba,
+				     const void *data, uint32_t size)
+{
+	uint64_t addr, off;
+	bool success;
+	int ret;
+
+	if (size > ni->lower.writesize)
+		return false;
+
+	addr = ba2addr(ni, ba);
+
+	for (off = 0; off < ni->lower.erasesize; off += ni->lower.writesize) {
+		WATCHDOG_RESET();
+
+		/* Prepare page data. fill 0xff to unused region */
+		memcpy(ni->page_cache, data, size);
+		memset(ni->page_cache + size, 0xff, ni->rawpage_size - size);
+
+		success = nmbm_write_phys_page(ni, addr + off, ni->page_cache,
+					       NULL, NMBM_MODE_PLACE_OOB);
+		if (!success)
+			return false;
+
+		/* Verify the data just written. ECC error indicates failure */
+		ret = nmbm_read_phys_page(ni, addr + off, ni->page_cache, NULL,
+					  NMBM_MODE_PLACE_OOB);
+		if (ret)
+			return false;
+
+		if (memcmp(ni->page_cache, data, size))
+			return false;
+	}
+
+	return true;
+}
+
+/*
+ * nmbm_write_signature - Write signature to NAND chip
+ * @ni: NMBM instance structure
+ * @limit: top block address allowed for writing
+ * @signature: the signature to be written
+ * @signature_ba: the actual block address where signature is written to
+ *
+ * Write signature within a specific range, from chip bottom to limit.
+ * At most one block will be written.
+ *
+ * @limit is not counted into the allowed write address.
+ */
+static bool nmbm_write_signature(struct nmbm_instance *ni, uint32_t limit,
+				 const struct nmbm_signature *signature,
+				 uint32_t *signature_ba)
+{
+	uint32_t ba = ni->block_count - 1;
+	bool success;
+
+	while (ba > limit) {
+		WATCHDOG_RESET();
+
+		if (nmbm_get_block_state(ni, ba) != BLOCK_ST_GOOD)
+			goto next_block;
+
+		success = nmbm_erase_phys_block(ni, ba2addr(ni, ba));
+		if (!success)
+			goto skip_bad_block;
+
+		success = nmbm_write_repeated_data(ni, ba, signature,
+						   sizeof(*signature));
+		if (success) {
+			*signature_ba = ba;
+			return true;
+		}
+
+	skip_bad_block:
+		nmbm_mark_phys_bad_block(ni, ba);
+		nmbm_set_block_state(ni, ba, BLOCK_ST_BAD);
+
+	next_block:
+		ba--;
+	};
+
+	return false;
+}
+
+/*
+ * nmbn_read_data - Read data
+ * @ni: NMBM instance structure
+ * @addr: linear address where the data will be read from
+ * @data: the data to be read
+ * @size: the size of data
+ *
+ * Read data range.
+ * Every page will be tried for at most NMBM_TRY_COUNT times.
+ *
+ * Return 0 for success, positive value for ecc error,
+ * negative value for other errors
+ */
+static int nmbn_read_data(struct nmbm_instance *ni, uint64_t addr, void *data,
+			  uint32_t size)
+{
+	uint64_t off = addr;
+	uint8_t *ptr = data;
+	uint32_t sizeremain = size, chunksize, leading;
+	int ret;
+
+	while (sizeremain) {
+		WATCHDOG_RESET();
+
+		leading = off & ni->writesize_mask;
+		chunksize = ni->lower.writesize - leading;
+		if (chunksize > sizeremain)
+			chunksize = sizeremain;
+
+		if (chunksize == ni->lower.writesize) {
+			ret = nmbm_read_phys_page(ni, off - leading, ptr, NULL,
+						  NMBM_MODE_PLACE_OOB);
+			if (ret)
+				return ret;
+		} else {
+			ret = nmbm_read_phys_page(ni, off - leading,
+						  ni->page_cache, NULL,
+						  NMBM_MODE_PLACE_OOB);
+			if (ret)
+				return ret;
+
+			memcpy(ptr, ni->page_cache + leading, chunksize);
+		}
+
+		off += chunksize;
+		ptr += chunksize;
+		sizeremain -= chunksize;
+	}
+
+	return 0;
+}
+
+/*
+ * nmbn_write_verify_data - Write data with validation
+ * @ni: NMBM instance structure
+ * @addr: linear address where the data will be written to
+ * @data: the data to be written
+ * @size: the size of data
+ *
+ * Write data and verify.
+ * Every page will be tried for at most NMBM_TRY_COUNT times.
+ */
+static bool nmbn_write_verify_data(struct nmbm_instance *ni, uint64_t addr,
+				   const void *data, uint32_t size)
+{
+	uint64_t off = addr;
+	const uint8_t *ptr = data;
+	uint32_t sizeremain = size, chunksize, leading;
+	bool success;
+	int ret;
+
+	while (sizeremain) {
+		WATCHDOG_RESET();
+
+		leading = off & ni->writesize_mask;
+		chunksize = ni->lower.writesize - leading;
+		if (chunksize > sizeremain)
+			chunksize = sizeremain;
+
+		/* Prepare page data. fill 0xff to unused region */
+		memset(ni->page_cache, 0xff, ni->rawpage_size);
+		memcpy(ni->page_cache + leading, ptr, chunksize);
+
+		success = nmbm_write_phys_page(ni, off - leading,
+					       ni->page_cache, NULL,
+					       NMBM_MODE_PLACE_OOB);
+		if (!success)
+			return false;
+
+		/* Verify the data just written. ECC error indicates failure */
+		ret = nmbm_read_phys_page(ni, off - leading, ni->page_cache,
+					  NULL, NMBM_MODE_PLACE_OOB);
+		if (ret)
+			return false;
+
+		if (memcmp(ni->page_cache + leading, ptr, chunksize))
+			return false;
+
+		off += chunksize;
+		ptr += chunksize;
+		sizeremain -= chunksize;
+	}
+
+	return true;
+}
+
+/*
+ * nmbm_write_mgmt_range - Write management data into NAND within a range
+ * @ni: NMBM instance structure
+ * @addr: preferred start block address for writing
+ * @limit: highest block address allowed for writing
+ * @data: the data to be written
+ * @size: the size of data
+ * @actual_start_ba: actual start block address of data
+ * @actual_end_ba: block address after the end of data
+ *
+ * @limit is not counted into the allowed write address.
+ */
+static bool nmbm_write_mgmt_range(struct nmbm_instance *ni, uint32_t ba,
+				  uint32_t limit, const void *data,
+				  uint32_t size, uint32_t *actual_start_ba,
+				  uint32_t *actual_end_ba)
+{
+	const uint8_t *ptr = data;
+	uint32_t sizeremain = size, chunksize;
+	bool success;
+
+	while (sizeremain && ba < limit) {
+		WATCHDOG_RESET();
+
+		chunksize = sizeremain;
+		if (chunksize > ni->lower.erasesize)
+			chunksize = ni->lower.erasesize;
+
+		if (nmbm_get_block_state(ni, ba) != BLOCK_ST_GOOD)
+			goto next_block;
+
+		success = nmbm_erase_phys_block(ni, ba2addr(ni, ba));
+		if (!success)
+			goto skip_bad_block;
+
+		success = nmbn_write_verify_data(ni, ba2addr(ni, ba), ptr,
+						 chunksize);
+		if (!success)
+			goto skip_bad_block;
+
+		if (sizeremain == size)
+			*actual_start_ba = ba;
+
+		ptr += chunksize;
+		sizeremain -= chunksize;
+
+		goto next_block;
+
+	skip_bad_block:
+		nmbm_mark_phys_bad_block(ni, ba);
+		nmbm_set_block_state(ni, ba, BLOCK_ST_BAD);
+
+	next_block:
+		ba++;
+	}
+
+	if (sizeremain)
+		return false;
+
+	*actual_end_ba = ba;
+
+	return true;
+}
+
+/*
+ * nmbm_generate_info_table_cache - Generate info table cache data
+ * @ni: NMBM instance structure
+ *
+ * Generate info table cache data to be written into flash.
+ */
+static bool nmbm_generate_info_table_cache(struct nmbm_instance *ni)
+{
+	bool changed = false;
+
+	memset(ni->info_table_cache, 0xff, ni->info_table_size);
+
+	memcpy(ni->info_table_cache + ni->info_table.state_table_off,
+	       ni->block_state, ni->state_table_size);
+
+	memcpy(ni->info_table_cache + ni->info_table.mapping_table_off,
+		ni->block_mapping, ni->mapping_table_size);
+
+	ni->info_table.header.magic = NMBM_MAGIC_INFO_TABLE;
+	ni->info_table.header.version = NMBM_VER;
+	ni->info_table.header.size = ni->info_table_size;
+
+	if (ni->block_state_changed || ni->block_mapping_changed) {
+		ni->info_table.write_count++;
+		changed = true;
+	}
+
+	memcpy(ni->info_table_cache, &ni->info_table, sizeof(ni->info_table));
+
+	nmbm_update_checksum((struct nmbm_header *)ni->info_table_cache);
+
+	return changed;
+}
+
+/*
+ * nmbm_write_info_table - Write info table into NAND within a range
+ * @ni: NMBM instance structure
+ * @ba: preferred start block address for writing
+ * @limit: highest block address allowed for writing
+ * @actual_start_ba: actual start block address of info table
+ * @actual_end_ba: block address after the end of info table
+ *
+ * @limit is counted into the allowed write address.
+ */
+static bool nmbm_write_info_table(struct nmbm_instance *ni, uint32_t ba,
+				  uint32_t limit, uint32_t *actual_start_ba,
+				  uint32_t *actual_end_ba)
+{
+	return nmbm_write_mgmt_range(ni, ba, limit, ni->info_table_cache,
+				     ni->info_table_size, actual_start_ba,
+				     actual_end_ba);
+}
+
+/*
+ * nmbm_mark_tables_clean - Mark info table `clean'
+ * @ni: NMBM instance structure
+ */
+static void nmbm_mark_tables_clean(struct nmbm_instance *ni)
+{
+	ni->block_state_changed = 0;
+	ni->block_mapping_changed = 0;
+}
+
+/*
+ * nmbm_try_reserve_blocks - Reserve blocks with compromisation
+ * @ni: NMBM instance structure
+ * @ba: start physical block address
+ * @nba: return physical block address after reservation
+ * @count: number of good blocks to be skipped
+ * @min_count: minimum number of good blocks to be skipped
+ * @limit: highest/lowest block address allowed for walking
+ *
+ * Reserve specific blocks. If failed, try to reserve as many as possible.
+ */
+static bool nmbm_try_reserve_blocks(struct nmbm_instance *ni, uint32_t ba,
+				    uint32_t *nba, uint32_t count,
+				    int32_t min_count, int32_t limit)
+{
+	int32_t nblocks = count;
+	bool success;
+
+	while (nblocks >= min_count) {
+		success = nmbm_block_walk(ni, true, ba, nba, nblocks, limit);
+		if (success)
+			return true;
+
+		nblocks--;
+	}
+
+	return false;
+}
+
+/*
+ * nmbm_rebuild_info_table - Build main & backup info table from scratch
+ * @ni: NMBM instance structure
+ * @allow_no_gap: allow no spare blocks between two tables
+ */
+static bool nmbm_rebuild_info_table(struct nmbm_instance *ni)
+{
+	uint32_t table_start_ba, table_end_ba, next_start_ba;
+	uint32_t main_table_end_ba;
+	bool success;
+
+	/* Set initial value */
+	ni->main_table_ba = 0;
+	ni->backup_table_ba = 0;
+	ni->mapping_blocks_ba = ni->mapping_blocks_top_ba;
+
+	/* Write main table */
+	success = nmbm_write_info_table(ni, ni->mgmt_start_ba,
+					ni->mapping_blocks_top_ba,
+					&table_start_ba, &table_end_ba);
+	if (!success) {
+		/* Failed to write main table, data will be lost */
+		nlog_emerg(ni, "Unable to write at least one info table!\n");
+		nlog_emerg(ni, "Please save your data before power off!\n");
+		ni->protected = 1;
+		return false;
+	}
+
+	/* Main info table is successfully written, record its offset */
+	ni->main_table_ba = table_start_ba;
+	main_table_end_ba = table_end_ba;
+
+	/* Adjust mapping_blocks_ba */
+	ni->mapping_blocks_ba = table_end_ba;
+
+	nmbm_mark_tables_clean(ni);
+
+	nlog_table_creation(ni, true, table_start_ba, table_end_ba);
+
+	/* Reserve spare blocks for main info table. */
+	success = nmbm_try_reserve_blocks(ni, table_end_ba,
+					  &next_start_ba,
+					  ni->info_table_spare_blocks, 0,
+					  ni->mapping_blocks_top_ba -
+					  size2blk(ni, ni->info_table_size));
+	if (!success) {
+		/* There is no spare block. */
+		nlog_debug(ni, "No room for backup info table\n");
+		return true;
+	}
+
+	/* Write backup info table. */
+	success = nmbm_write_info_table(ni, next_start_ba,
+					ni->mapping_blocks_top_ba,
+					&table_start_ba, &table_end_ba);
+	if (!success) {
+		/* There is no enough blocks for backup table. */
+		nlog_debug(ni, "No room for backup info table\n");
+		return true;
+	}
+
+	/* Backup table is successfully written, record its offset */
+	ni->backup_table_ba = table_start_ba;
+
+	/* Adjust mapping_blocks_off */
+	ni->mapping_blocks_ba = table_end_ba;
+
+	/* Erase spare blocks of main table to clean possible interference data */
+	nmbm_erase_range(ni, main_table_end_ba, ni->backup_table_ba);
+
+	nlog_table_creation(ni, false, table_start_ba, table_end_ba);
+
+	return true;
+}
+
+/*
+ * nmbm_rescue_single_info_table - Rescue when there is only one info table
+ * @ni: NMBM instance structure
+ *
+ * This function is called when there is only one info table exists.
+ * This function may fail if we can't write new info table
+ */
+static bool nmbm_rescue_single_info_table(struct nmbm_instance *ni)
+{
+	uint32_t table_start_ba, table_end_ba, write_ba;
+	bool success;
+
+	/* Try to write new info table in front of existing table */
+	success = nmbm_write_info_table(ni, ni->mgmt_start_ba,
+					ni->main_table_ba,
+					&table_start_ba,
+					&table_end_ba);
+	if (success) {
+		/*
+		 * New table becomes the main table, existing table becomes
+		 * the backup table.
+		 */
+		ni->backup_table_ba = ni->main_table_ba;
+		ni->main_table_ba = table_start_ba;
+
+		nmbm_mark_tables_clean(ni);
+
+		/* Erase spare blocks of main table to clean possible interference data */
+		nmbm_erase_range(ni, table_end_ba, ni->backup_table_ba);
+
+		nlog_table_creation(ni, true, table_start_ba, table_end_ba);
+
+		return true;
+	}
+
+	/* Try to reserve spare blocks for existing table */
+	success = nmbm_try_reserve_blocks(ni, ni->mapping_blocks_ba, &write_ba,
+					  ni->info_table_spare_blocks, 0,
+					  ni->mapping_blocks_top_ba -
+					  size2blk(ni, ni->info_table_size));
+	if (!success) {
+		nlog_warn(ni, "Failed to rescue single info table\n");
+		return false;
+	}
+
+	/* Try to write new info table next to the existing table */
+	while (write_ba >= ni->mapping_blocks_ba) {
+		WATCHDOG_RESET();
+
+		success = nmbm_write_info_table(ni, write_ba,
+						ni->mapping_blocks_top_ba,
+						&table_start_ba,
+						&table_end_ba);
+		if (success)
+			break;
+
+		write_ba--;
+	}
+
+	if (success) {
+		/* Erase spare blocks of main table to clean possible interference data */
+		nmbm_erase_range(ni, ni->mapping_blocks_ba, table_start_ba);
+
+		/* New table becomes the backup table */
+		ni->backup_table_ba = table_start_ba;
+		ni->mapping_blocks_ba = table_end_ba;
+
+		nmbm_mark_tables_clean(ni);
+
+		nlog_table_creation(ni, false, table_start_ba, table_end_ba);
+
+		return true;
+	}
+
+	nlog_warn(ni, "Failed to rescue single info table\n");
+	return false;
+}
+
+/*
+ * nmbm_update_single_info_table - Update specific one info table
+ * @ni: NMBM instance structure
+ */
+static bool nmbm_update_single_info_table(struct nmbm_instance *ni,
+					  bool update_main_table)
+{
+	uint32_t write_start_ba, write_limit, table_start_ba, table_end_ba;
+	bool success;
+
+	/* Determine the write range */
+	if (update_main_table) {
+		write_start_ba = ni->main_table_ba;
+		write_limit = ni->backup_table_ba;
+	} else {
+		write_start_ba = ni->backup_table_ba;
+		write_limit = ni->mapping_blocks_top_ba;
+	}
+
+	nmbm_mark_block_color_mgmt(ni, write_start_ba, write_limit - 1);
+
+	success = nmbm_write_info_table(ni, write_start_ba, write_limit,
+					&table_start_ba, &table_end_ba);
+	if (success) {
+		if (update_main_table) {
+			ni->main_table_ba = table_start_ba;
+		} else {
+			ni->backup_table_ba = table_start_ba;
+			ni->mapping_blocks_ba = table_end_ba;
+		}
+
+		nmbm_mark_tables_clean(ni);
+
+		nlog_table_update(ni, update_main_table, table_start_ba,
+				 table_end_ba);
+
+		return true;
+	}
+
+	if (update_main_table) {
+		/*
+		 * If failed to update main table, make backup table the new
+		 * main table, and call nmbm_rescue_single_info_table()
+		 */
+		nlog_warn(ni, "Unable to update %s info table\n",
+			 update_main_table ? "Main" : "Backup");
+
+		ni->main_table_ba = ni->backup_table_ba;
+		ni->backup_table_ba = 0;
+		return nmbm_rescue_single_info_table(ni);
+	}
+
+	/* Only one table left */
+	ni->mapping_blocks_ba = ni->backup_table_ba;
+	ni->backup_table_ba = 0;
+
+	return false;
+}
+
+/*
+ * nmbm_rescue_main_info_table - Rescue when failed to write main info table
+ * @ni: NMBM instance structure
+ *
+ * This function is called when main info table failed to be written, and
+ *    backup info table exists.
+ */
+static bool nmbm_rescue_main_info_table(struct nmbm_instance *ni)
+{
+	uint32_t tmp_table_start_ba, tmp_table_end_ba, main_table_start_ba;
+	uint32_t main_table_end_ba, write_ba;
+	uint32_t info_table_erasesize = size2blk(ni, ni->info_table_size);
+	bool success;
+
+	/* Try to reserve spare blocks for existing backup info table */
+	success = nmbm_try_reserve_blocks(ni, ni->mapping_blocks_ba, &write_ba,
+					  ni->info_table_spare_blocks, 0,
+					  ni->mapping_blocks_top_ba -
+					  info_table_erasesize);
+	if (!success) {
+		/* There is no spare block. Backup info table becomes the main table. */
+		nlog_err(ni, "No room for temporary info table\n");
+		ni->main_table_ba = ni->backup_table_ba;
+		ni->backup_table_ba = 0;
+		return true;
+	}
+
+	/* Try to write temporary info table into spare unmapped blocks */
+	while (write_ba >= ni->mapping_blocks_ba) {
+		WATCHDOG_RESET();
+
+		success = nmbm_write_info_table(ni, write_ba,
+						ni->mapping_blocks_top_ba,
+						&tmp_table_start_ba,
+						&tmp_table_end_ba);
+		if (success)
+			break;
+
+		write_ba--;
+	}
+
+	if (!success) {
+		/* Backup info table becomes the main table */
+		nlog_err(ni, "Failed to update main info table\n");
+		ni->main_table_ba = ni->backup_table_ba;
+		ni->backup_table_ba = 0;
+		return true;
+	}
+
+	/* Adjust mapping_blocks_off */
+	ni->mapping_blocks_ba = tmp_table_end_ba;
+
+	nmbm_mark_block_color_mgmt(ni, ni->backup_table_ba,
+				   tmp_table_end_ba - 1);
+
+	/*
+	 * Now write main info table at the beginning of management area.
+	 * This operation will generally destroy the original backup info
+	 * table.
+	 */
+	success = nmbm_write_info_table(ni, ni->mgmt_start_ba,
+					tmp_table_start_ba,
+					&main_table_start_ba,
+					&main_table_end_ba);
+	if (!success) {
+		/* Temporary info table becomes the main table */
+		ni->main_table_ba = tmp_table_start_ba;
+		ni->backup_table_ba = 0;
+
+		nmbm_mark_tables_clean(ni);
+
+		nlog_err(ni, "Failed to update main info table\n");
+		nmbm_mark_block_color_info_table(ni, tmp_table_start_ba,
+						 tmp_table_end_ba - 1);
+
+		return true;
+	}
+
+	/* Main info table has been successfully written, record its offset */
+	ni->main_table_ba = main_table_start_ba;
+
+	nmbm_mark_tables_clean(ni);
+
+	nlog_table_creation(ni, true, main_table_start_ba, main_table_end_ba);
+
+	/*
+	 * Temporary info table becomes the new backup info table if it's
+	 * not overwritten.
+	 */
+	if (main_table_end_ba <= tmp_table_start_ba) {
+		ni->backup_table_ba = tmp_table_start_ba;
+
+		nlog_table_creation(ni, false, tmp_table_start_ba,
+				   tmp_table_end_ba);
+
+		return true;
+	}
+
+	/* Adjust mapping_blocks_off */
+	ni->mapping_blocks_ba = main_table_end_ba;
+
+	/* Try to reserve spare blocks for new main info table */
+	success = nmbm_try_reserve_blocks(ni, main_table_end_ba, &write_ba,
+					  ni->info_table_spare_blocks, 0,
+					  ni->mapping_blocks_top_ba -
+					  info_table_erasesize);
+	if (!success) {
+		/* There is no spare block. Only main table exists. */
+		nlog_err(ni, "No room for backup info table\n");
+		ni->backup_table_ba = 0;
+		return true;
+	}
+
+	/* Write new backup info table. */
+	while (write_ba >= main_table_end_ba) {
+		WATCHDOG_RESET();
+
+		success = nmbm_write_info_table(ni, write_ba,
+						ni->mapping_blocks_top_ba,
+						&tmp_table_start_ba,
+						&tmp_table_end_ba);
+		if (success)
+			break;
+
+		write_ba--;
+	}
+
+	if (!success) {
+		nlog_err(ni, "No room for backup info table\n");
+		ni->backup_table_ba = 0;
+		return true;
+	}
+
+	/* Backup info table has been successfully written, record its offset */
+	ni->backup_table_ba = tmp_table_start_ba;
+
+	/* Adjust mapping_blocks_off */
+	ni->mapping_blocks_ba = tmp_table_end_ba;
+
+	/* Erase spare blocks of main table to clean possible interference data */
+	nmbm_erase_range(ni, main_table_end_ba, ni->backup_table_ba);
+
+	nlog_table_creation(ni, false, tmp_table_start_ba, tmp_table_end_ba);
+
+	return true;
+}
+
+/*
+ * nmbm_update_info_table_once - Update info table once
+ * @ni: NMBM instance structure
+ * @force: force update
+ *
+ * Update both main and backup info table. Return true if at least one info
+ * table has been successfully written.
+ * This function only try to update info table once regard less of the result.
+ */
+static bool nmbm_update_info_table_once(struct nmbm_instance *ni, bool force)
+{
+	uint32_t table_start_ba, table_end_ba;
+	uint32_t main_table_limit;
+	bool success;
+
+	/* Do nothing if there is no change */
+	if (!nmbm_generate_info_table_cache(ni) && !force)
+		return true;
+
+	/* Check whether both two tables exist */
+	if (!ni->backup_table_ba) {
+		main_table_limit = ni->mapping_blocks_top_ba;
+		goto write_main_table;
+	}
+
+	nmbm_mark_block_color_mgmt(ni, ni->backup_table_ba,
+				   ni->mapping_blocks_ba - 1);
+
+	/*
+	 * Write backup info table in its current range.
+	 * Note that limit is set to mapping_blocks_top_off to provide as many
+	 * spare blocks as possible for the backup table. If at last
+	 * unmapped blocks are used by backup table, mapping_blocks_off will
+	 * be adjusted.
+	 */
+	success = nmbm_write_info_table(ni, ni->backup_table_ba,
+					ni->mapping_blocks_top_ba,
+					&table_start_ba, &table_end_ba);
+	if (!success) {
+		/*
+		 * There is nothing to do if failed to write backup table.
+		 * Write the main table now.
+		 */
+		nlog_err(ni, "No room for backup table\n");
+		ni->mapping_blocks_ba = ni->backup_table_ba;
+		ni->backup_table_ba = 0;
+		main_table_limit = ni->mapping_blocks_top_ba;
+		goto write_main_table;
+	}
+
+	/* Backup table is successfully written, record its offset */
+	ni->backup_table_ba = table_start_ba;
+
+	/* Adjust mapping_blocks_off */
+	ni->mapping_blocks_ba = table_end_ba;
+
+	nmbm_mark_tables_clean(ni);
+
+	/* The normal limit of main table */
+	main_table_limit = ni->backup_table_ba;
+
+	nlog_table_update(ni, false, table_start_ba, table_end_ba);
+
+write_main_table:
+	if (!ni->main_table_ba)
+		goto rebuild_tables;
+
+	if (!ni->backup_table_ba)
+		nmbm_mark_block_color_mgmt(ni, ni->mgmt_start_ba,
+					   ni->mapping_blocks_ba - 1);
+	else
+		nmbm_mark_block_color_mgmt(ni, ni->mgmt_start_ba,
+					   ni->backup_table_ba - 1);
+
+	/* Write main info table in its current range */
+	success = nmbm_write_info_table(ni, ni->main_table_ba,
+					main_table_limit, &table_start_ba,
+					&table_end_ba);
+	if (!success) {
+		/* If failed to write main table, go rescue procedure */
+		if (!ni->backup_table_ba)
+			goto rebuild_tables;
+
+		return nmbm_rescue_main_info_table(ni);
+	}
+
+	/* Main info table is successfully written, record its offset */
+	ni->main_table_ba = table_start_ba;
+
+	/* Adjust mapping_blocks_off */
+	if (!ni->backup_table_ba)
+		ni->mapping_blocks_ba = table_end_ba;
+
+	nmbm_mark_tables_clean(ni);
+
+	nlog_table_update(ni, true, table_start_ba, table_end_ba);
+
+	return true;
+
+rebuild_tables:
+	return nmbm_rebuild_info_table(ni);
+}
+
+/*
+ * nmbm_update_info_table - Update info table
+ * @ni: NMBM instance structure
+ *
+ * Update both main and backup info table. Return true if at least one table
+ * has been successfully written.
+ * This function will try to update info table repeatedly until no new bad
+ * block found during updating.
+ */
+static bool nmbm_update_info_table(struct nmbm_instance *ni)
+{
+	bool success;
+
+	if (ni->protected)
+		return true;
+
+	while (ni->block_state_changed || ni->block_mapping_changed) {
+		success = nmbm_update_info_table_once(ni, false);
+		if (!success) {
+			nlog_err(ni, "Failed to update info table\n");
+			return false;
+		}
+	}
+
+	return true;
+}
+
+/*
+ * nmbm_map_block - Map a bad block to a unused spare block
+ * @ni: NMBM instance structure
+ * @lb: logic block addr to map
+ */
+static bool nmbm_map_block(struct nmbm_instance *ni, uint32_t lb)
+{
+	uint32_t pb;
+	bool success;
+
+	if (ni->mapping_blocks_ba == ni->mapping_blocks_top_ba) {
+		nlog_warn(ni, "No spare unmapped blocks.\n");
+		return false;
+	}
+
+	success = nmbm_block_walk(ni, false, ni->mapping_blocks_top_ba, &pb, 0,
+				  ni->mapping_blocks_ba);
+	if (!success) {
+		nlog_warn(ni, "No spare unmapped blocks.\n");
+		nmbm_update_info_table(ni);
+		ni->mapping_blocks_top_ba = ni->mapping_blocks_ba;
+		return false;
+	}
+
+	ni->block_mapping[lb] = pb;
+	ni->mapping_blocks_top_ba--;
+	ni->block_mapping_changed++;
+
+	nlog_info(ni, "Logic block %u mapped to physical blcok %u\n", lb, pb);
+	nmbm_mark_block_color_mapped(ni, pb);
+
+	return true;
+}
+
+/*
+ * nmbm_create_info_table - Create info table(s)
+ * @ni: NMBM instance structure
+ *
+ * This function assumes that the chip has no existing info table(s)
+ */
+static bool nmbm_create_info_table(struct nmbm_instance *ni)
+{
+	uint32_t lb;
+	bool success;
+
+	/* Set initial mapping_blocks_top_off  */
+	success = nmbm_block_walk(ni, false, ni->signature_ba,
+				  &ni->mapping_blocks_top_ba, 1,
+				  ni->mgmt_start_ba);
+	if (!success) {
+		nlog_err(ni, "No room for spare blocks\n");
+		return false;
+	}
+
+	/* Generate info table cache */
+	nmbm_generate_info_table_cache(ni);
+
+	/* Write info table */
+	success = nmbm_rebuild_info_table(ni);
+	if (!success) {
+		nlog_err(ni, "Failed to build info tables\n");
+		return false;
+	}
+
+	/* Remap bad block(s) at end of data area */
+	for (lb = ni->data_block_count; lb < ni->mgmt_start_ba; lb++) {
+		success = nmbm_map_block(ni, lb);
+		if (!success)
+			break;
+
+		ni->data_block_count++;
+	}
+
+	/* If state table and/or mapping table changed, update info table. */
+	success = nmbm_update_info_table(ni);
+	if (!success)
+		return false;
+
+	return true;
+}
+
+/*
+ * nmbm_create_new - Create NMBM on a new chip
+ * @ni: NMBM instance structure
+ */
+static bool nmbm_create_new(struct nmbm_instance *ni)
+{
+	bool success;
+
+	/* Determine the boundary of management blocks */
+	ni->mgmt_start_ba = ni->block_count * (NMBM_MGMT_DIV - ni->lower.max_ratio) / NMBM_MGMT_DIV;
+
+	if (ni->lower.max_reserved_blocks && ni->block_count - ni->mgmt_start_ba > ni->lower.max_reserved_blocks)
+		ni->mgmt_start_ba = ni->block_count - ni->lower.max_reserved_blocks;
+
+	nlog_info(ni, "NMBM management region starts at block %u [0x%08llx]\n",
+		  ni->mgmt_start_ba, ba2addr(ni, ni->mgmt_start_ba));
+	nmbm_mark_block_color_mgmt(ni, ni->mgmt_start_ba, ni->block_count - 1);
+
+	/* Fill block state table & mapping table */
+	nmbm_scan_badblocks(ni);
+	nmbm_build_mapping_table(ni);
+
+	/* Write signature */
+	ni->signature.header.magic = NMBM_MAGIC_SIGNATURE;
+	ni->signature.header.version = NMBM_VER;
+	ni->signature.header.size = sizeof(ni->signature);
+	ni->signature.nand_size = ni->lower.size;
+	ni->signature.block_size = ni->lower.erasesize;
+	ni->signature.page_size = ni->lower.writesize;
+	ni->signature.spare_size = ni->lower.oobsize;
+	ni->signature.mgmt_start_pb = ni->mgmt_start_ba;
+	ni->signature.max_try_count = NMBM_TRY_COUNT;
+	nmbm_update_checksum(&ni->signature.header);
+
+	success = nmbm_write_signature(ni, ni->mgmt_start_ba,
+				       &ni->signature, &ni->signature_ba);
+	if (!success) {
+		nlog_err(ni, "Failed to write signature to a proper offset\n");
+		return false;
+	}
+
+	nlog_info(ni, "Signature has been written to block %u [0x%08llx]\n",
+		 ni->signature_ba, ba2addr(ni, ni->signature_ba));
+	nmbm_mark_block_color_signature(ni, ni->signature_ba);
+
+	/* Write info table(s) */
+	success = nmbm_create_info_table(ni);
+	if (success) {
+		nlog_info(ni, "NMBM has been successfully created\n");
+		return true;
+	}
+
+	return false;
+}
+
+/*
+ * nmbm_check_info_table_header - Check if a info table header is valid
+ * @ni: NMBM instance structure
+ * @data: pointer to the info table header
+ */
+static bool nmbm_check_info_table_header(struct nmbm_instance *ni, void *data)
+{
+	struct nmbm_info_table_header *ifthdr = data;
+
+	if (ifthdr->header.magic != NMBM_MAGIC_INFO_TABLE)
+		return false;
+
+	if (ifthdr->header.size != ni->info_table_size)
+		return false;
+
+	if (ifthdr->mapping_table_off - ifthdr->state_table_off < ni->state_table_size)
+		return false;
+
+	if (ni->info_table_size - ifthdr->mapping_table_off < ni->mapping_table_size)
+		return false;
+
+	return true;
+}
+
+/*
+ * nmbm_check_info_table - Check if a whole info table is valid
+ * @ni: NMBM instance structure
+ * @start_ba: start block address of this table
+ * @end_ba: end block address of this table
+ * @data: pointer to the info table header
+ * @mapping_blocks_top_ba: return the block address of top remapped block
+ */
+static bool nmbm_check_info_table(struct nmbm_instance *ni, uint32_t start_ba,
+				  uint32_t end_ba, void *data,
+				  uint32_t *mapping_blocks_top_ba)
+{
+	struct nmbm_info_table_header *ifthdr = data;
+	int32_t *block_mapping = (int32_t *)((uintptr_t)data + ifthdr->mapping_table_off);
+	nmbm_bitmap_t *block_state = (nmbm_bitmap_t *)((uintptr_t)data + ifthdr->state_table_off);
+	uint32_t minimum_mapping_pb = ni->signature_ba;
+	uint32_t ba;
+
+	for (ba = 0; ba < ni->data_block_count; ba++) {
+		if ((block_mapping[ba] >= ni->data_block_count && block_mapping[ba] < end_ba) ||
+		    block_mapping[ba] == ni->signature_ba)
+			return false;
+
+		if (block_mapping[ba] >= end_ba && block_mapping[ba] < minimum_mapping_pb)
+			minimum_mapping_pb = block_mapping[ba];
+	}
+
+	for (ba = start_ba; ba < end_ba; ba++) {
+		if (nmbm_get_block_state(ni, ba) != BLOCK_ST_GOOD)
+			continue;
+
+		if (nmbm_get_block_state_raw(block_state, ba) != BLOCK_ST_GOOD)
+			return false;
+	}
+
+	*mapping_blocks_top_ba = minimum_mapping_pb - 1;
+
+	return true;
+}
+
+/*
+ * nmbm_try_load_info_table - Try to load info table from a address
+ * @ni: NMBM instance structure
+ * @ba: start block address of the info table
+ * @eba: return the block address after end of the table
+ * @write_count: return the write count of this table
+ * @mapping_blocks_top_ba: return the block address of top remapped block
+ * @table_loaded: used to record whether ni->info_table has valid data
+ */
+static bool nmbm_try_load_info_table(struct nmbm_instance *ni, uint32_t ba,
+				     uint32_t *eba, uint32_t *write_count,
+				     uint32_t *mapping_blocks_top_ba,
+				     bool table_loaded)
+{
+	struct nmbm_info_table_header *ifthdr = (void *)ni->info_table_cache;
+	uint8_t *off = ni->info_table_cache;
+	uint32_t limit = ba + size2blk(ni, ni->info_table_size);
+	uint32_t start_ba = 0, chunksize, sizeremain = ni->info_table_size;
+	bool success, checkhdr = true;
+	int ret;
+
+	while (sizeremain && ba < limit) {
+		WATCHDOG_RESET();
+
+		if (nmbm_get_block_state(ni, ba) != BLOCK_ST_GOOD)
+			goto next_block;
+
+		if (nmbm_check_bad_phys_block(ni, ba)) {
+			nmbm_set_block_state(ni, ba, BLOCK_ST_BAD);
+			goto next_block;
+		}
+
+		chunksize = sizeremain;
+		if (chunksize > ni->lower.erasesize)
+			chunksize = ni->lower.erasesize;
+
+		/* Assume block with ECC error has no info table data */
+		ret = nmbn_read_data(ni, ba2addr(ni, ba), off, chunksize);
+		if (ret < 0)
+			goto skip_bad_block;
+		else if (ret > 0)
+			return false;
+
+		if (checkhdr) {
+			success = nmbm_check_info_table_header(ni, off);
+			if (!success)
+				return false;
+
+			start_ba = ba;
+			checkhdr = false;
+		}
+
+		off += chunksize;
+		sizeremain -= chunksize;
+
+		goto next_block;
+
+	skip_bad_block:
+		/* Only mark bad in memory */
+		nmbm_set_block_state(ni, ba, BLOCK_ST_BAD);
+
+	next_block:
+		ba++;
+	}
+
+	if (sizeremain)
+		return false;
+
+	success = nmbm_check_header(ni->info_table_cache, ni->info_table_size);
+	if (!success)
+		return false;
+
+	*eba = ba;
+	*write_count = ifthdr->write_count;
+
+	success = nmbm_check_info_table(ni, start_ba, ba, ni->info_table_cache,
+					mapping_blocks_top_ba);
+	if (!success)
+		return false;
+
+	if (!table_loaded || ifthdr->write_count > ni->info_table.write_count) {
+		memcpy(&ni->info_table, ifthdr, sizeof(ni->info_table));
+		memcpy(ni->block_state,
+		       (uint8_t *)ifthdr + ifthdr->state_table_off,
+		       ni->state_table_size);
+		memcpy(ni->block_mapping,
+		       (uint8_t *)ifthdr + ifthdr->mapping_table_off,
+		       ni->mapping_table_size);
+		ni->info_table.write_count = ifthdr->write_count;
+	}
+
+	return true;
+}
+
+/*
+ * nmbm_search_info_table - Search info table from specific address
+ * @ni: NMBM instance structure
+ * @ba: start block address to search
+ * @limit: highest block address allowed for searching
+ * @table_start_ba: return the start block address of this table
+ * @table_end_ba: return the block address after end of this table
+ * @write_count: return the write count of this table
+ * @mapping_blocks_top_ba: return the block address of top remapped block
+ * @table_loaded: used to record whether ni->info_table has valid data
+ */
+static bool nmbm_search_info_table(struct nmbm_instance *ni, uint32_t ba,
+				   uint32_t limit, uint32_t *table_start_ba,
+				   uint32_t *table_end_ba,
+				   uint32_t *write_count,
+				   uint32_t *mapping_blocks_top_ba,
+				   bool table_loaded)
+{
+	bool success;
+
+	while (ba < limit - size2blk(ni, ni->info_table_size)) {
+		WATCHDOG_RESET();
+
+		success = nmbm_try_load_info_table(ni, ba, table_end_ba,
+						   write_count,
+						   mapping_blocks_top_ba,
+						   table_loaded);
+		if (success) {
+			*table_start_ba = ba;
+			return true;
+		}
+
+		ba++;
+	}
+
+	return false;
+}
+
+/*
+ * nmbm_load_info_table - Load info table(s) from a chip
+ * @ni: NMBM instance structure
+ * @ba: start block address to search info table
+ * @limit: highest block address allowed for searching
+ */
+static bool nmbm_load_info_table(struct nmbm_instance *ni, uint32_t ba,
+				 uint32_t limit)
+{
+	uint32_t main_table_end_ba, backup_table_end_ba, table_end_ba;
+	uint32_t main_mapping_blocks_top_ba, backup_mapping_blocks_top_ba;
+	uint32_t main_table_write_count, backup_table_write_count;
+	uint32_t i;
+	bool success;
+
+	/* Set initial value */
+	ni->main_table_ba = 0;
+	ni->backup_table_ba = 0;
+	ni->info_table.write_count = 0;
+	ni->mapping_blocks_top_ba = ni->signature_ba - 1;
+	ni->data_block_count = ni->signature.mgmt_start_pb;
+
+	/* Find first info table */
+	success = nmbm_search_info_table(ni, ba, limit, &ni->main_table_ba,
+		&main_table_end_ba, &main_table_write_count,
+		&main_mapping_blocks_top_ba, false);
+	if (!success) {
+		nlog_warn(ni, "No valid info table found\n");
+		return false;
+	}
+
+	table_end_ba = main_table_end_ba;
+
+	nlog_table_found(ni, true, main_table_write_count, ni->main_table_ba,
+			main_table_end_ba);
+
+	/* Find second info table */
+	success = nmbm_search_info_table(ni, main_table_end_ba, limit,
+		&ni->backup_table_ba, &backup_table_end_ba,
+		&backup_table_write_count, &backup_mapping_blocks_top_ba, true);
+	if (!success) {
+		nlog_warn(ni, "Second info table not found\n");
+	} else {
+		table_end_ba = backup_table_end_ba;
+
+		nlog_table_found(ni, false, backup_table_write_count,
+				ni->backup_table_ba, backup_table_end_ba);
+	}
+
+	/* Pick mapping_blocks_top_ba */
+	if (!ni->backup_table_ba) {
+		ni->mapping_blocks_top_ba= main_mapping_blocks_top_ba;
+	} else {
+		if (main_table_write_count >= backup_table_write_count)
+			ni->mapping_blocks_top_ba = main_mapping_blocks_top_ba;
+		else
+			ni->mapping_blocks_top_ba = backup_mapping_blocks_top_ba;
+	}
+
+	/* Set final mapping_blocks_ba */
+	ni->mapping_blocks_ba = table_end_ba;
+
+	/* Set final data_block_count */
+	for (i = ni->signature.mgmt_start_pb; i > 0; i--) {
+		if (ni->block_mapping[i - 1] >= 0) {
+			ni->data_block_count = i;
+			break;
+		}
+	}
+
+	/* Debug purpose: mark mapped blocks and bad blocks */
+	for (i = 0; i < ni->data_block_count; i++) {
+		if (ni->block_mapping[i] > ni->mapping_blocks_top_ba)
+			nmbm_mark_block_color_mapped(ni, ni->block_mapping[i]);
+	}
+
+	for (i = 0; i < ni->block_count; i++) {
+		if (nmbm_get_block_state(ni, i) == BLOCK_ST_BAD)
+			nmbm_mark_block_color_bad(ni, i);
+	}
+
+	/* Regenerate the info table cache from the final selected info table */
+	nmbm_generate_info_table_cache(ni);
+
+	/*
+	 * If only one table exists, try to write another table.
+	 * If two tables have different write count, try to update info table
+	 */
+	if (!ni->backup_table_ba) {
+		success = nmbm_rescue_single_info_table(ni);
+	} else if (main_table_write_count != backup_table_write_count) {
+		/* Mark state & mapping tables changed */
+		ni->block_state_changed = 1;
+		ni->block_mapping_changed = 1;
+
+		success = nmbm_update_single_info_table(ni,
+			main_table_write_count < backup_table_write_count);
+	} else {
+		success = true;
+	}
+
+	/*
+	 * If there is no spare unmapped blocks, or still only one table
+	 * exists, set the chip to read-only
+	 */
+	if (ni->mapping_blocks_ba == ni->mapping_blocks_top_ba) {
+		nlog_warn(ni, "No spare unmapped blocks. Device is now read-only\n");
+		ni->protected = 1;
+	} else if (!success) {
+		nlog_warn(ni, "Only one info table found. Device is now read-only\n");
+		ni->protected = 1;
+	}
+
+	return true;
+}
+
+/*
+ * nmbm_load_existing - Load NMBM from a new chip
+ * @ni: NMBM instance structure
+ */
+static bool nmbm_load_existing(struct nmbm_instance *ni)
+{
+	bool success;
+
+	/* Calculate the boundary of management blocks */
+	ni->mgmt_start_ba = ni->signature.mgmt_start_pb;
+
+	nlog_debug(ni, "NMBM management region starts at block %u [0x%08llx]\n",
+		  ni->mgmt_start_ba, ba2addr(ni, ni->mgmt_start_ba));
+	nmbm_mark_block_color_mgmt(ni, ni->mgmt_start_ba,
+				   ni->signature_ba - 1);
+
+	/* Look for info table(s) */
+	success = nmbm_load_info_table(ni, ni->mgmt_start_ba,
+		ni->signature_ba);
+	if (success) {
+		nlog_info(ni, "NMBM has been successfully attached\n");
+		return true;
+	}
+
+	if (!(ni->lower.flags & NMBM_F_CREATE))
+		return false;
+
+	/* Fill block state table & mapping table */
+	nmbm_scan_badblocks(ni);
+	nmbm_build_mapping_table(ni);
+
+	/* Write info table(s) */
+	success = nmbm_create_info_table(ni);
+	if (success) {
+		nlog_info(ni, "NMBM has been successfully created\n");
+		return true;
+	}
+
+	return false;
+}
+
+/*
+ * nmbm_find_signature - Find signature in the lower NAND chip
+ * @ni: NMBM instance structure
+ * @signature_ba: used for storing block address of the signature
+ * @signature_ba: return the actual block address of signature block
+ *
+ * Find a valid signature from a specific range in the lower NAND chip,
+ * from bottom (highest address) to top (lowest address)
+ *
+ * Return true if found.
+ */
+static bool nmbm_find_signature(struct nmbm_instance *ni,
+				struct nmbm_signature *signature,
+				uint32_t *signature_ba)
+{
+	struct nmbm_signature sig;
+	uint64_t off, addr;
+	uint32_t block_count, ba, limit;
+	bool success;
+	int ret;
+
+	/* Calculate top and bottom block address */
+	block_count = ni->lower.size >> ni->erasesize_shift;
+	ba = block_count;
+	limit = (block_count / NMBM_MGMT_DIV) * (NMBM_MGMT_DIV - ni->lower.max_ratio);
+	if (ni->lower.max_reserved_blocks && block_count - limit > ni->lower.max_reserved_blocks)
+		limit = block_count - ni->lower.max_reserved_blocks;
+
+	while (ba >= limit) {
+		WATCHDOG_RESET();
+
+		ba--;
+		addr = ba2addr(ni, ba);
+
+		if (nmbm_check_bad_phys_block(ni, ba))
+			continue;
+
+		/* Check every page.
+		 * As long as at leaset one page contains valid signature,
+		 * the block is treated as a valid signature block.
+		 */
+		for (off = 0; off < ni->lower.erasesize;
+		     off += ni->lower.writesize) {
+			WATCHDOG_RESET();
+
+			ret = nmbn_read_data(ni, addr + off, &sig,
+					     sizeof(sig));
+			if (ret)
+				continue;
+
+			/* Check for header size and checksum */
+			success = nmbm_check_header(&sig, sizeof(sig));
+			if (!success)
+				continue;
+
+			/* Check for header magic */
+			if (sig.header.magic == NMBM_MAGIC_SIGNATURE) {
+				/* Found it */
+				memcpy(signature, &sig, sizeof(sig));
+				*signature_ba = ba;
+				return true;
+			}
+		}
+	};
+
+	return false;
+}
+
+/*
+ * is_power_of_2_u64 - Check whether a 64-bit integer is power of 2
+ * @n: number to check
+ */
+static bool is_power_of_2_u64(uint64_t n)
+{
+	return (n != 0 && ((n & (n - 1)) == 0));
+}
+
+/*
+ * nmbm_check_lower_members - Validate the members of lower NAND device
+ * @nld: Lower NAND chip structure
+ */
+static bool nmbm_check_lower_members(struct nmbm_lower_device *nld)
+{
+
+	if (!nld->size || !is_power_of_2_u64(nld->size)) {
+		nmbm_log_lower(nld, NMBM_LOG_ERR,
+			       "Chip size %llu is not valid\n", nld->size);
+		return false;
+	}
+
+	if (!nld->erasesize || !is_power_of_2(nld->erasesize)) {
+		nmbm_log_lower(nld, NMBM_LOG_ERR,
+			       "Block size %u is not valid\n", nld->erasesize);
+		return false;
+	}
+
+	if (!nld->writesize || !is_power_of_2(nld->writesize)) {
+		nmbm_log_lower(nld, NMBM_LOG_ERR,
+			       "Page size %u is not valid\n", nld->writesize);
+		return false;
+	}
+
+	if (!nld->oobsize || !is_power_of_2(nld->oobsize)) {
+		nmbm_log_lower(nld, NMBM_LOG_ERR,
+			       "Page spare size %u is not valid\n", nld->oobsize);
+		return false;
+	}
+
+	if (!nld->read_page || !nld->write_page || !nld->erase_block) {
+		nmbm_log_lower(nld, NMBM_LOG_ERR,
+			       "read_page(), write_page() and erase_block() are required\n");
+		return false;
+	}
+
+	/* Data sanity check */
+	if (!nld->max_ratio)
+		nld->max_ratio = 1;
+
+	if (nld->max_ratio >= NMBM_MGMT_DIV - 1) {
+		nmbm_log_lower(nld, NMBM_LOG_ERR,
+			       "max ratio %u is invalid\n", nld->max_ratio);
+		return false;
+	}
+
+	if (nld->max_reserved_blocks && nld->max_reserved_blocks < NMBM_MGMT_BLOCKS_MIN) {
+		nmbm_log_lower(nld, NMBM_LOG_ERR,
+			       "max reserved blocks %u is too small\n", nld->max_reserved_blocks);
+		return false;
+	}
+
+	return true;
+}
+
+/*
+ * nmbm_calc_structure_size - Calculate the instance structure size
+ * @nld: NMBM lower device structure
+ */
+size_t nmbm_calc_structure_size(struct nmbm_lower_device *nld)
+{
+	uint32_t state_table_size, mapping_table_size, info_table_size;
+	uint32_t block_count;
+
+	block_count = nmbm_lldiv(nld->size, nld->erasesize);
+
+	/* Calculate info table size */
+	state_table_size = ((block_count + NMBM_BITMAP_BLOCKS_PER_UNIT - 1) /
+		NMBM_BITMAP_BLOCKS_PER_UNIT) * NMBM_BITMAP_UNIT_SIZE;
+	mapping_table_size = block_count * sizeof(int32_t);
+
+	info_table_size = NMBM_ALIGN(sizeof(struct nmbm_info_table_header),
+				     nld->writesize);
+	info_table_size += NMBM_ALIGN(state_table_size, nld->writesize);
+	info_table_size += NMBM_ALIGN(mapping_table_size, nld->writesize);
+
+	return info_table_size + state_table_size + mapping_table_size +
+		nld->writesize + nld->oobsize + sizeof(struct nmbm_instance);
+}
+
+/*
+ * nmbm_init_structure - Initialize members of instance structure
+ * @ni: NMBM instance structure
+ */
+static void nmbm_init_structure(struct nmbm_instance *ni)
+{
+	uint32_t pages_per_block, blocks_per_chip;
+	uintptr_t ptr;
+
+	pages_per_block = ni->lower.erasesize / ni->lower.writesize;
+	blocks_per_chip = nmbm_lldiv(ni->lower.size, ni->lower.erasesize);
+
+	ni->rawpage_size = ni->lower.writesize + ni->lower.oobsize;
+	ni->rawblock_size = pages_per_block * ni->rawpage_size;
+	ni->rawchip_size = blocks_per_chip * ni->rawblock_size;
+
+	ni->writesize_mask = ni->lower.writesize - 1;
+	ni->erasesize_mask = ni->lower.erasesize - 1;
+
+	ni->writesize_shift = ffs(ni->lower.writesize) - 1;
+	ni->erasesize_shift = ffs(ni->lower.erasesize) - 1;
+
+	/* Calculate number of block this chip */
+	ni->block_count = ni->lower.size >> ni->erasesize_shift;
+
+	/* Calculate info table size */
+	ni->state_table_size = ((ni->block_count + NMBM_BITMAP_BLOCKS_PER_UNIT - 1) /
+		NMBM_BITMAP_BLOCKS_PER_UNIT) * NMBM_BITMAP_UNIT_SIZE;
+	ni->mapping_table_size = ni->block_count * sizeof(*ni->block_mapping);
+
+	ni->info_table_size = NMBM_ALIGN(sizeof(ni->info_table),
+					 ni->lower.writesize);
+	ni->info_table.state_table_off = ni->info_table_size;
+
+	ni->info_table_size += NMBM_ALIGN(ni->state_table_size,
+					  ni->lower.writesize);
+	ni->info_table.mapping_table_off = ni->info_table_size;
+
+	ni->info_table_size += NMBM_ALIGN(ni->mapping_table_size,
+					  ni->lower.writesize);
+
+	ni->info_table_spare_blocks = nmbm_get_spare_block_count(
+		size2blk(ni, ni->info_table_size));
+
+	/* Assign memory to members */
+	ptr = (uintptr_t)ni + sizeof(*ni);
+
+	ni->info_table_cache = (void *)ptr;
+	ptr += ni->info_table_size;
+
+	ni->block_state = (void *)ptr;
+	ptr += ni->state_table_size;
+
+	ni->block_mapping = (void *)ptr;
+	ptr += ni->mapping_table_size;
+
+	ni->page_cache = (uint8_t *)ptr;
+
+	/* Initialize block state table */
+	ni->block_state_changed = 0;
+	memset(ni->block_state, 0xff, ni->state_table_size);
+
+	/* Initialize block mapping table */
+	ni->block_mapping_changed = 0;
+}
+
+/*
+ * nmbm_attach - Attach to a lower device
+ * @nld: NMBM lower device structure
+ * @ni: NMBM instance structure
+ */
+int nmbm_attach(struct nmbm_lower_device *nld, struct nmbm_instance *ni)
+{
+	bool success;
+
+	if (!nld || !ni)
+		return -EINVAL;
+
+	/* Set default log level */
+	ni->log_display_level = NMBM_DEFAULT_LOG_LEVEL;
+
+	/* Check lower members */
+	success = nmbm_check_lower_members(nld);
+	if (!success)
+		return -EINVAL;
+
+	/* Initialize NMBM instance */
+	memcpy(&ni->lower, nld, sizeof(struct nmbm_lower_device));
+	nmbm_init_structure(ni);
+
+	success = nmbm_find_signature(ni, &ni->signature, &ni->signature_ba);
+	if (!success) {
+		if (!(nld->flags & NMBM_F_CREATE)) {
+			nlog_err(ni, "Signature not found\n");
+			return -ENODEV;
+		}
+
+		success = nmbm_create_new(ni);
+		if (!success)
+			return -ENODEV;
+
+		return 0;
+	}
+
+	nlog_info(ni, "Signature found at block %u [0x%08llx]\n",
+		 ni->signature_ba, ba2addr(ni, ni->signature_ba));
+	nmbm_mark_block_color_signature(ni, ni->signature_ba);
+
+	if (ni->signature.header.version != NMBM_VER) {
+		nlog_err(ni, "NMBM version %u.%u is not supported\n",
+			NMBM_VERSION_MAJOR_GET(ni->signature.header.version),
+			NMBM_VERSION_MINOR_GET(ni->signature.header.version));
+		return -EINVAL;
+	}
+
+	if (ni->signature.nand_size != nld->size ||
+	    ni->signature.block_size != nld->erasesize ||
+	    ni->signature.page_size != nld->writesize ||
+	    ni->signature.spare_size != nld->oobsize) {
+		nlog_err(ni, "NMBM configuration mismatch\n");
+		return -EINVAL;
+	}
+
+	success = nmbm_load_existing(ni);
+	if (!success)
+		return -ENODEV;
+
+	return 0;
+}
+
+/*
+ * nmbm_detach - Detach from a lower device, and save all tables
+ * @ni: NMBM instance structure
+ */
+int nmbm_detach(struct nmbm_instance *ni)
+{
+	if (!ni)
+		return -EINVAL;
+
+	nmbm_update_info_table(ni);
+
+	nmbm_mark_block_color_normal(ni, 0, ni->block_count - 1);
+
+	return 0;
+}
+
+/*
+ * nmbm_erase_logic_block - Erase a logic block
+ * @ni: NMBM instance structure
+ * @nmbm_erase_logic_block: logic block address
+ *
+ * Logic block will be mapped to physical block before erasing.
+ * Bad block found during erasinh will be remapped to a good block if there is
+ * still at least one good spare block available.
+ */
+static int nmbm_erase_logic_block(struct nmbm_instance *ni, uint32_t block_addr)
+{
+	uint32_t pb;
+	bool success;
+
+retry:
+	/* Map logic block to physical block */
+	pb = ni->block_mapping[block_addr];
+
+	/* Whether the logic block is good (has valid mapping) */
+	if ((int32_t)pb < 0) {
+		nlog_debug(ni, "Logic block %u is a bad block\n", block_addr);
+		return -EIO;
+	}
+
+	/* Remap logic block if current physical block is a bad block */
+	if (nmbm_get_block_state(ni, pb) == BLOCK_ST_BAD ||
+	    nmbm_get_block_state(ni, pb) == BLOCK_ST_NEED_REMAP)
+		goto remap_logic_block;
+
+	success = nmbm_erase_phys_block(ni, ba2addr(ni, pb));
+	if (success)
+		return 0;
+
+	/* Mark bad block */
+	nmbm_mark_phys_bad_block(ni, pb);
+	nmbm_set_block_state(ni, pb, BLOCK_ST_BAD);
+
+remap_logic_block:
+	/* Try to assign a new block */
+	success = nmbm_map_block(ni, block_addr);
+	if (!success) {
+		/* Mark logic block unusable, and update info table */
+		ni->block_mapping[block_addr] = -1;
+		if (nmbm_get_block_state(ni, pb) != BLOCK_ST_NEED_REMAP)
+			nmbm_set_block_state(ni, pb, BLOCK_ST_BAD);
+		nmbm_update_info_table(ni);
+		return -EIO;
+	}
+
+	/* Update info table before erasing */
+	if (nmbm_get_block_state(ni, pb) != BLOCK_ST_NEED_REMAP)
+		nmbm_set_block_state(ni, pb, BLOCK_ST_BAD);
+	nmbm_update_info_table(ni);
+
+	goto retry;
+}
+
+/*
+ * nmbm_erase_block_range - Erase logic blocks
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ * @size: erase range
+ * @failed_addr: return failed block address if error occurs
+ */
+int nmbm_erase_block_range(struct nmbm_instance *ni, uint64_t addr,
+			   uint64_t size, uint64_t *failed_addr)
+{
+	uint32_t start_ba, end_ba;
+	int ret;
+
+	if (!ni)
+		return -EINVAL;
+
+	/* Sanity check */
+	if (ni->protected) {
+		nlog_debug(ni, "Device is forced read-only\n");
+		return -EROFS;
+	}
+
+	if (addr >= ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Address 0x%llx is invalid\n", addr);
+		return -EINVAL;
+	}
+
+	if (addr + size > ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Erase range 0xllxu is too large\n", size);
+		return -EINVAL;
+	}
+
+	if (!size) {
+		nlog_warn(ni, "No blocks to be erased\n");
+		return 0;
+	}
+
+	start_ba = addr2ba(ni, addr);
+	end_ba = addr2ba(ni, addr + size - 1);
+
+	while (start_ba <= end_ba) {
+		WATCHDOG_RESET();
+
+		ret = nmbm_erase_logic_block(ni, start_ba);
+		if (ret) {
+			if (failed_addr)
+				*failed_addr = ba2addr(ni, start_ba);
+			return ret;
+		}
+
+		start_ba++;
+	}
+
+	return 0;
+}
+
+/*
+ * nmbm_read_logic_page - Read page based on logic address
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ * @data: buffer to store main data. optional.
+ * @oob: buffer to store oob data. optional.
+ * @mode: read mode
+ */
+static int nmbm_read_logic_page(struct nmbm_instance *ni, uint64_t addr,
+				void *data, void *oob, enum nmbm_oob_mode mode)
+{
+	uint32_t lb, pb, offset;
+	uint64_t paddr;
+	int ret;
+
+	/* Extract block address and in-block offset */
+	lb = addr2ba(ni, addr);
+	offset = addr & ni->erasesize_mask;
+
+	/* Map logic block to physical block */
+	pb = ni->block_mapping[lb];
+
+	/* Whether the logic block is good (has valid mapping) */
+	if ((int32_t)pb < 0) {
+		nlog_debug(ni, "Logic block %u is a bad block\n", lb);
+		return -EIO;
+	}
+
+	/* Fail if physical block is marked bad */
+	if (nmbm_get_block_state(ni, pb) == BLOCK_ST_BAD)
+		return -EIO;
+
+	/* Assemble new address */
+	paddr = ba2addr(ni, pb) + offset;
+
+	ret = nmbm_read_phys_page(ni, paddr, data, oob, mode);
+	if (!ret)
+		return 0;
+
+	/* For ECC error, return positive value only */
+	if (ret > 0)
+		return 1;
+
+	/*
+	 * Do not remap bad block here. Just mark this block in state table.
+	 * Remap this block on erasing.
+	 */
+	nmbm_set_block_state(ni, pb, BLOCK_ST_NEED_REMAP);
+	nmbm_update_info_table(ni);
+
+	return -EIO;
+}
+
+/*
+ * nmbm_read_single_page - Read one page based on logic address
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ * @data: buffer to store main data. optional.
+ * @oob: buffer to store oob data. optional.
+ * @mode: read mode
+ */
+int nmbm_read_single_page(struct nmbm_instance *ni, uint64_t addr, void *data,
+			  void *oob, enum nmbm_oob_mode mode)
+{
+	if (!ni)
+		return -EINVAL;
+
+	/* Sanity check */
+	if (ni->protected) {
+		nlog_debug(ni, "Device is forced read-only\n");
+		return -EROFS;
+	}
+
+	if (addr >= ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Address 0x%llx is invalid\n", addr);
+		return -EINVAL;
+	}
+
+	return nmbm_read_logic_page(ni, addr, data, oob, mode);
+}
+
+/*
+ * nmbm_read_range - Read data without oob
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ * @size: data size to read
+ * @data: buffer to store main data to be read
+ * @mode: read mode
+ * @retlen: return actual data size read
+ */
+int nmbm_read_range(struct nmbm_instance *ni, uint64_t addr, size_t size,
+		    void *data, enum nmbm_oob_mode mode, size_t *retlen)
+{
+	uint64_t off = addr;
+	uint8_t *ptr = data;
+	size_t sizeremain = size, chunksize, leading;
+	int ret;
+
+	if (!ni)
+		return -EINVAL;
+
+	/* Sanity check */
+	if (ni->protected) {
+		nlog_debug(ni, "Device is forced read-only\n");
+		return -EROFS;
+	}
+
+	if (addr >= ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Address 0x%llx is invalid\n", addr);
+		return -EINVAL;
+	}
+
+	if (addr + size > ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Read range 0x%llx is too large\n", size);
+		return -EINVAL;
+	}
+
+	if (!size) {
+		nlog_warn(ni, "No data to be read\n");
+		return 0;
+	}
+
+	while (sizeremain) {
+		WATCHDOG_RESET();
+
+		leading = off & ni->writesize_mask;
+		chunksize = ni->lower.writesize - leading;
+		if (chunksize > sizeremain)
+			chunksize = sizeremain;
+
+		if (chunksize == ni->lower.writesize) {
+			ret = nmbm_read_logic_page(ni, off - leading, ptr,
+							NULL, mode);
+			if (ret)
+				break;
+		} else {
+			ret = nmbm_read_logic_page(ni, off - leading,
+							ni->page_cache, NULL,
+							mode);
+			if (ret)
+				break;
+
+			memcpy(ptr, ni->page_cache + leading, chunksize);
+		}
+
+		off += chunksize;
+		ptr += chunksize;
+		sizeremain -= chunksize;
+	}
+
+	if (retlen)
+		*retlen = size - sizeremain;
+
+	return ret;
+}
+
+/*
+ * nmbm_write_logic_page - Read page based on logic address
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ * @data: buffer contains main data. optional.
+ * @oob: buffer contains oob data. optional.
+ * @mode: write mode
+ */
+static int nmbm_write_logic_page(struct nmbm_instance *ni, uint64_t addr,
+				  const void *data, const void *oob,
+				  enum nmbm_oob_mode mode)
+{
+	uint32_t lb, pb, offset;
+	uint64_t paddr;
+	bool success;
+
+	/* Extract block address and in-block offset */
+	lb = addr2ba(ni, addr);
+	offset = addr & ni->erasesize_mask;
+
+	/* Map logic block to physical block */
+	pb = ni->block_mapping[lb];
+
+	/* Whether the logic block is good (has valid mapping) */
+	if ((int32_t)pb < 0) {
+		nlog_debug(ni, "Logic block %u is a bad block\n", lb);
+		return -EIO;
+	}
+
+	/* Fail if physical block is marked bad */
+	if (nmbm_get_block_state(ni, pb) == BLOCK_ST_BAD)
+		return -EIO;
+
+	/* Assemble new address */
+	paddr = ba2addr(ni, pb) + offset;
+
+	success = nmbm_write_phys_page(ni, paddr, data, oob, mode);
+	if (success)
+		return 0;
+
+	/*
+	 * Do not remap bad block here. Just mark this block in state table.
+	 * Remap this block on erasing.
+	 */
+	nmbm_set_block_state(ni, pb, BLOCK_ST_NEED_REMAP);
+	nmbm_update_info_table(ni);
+
+	return -EIO;
+}
+
+/*
+ * nmbm_write_single_page - Write one page based on logic address
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ * @data: buffer contains main data. optional.
+ * @oob: buffer contains oob data. optional.
+ * @mode: write mode
+ */
+int nmbm_write_single_page(struct nmbm_instance *ni, uint64_t addr,
+			   const void *data, const void *oob,
+			   enum nmbm_oob_mode mode)
+{
+	if (!ni)
+		return -EINVAL;
+
+	/* Sanity check */
+	if (ni->protected) {
+		nlog_debug(ni, "Device is forced read-only\n");
+		return -EROFS;
+	}
+
+	if (addr >= ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Address 0x%llx is invalid\n", addr);
+		return -EINVAL;
+	}
+
+	return nmbm_write_logic_page(ni, addr, data, oob, mode);
+}
+
+/*
+ * nmbm_write_range - Write data without oob
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ * @size: data size to write
+ * @data: buffer contains data to be written
+ * @mode: write mode
+ * @retlen: return actual data size written
+ */
+int nmbm_write_range(struct nmbm_instance *ni, uint64_t addr, size_t size,
+		     const void *data, enum nmbm_oob_mode mode,
+		     size_t *retlen)
+{
+	uint64_t off = addr;
+	const uint8_t *ptr = data;
+	size_t sizeremain = size, chunksize, leading;
+	int ret;
+
+	if (!ni)
+		return -EINVAL;
+
+	/* Sanity check */
+	if (ni->protected) {
+		nlog_debug(ni, "Device is forced read-only\n");
+		return -EROFS;
+	}
+
+	if (addr >= ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Address 0x%llx is invalid\n", addr);
+		return -EINVAL;
+	}
+
+	if (addr + size > ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Write size 0x%zx is too large\n", size);
+		return -EINVAL;
+	}
+
+	if (!size) {
+		nlog_warn(ni, "No data to be written\n");
+		return 0;
+	}
+
+	while (sizeremain) {
+		WATCHDOG_RESET();
+
+		leading = off & ni->writesize_mask;
+		chunksize = ni->lower.writesize - leading;
+		if (chunksize > sizeremain)
+			chunksize = sizeremain;
+
+		if (chunksize == ni->lower.writesize) {
+			ret = nmbm_write_logic_page(ni, off - leading, ptr,
+							 NULL, mode);
+			if (ret)
+				break;
+		} else {
+			memset(ni->page_cache, 0xff, leading);
+			memcpy(ni->page_cache + leading, ptr, chunksize);
+
+			ret = nmbm_write_logic_page(ni, off - leading,
+							 ni->page_cache, NULL,
+							 mode);
+			if (ret)
+				break;
+		}
+
+		off += chunksize;
+		ptr += chunksize;
+		sizeremain -= chunksize;
+	}
+
+	if (retlen)
+		*retlen = size - sizeremain;
+
+	return ret;
+}
+
+/*
+ * nmbm_check_bad_block - Check whether a logic block is usable
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ */
+int nmbm_check_bad_block(struct nmbm_instance *ni, uint64_t addr)
+{
+	uint32_t lb, pb;
+
+	if (!ni)
+		return -EINVAL;
+
+	if (addr >= ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Address 0x%llx is invalid\n", addr);
+		return -EINVAL;
+	}
+
+	lb = addr2ba(ni, addr);
+
+	/* Map logic block to physical block */
+	pb = ni->block_mapping[lb];
+
+	if ((int32_t)pb < 0)
+		return 1;
+
+	if (nmbm_get_block_state(ni, pb) == BLOCK_ST_BAD)
+		return 1;
+
+	return 0;
+}
+
+/*
+ * nmbm_mark_bad_block - Mark a logic block unusable
+ * @ni: NMBM instance structure
+ * @addr: logic linear address
+ */
+int nmbm_mark_bad_block(struct nmbm_instance *ni, uint64_t addr)
+{
+	uint32_t lb, pb;
+
+	if (!ni)
+		return -EINVAL;
+
+	if (addr >= ba2addr(ni, ni->data_block_count)) {
+		nlog_err(ni, "Address 0x%llx is invalid\n", addr);
+		return -EINVAL;
+	}
+
+	lb = addr2ba(ni, addr);
+
+	/* Map logic block to physical block */
+	pb = ni->block_mapping[lb];
+
+	if ((int32_t)pb < 0)
+		return 0;
+
+	ni->block_mapping[lb] = -1;
+	nmbm_mark_phys_bad_block(ni, pb);
+	nmbm_set_block_state(ni, pb, BLOCK_ST_BAD);
+	nmbm_update_info_table(ni);
+
+	return 0;
+}
+
+/*
+ * nmbm_get_avail_size - Get available user data size
+ * @ni: NMBM instance structure
+ */
+uint64_t nmbm_get_avail_size(struct nmbm_instance *ni)
+{
+	if (!ni)
+		return 0;
+
+	return (uint64_t)ni->data_block_count << ni->erasesize_shift;
+}
+
+/*
+ * nmbm_get_lower_device - Get lower device structure
+ * @ni: NMBM instance structure
+ * @nld: pointer to hold the data of lower device structure
+ */
+int nmbm_get_lower_device(struct nmbm_instance *ni, struct nmbm_lower_device *nld)
+{
+	if (!ni)
+		return -EINVAL;
+
+	if (nld)
+		memcpy(nld, &ni->lower, sizeof(*nld));
+
+	return 0;
+}
+
+#include "nmbm-debug.inl"
diff --git a/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-debug.h b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-debug.h
new file mode 100644
index 000000000..582118333
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-debug.h
@@ -0,0 +1,20 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Debug addons for NAND Mapped-block Management (NMBM)
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#ifndef _NMBM_DEBUG_H_
+#define _NMBM_DEBUG_H_
+
+#define nmbm_mark_block_color_normal(ni, start_ba, end_ba)
+#define nmbm_mark_block_color_bad(ni, ba)
+#define nmbm_mark_block_color_mgmt(ni, start_ba, end_ba)
+#define nmbm_mark_block_color_signature(ni, ba)
+#define nmbm_mark_block_color_info_table(ni, start_ba, end_ba)
+#define nmbm_mark_block_color_mapped(ni, ba)
+
+#endif /* _NMBM_DEBUG_H_ */
diff --git a/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-debug.inl b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-debug.inl
new file mode 100644
index 000000000..e69de29bb
diff --git a/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-mtd.c b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-mtd.c
new file mode 100644
index 000000000..2a21ab98e
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-mtd.c
@@ -0,0 +1,831 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * MTD layer for NAND Mapped-block Management (NMBM)
+ *
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/sched.h>
+#include <linux/wait.h>
+#include <linux/spinlock.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/flashchip.h>
+#include <linux/mtd/partitions.h>
+#include <linux/of_platform.h>
+#include <linux/kern_levels.h>
+
+#include "nmbm-private.h"
+#include "nmbm-debug.h"
+
+#define NMBM_MAX_RATIO_DEFAULT			1
+#define NMBM_MAX_BLOCKS_DEFAULT			256
+
+struct nmbm_mtd {
+	struct mtd_info upper;
+	struct mtd_info *lower;
+
+	struct nmbm_instance *ni;
+	uint8_t *page_cache;
+
+	flstate_t state;
+	spinlock_t lock;
+	wait_queue_head_t wq;
+
+	struct device *dev;
+	struct list_head node;
+};
+
+struct list_head nmbm_devs;
+static DEFINE_MUTEX(nmbm_devs_lock);
+
+static int nmbm_lower_read_page(void *arg, uint64_t addr, void *buf, void *oob,
+				enum nmbm_oob_mode mode)
+{
+	struct nmbm_mtd *nm = arg;
+	struct mtd_oob_ops ops;
+	int ret;
+
+	memset(&ops, 0, sizeof(ops));
+
+	switch (mode) {
+	case NMBM_MODE_PLACE_OOB:
+		ops.mode = MTD_OPS_PLACE_OOB;
+		break;
+	case NMBM_MODE_AUTO_OOB:
+		ops.mode = MTD_OPS_AUTO_OOB;
+		break;
+	case NMBM_MODE_RAW:
+		ops.mode = MTD_OPS_RAW;
+		break;
+	default:
+		pr_debug("%s: unsupported NMBM mode: %u\n", __func__, mode);
+		return -ENOTSUPP;
+	}
+
+	if (buf) {
+		ops.datbuf = buf;
+		ops.len = nm->lower->writesize;
+	}
+
+	if (oob) {
+		ops.oobbuf = oob;
+		ops.ooblen = mtd_oobavail(nm->lower, &ops);
+	}
+
+	ret = mtd_read_oob(nm->lower, addr, &ops);
+	nm->upper.ecc_stats.corrected = nm->lower->ecc_stats.corrected;
+	nm->upper.ecc_stats.failed = nm->lower->ecc_stats.failed;
+
+	if (ret == -EBADMSG)
+		return 1;
+
+	if (ret && ret != -EUCLEAN)
+		return ret;
+
+	return 0;
+}
+
+static int nmbm_lower_write_page(void *arg, uint64_t addr, const void *buf,
+				 const void *oob, enum nmbm_oob_mode mode)
+{
+	struct nmbm_mtd *nm = arg;
+	struct mtd_oob_ops ops;
+
+	memset(&ops, 0, sizeof(ops));
+
+	switch (mode) {
+	case NMBM_MODE_PLACE_OOB:
+		ops.mode = MTD_OPS_PLACE_OOB;
+		break;
+	case NMBM_MODE_AUTO_OOB:
+		ops.mode = MTD_OPS_AUTO_OOB;
+		break;
+	case NMBM_MODE_RAW:
+		ops.mode = MTD_OPS_RAW;
+		break;
+	default:
+		pr_debug("%s: unsupported NMBM mode: %u\n", __func__, mode);
+		return -ENOTSUPP;
+	}
+
+	if (buf) {
+		ops.datbuf = (uint8_t *)buf;
+		ops.len = nm->lower->writesize;
+	}
+
+	if (oob) {
+		ops.oobbuf = (uint8_t *)oob;
+		ops.ooblen = mtd_oobavail(nm->lower, &ops);
+	}
+
+	return mtd_write_oob(nm->lower, addr, &ops);
+}
+
+static int nmbm_lower_erase_block(void *arg, uint64_t addr)
+{
+	struct nmbm_mtd *nm = arg;
+	struct erase_info ei;
+
+	memset(&ei, 0, sizeof(ei));
+
+	ei.mtd = nm->lower;
+	ei.addr = addr;
+	ei.len = nm->lower->erasesize;
+
+	return mtd_erase(nm->lower, &ei);
+}
+
+static int nmbm_lower_is_bad_block(void *arg, uint64_t addr)
+{
+	struct nmbm_mtd *nm = arg;
+
+	return mtd_block_isbad(nm->lower, addr);
+}
+
+static int nmbm_lower_mark_bad_block(void *arg, uint64_t addr)
+{
+	struct nmbm_mtd *nm = arg;
+
+	return mtd_block_markbad(nm->lower, addr);
+}
+
+static void nmbm_lower_log(void *arg, enum nmbm_log_category level,
+			   const char *fmt, va_list ap)
+{
+	struct nmbm_mtd *nm = arg;
+	char *msg;
+	char *kl;
+
+	msg = kvasprintf(GFP_KERNEL, fmt, ap);
+	if (!msg) {
+		dev_warn(nm->dev, "unable to print log\n");
+		return;
+	}
+
+	switch (level) {
+	case NMBM_LOG_DEBUG:
+		kl = KERN_DEBUG;
+		break;
+	case NMBM_LOG_WARN:
+		kl = KERN_WARNING;
+		break;
+	case NMBM_LOG_ERR:
+		kl = KERN_ERR;
+		break;
+	case NMBM_LOG_EMERG:
+		kl = KERN_EMERG;
+		break;
+	default:
+		kl = KERN_INFO ;
+	}
+
+	dev_printk(kl, nm->dev, "%s", msg);
+
+	kfree(msg);
+}
+
+static int nmbm_get_device(struct nmbm_mtd *nm, int new_state)
+{
+	DECLARE_WAITQUEUE(wait, current);
+
+retry:
+	spin_lock(&nm->lock);
+
+	if (nm->state == FL_READY) {
+		nm->state = new_state;
+		spin_unlock(&nm->lock);
+		return 0;
+	}
+
+	if (new_state == FL_PM_SUSPENDED) {
+		if (nm->state == FL_PM_SUSPENDED) {
+			spin_unlock(&nm->lock);
+			return 0;
+		}
+	}
+
+	set_current_state(TASK_UNINTERRUPTIBLE);
+	add_wait_queue(&nm->wq, &wait);
+	spin_unlock(&nm->lock);
+	schedule();
+	remove_wait_queue(&nm->wq, &wait);
+	goto retry;
+}
+
+static void nmbm_release_device(struct nmbm_mtd *nm)
+{
+	spin_lock(&nm->lock);
+	nm->state = FL_READY;
+	wake_up(&nm->wq);
+	spin_unlock(&nm->lock);
+}
+
+static int nmbm_mtd_read(struct mtd_info *mtd, loff_t from, size_t len,
+			 size_t *retlen, u_char *buf)
+{
+	struct nmbm_mtd *nm = container_of(mtd, struct nmbm_mtd, upper);
+	int ret;
+
+	/* Do not allow read past end of device */
+	if ((from + len) > mtd->size) {
+		pr_debug("%s: attempt to write beyond end of device\n",
+			 __func__);
+		return -EINVAL;
+	}
+
+	nmbm_get_device(nm, FL_READING);
+	ret = nmbm_read_range(nm->ni, from, len, buf, MTD_OPS_PLACE_OOB,
+			      retlen);
+	nmbm_release_device(nm);
+
+	return ret;
+}
+
+static int nmbm_mtd_write(struct mtd_info *mtd, loff_t to, size_t len,
+			  size_t *retlen, const u_char *buf)
+{
+	struct nmbm_mtd *nm = container_of(mtd, struct nmbm_mtd, upper);
+	int ret;
+
+	/* Do not allow write past end of device */
+	if ((to + len) > mtd->size) {
+		pr_debug("%s: attempt to write beyond end of device\n",
+			 __func__);
+		return -EINVAL;
+	}
+
+	nmbm_get_device(nm, FL_WRITING);
+	ret = nmbm_write_range(nm->ni, to, len, buf, MTD_OPS_PLACE_OOB,
+			       retlen);
+	nmbm_release_device(nm);
+
+	return ret;
+}
+
+static int nmbm_mtd_erase(struct mtd_info *mtd, struct erase_info *instr)
+{
+	struct nmbm_mtd *nm = container_of(mtd, struct nmbm_mtd, upper);
+	int ret;
+
+	nmbm_get_device(nm, FL_ERASING);
+
+	instr->state = MTD_ERASING;
+
+	ret = nmbm_erase_block_range(nm->ni, instr->addr, instr->len,
+				     &instr->fail_addr);
+	if (ret)
+		instr->state = MTD_ERASE_FAILED;
+	else
+		instr->state = MTD_ERASE_DONE;
+
+	nmbm_release_device(nm);
+
+	if (!ret)
+		mtd_erase_callback(instr);
+	else
+		ret = -EIO;
+
+	return ret;
+}
+
+static int nmbm_mtd_read_data(struct nmbm_mtd *nm, uint64_t addr,
+			      struct mtd_oob_ops *ops, enum nmbm_oob_mode mode)
+{
+	size_t len, ooblen, maxooblen, chklen;
+	uint32_t col, ooboffs;
+	uint8_t *datcache, *oobcache;
+	int ret;
+
+	col = addr & nm->lower->writesize_mask;
+	addr &= ~nm->lower->writesize_mask;
+	maxooblen = mtd_oobavail(nm->lower, ops);
+	ooboffs = ops->ooboffs;
+	ooblen = ops->ooblen;
+	len = ops->len;
+
+	datcache = len ? nm->page_cache : NULL;
+	oobcache = ooblen ? nm->page_cache + nm->lower->writesize : NULL;
+
+	ops->oobretlen = 0;
+	ops->retlen = 0;
+
+	while (len || ooblen) {
+		ret = nmbm_read_single_page(nm->ni, addr, datcache, oobcache,
+					    mode);
+		if (ret) {
+			if (ret > 0)
+				return -EBADMSG;
+			return -EIO;
+		}
+
+		if (len) {
+			/* Move data */
+			chklen = nm->lower->writesize - col;
+			if (chklen > len)
+				chklen = len;
+
+			memcpy(ops->datbuf + ops->retlen, datcache + col,
+			       chklen);
+			len -= chklen;
+			col = 0; /* (col + chklen) %  */
+			ops->retlen += chklen;
+		}
+
+		if (ooblen) {
+			/* Move oob */
+			chklen = maxooblen - ooboffs;
+			if (chklen > ooblen)
+				chklen = ooblen;
+
+			memcpy(ops->oobbuf + ops->oobretlen, oobcache + ooboffs,
+			       chklen);
+			ooblen -= chklen;
+			ooboffs = 0; /* (ooboffs + chklen) % maxooblen; */
+			ops->oobretlen += chklen;
+		}
+
+		addr += nm->lower->writesize;
+	}
+
+	return 0;
+}
+
+static int nmbm_mtd_read_oob(struct mtd_info *mtd, loff_t from,
+			     struct mtd_oob_ops *ops)
+{
+	struct nmbm_mtd *nm = container_of(mtd, struct nmbm_mtd, upper);
+	uint32_t maxooblen;
+	enum nmbm_oob_mode mode;
+	int ret;
+
+	if (!ops->oobbuf && !ops->datbuf) {
+		if (ops->ooblen || ops->len)
+			return -EINVAL;
+
+		return 0;
+	}
+
+	switch (ops->mode) {
+	case MTD_OPS_PLACE_OOB:
+		mode = NMBM_MODE_PLACE_OOB;
+		break;
+	case MTD_OPS_AUTO_OOB:
+		mode = NMBM_MODE_AUTO_OOB;
+		break;
+	case MTD_OPS_RAW:
+		mode = NMBM_MODE_RAW;
+		break;
+	default:
+		pr_debug("%s: unsupported oob mode: %u\n", __func__, ops->mode);
+		return -ENOTSUPP;
+	}
+
+	maxooblen = mtd_oobavail(mtd, ops);
+
+	/* Do not allow read past end of device */
+	if (ops->datbuf && (from + ops->len) > mtd->size) {
+		pr_debug("%s: attempt to read beyond end of device\n",
+			 __func__);
+		return -EINVAL;
+	}
+
+	if (!ops->oobbuf) {
+		nmbm_get_device(nm, FL_READING);
+
+		/* Optimized for reading data only */
+		ret = nmbm_read_range(nm->ni, from, ops->len, ops->datbuf,
+				      mode, &ops->retlen);
+
+		nmbm_release_device(nm);
+
+		if (ret > 0)
+			return -EBADMSG;
+		else if (ret)
+			return -EIO;
+
+		return 0;
+	}
+
+	if (unlikely(ops->ooboffs >= maxooblen)) {
+		pr_debug("%s: attempt to start read outside oob\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	if (unlikely(from >= mtd->size ||
+	    ops->ooboffs + ops->ooblen > ((mtd->size >> mtd->writesize_shift) -
+	    (from >> mtd->writesize_shift)) * maxooblen)) {
+		pr_debug("%s: attempt to read beyond end of device\n",
+				__func__);
+		return -EINVAL;
+	}
+
+	nmbm_get_device(nm, FL_READING);
+	ret = nmbm_mtd_read_data(nm, from, ops, mode);
+	nmbm_release_device(nm);
+
+	return ret;
+}
+
+static int nmbm_mtd_write_data(struct nmbm_mtd *nm, uint64_t addr,
+			       struct mtd_oob_ops *ops, enum nmbm_oob_mode mode)
+{
+	size_t len, ooblen, maxooblen, chklen;
+	uint32_t col, ooboffs;
+	uint8_t *datcache, *oobcache;
+	int ret;
+
+	col = addr & nm->lower->writesize_mask;
+	addr &= ~nm->lower->writesize_mask;
+	maxooblen = mtd_oobavail(nm->lower, ops);
+	ooboffs = ops->ooboffs;
+	ooblen = ops->ooblen;
+	len = ops->len;
+
+	datcache = len ? nm->page_cache : NULL;
+	oobcache = ooblen ? nm->page_cache + nm->lower->writesize : NULL;
+
+	ops->oobretlen = 0;
+	ops->retlen = 0;
+
+	while (len || ooblen) {
+		if (len) {
+			/* Move data */
+			chklen = nm->lower->writesize - col;
+			if (chklen > len)
+				chklen = len;
+
+			memset(datcache, 0xff, col);
+			memcpy(datcache + col, ops->datbuf + ops->retlen,
+			       chklen);
+			memset(datcache + col + chklen, 0xff,
+			       nm->lower->writesize - col - chklen);
+			len -= chklen;
+			col = 0; /* (col + chklen) %  */
+			ops->retlen += chklen;
+		}
+
+		if (ooblen) {
+			/* Move oob */
+			chklen = maxooblen - ooboffs;
+			if (chklen > ooblen)
+				chklen = ooblen;
+
+			memset(oobcache, 0xff, ooboffs);
+			memcpy(oobcache + ooboffs,
+			       ops->oobbuf + ops->oobretlen, chklen);
+			memset(oobcache + ooboffs + chklen, 0xff,
+			       nm->lower->oobsize - ooboffs - chklen);
+			ooblen -= chklen;
+			ooboffs = 0; /* (ooboffs + chklen) % maxooblen; */
+			ops->oobretlen += chklen;
+		}
+
+		ret = nmbm_write_single_page(nm->ni, addr, datcache, oobcache,
+					     mode);
+		if (ret)
+			return ret;
+
+		addr += nm->lower->writesize;
+	}
+
+	return 0;
+}
+
+static int nmbm_mtd_write_oob(struct mtd_info *mtd, loff_t to,
+			      struct mtd_oob_ops *ops)
+{
+	struct nmbm_mtd *nm = container_of(mtd, struct nmbm_mtd, upper);
+	enum nmbm_oob_mode mode;
+	uint32_t maxooblen;
+	int ret;
+
+	if (!ops->oobbuf && !ops->datbuf) {
+		if (ops->ooblen || ops->len)
+			return -EINVAL;
+
+		return 0;
+	}
+
+	switch (ops->mode) {
+	case MTD_OPS_PLACE_OOB:
+		mode = NMBM_MODE_PLACE_OOB;
+		break;
+	case MTD_OPS_AUTO_OOB:
+		mode = NMBM_MODE_AUTO_OOB;
+		break;
+	case MTD_OPS_RAW:
+		mode = NMBM_MODE_RAW;
+		break;
+	default:
+		pr_debug("%s: unsupported oob mode: %u\n", __func__,
+			 ops->mode);
+		return -ENOTSUPP;
+	}
+
+	maxooblen = mtd_oobavail(mtd, ops);
+
+	/* Do not allow write past end of device */
+	if (ops->datbuf && (to + ops->len) > mtd->size) {
+		pr_debug("%s: attempt to write beyond end of device\n",
+			 __func__);
+		return -EINVAL;
+	}
+
+	if (!ops->oobbuf) {
+		nmbm_get_device(nm, FL_WRITING);
+
+		/* Optimized for writing data only */
+		ret = nmbm_write_range(nm->ni, to, ops->len, ops->datbuf,
+				       mode, &ops->retlen);
+
+		nmbm_release_device(nm);
+
+		return ret;
+	}
+
+	if (unlikely(ops->ooboffs >= maxooblen)) {
+		pr_debug("%s: attempt to start write outside oob\n",
+			__func__);
+		return -EINVAL;
+	}
+
+	if (unlikely(to >= mtd->size ||
+	    ops->ooboffs + ops->ooblen > ((mtd->size >> mtd->writesize_shift) -
+	    (to >> mtd->writesize_shift)) * maxooblen)) {
+		pr_debug("%s: attempt to write beyond end of device\n",
+				__func__);
+		return -EINVAL;
+	}
+
+	nmbm_get_device(nm, FL_WRITING);
+	ret = nmbm_mtd_write_data(nm, to, ops, mode);
+	nmbm_release_device(nm);
+
+	return ret;
+}
+
+static int nmbm_mtd_block_isbad(struct mtd_info *mtd, loff_t offs)
+{
+	struct nmbm_mtd *nm = container_of(mtd, struct nmbm_mtd, upper);
+	int ret;
+
+	nmbm_get_device(nm, FL_READING);
+	ret = nmbm_check_bad_block(nm->ni, offs);
+	nmbm_release_device(nm);
+
+	return ret;
+}
+
+static int nmbm_mtd_block_markbad(struct mtd_info *mtd, loff_t offs)
+{
+	struct nmbm_mtd *nm = container_of(mtd, struct nmbm_mtd, upper);
+	int ret;
+
+	nmbm_get_device(nm, FL_WRITING);
+	ret = nmbm_mark_bad_block(nm->ni, offs);
+	nmbm_release_device(nm);
+
+	return ret;
+}
+
+static void nmbm_mtd_shutdown(struct mtd_info *mtd)
+{
+	struct nmbm_mtd *nm = container_of(mtd, struct nmbm_mtd, upper);
+
+	nmbm_get_device(nm, FL_PM_SUSPENDED);
+}
+
+static int nmbm_probe(struct platform_device *pdev)
+{
+	struct device_node *mtd_np, *np = pdev->dev.of_node;
+	uint32_t max_ratio, max_reserved_blocks, alloc_size;
+	struct mtd_part_parser_data ppdata;
+	struct device_node *ofpart_node;
+	struct nmbm_lower_device nld;
+	struct mtd_info *lower, *mtd;
+	struct nmbm_mtd *nm;
+	const char *mtdname;
+	bool forced_create;
+	int ret;
+
+	mtd_np = of_parse_phandle(np, "lower-mtd-device", 0);
+	if (mtd_np) {
+		lower = get_mtd_device_by_node(mtd_np);
+		if (!IS_ERR(lower))
+			goto do_attach_mtd;
+
+		dev_dbg(&pdev->dev, "failed to find mtd device by phandle\n");
+		return -EPROBE_DEFER;
+	}
+
+	ret = of_property_read_string(np, "lower-mtd-name", &mtdname);
+	if (!ret) {
+		lower = get_mtd_device_nm(mtdname);
+		if (!IS_ERR(lower))
+			goto do_attach_mtd;
+
+		dev_dbg(&pdev->dev, "failed to find mtd device by name '%s'\n",
+			mtdname);
+		return -EPROBE_DEFER;
+	}
+
+do_attach_mtd:
+	if (of_property_read_u32(np, "max-ratio", &max_ratio))
+		max_ratio = NMBM_MAX_RATIO_DEFAULT;
+
+	if (of_property_read_u32(np, "max-reserved-blocks",
+				 &max_reserved_blocks))
+		max_reserved_blocks = NMBM_MAX_BLOCKS_DEFAULT;
+
+	forced_create = of_property_read_bool(np, "forced-create");
+
+	memset(&nld, 0, sizeof(nld));
+
+	nld.flags = forced_create ? NMBM_F_CREATE : 0;
+	nld.max_ratio = max_ratio;
+	nld.max_reserved_blocks = max_reserved_blocks;
+
+	nld.size = lower->size;
+	nld.erasesize = lower->erasesize;
+	nld.writesize = lower->writesize;
+	nld.oobsize = lower->oobsize;
+	nld.oobavail = lower->oobavail;
+
+	nld.read_page = nmbm_lower_read_page;
+	nld.write_page = nmbm_lower_write_page;
+	nld.erase_block = nmbm_lower_erase_block;
+	nld.is_bad_block = nmbm_lower_is_bad_block;
+	nld.mark_bad_block = nmbm_lower_mark_bad_block;
+
+	nld.logprint = nmbm_lower_log;
+
+	alloc_size = nmbm_calc_structure_size(&nld);
+
+	nm = devm_kzalloc(&pdev->dev, sizeof(*nm) + alloc_size +
+			  lower->writesize + lower->oobsize, GFP_KERNEL);
+	if (!nm) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	nm->ni = (void *)nm + sizeof(*nm);
+	nm->page_cache = (uint8_t *)nm->ni + alloc_size;
+	nm->lower = lower;
+	nm->dev = &pdev->dev;
+
+	INIT_LIST_HEAD(&nm->node);
+	spin_lock_init(&nm->lock);
+	init_waitqueue_head(&nm->wq);
+
+	nld.arg = nm;
+
+	ret = nmbm_attach(&nld, nm->ni);
+	if (ret)
+		goto out;
+
+	/* Initialize upper mtd */
+	mtd = &nm->upper;
+
+	mtd->owner = THIS_MODULE;
+	mtd->dev.parent = &pdev->dev;
+	mtd->type = lower->type;
+	mtd->flags = lower->flags;
+
+	mtd->size = (uint64_t)nm->ni->data_block_count * lower->erasesize;
+	mtd->erasesize = lower->erasesize;
+	mtd->writesize = lower->writesize;
+	mtd->writebufsize = lower->writesize;
+	mtd->oobsize = lower->oobsize;
+	mtd->oobavail = lower->oobavail;
+
+	mtd->erasesize_shift = lower->erasesize_shift;
+	mtd->writesize_shift = lower->writesize_shift;
+	mtd->erasesize_mask = lower->erasesize_mask;
+	mtd->writesize_mask = lower->writesize_mask;
+
+	mtd->bitflip_threshold = lower->bitflip_threshold;
+
+	mtd->ooblayout = lower->ooblayout;
+	mtd->ecclayout = lower->ecclayout;
+
+	mtd->ecc_step_size = lower->ecc_step_size;
+	mtd->ecc_strength = lower->ecc_strength;
+
+	mtd->numeraseregions = lower->numeraseregions;
+	mtd->eraseregions = lower->eraseregions;
+
+	mtd->_read = nmbm_mtd_read;
+	mtd->_write = nmbm_mtd_write;
+	mtd->_erase = nmbm_mtd_erase;
+	mtd->_read_oob = nmbm_mtd_read_oob;
+	mtd->_write_oob = nmbm_mtd_write_oob;
+	mtd->_block_isbad = nmbm_mtd_block_isbad;
+	mtd->_block_markbad = nmbm_mtd_block_markbad;
+	mtd->_reboot = nmbm_mtd_shutdown;
+
+	ppdata.of_node = pdev->dev.of_node;
+
+	ofpart_node = of_get_child_by_name(ppdata.of_node, "partitions");
+	if (ofpart_node) {
+		static const char *const probes[] = {"ofpart", NULL};
+
+		ret = mtd_device_parse_register(mtd, probes, &ppdata, NULL, 0);
+		if (ret) {
+			dev_err(&pdev->dev, "mtd partition parsing error\n");
+			nmbm_detach(nm->ni);
+			goto out;
+		}
+	}
+
+	platform_set_drvdata(pdev, nm);
+
+	mutex_lock(&nmbm_devs_lock);
+	list_add_tail(&nm->node, &nmbm_devs);
+	mutex_unlock(&nmbm_devs_lock);
+
+	return 0;
+
+out:
+	if (nm)
+		devm_kfree(&pdev->dev, nm);
+
+	put_mtd_device(lower);
+
+	return ret;
+}
+
+static int nmbm_remove(struct platform_device *pdev)
+{
+	struct nmbm_mtd *nm = platform_get_drvdata(pdev);
+	struct mtd_info *lower = nm->lower;
+	int ret;
+
+	ret = mtd_device_unregister(&nm->upper);
+	if (ret)
+		return ret;
+
+	nmbm_detach(nm->ni);
+
+	mutex_lock(&nmbm_devs_lock);
+	list_add_tail(&nm->node, &nmbm_devs);
+	mutex_unlock(&nmbm_devs_lock);
+
+	devm_kfree(&pdev->dev, nm);
+
+	put_mtd_device(lower);
+
+	platform_set_drvdata(pdev, NULL);
+
+	return 0;
+}
+
+static const struct of_device_id nmbm_ids[] = {
+	{ .compatible = "generic,nmbm" },
+	{ },
+};
+
+MODULE_DEVICE_TABLE(of, nmbm_ids);
+
+static struct platform_driver nmbm_driver = {
+	.probe = nmbm_probe,
+	.remove = nmbm_remove,
+	.driver = {
+		.name = "nmbm",
+		.of_match_table = nmbm_ids,
+	},
+};
+
+static int __init nmbm_init(void)
+{
+	int ret;
+
+	INIT_LIST_HEAD(&nmbm_devs);
+
+	ret = platform_driver_register(&nmbm_driver);
+	if (ret) {
+		pr_err("failed to register nmbm driver\n");
+		return ret;
+	}
+
+	return 0;
+}
+module_init(nmbm_init);
+
+static void __exit nmbm_exit(void)
+{
+	platform_driver_unregister(&nmbm_driver);
+}
+module_exit(nmbm_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Weijie Gao <weijie.gao@mediatek.com>");
+MODULE_DESCRIPTION("NAND mapping block management");
diff --git a/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-private.h b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-private.h
new file mode 100644
index 000000000..c285aeb9d
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/mtd/nmbm/nmbm-private.h
@@ -0,0 +1,137 @@
+/* SPDX-License-Identifier: GPL-2.0 OR BSD-3-Clause */
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * Definitions for NAND Mapped-block Management (NMBM)
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#ifndef _NMBM_PRIVATE_H_
+#define _NMBM_PRIVATE_H_
+
+#include <nmbm/nmbm.h>
+
+#define NMBM_MAGIC_SIGNATURE			0x304d4d4e	/* NMM0 */
+#define NMBM_MAGIC_INFO_TABLE			0x314d4d4e	/* NMM1 */
+
+#define NMBM_VERSION_MAJOR_S			0
+#define NMBM_VERSION_MAJOR_M			0xffff
+#define NMBM_VERSION_MINOR_S			16
+#define NMBM_VERSION_MINOR_M			0xffff
+#define NMBM_VERSION_MAKE(major, minor)		(((major) & NMBM_VERSION_MAJOR_M) | \
+						(((minor) & NMBM_VERSION_MINOR_M) << \
+						NMBM_VERSION_MINOR_S))
+#define NMBM_VERSION_MAJOR_GET(ver)		(((ver) >> NMBM_VERSION_MAJOR_S) & \
+						NMBM_VERSION_MAJOR_M)
+#define NMBM_VERSION_MINOR_GET(ver)		(((ver) >> NMBM_VERSION_MINOR_S) & \
+						NMBM_VERSION_MINOR_M)
+
+typedef uint32_t				nmbm_bitmap_t;
+#define NMBM_BITMAP_UNIT_SIZE			(sizeof(nmbm_bitmap_t))
+#define NMBM_BITMAP_BITS_PER_BLOCK		2
+#define NMBM_BITMAP_BITS_PER_UNIT		(8 * sizeof(nmbm_bitmap_t))
+#define NMBM_BITMAP_BLOCKS_PER_UNIT		(NMBM_BITMAP_BITS_PER_UNIT / \
+						 NMBM_BITMAP_BITS_PER_BLOCK)
+
+#define NMBM_SPARE_BLOCK_MULTI			1
+#define NMBM_SPARE_BLOCK_DIV			2
+#define NMBM_SPARE_BLOCK_MIN			2
+
+#define NMBM_MGMT_DIV				16
+#define NMBM_MGMT_BLOCKS_MIN			32
+
+#define NMBM_TRY_COUNT				3
+
+#define BLOCK_ST_BAD				0
+#define BLOCK_ST_NEED_REMAP			2
+#define BLOCK_ST_GOOD				3
+#define BLOCK_ST_MASK				3
+
+struct nmbm_header {
+	uint32_t magic;
+	uint32_t version;
+	uint32_t size;
+	uint32_t checksum;
+};
+
+struct nmbm_signature {
+	struct nmbm_header header;
+	uint64_t nand_size;
+	uint32_t block_size;
+	uint32_t page_size;
+	uint32_t spare_size;
+	uint32_t mgmt_start_pb;
+	uint8_t max_try_count;
+	uint8_t padding[3];
+};
+
+struct nmbm_info_table_header {
+	struct nmbm_header header;
+	uint32_t write_count;
+	uint32_t state_table_off;
+	uint32_t mapping_table_off;
+	uint32_t padding;
+};
+
+struct nmbm_instance {
+	struct nmbm_lower_device lower;
+
+	uint32_t rawpage_size;
+	uint32_t rawblock_size;
+	uint32_t rawchip_size;
+
+	uint32_t writesize_mask;
+	uint32_t erasesize_mask;
+	uint16_t writesize_shift;
+	uint16_t erasesize_shift;
+
+	struct nmbm_signature signature;
+
+	uint8_t *info_table_cache;
+	uint32_t info_table_size;
+	uint32_t info_table_spare_blocks;
+	struct nmbm_info_table_header info_table;
+
+	nmbm_bitmap_t *block_state;
+	uint32_t block_state_changed;
+	uint32_t state_table_size;
+
+	int32_t *block_mapping;
+	uint32_t block_mapping_changed;
+	uint32_t mapping_table_size;
+
+	uint8_t *page_cache;
+
+	int protected;
+
+	uint32_t block_count;
+	uint32_t data_block_count;
+
+	uint32_t mgmt_start_ba;
+	uint32_t main_table_ba;
+	uint32_t backup_table_ba;
+	uint32_t mapping_blocks_ba;
+	uint32_t mapping_blocks_top_ba;
+	uint32_t signature_ba;
+
+	enum nmbm_log_category log_display_level;
+};
+
+/* Log utilities */
+#define nlog_debug(ni, fmt, ...) \
+	nmbm_log(ni, NMBM_LOG_DEBUG, fmt, ##__VA_ARGS__)
+
+#define nlog_info(ni, fmt, ...) \
+	nmbm_log(ni, NMBM_LOG_INFO, fmt, ##__VA_ARGS__)
+
+#define nlog_warn(ni, fmt, ...) \
+	nmbm_log(ni, NMBM_LOG_WARN, fmt, ##__VA_ARGS__)
+
+#define nlog_err(ni, fmt, ...) \
+	nmbm_log(ni, NMBM_LOG_ERR, fmt, ##__VA_ARGS__)
+
+#define nlog_emerg(ni, fmt, ...) \
+	nmbm_log(ni, NMBM_LOG_EMERG, fmt, ##__VA_ARGS__)
+
+#endif /* _NMBM_PRIVATE_H_ */
diff --git a/trunk/linux-4.4.x/drivers/mtd/ubi/build.c b/trunk/linux-4.4.x/drivers/mtd/ubi/build.c
index 3ceda112a..d54c69c7b 100644
--- a/trunk/linux-4.4.x/drivers/mtd/ubi/build.c
+++ b/trunk/linux-4.4.x/drivers/mtd/ubi/build.c
@@ -1141,7 +1141,6 @@ int ubi_detach_mtd_dev(int ubi_num, int anyway)
 	ubi_wl_close(ubi);
 	ubi_free_internal_volumes(ubi);
 	vfree(ubi->vtbl);
-	put_mtd_device(ubi->mtd);
 	vfree(ubi->peb_buf);
 	vfree(ubi->fm_buf);
 	ubi_msg(ubi, "mtd%d is detached", ubi->mtd->index);
diff --git a/trunk/linux-4.4.x/drivers/net/Kconfig b/trunk/linux-4.4.x/drivers/net/Kconfig
index 25662ac44..ecc81bb0d 100644
--- a/trunk/linux-4.4.x/drivers/net/Kconfig
+++ b/trunk/linux-4.4.x/drivers/net/Kconfig
@@ -241,6 +241,125 @@ config RIONET_RX_SIZE
 	depends on RIONET
 	default "128"
 
+config IMQ
+	tristate "IMQ (intermediate queueing device) support"
+	depends on NETDEVICES && NETFILTER
+	---help---
+	  The IMQ device(s) is used as placeholder for QoS queueing
+	  disciplines. Every packet entering/leaving the IP stack can be
+	  directed through the IMQ device where it's enqueued/dequeued to the
+	  attached qdisc. This allows you to treat network devices as classes
+	  and distribute bandwidth among them. Iptables is used to specify
+	  through which IMQ device, if any, packets travel.
+
+	  More information at: https://github.com/imq/linuximq
+
+	  To compile this driver as a module, choose M here: the module
+	  will be called imq.  If unsure, say N.
+
+choice
+	prompt "IMQ behavior (PRE/POSTROUTING)"
+	depends on IMQ
+	default IMQ_BEHAVIOR_AB
+	help
+	  This setting defines how IMQ behaves in respect to its
+	  hooking in PREROUTING and POSTROUTING.
+
+	  IMQ can work in any of the following ways:
+
+	      PREROUTING   |      POSTROUTING
+	  -----------------|-------------------
+	  #1  After NAT    |      After NAT
+	  #2  After NAT    |      Before NAT
+	  #3  Before NAT   |      After NAT
+	  #4  Before NAT   |      Before NAT
+
+	  The default behavior is to hook before NAT on PREROUTING
+	  and after NAT on POSTROUTING (#3).
+
+	  This settings are specially usefull when trying to use IMQ
+	  to shape NATed clients.
+
+	  More information can be found at: https://github.com/imq/linuximq
+
+	  If not sure leave the default settings alone.
+
+config IMQ_BEHAVIOR_AA
+	bool "IMQ AA"
+	help
+	  This setting defines how IMQ behaves in respect to its
+	  hooking in PREROUTING and POSTROUTING.
+
+	  Choosing this option will make IMQ hook like this:
+
+	  PREROUTING:   After NAT
+	  POSTROUTING:  After NAT
+
+	  More information can be found at: https://github.com/imq/linuximq
+
+	  If not sure leave the default settings alone.
+
+config IMQ_BEHAVIOR_AB
+	bool "IMQ AB"
+	help
+	  This setting defines how IMQ behaves in respect to its
+	  hooking in PREROUTING and POSTROUTING.
+
+	  Choosing this option will make IMQ hook like this:
+
+	  PREROUTING:   After NAT
+	  POSTROUTING:  Before NAT
+
+	  More information can be found at: https://github.com/imq/linuximq
+
+	  If not sure leave the default settings alone.
+
+config IMQ_BEHAVIOR_BA
+	bool "IMQ BA"
+	help
+	  This setting defines how IMQ behaves in respect to its
+	  hooking in PREROUTING and POSTROUTING.
+
+	  Choosing this option will make IMQ hook like this:
+
+	  PREROUTING:   Before NAT
+	  POSTROUTING:  After NAT
+
+	  More information can be found at: https://github.com/imq/linuximq
+
+	  If not sure leave the default settings alone.
+
+config IMQ_BEHAVIOR_BB
+	bool "IMQ BB"
+	help
+	  This setting defines how IMQ behaves in respect to its
+	  hooking in PREROUTING and POSTROUTING.
+
+	  Choosing this option will make IMQ hook like this:
+
+	  PREROUTING:   Before NAT
+	  POSTROUTING:  Before NAT
+
+	  More information can be found at: https://github.com/imq/linuximq
+
+	  If not sure leave the default settings alone.
+
+endchoice
+
+config IMQ_NUM_DEVS
+	int "Number of IMQ devices"
+	range 2 16
+	depends on IMQ
+	default "16"
+	help
+	  This setting defines how many IMQ devices will be created.
+
+	  The default value is 16.
+
+	  More information can be found at: https://github.com/imq/linuximq
+
+	  If not sure leave the default settings alone.
+
 config TUN
 	tristate "Universal TUN/TAP device driver support"
 	depends on INET
diff --git a/trunk/linux-4.4.x/drivers/net/Makefile b/trunk/linux-4.4.x/drivers/net/Makefile
index 1aa7cb845..b3a300201 100644
--- a/trunk/linux-4.4.x/drivers/net/Makefile
+++ b/trunk/linux-4.4.x/drivers/net/Makefile
@@ -10,6 +10,7 @@ obj-$(CONFIG_IPVLAN) += ipvlan/
 obj-$(CONFIG_DUMMY) += dummy.o
 obj-$(CONFIG_EQUALIZER) += eql.o
 obj-$(CONFIG_IFB) += ifb.o
+obj-$(CONFIG_IMQ) += imq.o
 obj-$(CONFIG_MACSEC) += macsec.o
 obj-$(CONFIG_MACVLAN) += macvlan.o
 obj-$(CONFIG_MACVTAP) += macvtap.o
diff --git a/trunk/linux-4.4.x/drivers/net/dsa/mt7530.c b/trunk/linux-4.4.x/drivers/net/dsa/mt7530.c
index 0e1b70d3d..365d838ec 100644
--- a/trunk/linux-4.4.x/drivers/net/dsa/mt7530.c
+++ b/trunk/linux-4.4.x/drivers/net/dsa/mt7530.c
@@ -696,6 +696,12 @@ mt7530_cpu_port_enable(struct mt7530_priv *priv,
 	mt7530_write(priv, MT7530_PVC_P(port),
 		     PORT_SPEC_TAG);
 
+	/* Enable Mediatek header mode on the GMAC that the cpu port
+	 * connects to
+	 */
+	regmap_write_bits(priv->ethernet, MTK_GDMA_FWD_CFG(0),
+			  GDMA_SPEC_TAG, GDMA_SPEC_TAG);
+
 	/* Setup the MAC by default for the cpu port */
 	mt7530_write(priv, MT7530_PMCR_P(port), PMCR_CPUP_LINK);
 
diff --git a/trunk/linux-4.4.x/drivers/net/dsa/mt7530.h b/trunk/linux-4.4.x/drivers/net/dsa/mt7530.h
index 74db9822e..8fd7d78d7 100644
--- a/trunk/linux-4.4.x/drivers/net/dsa/mt7530.h
+++ b/trunk/linux-4.4.x/drivers/net/dsa/mt7530.h
@@ -22,6 +22,10 @@
 
 #define TRGMII_BASE(x)			(0x10000 + (x))
 
+/* Registers for GDMA configuration access */
+#define MTK_GDMA_FWD_CFG(x)		(0x500 + (x * 0x1000))
+#define GDMA_SPEC_TAG			BIT(24)
+
 /* Registers to ethsys access */
 #define ETHSYS_CLKCFG0			0x2c
 #define  ETHSYS_TRGMII_CLK_SEL362_5	BIT(11)
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_dbg.c b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_dbg.c
index a745eddde..de7a8de90 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_dbg.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_dbg.c
@@ -28,23 +28,43 @@
 #include "mtk_eth_soc.h"
 #include "mtk_eth_dbg.h"
 
+u32 hw_lro_agg_num_cnt[MTK_HW_LRO_RING_NUM][MTK_HW_LRO_MAX_AGG_CNT + 1];
+u32 hw_lro_agg_size_cnt[MTK_HW_LRO_RING_NUM][16];
+u32 hw_lro_tot_agg_cnt[MTK_HW_LRO_RING_NUM];
+u32 hw_lro_tot_flush_cnt[MTK_HW_LRO_RING_NUM];
+u32 hw_lro_agg_flush_cnt[MTK_HW_LRO_RING_NUM];
+u32 hw_lro_age_flush_cnt[MTK_HW_LRO_RING_NUM];
+u32 hw_lro_seq_flush_cnt[MTK_HW_LRO_RING_NUM];
+u32 hw_lro_timestamp_flush_cnt[MTK_HW_LRO_RING_NUM];
+u32 hw_lro_norule_flush_cnt[MTK_HW_LRO_RING_NUM];
+u32 mtk_hwlro_stats_ebl;
+static struct proc_dir_entry *proc_hw_lro_stats, *proc_hw_lro_auto_tlb;
+typedef int (*mtk_lro_dbg_func) (int par);
 struct mtk_eth *g_eth;
 
 void mt7530_mdio_w32(struct mtk_eth *eth, u32 reg, u32 val)
 {
+	mutex_lock(&eth->mii_bus->mdio_lock);
+
 	_mtk_mdio_write(eth, 0x1f, 0x1f, (reg >> 6) & 0x3ff);
 	_mtk_mdio_write(eth, 0x1f, (reg >> 2) & 0xf,  val & 0xffff);
 	_mtk_mdio_write(eth, 0x1f, 0x10, val >> 16);
+
+	mutex_unlock(&eth->mii_bus->mdio_lock);
 }
 
 u32 mt7530_mdio_r32(struct mtk_eth *eth, u32 reg)
 {
 	u16 high, low;
 
+	mutex_lock(&eth->mii_bus->mdio_lock);
+
 	_mtk_mdio_write(eth, 0x1f, 0x1f, (reg >> 6) & 0x3ff);
 	low = _mtk_mdio_read(eth, 0x1f, (reg >> 2) & 0xf);
 	high = _mtk_mdio_read(eth, 0x1f, 0x10);
 
+	mutex_unlock(&eth->mii_bus->mdio_lock);
+
 	return (high << 16) | (low & 0xffff);
 }
 
@@ -356,7 +376,8 @@ void mii_mgr_read_combine(struct mtk_eth *eth, u32 phy_addr, u32 phy_register,
 		*read_data = mt7530_mdio_r32(eth, phy_register);
 
 	else
-		*read_data = _mtk_mdio_read(eth, phy_addr, phy_register);
+		*read_data = mdiobus_read_nested(eth->mii_bus, phy_addr,
+						 phy_register);
 }
 
 void mii_mgr_write_combine(struct mtk_eth *eth, u32 phy_addr, u32 phy_register,
@@ -366,7 +387,8 @@ void mii_mgr_write_combine(struct mtk_eth *eth, u32 phy_addr, u32 phy_register,
 		mt7530_mdio_w32(eth, phy_register, write_data);
 
 	else
-		_mtk_mdio_write(eth, phy_addr, phy_register, write_data);
+		mdiobus_write_nested(eth->mii_bus, phy_addr, phy_register,
+				     write_data);
 }
 
 static void mii_mgr_read_cl45(struct mtk_eth *eth, u32 port, u32 devad, u32 reg, u32 *data)
@@ -442,7 +464,6 @@ int mtk_do_priv_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 
 		return 0;
 	default:
-		pr_info("%s ioctl %d is not supported", __func__, cmd);
 		break;
 	}
 
@@ -678,13 +699,456 @@ static const struct file_operations rx_ring_fops = {
 	.release = single_release
 };
 
-#define PROCREG_ESW_CNT         "esw_cnt"
-#define PROCREG_TXRING          "tx_ring"
-#define PROCREG_RXRING          "rx_ring"
-#define PROCREG_DIR             "mtketh"
+int dbg_regs_read(struct seq_file *seq, void *v)
+{
+	struct mtk_eth *eth = g_eth;
+
+	seq_puts(seq, "   <<PSE DEBUG REG DUMP>>\n");
+	seq_printf(seq, "| PSE_FQFC_CFG	: %08x |\n",
+		   mtk_r32(eth, MTK_PSE_FQFC_CFG));
+	seq_printf(seq, "| PSE_IQ_STA1	: %08x |\n",
+		   mtk_r32(eth, MTK_PSE_IQ_STA1));
+	seq_printf(seq, "| PSE_IQ_STA2	: %08x |\n",
+		   mtk_r32(eth, MTK_PSE_IQ_STA2));
+	seq_printf(seq, "| PSE_OQ_STA1	: %08x |\n",
+		   mtk_r32(eth, MTK_PSE_OQ_STA1));
+	seq_printf(seq, "| PSE_OQ_STA2	: %08x |\n",
+		   mtk_r32(eth, MTK_PSE_OQ_STA2));
+	seq_printf(seq, "| FE_PSE_FREE	: %08x |\n",
+		   mtk_r32(eth, MTK_FE_PSE_FREE));
+	seq_printf(seq, "| FE_DROP_FQ	: %08x |\n",
+		   mtk_r32(eth, MTK_FE_DROP_FQ));
+	seq_printf(seq, "| FE_DROP_FC	: %08x |\n",
+		   mtk_r32(eth, MTK_FE_DROP_FC));
+	seq_printf(seq, "| FE_DROP_PPE	: %08x |\n",
+		   mtk_r32(eth, MTK_FE_DROP_PPE));
+	seq_printf(seq, "| GDM1_IG_CTRL	: %08x |\n",
+		   mtk_r32(eth, MTK_GDMA_FWD_CFG(0)));
+	seq_printf(seq, "| GDM2_IG_CTRL	: %08x |\n",
+		   mtk_r32(eth, MTK_GDMA_FWD_CFG(1)));
+	seq_printf(seq, "| MAC_P1_MCR	: %08x |\n",
+		   mtk_r32(eth, MTK_MAC_MCR(0)));
+	seq_printf(seq, "| MAC_P2_MCR	: %08x |\n",
+		   mtk_r32(eth, MTK_MAC_MCR(1)));
+
+	return 0;
+}
+
+static int dbg_regs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, dbg_regs_read, 0);
+}
+
+static const struct file_operations dbg_regs_fops = {
+	.owner = THIS_MODULE,
+	.open = dbg_regs_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release
+};
+
+void hw_lro_stats_update(u32 ring_no, struct mtk_rx_dma *rxd)
+{
+	u32 agg_cnt = RX_DMA_GET_REV(rxd->rxd2);
+	u32 agg_size = RX_DMA_GET_PLEN0(rxd->rxd2) |
+		(RX_DMA_GET_PLEN1(rxd->rxd2) << 14);
+
+	hw_lro_agg_size_cnt[ring_no - 1][agg_size / 5000]++;
+	hw_lro_agg_num_cnt[ring_no - 1][agg_cnt]++;
+	hw_lro_tot_flush_cnt[ring_no - 1]++;
+	hw_lro_tot_agg_cnt[ring_no - 1] += agg_cnt;
+}
+
+void hw_lro_flush_stats_update(u32 ring_no, struct mtk_rx_dma *rxd)
+{
+	u32 flush_reason = RX_DMA_GET_REV(rxd->rxd2);
+
+	if ((flush_reason & 0x7) == MTK_HW_LRO_AGG_FLUSH)
+		hw_lro_agg_flush_cnt[ring_no - 1]++;
+	else if ((flush_reason & 0x7) == MTK_HW_LRO_AGE_FLUSH)
+		hw_lro_age_flush_cnt[ring_no - 1]++;
+	else if ((flush_reason & 0x7) == MTK_HW_LRO_NOT_IN_SEQ_FLUSH)
+		hw_lro_seq_flush_cnt[ring_no - 1]++;
+	else if ((flush_reason & 0x7) == MTK_HW_LRO_TIMESTAMP_FLUSH)
+		hw_lro_timestamp_flush_cnt[ring_no - 1]++;
+	else if ((flush_reason & 0x7) == MTK_HW_LRO_NON_RULE_FLUSH)
+		hw_lro_norule_flush_cnt[ring_no - 1]++;
+}
+
+ssize_t hw_lro_stats_write(struct file *file, const char __user *buffer,
+			   size_t count, loff_t *data)
+{
+	memset(hw_lro_agg_num_cnt, 0, sizeof(hw_lro_agg_num_cnt));
+	memset(hw_lro_agg_size_cnt, 0, sizeof(hw_lro_agg_size_cnt));
+	memset(hw_lro_tot_agg_cnt, 0, sizeof(hw_lro_tot_agg_cnt));
+	memset(hw_lro_tot_flush_cnt, 0, sizeof(hw_lro_tot_flush_cnt));
+	memset(hw_lro_agg_flush_cnt, 0, sizeof(hw_lro_agg_flush_cnt));
+	memset(hw_lro_age_flush_cnt, 0, sizeof(hw_lro_age_flush_cnt));
+	memset(hw_lro_seq_flush_cnt, 0, sizeof(hw_lro_seq_flush_cnt));
+	memset(hw_lro_timestamp_flush_cnt, 0,
+	       sizeof(hw_lro_timestamp_flush_cnt));
+	memset(hw_lro_norule_flush_cnt, 0, sizeof(hw_lro_norule_flush_cnt));
+
+	pr_info("clear hw lro cnt table\n");
+
+	return count;
+}
+
+int hw_lro_stats_read(struct seq_file *seq, void *v)
+{
+	int i;
+
+	seq_puts(seq, "HW LRO statistic dump:\n");
+
+	/* Agg number count */
+	seq_puts(seq, "Cnt:   RING1 | RING2 | RING3 | Total\n");
+	for (i = 0; i <= MTK_HW_LRO_MAX_AGG_CNT; i++) {
+		seq_printf(seq, " %d :      %d        %d        %d        %d\n",
+			   i, hw_lro_agg_num_cnt[0][i],
+			   hw_lro_agg_num_cnt[1][i], hw_lro_agg_num_cnt[2][i],
+			   hw_lro_agg_num_cnt[0][i] + hw_lro_agg_num_cnt[1][i] +
+			   hw_lro_agg_num_cnt[2][i]);
+	}
+
+	/* Total agg count */
+	seq_puts(seq, "Total agg:   RING1 | RING2 | RING3 | Total\n");
+	seq_printf(seq, "                %d      %d      %d      %d\n",
+		   hw_lro_tot_agg_cnt[0], hw_lro_tot_agg_cnt[1],
+		   hw_lro_tot_agg_cnt[2],
+		   hw_lro_tot_agg_cnt[0] + hw_lro_tot_agg_cnt[1] +
+		   hw_lro_tot_agg_cnt[2]);
+
+	/* Total flush count */
+	seq_puts(seq, "Total flush:   RING1 | RING2 | RING3 | Total\n");
+	seq_printf(seq, "                %d      %d      %d      %d\n",
+		   hw_lro_tot_flush_cnt[0], hw_lro_tot_flush_cnt[1],
+		   hw_lro_tot_flush_cnt[2],
+		   hw_lro_tot_flush_cnt[0] + hw_lro_tot_flush_cnt[1] +
+		   hw_lro_tot_flush_cnt[2]);
+
+	/* Avg agg count */
+	seq_puts(seq, "Avg agg:   RING1 | RING2 | RING3 | Total\n");
+	seq_printf(seq, "                %d      %d      %d      %d\n",
+		   (hw_lro_tot_flush_cnt[0]) ?
+		    hw_lro_tot_agg_cnt[0] / hw_lro_tot_flush_cnt[0] : 0,
+		   (hw_lro_tot_flush_cnt[1]) ?
+		    hw_lro_tot_agg_cnt[1] / hw_lro_tot_flush_cnt[1] : 0,
+		   (hw_lro_tot_flush_cnt[2]) ?
+		    hw_lro_tot_agg_cnt[2] / hw_lro_tot_flush_cnt[2] : 0,
+		   (hw_lro_tot_flush_cnt[0] + hw_lro_tot_flush_cnt[1] +
+		    hw_lro_tot_flush_cnt[2]) ?
+		    ((hw_lro_tot_agg_cnt[0] + hw_lro_tot_agg_cnt[1] +
+		      hw_lro_tot_agg_cnt[2]) / (hw_lro_tot_flush_cnt[0] +
+		      hw_lro_tot_flush_cnt[1] + hw_lro_tot_flush_cnt[2])) : 0);
+
+	/*  Statistics of aggregation size counts */
+	seq_puts(seq, "HW LRO flush pkt len:\n");
+	seq_puts(seq, " Length  | RING1  | RING2  | RING3  | Total\n");
+	for (i = 0; i < 15; i++) {
+		seq_printf(seq, "%d~%d: %d      %d      %d      %d\n", i * 5000,
+			   (i + 1) * 5000, hw_lro_agg_size_cnt[0][i],
+			   hw_lro_agg_size_cnt[1][i], hw_lro_agg_size_cnt[2][i],
+			   hw_lro_agg_size_cnt[0][i] +
+			   hw_lro_agg_size_cnt[1][i] +
+			   hw_lro_agg_size_cnt[2][i]);
+	}
+
+	seq_puts(seq, "Flush reason:   RING1 | RING2 | RING3 | Total\n");
+	seq_printf(seq, "AGG timeout:      %d      %d      %d      %d\n",
+		   hw_lro_agg_flush_cnt[0], hw_lro_agg_flush_cnt[1],
+		   hw_lro_agg_flush_cnt[2],
+		   (hw_lro_agg_flush_cnt[0] + hw_lro_agg_flush_cnt[1] +
+		    hw_lro_agg_flush_cnt[2]));
+
+	seq_printf(seq, "AGE timeout:      %d      %d      %d      %d\n",
+		   hw_lro_age_flush_cnt[0], hw_lro_age_flush_cnt[1],
+		   hw_lro_age_flush_cnt[2],
+		   (hw_lro_age_flush_cnt[0] + hw_lro_age_flush_cnt[1] +
+		    hw_lro_age_flush_cnt[2]));
+
+	seq_printf(seq, "Not in-sequence:  %d      %d      %d      %d\n",
+		   hw_lro_seq_flush_cnt[0], hw_lro_seq_flush_cnt[1],
+		   hw_lro_seq_flush_cnt[2],
+		   (hw_lro_seq_flush_cnt[0] + hw_lro_seq_flush_cnt[1] +
+		    hw_lro_seq_flush_cnt[2]));
+
+	seq_printf(seq, "Timestamp:        %d      %d      %d      %d\n",
+		   hw_lro_timestamp_flush_cnt[0],
+		   hw_lro_timestamp_flush_cnt[1],
+		   hw_lro_timestamp_flush_cnt[2],
+		   (hw_lro_timestamp_flush_cnt[0] +
+		    hw_lro_timestamp_flush_cnt[1] +
+		    hw_lro_timestamp_flush_cnt[2]));
+
+	seq_printf(seq, "No LRO rule:      %d      %d      %d      %d\n",
+		   hw_lro_norule_flush_cnt[0],
+		   hw_lro_norule_flush_cnt[1],
+		   hw_lro_norule_flush_cnt[2],
+		   (hw_lro_norule_flush_cnt[0] +
+		    hw_lro_norule_flush_cnt[1] +
+		    hw_lro_norule_flush_cnt[2]));
+
+	return 0;
+}
+
+static int hw_lro_stats_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, hw_lro_stats_read, NULL);
+}
+
+static const struct file_operations hw_lro_stats_fops = {
+	.owner = THIS_MODULE,
+	.open = hw_lro_stats_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.write = hw_lro_stats_write,
+	.release = single_release
+};
+
+int hwlro_agg_cnt_ctrl(int cnt)
+{
+	int i;
+
+	FOR_EACH_LRO_RING(i) {
+		SET_PDMA_RXRING_MAX_AGG_CNT(g_eth, i, cnt);
+	}
+
+	return 0;
+}
+
+int hwlro_agg_time_ctrl(int time)
+{
+	int i;
+
+	FOR_EACH_LRO_RING(i) {
+		SET_PDMA_RXRING_AGG_TIME(g_eth, i, time);
+	}
+
+	return 0;
+}
+
+int hwlro_age_time_ctrl(int time)
+{
+	int i;
+
+	FOR_EACH_LRO_RING(i) {
+		SET_PDMA_RXRING_AGE_TIME(g_eth, i, time);
+	}
+
+	return 0;
+}
+
+int hwlro_threshold_ctrl(int bandwidth)
+{
+	SET_PDMA_LRO_BW_THRESHOLD(g_eth, bandwidth);
+
+	return 0;
+}
+
+int hwlro_ring_enable_ctrl(int enable)
+{
+	int i;
+
+	pr_info("[%s] %s HW LRO rings\n", __func__, (enable) ? "Enable" : "Disable");
+
+	FOR_EACH_LRO_RING(i) {
+		SET_PDMA_RXRING_VALID(g_eth, i, enable);
+	}
+
+	return 0;
+}
+
+int hwlro_stats_enable_ctrl(int enable)
+{
+	pr_info("[%s] %s HW LRO statistics\n", __func__, (enable) ? "Enable" : "Disable");
+	mtk_hwlro_stats_ebl = enable;
+
+	return 0;
+}
+
+static const mtk_lro_dbg_func lro_dbg_func[] = {
+	[0] = hwlro_agg_cnt_ctrl,
+	[1] = hwlro_agg_time_ctrl,
+	[2] = hwlro_age_time_ctrl,
+	[3] = hwlro_threshold_ctrl,
+	[4] = hwlro_ring_enable_ctrl,
+	[5] = hwlro_stats_enable_ctrl,
+};
+
+ssize_t hw_lro_auto_tlb_write(struct file *file, const char __user *buffer,
+			      size_t count, loff_t *data)
+{
+	char buf[32];
+	char *p_buf;
+	char *p_token = NULL;
+	char *p_delimiter = " \t";
+	long x = 0, y = 0;
+	int len = count;
+	int ret;
+
+	pr_info("[%s] write parameter len = %d\n\r", __func__, (int)len);
+
+	if (len >= sizeof(buf)) {
+		pr_info("Input handling fail!\n");
+		len = sizeof(buf) - 1;
+		return -1;
+	}
+
+	if (copy_from_user(buf, buffer, len))
+		return -EFAULT;
+
+	buf[len] = '\0';
+	pr_info("[%s] write parameter data = %s\n\r", __func__, buf);
+
+	p_buf = buf;
+	p_token = strsep(&p_buf, p_delimiter);
+	if (!p_token)
+		x = 0;
+	else
+		ret = kstrtol(p_token, 10, &x);
+
+	p_token = strsep(&p_buf, "\t\n ");
+	if (p_token) {
+		ret = kstrtol(p_token, 10, &y);
+		pr_info("y = %ld\n\r", y);
+	}
+
+	if (lro_dbg_func[x] && (ARRAY_SIZE(lro_dbg_func) > x))
+		(*lro_dbg_func[x]) (y);
+
+	return count;
+}
+
+void hw_lro_auto_tlb_dump(struct seq_file *seq, u32 index)
+{
+	int i;
+	struct mtk_lro_alt alt;
+	__be32 addr;
+	u32 tlb_info[9];
+	u32 dw_len, cnt, priority;
+	u32 entry;
+
+	if (index > 4)
+		index = index - 1;
+	entry = (index * 9) + 1;
+
+	/* read valid entries of the auto-learn table */
+	mtk_w32(g_eth, entry, MTK_FE_ALT_CF8);
+
+	for (i = 0; i < 9; i++)
+		tlb_info[i] = mtk_r32(g_eth, MTK_FE_ALT_SEQ_CFC);
+
+	memcpy(&alt, tlb_info, sizeof(struct mtk_lro_alt));
+
+	dw_len = alt.alt_info7.dw_len;
+	cnt = alt.alt_info6.cnt;
+
+	if (mtk_r32(g_eth, MTK_PDMA_LRO_CTRL_DW0) & MTK_LRO_ALT_PKT_CNT_MODE)
+		priority = cnt;		/* packet count */
+	else
+		priority = dw_len;	/* byte count */
+
+	/* dump valid entries of the auto-learn table */
+	if (index >= 4)
+		seq_printf(seq, "\n===== TABLE Entry: %d (Act) =====\n", index);
+	else
+		seq_printf(seq, "\n===== TABLE Entry: %d (LRU) =====\n", index);
+
+	if (alt.alt_info8.ipv4) {
+		addr = htonl(alt.alt_info1.sip0);
+		seq_printf(seq, "SIP = %pI4 (IPv4)\n", &addr);
+	} else {
+		seq_printf(seq, "SIP = %08X:%08X:%08X:%08X (IPv6)\n",
+			   alt.alt_info4.sip3, alt.alt_info3.sip2,
+			   alt.alt_info2.sip1, alt.alt_info1.sip0);
+	}
+
+	seq_printf(seq, "DIP_ID = %d\n", alt.alt_info8.dip_id);
+	seq_printf(seq, "TCP SPORT = %d | TCP DPORT = %d\n",
+		   alt.alt_info0.stp, alt.alt_info0.dtp);
+	seq_printf(seq, "VLAN_VID_VLD = %d\n", alt.alt_info6.vlan_vid_vld);
+	seq_printf(seq, "VLAN1 = %d | VLAN2 = %d | VLAN3 = %d | VLAN4 =%d\n",
+		   (alt.alt_info5.vlan_vid0 & 0xfff),
+		   ((alt.alt_info5.vlan_vid0 >> 12) & 0xfff),
+		   ((alt.alt_info6.vlan_vid1 << 8) |
+		   ((alt.alt_info5.vlan_vid0 >> 24) & 0xfff)),
+		   ((alt.alt_info6.vlan_vid1 >> 4) & 0xfff));
+	seq_printf(seq, "TPUT = %d | FREQ = %d\n", dw_len, cnt);
+	seq_printf(seq, "PRIORITY = %d\n", priority);
+}
+
+int hw_lro_auto_tlb_read(struct seq_file *seq, void *v)
+{
+	int i;
+	u32 reg_val;
+	u32 reg_op1, reg_op2, reg_op3, reg_op4;
+	u32 agg_cnt, agg_time, age_time;
+
+	seq_puts(seq, "Usage of /proc/mtketh/hw_lro_auto_tlb:\n");
+	seq_puts(seq, "echo [function] [setting] > /proc/mtketh/hw_lro_auto_tlb\n");
+	seq_puts(seq, "Functions:\n");
+	seq_puts(seq, "[0] = hwlro_agg_cnt_ctrl\n");
+	seq_puts(seq, "[1] = hwlro_agg_time_ctrl\n");
+	seq_puts(seq, "[2] = hwlro_age_time_ctrl\n");
+	seq_puts(seq, "[3] = hwlro_threshold_ctrl\n");
+	seq_puts(seq, "[4] = hwlro_ring_enable_ctrl\n");
+	seq_puts(seq, "[5] = hwlro_stats_enable_ctrl\n\n");
+
+	/* Read valid entries of the auto-learn table */
+	mtk_w32(g_eth, 0, MTK_FE_ALT_CF8);
+	reg_val = mtk_r32(g_eth, MTK_FE_ALT_SEQ_CFC);
+
+	seq_printf(seq,
+		   "HW LRO Auto-learn Table: (MTK_FE_ALT_SEQ_CFC=0x%x)\n",
+		   reg_val);
+
+	for (i = 7; i >= 0; i--) {
+		if (reg_val & (1 << i))
+			hw_lro_auto_tlb_dump(seq, i);
+	}
+
+	/* Read the agg_time/age_time/agg_cnt of LRO rings */
+	seq_puts(seq, "\nHW LRO Ring Settings\n");
+
+	FOR_EACH_LRO_RING(i) {
+		reg_op1 = mtk_r32(g_eth, MTK_LRO_CTRL_DW1_CFG(i));
+		reg_op2 = mtk_r32(g_eth, MTK_LRO_CTRL_DW2_CFG(i));
+		reg_op3 = mtk_r32(g_eth, MTK_LRO_CTRL_DW3_CFG(i));
+		reg_op4 = mtk_r32(g_eth, MTK_PDMA_LRO_CTRL_DW2);
+
+		agg_cnt =
+		    ((reg_op3 & 0x3) << 6) |
+		    ((reg_op2 >> MTK_LRO_RING_AGG_CNT_L_OFFSET) & 0x3f);
+		agg_time = (reg_op2 >> MTK_LRO_RING_AGG_TIME_OFFSET) & 0xffff;
+		age_time =
+		    ((reg_op2 & 0x3f) << 10) |
+		    ((reg_op1 >> MTK_LRO_RING_AGE_TIME_L_OFFSET) & 0x3ff);
+		seq_printf(seq,
+			   "Ring[%d]: MAX_AGG_CNT=%d, AGG_TIME=%d, AGE_TIME=%d, Threshold=%d\n",
+			   i, agg_cnt, agg_time, age_time, reg_op4);
+	}
+
+	seq_puts(seq, "\n");
+
+	return 0;
+}
+
+static int hw_lro_auto_tlb_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, hw_lro_auto_tlb_read, NULL);
+}
+
+static const struct file_operations hw_lro_auto_tlb_fops = {
+	.owner = THIS_MODULE,
+	.open = hw_lro_auto_tlb_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.write = hw_lro_auto_tlb_write,
+	.release = single_release
+};
 
 struct proc_dir_entry *proc_reg_dir;
-static struct proc_dir_entry *proc_esw_cnt;
+static struct proc_dir_entry *proc_esw_cnt, *proc_dbg_regs;
 
 int debug_proc_init(struct mtk_eth *eth)
 {
@@ -708,6 +1172,26 @@ int debug_proc_init(struct mtk_eth *eth)
 	if (!proc_esw_cnt)
 		pr_notice("!! FAIL to create %s PROC !!\n", PROCREG_ESW_CNT);
 
+	proc_dbg_regs =
+	    proc_create(PROCREG_DBG_REGS, 0, proc_reg_dir, &dbg_regs_fops);
+	if (!proc_dbg_regs)
+		pr_notice("!! FAIL to create %s PROC !!\n", PROCREG_DBG_REGS);
+
+	if (g_eth->hwlro) {
+		proc_hw_lro_stats =
+			proc_create(PROCREG_HW_LRO_STATS, 0, proc_reg_dir,
+				    &hw_lro_stats_fops);
+		if (!proc_hw_lro_stats)
+			pr_info("!! FAIL to create %s PROC !!\n", PROCREG_HW_LRO_STATS);
+
+		proc_hw_lro_auto_tlb =
+			proc_create(PROCREG_HW_LRO_AUTO_TLB, 0, proc_reg_dir,
+				    &hw_lro_auto_tlb_fops);
+		if (!proc_hw_lro_auto_tlb)
+			pr_info("!! FAIL to create %s PROC !!\n",
+				PROCREG_HW_LRO_AUTO_TLB);
+	}
+
 	return 0;
 }
 
@@ -723,5 +1207,16 @@ void debug_proc_exit(void)
 
 	if (proc_reg_dir)
 		remove_proc_entry(PROCREG_DIR, 0);
+
+	if (proc_dbg_regs)
+		remove_proc_entry(PROCREG_DBG_REGS, proc_reg_dir);
+
+	if (g_eth->hwlro) {
+		if (proc_hw_lro_stats)
+			remove_proc_entry(PROCREG_HW_LRO_STATS, proc_reg_dir);
+
+		if (proc_hw_lro_auto_tlb)
+			remove_proc_entry(PROCREG_HW_LRO_AUTO_TLB, proc_reg_dir);
+	}
 }
 
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_dbg.h b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_dbg.h
index 32984971f..c4f0a948e 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_dbg.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_dbg.h
@@ -15,17 +15,149 @@
  *   Copyright (C) 2013-2016 Michael Lee <igvtee@gmail.com>
  */
 
+#include "mtk_eth_soc.h"
+
 #ifndef MTK_ETH_DBG_H
 #define MTK_ETH_DBG_H
 
 #ifdef CONFIG_NET_MEDIATEK_DBG
-#define MTKETH_MII_READ                  0x89F3
-#define MTKETH_MII_WRITE                 0x89F4
-#define MTKETH_ESW_REG_READ              0x89F1
-#define MTKETH_ESW_REG_WRITE             0x89F2
-#define MTKETH_MII_READ_CL45             0x89FC
-#define MTKETH_MII_WRITE_CL45            0x89FD
-#define REG_ESW_MAX                     0xFC
+/* Debug Purpose Registers */
+#define MTK_PSE_FQFC_CFG		0x100
+#define MTK_PSE_IQ_STA1			0x110
+#define MTK_PSE_IQ_STA2			0x114
+#define MTK_PSE_OQ_STA1			0x118
+#define MTK_PSE_OQ_STA2			0x11C
+#define MTK_FE_PSE_FREE			0x240
+#define MTK_FE_DROP_FQ			0x244
+#define MTK_FE_DROP_FC			0x248
+#define MTK_FE_DROP_PPE			0x24C
+
+#define MTKETH_MII_READ			0x89F3
+#define MTKETH_MII_WRITE		0x89F4
+#define MTKETH_ESW_REG_READ		0x89F1
+#define MTKETH_ESW_REG_WRITE		0x89F2
+#define MTKETH_MII_READ_CL45		0x89FC
+#define MTKETH_MII_WRITE_CL45		0x89FD
+#define REG_ESW_MAX			0xFC
+
+#define PROCREG_ESW_CNT			"esw_cnt"
+#define PROCREG_TXRING			"tx_ring"
+#define PROCREG_RXRING			"rx_ring"
+#define PROCREG_DIR			"mtketh"
+#define PROCREG_DBG_REGS		"dbg_regs"
+#define PROCREG_HW_LRO_STATS		"hw_lro_stats"
+#define PROCREG_HW_LRO_AUTO_TLB		"hw_lro_auto_tlb"
+
+/* HW LRO flush reason */
+#define MTK_HW_LRO_AGG_FLUSH		(1)
+#define MTK_HW_LRO_AGE_FLUSH		(2)
+#define MTK_HW_LRO_NOT_IN_SEQ_FLUSH	(3)
+#define MTK_HW_LRO_TIMESTAMP_FLUSH	(4)
+#define MTK_HW_LRO_NON_RULE_FLUSH	(5)
+
+#define SET_PDMA_RXRING_MAX_AGG_CNT(eth, x, y)				\
+{									\
+	u32 reg_val1 = mtk_r32(eth, MTK_LRO_CTRL_DW2_CFG(x));		\
+	u32 reg_val2 = mtk_r32(eth, MTK_LRO_CTRL_DW3_CFG(x));		\
+	reg_val1 &= ~MTK_LRO_RING_AGG_CNT_L_MASK;			\
+	reg_val2 &= ~MTK_LRO_RING_AGG_CNT_H_MASK;			\
+	reg_val1 |= ((y) & 0x3f) << MTK_LRO_RING_AGG_CNT_L_OFFSET;	\
+	reg_val2 |= (((y) >> 6) & 0x03) <<				\
+		     MTK_LRO_RING_AGG_CNT_H_OFFSET;			\
+	mtk_w32(eth, reg_val1, MTK_LRO_CTRL_DW2_CFG(x));		\
+	mtk_w32(eth, reg_val2, MTK_LRO_CTRL_DW3_CFG(x));		\
+}
+
+#define SET_PDMA_RXRING_AGG_TIME(eth, x, y)				\
+{									\
+	u32 reg_val = mtk_r32(eth, MTK_LRO_CTRL_DW2_CFG(x));		\
+	reg_val &= ~MTK_LRO_RING_AGG_TIME_MASK;				\
+	reg_val |= ((y) & 0xffff) << MTK_LRO_RING_AGG_TIME_OFFSET;	\
+	mtk_w32(eth, reg_val, MTK_LRO_CTRL_DW2_CFG(x));			\
+}
+
+#define SET_PDMA_RXRING_AGE_TIME(eth, x, y)				\
+{									\
+	u32 reg_val1 = mtk_r32(eth, MTK_LRO_CTRL_DW1_CFG(x));		\
+	u32 reg_val2 = mtk_r32(eth, MTK_LRO_CTRL_DW2_CFG(x));		\
+	reg_val1 &= ~MTK_LRO_RING_AGE_TIME_L_MASK;			\
+	reg_val2 &= ~MTK_LRO_RING_AGE_TIME_H_MASK;			\
+	reg_val1 |= ((y) & 0x3ff) << MTK_LRO_RING_AGE_TIME_L_OFFSET;	\
+	reg_val2 |= (((y) >> 10) & 0x03f) <<				\
+		     MTK_LRO_RING_AGE_TIME_H_OFFSET;			\
+	mtk_w32(eth, reg_val1, MTK_LRO_CTRL_DW1_CFG(x));		\
+	mtk_w32(eth, reg_val2, MTK_LRO_CTRL_DW2_CFG(x));		\
+}
+
+#define SET_PDMA_LRO_BW_THRESHOLD(eth, x)				\
+{									\
+	u32 reg_val = mtk_r32(eth, MTK_PDMA_LRO_CTRL_DW2);		\
+	reg_val = (x);							\
+	mtk_w32(eth, reg_val, MTK_PDMA_LRO_CTRL_DW2);			\
+}
+
+#define SET_PDMA_RXRING_VALID(eth, x, y)				\
+{									\
+	u32 reg_val = mtk_r32(eth, MTK_LRO_CTRL_DW2_CFG(x));		\
+	reg_val &= ~(0x1 << MTK_RX_PORT_VALID_OFFSET);			\
+	reg_val |= ((y) & 0x1) << MTK_RX_PORT_VALID_OFFSET;		\
+	mtk_w32(eth, reg_val, MTK_LRO_CTRL_DW2_CFG(x));			\
+}
+
+struct mtk_lro_alt_info0 {
+	u32 dtp : 16;
+	u32 stp : 16;
+};
+
+struct mtk_lro_alt_info1 {
+	u32 sip0 : 32;
+};
+
+struct mtk_lro_alt_info2 {
+	u32 sip1 : 32;
+};
+
+struct mtk_lro_alt_info3 {
+	u32 sip2 : 32;
+};
+
+struct mtk_lro_alt_info4 {
+	u32 sip3 : 32;
+};
+
+struct mtk_lro_alt_info5 {
+	u32 vlan_vid0 : 32;
+};
+
+struct mtk_lro_alt_info6 {
+	u32 vlan_vid1 : 16;
+	u32 vlan_vid_vld : 4;
+	u32 cnt : 12;
+};
+
+struct mtk_lro_alt_info7 {
+	u32 dw_len : 32;
+};
+
+struct mtk_lro_alt_info8 {
+	u32 dip_id : 2;
+	u32 ipv6 : 1;
+	u32 ipv4 : 1;
+	u32 resv : 27;
+	u32 valid : 1;
+};
+
+struct mtk_lro_alt {
+	struct mtk_lro_alt_info0 alt_info0;
+	struct mtk_lro_alt_info1 alt_info1;
+	struct mtk_lro_alt_info2 alt_info2;
+	struct mtk_lro_alt_info3 alt_info3;
+	struct mtk_lro_alt_info4 alt_info4;
+	struct mtk_lro_alt_info5 alt_info5;
+	struct mtk_lro_alt_info6 alt_info6;
+	struct mtk_lro_alt_info7 alt_info7;
+	struct mtk_lro_alt_info8 alt_info8;
+};
 
 struct mtk_esw_reg {
 	unsigned int off;
@@ -67,6 +199,8 @@ void debug_proc_exit(void);
 int mtketh_debugfs_init(struct mtk_eth *eth);
 void mtketh_debugfs_exit(struct mtk_eth *eth);
 int mtk_do_priv_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd);
+void hw_lro_stats_update(u32 ring_no, struct mtk_rx_dma *rxd);
+void hw_lro_flush_stats_update(u32 ring_no, struct mtk_rx_dma *rxd);
 #else
 int mtk_do_priv_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
 {
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_soc.c b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_soc.c
index b0f8975eb..3ab9f1dfc 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_soc.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_soc.c
@@ -32,6 +32,12 @@
 #include "mtk_hnat/nf_hnat_mtk.h"
 #endif
 
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
+#include "mtk_hnat/hnat_sfq.h"
+int (*hnat_sfq_init_hook)(void) = NULL;
+EXPORT_SYMBOL(hnat_sfq_init_hook);
+#endif
+
 static int mtk_msg_level = -1;
 module_param_named(msg_level, mtk_msg_level, int, 0);
 MODULE_PARM_DESC(msg_level, "Message level (-1=defaults,0=none,...,16=all)");
@@ -227,6 +233,7 @@ static void mtk_phy_link_adjust(struct net_device *dev)
 	u16 lcl_adv = 0, rmt_adv = 0;
 	u32 lcl_eee = 0, rmt_eee = 0;
 	u8 flowctrl;
+	u32 mac_eee;
 	u32 mcr = MAC_MCR_MAX_RX_1536 | MAC_MCR_IPG_CFG |
 		  MAC_MCR_FORCE_MODE | MAC_MCR_TX_EN |
 		  MAC_MCR_RX_EN | MAC_MCR_BACKOFF_EN |
@@ -319,14 +326,33 @@ static void mtk_phy_link_adjust(struct net_device *dev)
 			  flowctrl & FLOW_CTRL_RX ? "enabled" : "disabled",
 			  flowctrl & FLOW_CTRL_TX ? "enabled" : "disabled");
 	}
-	/*EEE capability*/
-	mtk_cl45_ind_read(eth, 0, MDIO_MMD_AN, MDIO_AN_EEE_ADV, &lcl_eee);
-	mtk_cl45_ind_read(eth, 0, MDIO_MMD_AN, MDIO_AN_EEE_LPABLE, &rmt_eee);
 
-	if ((lcl_eee & rmt_eee & MDIO_EEE_1000T) == MDIO_EEE_1000T)
-		mcr |= MAC_MCR_MDIO_EEE_1000T;
-	if ((lcl_eee & rmt_eee & MDIO_EEE_100TX) == MDIO_EEE_100TX)
-		mcr |= MAC_MCR_MDIO_EEE_100TX;
+	/*EEE capability*/
+	if (!of_phy_is_fixed_link(mac->of_node)) {
+		mtk_cl45_ind_read(eth, dev->phydev->addr, MDIO_MMD_AN,
+				  MDIO_AN_EEE_ADV, &lcl_eee);
+		mtk_cl45_ind_read(eth, dev->phydev->addr, MDIO_MMD_AN,
+				  MDIO_AN_EEE_LPABLE, &rmt_eee);
+
+		if ((lcl_eee & rmt_eee & MDIO_EEE_1000T) == MDIO_EEE_1000T)
+			mcr |= MAC_MCR_MDIO_EEE_1000T;
+		if ((lcl_eee & rmt_eee & MDIO_EEE_100TX) == MDIO_EEE_100TX)
+			mcr |= MAC_MCR_MDIO_EEE_100TX;
+
+		mac_eee = mtk_r32(mac->hw, MTK_MAC_EEE(mac->id));
+		mac_eee &= ~MAC_EEE_SETTING_MASK;
+		if (mcr & (MAC_MCR_MDIO_EEE_100TX | MAC_MCR_MDIO_EEE_1000T))
+			mac_eee |= MAC_WAKEUP_TIME_1000(0x11) |
+				   MAC_WAKEUP_TIME_100(0x1e) |
+				   MAC_LPI_TXIDLE_THD(0x1e);
+		mtk_w32(mac->hw, mac_eee, MTK_MAC_EEE(mac->id));
+	}
+
+	/* Force eth0 MAC link-up to prevent packet queue in PSE
+	 * for HNAT ping-pong device usage
+	 */
+	if (dev->phydev->link || mac->id == 0)
+		mcr |= MAC_MCR_FORCE_LINK;
 
 	/*Setup MCR*/
 	mtk_w32(mac->hw, mcr, MTK_MAC_MCR(mac->id));
@@ -336,6 +362,10 @@ static void mtk_phy_link_adjust(struct net_device *dev)
 	else
 		netif_carrier_off(dev);
 
+	/* Force eth0 carrier on for HNAT ping-pong device usage */
+	if (mac->id == 0)
+		netif_carrier_on(dev);
+
 	if (!of_phy_is_fixed_link(mac->of_node))
 		phy_print_status(dev->phydev);
 }
@@ -367,38 +397,6 @@ static int mtk_phy_connect_node(struct mtk_eth *eth, struct mtk_mac *mac,
 	return 0;
 }
 
-static void mtk_phy_print_status(struct net_device *dev)
-{
-	phy_print_status(dev->phydev);
-}
-
-static int mtk_phy_link_connect_node(struct mtk_eth *eth, struct mtk_mac *mac,
-				                                     struct device_node *phy_node)
-{
-	struct phy_device *phydev;
-	int phy_mode;
-
-	phy_mode = of_get_phy_mode(phy_node);
-	if (phy_mode < 0) {
-		dev_err(eth->dev, "incorrect phy-mode %d\n", phy_mode);
-		return -EINVAL;
-	}
-
-	phydev = of_phy_connect(eth->netdev[mac->id], phy_node,
-				mtk_phy_print_status, 0, phy_mode);
-	if (!phydev) {
-		dev_err(eth->dev, "could not connect to PHY\n");
-		return -ENODEV;
-	}
-
-	dev_info(eth->dev,
-		 "connected mac %d to PHY at %s [uid=%08x, driver=%s]\n",
-		 mac->id, dev_name(&phydev->dev), phydev->phy_id,
-		 phydev->drv->name);
-
-	return 0;
-}
-
 static int mtk_phy_connect(struct net_device *dev)
 {
 	struct mtk_mac *mac = netdev_priv(dev);
@@ -448,6 +446,7 @@ err_phy:
 static int mtk_mdio_init(struct mtk_eth *eth)
 {
 	struct device_node *mii_np;
+	u32 val;
 	int ret;
 
 	mii_np = of_get_child_by_name(eth->dev->of_node, "mdio-bus");
@@ -473,6 +472,10 @@ static int mtk_mdio_init(struct mtk_eth *eth)
 	eth->mii_bus->priv = eth;
 	eth->mii_bus->parent = eth->dev;
 
+	/* Disable PHY auto-polling to avoid mdio access from HW */
+	val = mtk_r32(eth, MTK_PHY_PSC);
+	mtk_w32(eth, val & ~PHY_AP_EN, MTK_PHY_PSC);
+
 	snprintf(eth->mii_bus->id, MII_BUS_ID_SIZE, "%s", mii_np->name);
 	ret = of_mdiobus_register(eth->mii_bus, mii_np);
 
@@ -761,6 +764,7 @@ static int mtk_tx_map(struct sk_buff *skb, struct net_device *dev,
 	int i, n_desc = 1;
 	u32 txd4 = 0, fport;
 	u32 qid = 0;
+	u32 sfq_info = 0;
 
 	itxd = ring->next_free;
 	if (itxd == ring->last_free)
@@ -780,7 +784,15 @@ static int mtk_tx_map(struct sk_buff *skb, struct net_device *dev,
 	if (skb->ip_summed == CHECKSUM_PARTIAL)
 		txd4 |= TX_DMA_CHKSUM;
 
+	/* VLAN header offload */
+	if (skb_vlan_tag_present(skb))
+		txd4 |= TX_DMA_INS_VLAN | skb_vlan_tag_get(skb);
+
 #if defined(CONFIG_NET_MEDIATEK_HW_QOS)
+	if (hnat_sfq_init_hook)
+		sfq_info =
+			TX_DMA_VQID(skb_hnat_entry(skb) % MTK_PER_GRP_VQ_NUM);
+
 	qid = skb->mark & (MTK_QDMA_TX_MASK);
 #else
 	qid = mac->id;
@@ -837,7 +849,8 @@ static int mtk_tx_map(struct sk_buff *skb, struct net_device *dev,
 			WRITE_ONCE(txd->txd1, mapped_addr);
 			WRITE_ONCE(txd->txd3, (TX_DMA_SWC | QID_LOW_BITS(qid) |
 					       TX_DMA_PLEN0(frag_map_size) |
-					       last_frag * TX_DMA_LS0));
+					       last_frag * TX_DMA_LS0) |
+					       sfq_info);
 			WRITE_ONCE(txd->txd4, fport | QID_HIGH_BITS(qid));
 
 			tx_buf = mtk_desc_to_tx_buf(ring, txd);
@@ -858,7 +871,8 @@ static int mtk_tx_map(struct sk_buff *skb, struct net_device *dev,
 	itx_buf->skb = skb;
 
 	WRITE_ONCE(itxd->txd3, (TX_DMA_SWC | TX_DMA_PLEN0(skb_headlen(skb)) |
-				(!nr_frags * TX_DMA_LS0)) | QID_LOW_BITS(qid));
+				(!nr_frags * TX_DMA_LS0)) | QID_LOW_BITS(qid) |
+				sfq_info);
 	WRITE_ONCE(itxd->txd4, txd4 | QID_HIGH_BITS(qid));
 
 	//netdev_sent_queue(dev, skb->len);
@@ -1062,12 +1076,9 @@ static int mtk_poll_rx(struct napi_struct *napi, int budget,
 			break;
 
 		/* find out which mac the packet come from. values start at 1 */
-#if defined(CONFIG_NET_DSA)
-		mac = (trxd.rxd4 >> 22) & 0x1;
-		mac = (mac + 1) % 2;
-#else
 		mac = (trxd.rxd4 >> RX_DMA_FPORT_SHIFT) &
 			RX_DMA_FPORT_MASK;
+
 		/* From QDMA(5). This is a external interface case of HWNAT.
 		 * When the incoming frame comes from an external interface
 		 * rather than GMAC1/GMAC2, HWNAT driver sends the original
@@ -1075,11 +1086,19 @@ static int mtk_poll_rx(struct napi_struct *napi, int budget,
 		 * frame learning. After learning, PPE transmit the
 		 * original frame back to PPD again to run SW NAT path.
 		 */
+#if defined(CONFIG_NET_DSA_MT7530)
+		/* In dsa case, when PSE(before mt7622) receives frame with
+		 * switch special tag, rxd4[22] will be set to 1, and FPORT
+		 * will be set to switch ingress port. The real PSE ingress
+		 * port of this kind of traffic is GMAC1 actually.
+		 */
+		if (mac == 5 || (trxd.rxd4 & BIT(22)))
+#else
 		if (mac == 5)
+#endif
 			mac = 0;
 		else
 			mac--;
-#endif
 		if (unlikely(mac < 0 || mac >= MTK_MAC_COUNT ||
 			     !eth->netdev[mac]))
 			goto release_desc;
@@ -1116,7 +1135,11 @@ static int mtk_poll_rx(struct napi_struct *napi, int budget,
 
 		dma_unmap_single(eth->dev, trxd.rxd1,
 				 ring->buf_size, DMA_FROM_DEVICE);
+
 		pktlen = RX_DMA_GET_PLEN0(trxd.rxd2);
+		if (IS_HW_LRO_RING(ring->ring_no) && eth->hwlro)
+			pktlen |= (RX_DMA_GET_PLEN1(trxd.rxd2) << 14);
+
 		skb->dev = netdev;
 		skb_put(skb, pktlen);
 		if (trxd.rxd4 & RX_DMA_L4_VALID)
@@ -1126,9 +1149,20 @@ static int mtk_poll_rx(struct napi_struct *napi, int budget,
 		skb->protocol = eth_type_trans(skb, netdev);
 
 		if (netdev->features & NETIF_F_HW_VLAN_CTAG_RX &&
-		    RX_DMA_VID(trxd.rxd3))
-			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
-					       RX_DMA_VID(trxd.rxd3));
+		    (trxd.rxd2 & RX_DMA_VTAG)) {
+			__vlan_hwaccel_put_tag(skb,
+					       htons(RX_DMA_VPID(trxd.rxd3)),
+					       RX_DMA_TCI(trxd.rxd3));
+
+			/* If netdev is attached to dsa switch with special
+			 * tag protocol on VLAN field, the special tag can
+			 * be offload by RX HW VLAN offload. Disable
+			 * VLAN_TAG_PRESENT to avoid unexpected 8021d
+			 * handler before packet enter dsa framework.
+			 */
+			if (netdev_uses_dsa(netdev))
+				skb->vlan_tci &= ~VLAN_TAG_PRESENT;
+		}
 
 #if defined(CONFIG_NET_MEDIATEK_HNAT) || defined(CONFIG_NET_MEDIATEK_HNAT_MODULE)
 		*(u32 *)(skb->head) = trxd.rxd4;
@@ -1143,6 +1177,11 @@ static int mtk_poll_rx(struct napi_struct *napi, int budget,
 			     __func__, skb_hnat_entry(skb), skb_hnat_sport(skb),
 			     skb_hnat_reason(skb), skb_hnat_alg(skb));
 #endif
+		if (mtk_hwlro_stats_ebl &&
+		    IS_HW_LRO_RING(ring->ring_no) && eth->hwlro) {
+			hw_lro_stats_update(ring->ring_no, &trxd);
+			hw_lro_flush_stats_update(ring->ring_no, &trxd);
+		}
 
 		skb_record_rx_queue(skb, 0);
 		napi_gro_receive(napi, skb);
@@ -1151,7 +1190,10 @@ static int mtk_poll_rx(struct napi_struct *napi, int budget,
 		rxd->rxd1 = (unsigned int)dma_addr;
 
 release_desc:
-		rxd->rxd2 = RX_DMA_PLEN0(ring->buf_size);
+		rxd->rxd2 = (IS_HW_LRO_RING(ring->ring_no) && eth->hwlro) ?
+			     RX_DMA_PLEN0(ring->buf_size) |
+			     RX_DMA_PLEN1(ring->buf_size >> 14) :
+			     RX_DMA_PLEN0(ring->buf_size);
 
 		ring->calc_idx = idx;
 
@@ -1438,12 +1480,17 @@ static int mtk_rx_alloc(struct mtk_eth *eth, int ring_no, int rx_flag)
 			return -ENOMEM;
 		ring->dma[i].rxd1 = (unsigned int)dma_addr;
 
-		ring->dma[i].rxd2 = RX_DMA_PLEN0(ring->buf_size);
+		ring->dma[i].rxd2 =
+			(IS_HW_LRO_RING(ring->ring_no) && eth->hwlro) ?
+			 RX_DMA_PLEN0(ring->buf_size) |
+			 RX_DMA_PLEN1(ring->buf_size >> 14) :
+			 RX_DMA_PLEN0(ring->buf_size);
 	}
 	ring->dma_size = rx_dma_size;
 	ring->calc_idx_update = false;
 	ring->calc_idx = rx_dma_size - 1;
 	ring->crx_idx_reg = MTK_PRX_CRX_IDX_CFG(ring_no);
+	ring->ring_no = ring_no;
 	/* make sure that all changes to the dma ring are flushed before we
 	 * continue
 	 */
@@ -1540,9 +1587,15 @@ static int mtk_hwlro_rx_init(struct mtk_eth *eth)
 	/* enable HW LRO */
 	lro_ctrl_dw0 |= MTK_LRO_EN;
 
+	/* enable cpu reason black list */
+	lro_ctrl_dw0 |= MTK_LRO_CRSN_BNW;
+
 	mtk_w32(eth, lro_ctrl_dw3, MTK_PDMA_LRO_CTRL_DW3);
 	mtk_w32(eth, lro_ctrl_dw0, MTK_PDMA_LRO_CTRL_DW0);
 
+	/* no use PPE cpu reason */
+	mtk_w32(eth, 0xffffffff, MTK_PDMA_LRO_CTRL_DW1);
+
 	return 0;
 }
 
@@ -1806,6 +1859,15 @@ static int mtk_dma_init(struct mtk_eth *eth)
 	/* Enable random early drop and set drop threshold automatically */
 	mtk_w32(eth, FC_THRES_DROP_MODE | FC_THRES_DROP_EN | FC_THRES_MIN,
 		MTK_QDMA_FC_THRES);
+
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
+	if (hnat_sfq_init_hook) {
+		err = hnat_sfq_init_hook();
+		if (err)
+			return err;
+	}
+#endif
+
 	mtk_w32(eth, 0x0, MTK_QDMA_HRED2);
 
 	return 0;
@@ -1837,6 +1899,7 @@ static void mtk_dma_free(struct mtk_eth *eth)
 	}
 
 	kfree(eth->scratch_head);
+	eth->scratch_head = NULL;
 }
 
 static void mtk_tx_timeout(struct net_device *dev)
@@ -1883,8 +1946,8 @@ static irqreturn_t mtk_handle_irq_rx(int irq, void *_eth)
 	struct mtk_eth *eth = _eth;
 
 	if (likely(napi_schedule_prep(&eth->rx_napi))) {
-		__napi_schedule(&eth->rx_napi);
 		mtk_rx_irq_disable(eth, MTK_RX_DONE_INT);
+		__napi_schedule(&eth->rx_napi);
 	}
 
 	return IRQ_HANDLED;
@@ -1895,8 +1958,8 @@ static irqreturn_t mtk_handle_irq_tx(int irq, void *_eth)
 	struct mtk_eth *eth = _eth;
 
 	if (likely(napi_schedule_prep(&eth->tx_napi))) {
-		__napi_schedule(&eth->tx_napi);
 		mtk_tx_irq_disable(eth, MTK_TX_DONE_INT);
+		__napi_schedule(&eth->tx_napi);
 	}
 
 	return IRQ_HANDLED;
@@ -1941,20 +2004,24 @@ static int mtk_start_dma(struct mtk_eth *eth)
 	return 0;
 }
 
-static void mtk_gdma_config(struct mtk_eth *eth, u32 config)
+static void mtk_gdma_igr_ctrl(struct mtk_eth *eth, u32 gdma, u32 action)
 {
-	int i;
+	u32 val = mtk_r32(eth, MTK_GDMA_FWD_CFG(gdma));
 
-	for (i = 0; i < 2; i++) {
-		u32 val = mtk_r32(eth, MTK_GDMA_FWD_CFG(i));
+	/* default setup the forward port to send frame to PDMA */
+	val &= ~0xffff;
+	val |= action;
 
-		/* default setup the forward port to send frame to PDMA */
-		val &= ~0xffff;
+	mtk_w32(eth, val, MTK_GDMA_FWD_CFG(gdma));
+}
 
-		val |= config;
+static void mtk_gdma_config(struct mtk_eth *eth, u32 config)
+{
+	int i;
+
+	for (i = 0; i < 2; i++)
+		mtk_gdma_igr_ctrl(eth, i, config);
 
-		mtk_w32(eth, val, MTK_GDMA_FWD_CFG(i));
-	}
 	/*Reset and enable PSE*/
 	mtk_w32(eth, RST_GL_PSE, MTK_RST_GL);
 	mtk_w32(eth, 0, MTK_RST_GL);
@@ -1964,7 +2031,6 @@ static int mtk_open(struct net_device *dev)
 {
 	struct mtk_mac *mac = netdev_priv(dev);
 	struct mtk_eth *eth = mac->hw;
-	struct device_node *np;
 
 	/* we run 2 netdevs on the same dma ring so we only bring it up once */
 	if (!atomic_read(&eth->dma_refcnt)) {
@@ -1973,7 +2039,6 @@ static int mtk_open(struct net_device *dev)
 		if (err)
 			return err;
 
-		mtk_gdma_config(eth, MTK_GDMA_ICS_EN | MTK_GDMA_TCS_EN | MTK_GDMA_UCS_EN);
 
 		napi_enable(&eth->tx_napi);
 		napi_enable(&eth->rx_napi);
@@ -1982,16 +2047,25 @@ static int mtk_open(struct net_device *dev)
 	}
 	atomic_inc(&eth->dma_refcnt);
 
-	np = of_parse_phandle(mac->of_node, "phy-link-handle", 0);
-	if (np) {
-		if (dev->phydev)
-			phy_disconnect(dev->phydev);
-		mtk_phy_link_connect_node(eth, mac, np);
+	if (dev == eth->netdev[0] && netdev_uses_dsa(dev)) {
+		u32 val;
+
+		/* Indicates CDM to parse the MTK special tag from CPU
+		 * which only works for packets tagged with DSA_TAG_PROTO_MTK.
+		 */
+		val = mtk_r32(eth, MTK_GDMA_FWD_CFG(0));
+		mtk_w32(eth, val | MTK_GDMA_SPEC_TAG, MTK_GDMA_FWD_CFG(0));
+		val = mtk_r32(eth, MTK_CDMP_IG_CTRL);
+		mtk_w32(eth, val | MTK_CDMP_STAG_EN, MTK_CDMP_IG_CTRL);
+		val = mtk_r32(eth, MTK_CDMQ_IG_CTRL);
+		mtk_w32(eth, val | MTK_CDMQ_STAG_EN, MTK_CDMQ_IG_CTRL);
 	}
 
 	phy_start(dev->phydev);
 	netif_start_queue(dev);
 
+	mtk_gdma_igr_ctrl(eth, mac->id, MTK_GDMA_PDMA_ALL);
+
 	return 0;
 }
 
@@ -2023,6 +2097,8 @@ static int mtk_stop(struct net_device *dev)
 	struct mtk_mac *mac = netdev_priv(dev);
 	struct mtk_eth *eth = mac->hw;
 
+	mtk_gdma_igr_ctrl(eth, mac->id, MTK_GDMA_DROP_ALL);
+
 	netif_tx_disable(dev);
 	phy_stop(dev->phydev);
 
@@ -2030,7 +2106,6 @@ static int mtk_stop(struct net_device *dev)
 	if (!atomic_dec_and_test(&eth->dma_refcnt))
 		return 0;
 
-	mtk_gdma_config(eth, MTK_GDMA_DROP_ALL);
 
 	mtk_tx_irq_disable(eth, MTK_TX_DONE_INT);
 	mtk_rx_irq_disable(eth, MTK_RX_DONE_INT);
@@ -2088,6 +2163,12 @@ err_disable_clks:
 static int mtk_hw_init(struct mtk_eth *eth)
 {
 	int i, val, ret;
+	/*FIXME : ioc patch*/
+	void __iomem *reg_virt;
+#define sys_reg_write(phys, val) (__raw_writel(val, (void __iomem *)phys))
+	reg_virt = ioremap(0x10395000, 0x10);
+	sys_reg_write(reg_virt, 0x00000003);
+	/*-----------------*/
 
 	if (test_and_set_bit(MTK_HW_INIT, &eth->state))
 		return 0;
@@ -2099,6 +2180,7 @@ static int mtk_hw_init(struct mtk_eth *eth)
 	if (ret)
 		goto err_disable_pm;
 
+	ethsys_reset(eth, RSTCTRL_ETH);
 	ethsys_reset(eth, RSTCTRL_FE);
 	ethsys_reset(eth, RSTCTRL_PPE);
 
@@ -2129,18 +2211,8 @@ static int mtk_hw_init(struct mtk_eth *eth)
 	for (i = 0; i < MTK_MAC_COUNT; i++)
 		mtk_w32(eth, 0, MTK_MAC_MCR(i));
 
-	/* Indicates CDM to parse the MTK special tag from CPU
-	 * which also is working out for untag packets.
-	 */
-	val = mtk_r32(eth, MTK_CDMQ_IG_CTRL);
-	mtk_w32(eth, val | MTK_CDMQ_STAG_EN, MTK_CDMQ_IG_CTRL);
-
-	/* Disable RX VLan Offloading */
-	mtk_w32(eth, 0, MTK_CDMP_EG_CTRL);
-
-#if defined(CONFIG_NET_DSA)
-	mtk_w32(eth, 0x81000001, MTK_CDMP_IG_CTRL);
-#endif
+	/* Enable RX VLAN Offloading */
+	mtk_w32(eth, 1, MTK_CDMP_EG_CTRL);
 
 	mtk_w32(eth, 0x8f0f8f0f, MTK_PDMA_DELAY_INT);
 	mtk_w32(eth, 0x8f0f8f0f, MTK_QDMA_DELAY_INT);
@@ -2171,8 +2243,8 @@ static int mtk_hw_deinit(struct mtk_eth *eth)
 
 	mtk_clk_disable(eth);
 
-	pm_runtime_put_sync(eth->dev);
-	pm_runtime_disable(eth->dev);
+	/* pm_runtime_put_sync(eth->dev); */
+	/* pm_runtime_disable(eth->dev); */
 
 	return 0;
 }
@@ -2194,6 +2266,7 @@ static int __init mtk_init(struct net_device *dev)
 			dev->dev_addr);
 	}
 
+	mtk_gdma_config(eth, MTK_GDMA_ICS_EN | MTK_GDMA_TCS_EN | MTK_GDMA_UCS_EN);
 	return mtk_phy_connect(dev);
 }
 
@@ -2207,6 +2280,7 @@ static void mtk_uninit(struct net_device *dev)
 		of_phy_deregister_fixed_link(mac->of_node);
 	mtk_tx_irq_disable(eth, ~0);
 	mtk_rx_irq_disable(eth, ~0);
+	mtk_gdma_config(eth, MTK_GDMA_DROP_ALL);
 }
 
 static int mtk_do_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
@@ -2257,6 +2331,7 @@ static void mtk_pending_work(struct work_struct *work)
 		pinctrl_select_state(eth->dev->pins->p,
 				     eth->dev->pins->default_state);
 	mtk_hw_init(eth);
+	mtk_gdma_config(eth, MTK_GDMA_ICS_EN | MTK_GDMA_TCS_EN | MTK_GDMA_UCS_EN);
 
 	for (i = 0; i < MTK_MAC_COUNT; i++) {
 		if (!eth->mac[i] ||
@@ -2730,7 +2805,8 @@ static int mtk_probe(struct platform_device *pdev)
 		if (err)
 			goto err_free_dev;
 	}
-
+	/*assert reset of EPHYs which are not used. */
+	regmap_update_bits(eth->ethsys, ETHSYS_RSTCTRL, BIT(24), BIT(24));
 	err = mtk_mdio_init(eth);
 	if (err)
 		goto err_free_dev;
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_soc.h b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_soc.h
index 027a85556..17f1ec537 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_soc.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_eth_soc.h
@@ -39,16 +39,22 @@
 				 NETIF_MSG_TX_ERR)
 #define MTK_HW_FEATURES		(NETIF_F_IP_CSUM | \
 				 NETIF_F_RXCSUM | \
+				 NETIF_F_HW_VLAN_CTAG_TX | \
+				 NETIF_F_HW_VLAN_CTAG_RX | \
 				 NETIF_F_SG | NETIF_F_TSO | \
 				 NETIF_F_TSO6 | \
 				 NETIF_F_IPV6_CSUM)
 #define NEXT_RX_DESP_IDX(X, Y)	(((X) + 1) & ((Y) - 1))
+#define IS_HW_LRO_RING(ring_no)	((ring_no > 0) && (ring_no < 4))
+#define FOR_EACH_LRO_RING(ring_no)		\
+	for ((ring_no) = 1; (ring_no) < 4; (ring_no)++)
 
 #define MTK_MAX_RX_RING_NUM	4
 #define MTK_HW_LRO_DMA_SIZE	8
 
 #define	MTK_MAX_LRO_RX_LENGTH		(4096 * 3)
 #define	MTK_MAX_LRO_IP_CNT		2
+#define MTK_HW_LRO_RING_NUM		3
 #define	MTK_HW_LRO_TIMER_UNIT		1	/* 20 us */
 #define	MTK_HW_LRO_REFRESH_TIME		50000	/* 1 sec. */
 #define	MTK_HW_LRO_AGG_TIME		10	/* 200us */
@@ -73,22 +79,30 @@
 /* Frame Engine Interrupt Grouping Register */
 #define MTK_FE_INT_GRP		0x20
 
+/* Frame Engine LRO auto-learn table info */
+#define MTK_FE_ALT_CF8		0x300
+#define MTK_FE_ALT_SGL_CFC	0x304
+#define MTK_FE_ALT_SEQ_CFC	0x308
+
 /* CDMP Ingress Control Register */
 #define MTK_CDMQ_IG_CTRL	0x1400
 #define MTK_CDMQ_STAG_EN	BIT(0)
 
 /* CDMP Ingress Control Register */
 #define MTK_CDMP_IG_CTRL       0x400
+#define MTK_CDMP_STAG_EN	BIT(0)
 
 /* CDMP Exgress Control Register */
 #define MTK_CDMP_EG_CTRL	0x404
 
 /* GDM Exgress Control Register */
 #define MTK_GDMA_FWD_CFG(x)	(0x500 + (x * 0x1000))
+#define MTK_GDMA_SPEC_TAG	BIT(24)
 #define MTK_GDMA_ICS_EN		BIT(22)
 #define MTK_GDMA_TCS_EN		BIT(21)
 #define MTK_GDMA_UCS_EN		BIT(20)
 #define MTK_GDMA_DROP_ALL       0x7777
+#define MTK_GDMA_PDMA_ALL       0x0
 
 /* Unicast Filter MAC Address Register - Low */
 #define MTK_GDMA_MAC_ADRL(x)	(0x508 + (x * 0x1000))
@@ -111,6 +125,7 @@
 /* PDMA HW LRO Control Registers */
 #define MTK_PDMA_LRO_CTRL_DW0	0x980
 #define MTK_LRO_EN			BIT(0)
+#define MTK_LRO_CRSN_BNW		BIT(6)
 #define MTK_L3_CKS_UPD_EN		BIT(7)
 #define MTK_LRO_ALT_PKT_CNT_MODE	BIT(21)
 #define MTK_LRO_RING_RELINQUISH_REQ	(0x7 << 26)
@@ -174,6 +189,36 @@
 #define MTK_RING_MAX_AGG_CNT_L		((MTK_HW_LRO_MAX_AGG_CNT & 0x3f) << 26)
 #define MTK_RING_MAX_AGG_CNT_H		((MTK_HW_LRO_MAX_AGG_CNT >> 6) & 0x3)
 
+/* LRO_RX_RING_CTRL_DW masks */
+#define BITS(m, n)			(~(BIT(m) - 1) & ((BIT(n) - 1) | BIT(n)))
+#define MTK_LRO_RING_AGG_TIME_MASK	BITS(10, 25)
+#define MTK_LRO_RING_AGG_CNT_L_MASK	BITS(26, 31)
+#define MTK_LRO_RING_AGG_CNT_H_MASK	BITS(0, 1)
+#define MTK_LRO_RING_AGE_TIME_L_MASK	BITS(22, 31)
+#define MTK_LRO_RING_AGE_TIME_H_MASK	BITS(0, 5)
+
+/* LRO_RX_RING_CTRL_DW0 offsets */
+#define MTK_RX_IPV6_FORCE_OFFSET	(0)
+#define MTK_RX_IPV4_FORCE_OFFSET	(1)
+
+/* LRO_RX_RING_CTRL_DW1 offsets  */
+#define MTK_LRO_RING_AGE_TIME_L_OFFSET	(22)
+
+/* LRO_RX_RING_CTRL_DW2 offsets  */
+#define MTK_LRO_RING_AGE_TIME_H_OFFSET	(0)
+#define MTK_RX_MODE_OFFSET		(6)
+#define MTK_RX_PORT_VALID_OFFSET	(8)
+#define MTK_RX_MYIP_VALID_OFFSET	(9)
+#define MTK_LRO_RING_AGG_TIME_OFFSET	(10)
+#define MTK_LRO_RING_AGG_CNT_L_OFFSET	(26)
+
+/* LRO_RX_RING_CTRL_DW3 offsets  */
+#define MTK_LRO_RING_AGG_CNT_H_OFFSET	(0)
+
+/* LRO_RX_RING_STP_DTP_DW offsets */
+#define MTK_RX_TCP_DEST_PORT_OFFSET	(0)
+#define MTK_RX_TCP_SRC_PORT_OFFSET	(16)
+
 /* QDMA TX Queue Configuration Registers */
 #define MTK_QTX_CFG(x)		(0x1800 + (x * 0x10))
 #define QDMA_RES_THRES		4
@@ -215,6 +260,7 @@
 /* QDMA Flow Control Register */
 #define MTK_QDMA_FC_THRES	0x1A10
 #define FC_THRES_DROP_MODE	BIT(20)
+#define FC_THRES_DROP_FSTVQ	BIT(19)
 #define FC_THRES_DROP_EN	(7 << 16)
 #define FC_THRES_MIN		0x4444
 
@@ -242,8 +288,11 @@
 /* QDMA Interrupt Status Register */
 #define MTK_QDMA_INT_MASK	0x1A1C
 
-/* QDMA Interrupt Mask Register */
+/* QDMA HW/SW RED Distribution Register */
+#define MTK_QDMA_HRED1		0x1A40
 #define MTK_QDMA_HRED2		0x1A44
+#define MTK_QDMA_SRED1		0x1A48
+#define MTK_QDMA_SRED2		0x1A4C
 
 /* QDMA TX Forward CPU Pointer Register */
 #define MTK_QTX_CTX_PTR		0x1B00
@@ -284,6 +333,7 @@
 #define TX_DMA_TSO		BIT(28)
 #define TX_DMA_FPORT_SHIFT	25
 #define TX_DMA_FPORT_MASK	0x7
+#define TX_DMA_VQIDO		BIT(17)
 #define TX_DMA_INS_VLAN		BIT(16)
 
 /* QDMA descriptor txd3 */
@@ -292,20 +342,34 @@
 #define TX_DMA_PLEN0(_x)	(((_x) & MTK_TX_DMA_BUF_LEN) << 16)
 #define TX_DMA_SWC		BIT(14)
 #define TX_DMA_SDL(_x)		(((_x) & 0x3fff) << 16)
+#define TX_DMA_IPOFST(_x)	(((_x) & 0x7f) << 7)
+#define TX_DMA_PROT(_x)		(((_x) & 0x7) << 4)
+#define TX_DMA_VQID(_x)		(((_x) & 0x3ff) << 4)
 
 /* QDMA descriptor rxd2 */
 #define RX_DMA_DONE		BIT(31)
+#define RX_DMA_PLEN1(_x)	(((_x) & 0x3) << 0)
 #define RX_DMA_PLEN0(_x)	(((_x) & 0x3fff) << 16)
+#define RX_DMA_GET_PLEN1(_x)	(((_x) >> 0) & 0x3)
+#define RX_DMA_GET_AGG_CNT(_x)	(((_x) >> 2) & 0xff)
+#define RX_DMA_GET_REV(_x)	(((_x) >> 10) & 0x1f)
 #define RX_DMA_GET_PLEN0(_x)	(((_x) >> 16) & 0x3fff)
+#define RX_DMA_VTAG             BIT(15)
 
 /* QDMA descriptor rxd3 */
-#define RX_DMA_VID(_x)		((_x) & 0xfff)
+#define RX_DMA_VID(_x)		((_x) & VLAN_VID_MASK)
+#define RX_DMA_TCI(_x)		((_x) & (VLAN_PRIO_MASK | VLAN_VID_MASK))
+#define RX_DMA_VPID(_x)		(((_x) >> 16) & 0xffff)
 
 /* QDMA descriptor rxd4 */
 #define RX_DMA_L4_VALID		BIT(24)
 #define RX_DMA_FPORT_SHIFT	19
 #define RX_DMA_FPORT_MASK	0x7
 
+/* PHY Polling and SMI Master Control */
+#define MTK_PHY_PSC		0x10000
+#define PHY_AP_EN		BIT(31)
+
 /* PHY Indirect Access Control registers */
 #define MTK_PHY_IAC		0x10004
 #define PHY_IAC_ACCESS		BIT(31)
@@ -343,6 +407,15 @@
 				 MAC_MCR_FORCE_TX_FC | MAC_MCR_SPEED_1000 | \
 				 MAC_MCR_FORCE_DPX | MAC_MCR_FORCE_LINK)
 
+/* Mac EEE control registers */
+#define MTK_MAC_EEE(x)	(0x10104 + (x * 0x100))
+#define MAC_WAKEUP_TIME_1000(x)	((x << 24) & GENMASK(31, 24))
+#define MAC_WAKEUP_TIME_100(x)	((x << 16) & GENMASK(23, 16))
+#define MAC_LPI_TXIDLE_THD(x)	((x << 8) & GENMASK(15, 8))
+#define MAC_EEE_SETTING_MASK	(MAC_WAKEUP_TIME_1000(0xff) | \
+				 MAC_WAKEUP_TIME_100(0xff) | \
+				 MAC_LPI_TXIDLE_THD(0xff))
+
 /* TRGMII RXC control register */
 #define TRGMII_RCK_CTRL		0x10300
 #define DQSI0(x)		((x << 0) & GENMASK(6, 0))
@@ -403,12 +476,17 @@
 #define ETHSYS_RSTCTRL		0x34
 #define RSTCTRL_FE		BIT(6)
 #define RSTCTRL_PPE		BIT(31)
+#define RSTCTRL_ETH		BIT(23)
 
 /* SGMII subsystem config registers */
 /* Register to auto-negotiation restart */
 #define SGMSYS_PCS_CONTROL_1	0x0
+#define SGMII_AN_ENABLE		BIT(12)
 #define SGMII_AN_RESTART	BIT(9)
 
+#define SGMSYS_PCS_SPEED_ABILITY	0x8
+#define SGMII_TX_CONFIG		BIT(0)
+
 /* Register to programmable link timer, the unit in 2 * 8ns */
 #define SGMSYS_PCS_LINK_TIMER	0x18
 #define SGMII_LINK_TIMER_DEFAULT	(0x186a0 & GENMASK(19, 0))
@@ -416,10 +494,12 @@
 /* Register to control remote fault */
 #define SGMSYS_SGMII_MODE	0x20
 #define SGMII_REMOTE_FAULT_DIS	BIT(8)
+#define SGMII_SPEED_DUPLEX_AN	BIT(1)
 
 /* Register to power up QPHY */
 #define SGMSYS_QPHY_PWR_STATE_CTRL 0xe8
 #define	SGMII_PHYA_PWD		BIT(4)
+#define	SGMII_PHYA_DOWN_IDLE	GENMASK(4, 0)
 
 /* Infrasys subsystem config registers */
 #define INFRA_MISC2		0x70c
@@ -599,6 +679,7 @@ enum mtk_rx_flags {
  * @frag_size:		How big can each fragment be
  * @buf_size:		The size of each packet buffer
  * @calc_idx:		The current head of ring
+ * @ring_no:		The index of ring
  */
 struct mtk_rx_ring {
 	struct mtk_rx_dma *dma;
@@ -610,6 +691,7 @@ struct mtk_rx_ring {
 	bool calc_idx_update;
 	u16 calc_idx;
 	u32 crx_idx_reg;
+	u32 ring_no;
 };
 
 enum mtk_eth_mux {
@@ -859,6 +941,8 @@ struct mtk_mac {
 /* the struct describing the SoC. these are declared in the soc_xyz.c files */
 extern const struct of_device_id of_mtk_match[];
 
+extern u32 mtk_hwlro_stats_ebl;
+
 /* read the hardware status register */
 void mtk_stats_update_mac(struct mtk_mac *mac);
 
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/Makefile b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/Makefile
index 1bbd891b9..d6bec58bc 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/Makefile
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/Makefile
@@ -1,4 +1,6 @@
 ccflags-y=-Werror
 
-obj-m         += hw_nat.o
-hw_nat-objs := hnat.o hnat_nf_hook.o hnat_debugfs.o hnat_mcast.o
+obj-$(CONFIG_NET_MEDIATEK_HNAT)         += mtkhnat.o
+mtkhnat-objs := hnat.o hnat_nf_hook.o hnat_debugfs.o hnat_mcast.o
+mtkhnat-$(CONFIG_NET_DSA_MT7530)	+= hnat_stag.o
+mtkhnat-$(CONFIG_NET_MEDIATEK_HW_QOS)	+= hnat_sfq.o
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat.c b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat.c
index 7104a2133..b8c530e3f 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat.c
@@ -144,15 +144,18 @@ static int hnat_start(void)
 	u32 foe_table_sz;
 	u32 foe_mib_tb_sz;
 	int etry_num_cfg;
+	int i = 0;
 
 	/* mapp the FOE table */
-	for (etry_num_cfg = DEF_ETRY_NUM_CFG ; etry_num_cfg >= 0 ; etry_num_cfg--, hnat_priv->foe_etry_num /= 2) {
+	for (i = DEF_ETRY_NUM_CFG ; i >= 0 ; i--, hnat_priv->foe_etry_num /= 2) {
 		foe_table_sz = hnat_priv->foe_etry_num * sizeof(struct foe_entry);
 		hnat_priv->foe_table_cpu = dma_alloc_coherent(
 			hnat_priv->dev, foe_table_sz, &hnat_priv->foe_table_dev, GFP_KERNEL);
 
-		if (hnat_priv->foe_table_cpu)
+		if (hnat_priv->foe_table_cpu) {
+			etry_num_cfg = i;
 			break;
+		}
 	}
 
 	if (!hnat_priv->foe_table_cpu)
@@ -244,6 +247,16 @@ static int hnat_start(void)
 
 	hnat_priv->g_ppdev = dev_get_by_name(&init_net, hnat_priv->ppd);
 
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
+	if (hnat_priv->data->sfq) {
+		for (i = 0; i < MTK_VQG_NUM; i++)
+			hnat_priv->sfq_tbl_cpu[i] = NULL;
+
+		if (hnat_sfq_init())
+			return -1;
+	}
+#endif
+
 	dev_info(hnat_priv->dev, "hwnat start\n");
 
 	return 0;
@@ -342,6 +355,11 @@ static void hnat_stop(void)
 		writel(0, hnat_priv->ppe_base + PPE_MIB_TB_BASE);
 		kfree(hnat_priv->acct);
 	}
+
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
+	if (hnat_priv->data->sfq)
+		hnat_sfq_deinit();
+#endif
 }
 
 static void hnat_release_netdev(void)
@@ -394,7 +412,8 @@ int hnat_disable_hook(void)
 	struct foe_entry *entry;
 
 	ra_sw_nat_hook_tx = NULL;
-	hnat_unregister_nf_hooks();
+	if (hook_toggle)
+		hnat_unregister_nf_hooks();
 
 	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SMA, SMA_ONLY_FWD_CPU);
 	for (hash_index = 0; hash_index < hnat_priv->foe_etry_num; hash_index++) {
@@ -415,7 +434,7 @@ int hnat_disable_hook(void)
 	return 0;
 }
 
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 static struct packet_type mtk_pack_type __read_mostly = {
 	.type   = HQOS_MAGIC_TAG,
 	.func   = mtk_hqos_ptype_cb,
@@ -456,14 +475,14 @@ static int hnat_probe(struct platform_device *pdev)
 
 	err = of_property_read_string(np, "mtketh-lan", &name);
 	if (err < 0)
-		strncpy(hnat_priv->lan, "eth2", IFNAMSIZ);
+		strncpy(hnat_priv->lan, "eth0", IFNAMSIZ);
 	else
 		strncpy(hnat_priv->lan, (char *)name, IFNAMSIZ);
 	dev_info(&pdev->dev, "lan = %s\n", hnat_priv->lan);
 
 	err = of_property_read_string(np, "mtketh-ppd", &name);
 	if (err < 0)
-		strncpy(hnat_priv->ppd, "eth2", IFNAMSIZ);
+		strncpy(hnat_priv->ppd, "eth0", IFNAMSIZ);
 	else
 		strncpy(hnat_priv->ppd, (char *)name, IFNAMSIZ);
 	dev_info(&pdev->dev, "ppd = %s\n", hnat_priv->ppd);
@@ -548,7 +567,7 @@ static int hnat_probe(struct platform_device *pdev)
 		add_timer(&hnat_priv->hnat_reset_timestamp_timer);
 	}
 
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 	if (IS_GMAC1_MODE)
 		dev_add_pack(&mtk_pack_type);
 #endif
@@ -583,7 +602,7 @@ static int hnat_remove(struct platform_device *pdev)
 	if (hnat_priv->data->version == MTK_HNAT_V3)
 		del_timer_sync(&hnat_priv->hnat_reset_timestamp_timer);
 
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 	if (IS_GMAC1_MODE)
 		dev_remove_pack(&mtk_pack_type);
 #endif
@@ -596,6 +615,7 @@ static const struct mtk_hnat_data hnat_data_v1 = {
 	.whnat = false,
 	.per_flow_accounting = false,
 	.mcast = false,
+	.sfq = false,
 	.version = MTK_HNAT_V1,
 };
 
@@ -604,6 +624,7 @@ static const struct mtk_hnat_data hnat_data_v2 = {
 	.whnat = true,
 	.per_flow_accounting = true,
 	.mcast = false,
+	.sfq = false,
 	.version = MTK_HNAT_V2,
 };
 
@@ -612,6 +633,7 @@ static const struct mtk_hnat_data hnat_data_v3 = {
 	.whnat = false,
 	.per_flow_accounting = false,
 	.mcast = false,
+	.sfq = false,
 	.version = MTK_HNAT_V3,
 };
 
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat.h b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat.h
index af9934bd0..9801f05f4 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat.h
@@ -18,6 +18,7 @@
 #include <net/netevent.h>
 #include <net/netfilter/nf_hnat.h>
 #include "hnat_mcast.h"
+#include "hnat_sfq.h"
 
 /*--------------------------------------------------------------------------*/
 /* Register Offset*/
@@ -484,9 +485,9 @@ struct foe_entry {
 /* If user wants to change default FOE entry number, both DEF_ETRY_NUM and
  * DEF_ETRY_NUM_CFG need to be modified.
  */
-#define DEF_ETRY_NUM		16384
+#define DEF_ETRY_NUM		8192
 /* feasible values : 16384, 8192, 4096, 2048, 1024 */
-#define DEF_ETRY_NUM_CFG	TABLE_16K
+#define DEF_ETRY_NUM_CFG	TABLE_8K
 /* corresponding values : TABLE_16K, TABLE_8K, TABLE_4K, TABLE_2K, TABLE_1K */
 #define MAX_EXT_DEVS		(0x3fU)
 #define MAX_IF_NUM		64
@@ -516,6 +517,7 @@ struct mtk_hnat_data {
 	bool whnat;
 	bool per_flow_accounting;
 	bool mcast;
+	bool sfq;
 	enum mtk_hnat_version version;
 };
 
@@ -525,6 +527,8 @@ struct mtk_hnat {
 	void __iomem *ppe_base;
 	struct foe_entry *foe_table_cpu;
 	dma_addr_t foe_table_dev;
+	struct mtk_sfq_table *sfq_tbl_cpu[MTK_VQG_NUM];
+	dma_addr_t sfq_tbl_dev[MTK_VQG_NUM];
 	u8 enable;
 	u8 enable1;
 	struct dentry *root;
@@ -555,7 +559,8 @@ struct mtk_hnat {
 	struct timer_list hnat_sma_build_entry_timer;
 	struct timer_list hnat_reset_timestamp_timer;
 	struct timer_list hnat_mcast_check_timer;
-	bool ipv6_en;
+
+	bool nf_stat_en;
 };
 
 struct extdev_entry {
@@ -712,6 +717,7 @@ enum FoeIpAct {
 #define IS_IPV6_GRP(x)                                                         \
 	(IS_IPV6_3T_ROUTE(x) | IS_IPV6_5T_ROUTE(x) | IS_IPV6_6RD(x) |          \
 	 IS_IPV4_DSLITE(x))
+#define IS_BOND_MODE (!strncmp(LAN_DEV_NAME, "bond", 4))
 #define IS_GMAC1_MODE ((hnat_priv->gmac_num == 1) ? 1 : 0)
 
 #define es(entry) (entry_state[entry->bfib1.state])
@@ -807,6 +813,8 @@ int hnat_disable_hook(void);
 void hnat_cache_ebl(int enable);
 void set_gmac_ppe_fwd(int gmac_no, int enable);
 int entry_delete(int index);
+struct hnat_accounting *hnat_get_count(struct mtk_hnat *h, u32 index,
+				       struct hnat_accounting *diff);
 
 static inline u16 foe_timestamp(struct mtk_hnat *h)
 {
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_debugfs.c b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_debugfs.c
index d92fa0a5a..e3c1af2cb 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_debugfs.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_debugfs.c
@@ -495,7 +495,7 @@ int cr_set_usage(int level)
 	pr_info("              4     0~65535    Set UDP bind lifetime\n");
 	pr_info("              5     0~255      Set TCP keep alive interval\n");
 	pr_info("              6     0~255      Set UDP keep alive interval\n");
-	pr_info("              7     0~1        Set hnat disable/enable ipv6\n");
+	pr_info("              7     0~1        Set hnat counter update to nf_conntrack\n");
 
 	return 0;
 }
@@ -562,35 +562,20 @@ int udp_keep_alive(int udp_interval)
 	return 0;
 }
 
-int set_ipv6_toggle(int toggle)
- {
- 	struct mtk_hnat *h = hnat_priv;
-
- 	if (toggle == 1)
- 		pr_info("Enable hnat ipv6\n");
- 	else if (toggle == 0)
- 		pr_info("Disable hnat ipv6\n");
- 	else
- 		pr_info("input error\n");
- 	h->ipv6_en = toggle;
-
- 	return 0;
- }
-
- void mtk_ppe_dev_hook(const char *name, int toggle)
- {
- 	struct net_device *dev;
- 	dev = dev_get_by_name(&init_net, name);
- 	if (dev) {
- 		if (toggle) {
- 			mtk_ppe_dev_register_hook(dev);
- 		} else {
- 			mtk_ppe_dev_unregister_hook(dev);
- 		}
- 	}
- 	return;
- }
+int set_nf_update_toggle(int toggle)
+{
+	struct mtk_hnat *h = hnat_priv;
+
+	if (toggle == 1)
+		pr_info("Enable hnat counter update to nf_conntrack\n");
+	else if (toggle == 0)
+		pr_info("Disable hnat counter update to nf_conntrack\n");
+	else
+		pr_info("input error\n");
+	h->nf_stat_en = toggle;
 
+	return 0;
+}
 
 static const debugfs_write_func hnat_set_func[] = {
 	[0] = hnat_set_usage,
@@ -608,46 +593,63 @@ static const debugfs_write_func cr_set_func[] = {
 	[0] = cr_set_usage,      [1] = binding_threshold,
 	[2] = tcp_bind_lifetime, [3] = fin_bind_lifetime,
 	[4] = udp_bind_lifetime, [5] = tcp_keep_alive,
-	[6] = udp_keep_alive,	[7] = set_ipv6_toggle, 
+	[6] = udp_keep_alive,    [7] = set_nf_update_toggle,
 };
 
-static struct hnat_accounting *hnat_get_count(struct mtk_hnat *h, u32 index)
+int read_mib(struct mtk_hnat *h, u32 index, u64 *bytes, u64 *packets)
 {
-	struct hnat_accounting *acount;
+	int ret;
 	u32 val, cnt_r0, cnt_r1, cnt_r2;
-	int ret = -1;
-
-	if (!hnat_priv->data->per_flow_accounting)
-		return NULL;
 
 	writel(index | (1 << 16), h->ppe_base + PPE_MIB_SER_CR);
 	ret = readx_poll_timeout_atomic(readl, h->ppe_base + PPE_MIB_SER_CR, val,
 					!(val & BIT_MIB_BUSY), 20, 10000);
 	if (ret < 0) {
-		pr_notice("mib busy,please check later\n");
-		return NULL;
+		pr_notice("mib busy, please check later\n");
+		return ret;
 	}
 	cnt_r0 = readl(h->ppe_base + PPE_MIB_SER_R0);
 	cnt_r1 = readl(h->ppe_base + PPE_MIB_SER_R1);
 	cnt_r2 = readl(h->ppe_base + PPE_MIB_SER_R2);
-	acount = &h->acct[index];
-	acount->bytes += cnt_r0 + ((u64)(cnt_r1 & 0xffff) << 32);
-	acount->packets +=
-		((cnt_r1 & 0xffff0000) >> 16) + ((cnt_r2 & 0xffffff) << 16);
+	*bytes = cnt_r0 + ((u64)(cnt_r1 & 0xffff) << 32);
+	*packets = ((cnt_r1 & 0xffff0000) >> 16) + ((cnt_r2 & 0xffffff) << 16);
 
-	return acount;
+	return 0;
 }
 
-#define PRINT_COUNT(m, acount) {if (acount) \
+struct hnat_accounting *hnat_get_count(struct mtk_hnat *h, u32 index,
+				       struct hnat_accounting *diff)
+{
+	u64 bytes, packets;
+
+	if (!hnat_priv->data->per_flow_accounting)
+		return NULL;
+
+	if (read_mib(h, index, &bytes, &packets))
+		return NULL;
+
+	h->acct[index].bytes += bytes;
+	h->acct[index].packets += packets;
+
+	if (diff) {
+		diff->bytes = bytes;
+		diff->packets = packets;
+	}
+
+	return &h->acct[index];
+}
+EXPORT_SYMBOL(hnat_get_count);
+
+#define PRINT_COUNT(m, acct) {if (acct) \
 		seq_printf(m, "bytes=%llu|packets=%llu|", \
-			   acount->bytes, acount->packets); }
+			   acct->bytes, acct->packets); }
 static int hnat_debug_show(struct seq_file *m, void *private)
 {
 	struct mtk_hnat *h = hnat_priv;
 	struct foe_entry *entry, *end;
 	unsigned char h_dest[ETH_ALEN];
 	unsigned char h_source[ETH_ALEN];
-	struct hnat_accounting *acount;
+	struct hnat_accounting *acct;
 	u32 entry_index = 0;
 
 	entry = h->foe_table_cpu;
@@ -658,7 +660,8 @@ static int hnat_debug_show(struct seq_file *m, void *private)
 			entry_index++;
 			continue;
 		}
-		acount = hnat_get_count(h, entry_index);
+		acct = hnat_get_count(h, entry_index, NULL);
+
 		if (IS_IPV4_HNAPT(entry)) {
 			__be32 saddr = htonl(entry->ipv4_hnapt.sip);
 			__be32 daddr = htonl(entry->ipv4_hnapt.dip);
@@ -671,7 +674,7 @@ static int hnat_debug_show(struct seq_file *m, void *private)
 			*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
 			*((u16 *)&h_dest[4]) =
 				swab16(entry->ipv4_hnapt.dmac_lo);
-			PRINT_COUNT(m, acount);
+			PRINT_COUNT(m, acct);
 			seq_printf(m,
 				   "addr=0x%p|index=%d|state=%s|type=%s|%pI4:%d->%pI4:%d=>%pI4:%d->%pI4:%d|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x|vlan1=%d|vlan2=%d\n",
 				   entry, ei(entry, end), es(entry), pt(entry), &saddr,
@@ -696,7 +699,7 @@ static int hnat_debug_show(struct seq_file *m, void *private)
 			*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
 			*((u16 *)&h_dest[4]) =
 				swab16(entry->ipv4_hnapt.dmac_lo);
-			PRINT_COUNT(m, acount);
+			PRINT_COUNT(m, acct);
 			seq_printf(m,
 				   "addr=0x%p|index=%d|state=%s|type=%s|%pI4->%pI4=>%pI4->%pI4|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x|vlan1=%d|vlan2=%d\n",
 				   entry, ei(entry, end), es(entry), pt(entry), &saddr,
@@ -723,7 +726,7 @@ static int hnat_debug_show(struct seq_file *m, void *private)
 			*((u32 *)h_dest) = swab32(entry->ipv6_5t_route.dmac_hi);
 			*((u16 *)&h_dest[4]) =
 				swab16(entry->ipv6_5t_route.dmac_lo);
-			PRINT_COUNT(m, acount);
+			PRINT_COUNT(m, acct);
 			seq_printf(m,
 				   "addr=0x%p|index=%d|state=%s|type=%s|SIP=%08x:%08x:%08x:%08x(sp=%d)->DIP=%08x:%08x:%08x:%08x(dp=%d)|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x\n",
 				   entry, ei(entry, end), es(entry), pt(entry), ipv6_sip0,
@@ -751,7 +754,7 @@ static int hnat_debug_show(struct seq_file *m, void *private)
 			*((u32 *)h_dest) = swab32(entry->ipv6_5t_route.dmac_hi);
 			*((u16 *)&h_dest[4]) =
 				swab16(entry->ipv6_5t_route.dmac_lo);
-			PRINT_COUNT(m, acount);
+			PRINT_COUNT(m, acct);
 			seq_printf(m,
 				   "addr=0x%p|index=%d|state=%s|type=%s|SIP=%08x:%08x:%08x:%08x->DIP=%08x:%08x:%08x:%08x|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x\n",
 				   entry, ei(entry, end), es(entry), pt(entry), ipv6_sip0,
@@ -779,7 +782,7 @@ static int hnat_debug_show(struct seq_file *m, void *private)
 			*((u32 *)h_dest) = swab32(entry->ipv6_5t_route.dmac_hi);
 			*((u16 *)&h_dest[4]) =
 				swab16(entry->ipv6_5t_route.dmac_lo);
-			PRINT_COUNT(m, acount);
+			PRINT_COUNT(m, acct);
 			seq_printf(m,
 				   "addr=0x%p|index=%d|state=%s|type=%s|SIP=%08x:%08x:%08x:%08x(sp=%d)->DIP=%08x:%08x:%08x:%08x(dp=%d)|TSIP=%pI4->TDIP=%pI4|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x\n",
 				   entry, ei(entry, end), es(entry), pt(entry), ipv6_sip0,
@@ -809,7 +812,7 @@ static int hnat_debug_show(struct seq_file *m, void *private)
 			*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
 			*((u16 *)&h_dest[4]) =
 				swab16(entry->ipv4_hnapt.dmac_lo);
-			PRINT_COUNT(m, acount);
+			PRINT_COUNT(m, acct);
 			seq_printf(m,
 				   "addr=0x%p|index=%d|state=%s|type=%s|SIP=%pI4->DIP=%pI4|TSIP=%08x:%08x:%08x:%08x->TDIP=%08x:%08x:%08x:%08x|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x\n",
 				   entry, ei(entry, end), es(entry), pt(entry), &saddr,
@@ -1750,23 +1753,141 @@ static const struct file_operations hnat_version_fops = {
 	.release = single_release,
 };
 
+int sfq_dump_mib_cnt(int pqid)
+{
+	u32 val_pq, val_pq_drop;
+	u32 val_vq, val_vq_drop;
+	u32 addr_val;
+	u32 i;
+
+	addr_val = pqid << 16;
+	writel(addr_val, hnat_priv->fe_base + MTK_VQTX_MIB_IF);
+	val_pq = readl(hnat_priv->fe_base + MTK_QTX_MIB_PCNT);
+	val_pq_drop = readl(hnat_priv->fe_base + MTK_QTX_MIB_DPCNT);
+	pr_info("\n++++++++++ PQ %d ++++++++++\n", pqid);
+	pr_info("PQ %d: QTX_MIB_PCNT PKT-CNT: %010u\n", pqid, val_pq);
+	pr_info("PQ %d: QTX_MIB_DPCNT PKT-Drop-CNT: %010u\n",
+		pqid, val_pq_drop);
+
+	if (!val_pq)
+		return 0;
+
+	for (i = 0; i < MTK_PER_GRP_VQ_NUM; i++) {
+		addr_val = 0x10000000 + i + (pqid << 16);
+		writel(addr_val, hnat_priv->fe_base + MTK_VQTX_MIB_IF);
+		val_vq = readl(hnat_priv->fe_base + MTK_VQTX_MIB_PCNT);
+		val_vq_drop = readl(hnat_priv->fe_base + MTK_VQTX_MIB_DPCNT);
+
+		if (val_vq) {
+			pr_info("\n========== VQ %d ==========\n", i);
+			pr_info("VQ %d: VQTX_MIB_PCNT PKT-CNT: %010u\n",
+				i, val_vq);
+			pr_info("VQ %d: VQTX_MIB_DPCNT PKT-Drop-CNT: %010u\n",
+				i, val_vq_drop);
+		}
+	}
+
+	return 0;
+}
+
+static ssize_t hnat_sfq_write(struct file *file, const char __user *buffer,
+			      size_t count, loff_t *data)
+{
+	char buf[32];
+	char *p_buf;
+	char *p_token = NULL;
+	char *p_delimiter = " \t";
+	int len = count;
+	int cmd;
+	int pqid[4];
+
+	if (len >= sizeof(buf)) {
+		pr_info("Input handling fail!\n");
+		len = sizeof(buf) - 1;
+		return -1;
+	}
+
+	if (copy_from_user(buf, buffer, len))
+		return -EFAULT;
+
+	buf[len] = '\0';
+	p_buf = buf;
+	p_token = strsep(&p_buf, p_delimiter);
+
+	if (!p_token || !p_buf)
+		return -1;
+
+	if (sscanf(p_buf, "%d %d %d %d",
+		   &pqid[0], &pqid[1], &pqid[2], &pqid[3]) <= 0)
+		return -EFAULT;
+
+	kstrtoint(p_token, 10, &cmd);
+
+	switch (cmd) {
+	case 0:
+		sfq_dump_mib_cnt(pqid[0]);
+		break;
+	case 1:
+		writel(VQTX_0_BIND_QID(pqid[0]) | VQTX_1_BIND_QID(pqid[1]) |
+		       VQTX_2_BIND_QID(pqid[2]) | VQTX_3_BIND_QID(pqid[3]),
+		       hnat_priv->fe_base + MTK_VQTX_0_3_BIND_QID);
+		break;
+	case 2:
+		writel(VQTX_4_BIND_QID(pqid[0]) | VQTX_5_BIND_QID(pqid[1]) |
+		       VQTX_6_BIND_QID(pqid[2]) | VQTX_7_BIND_QID(pqid[3]),
+		       hnat_priv->fe_base + MTK_VQTX_4_7_BIND_QID);
+		break;
+	default:
+		pr_info("No handler defined for command id %d\n\r", cmd);
+		break;
+	}
+
+	return count;
+}
+
+static int hnat_sfq_read(struct seq_file *m, void *private)
+{
+	seq_puts(m, "Usage of SFQ debug interface:\n");
+	seq_puts(m, "### CMD-0: Dump VQ MIB counter of a specified PQ ###\n");
+	seq_puts(m, "echo 0 [pqid] > /sys/kernel/debug/hnat/qdma_sfq\n");
+	seq_puts(m, "### CMD-1: Set PQ number which binds with VQ group 0~3 ###\n");
+	seq_puts(m, "echo 1 [pqid0] [pqid1] [pqid2] [pqid3] > /sys/kernel/debug/hnat/qdma_sfq\n");
+	seq_puts(m, "### CMD-2: Set PQ number which binds with VQ group 4~7 ###\n");
+	seq_puts(m, "echo 2 [pqid4] [pqid5] [pqid6] [pqid7] > /sys/kernel/debug/hnat/qdma_sfq\n");
+
+	return 0;
+}
+
+static int hnat_sfq_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, hnat_sfq_read, file->private_data);
+}
+
+static const struct file_operations hnat_sfq_fops = {
+	.open = hnat_sfq_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.write = hnat_sfq_write,
+	.release = single_release,
+};
+
 int get_ppe_mib(int index, u64 *pkt_cnt, u64 *byte_cnt)
 {
 	struct mtk_hnat *h = hnat_priv;
-	struct hnat_accounting *acount;
+	struct hnat_accounting *acct;
 	struct foe_entry *entry;
 
-	acount = hnat_get_count(h, index);
+	acct = hnat_get_count(h, index, NULL);
 	entry = hnat_priv->foe_table_cpu + index;
 
-	if (!acount)
+	if (!acct)
 		return -1;
 
 	if (entry->bfib1.state != BIND)
 		return -1;
 
-	*pkt_cnt = acount->packets;
-	*byte_cnt = acount->bytes;
+	*pkt_cnt = acct->packets;
+	*byte_cnt = acct->bytes;
 
 	return 0;
 }
@@ -1875,6 +1996,10 @@ int __init hnat_init_debugfs(struct mtk_hnat *h)
 	debugfs_create_file("hnat_ppd_if", S_IRUGO | S_IRUGO, root, h,
 			    &hnat_ppd_if_fops);
 
+	if (hnat_priv->data->sfq)
+		debugfs_create_file("qdma_sfq", S_IRUGO | S_IRUGO, root, h,
+				    &hnat_sfq_fops);
+
 	for (i = 0; i < hnat_priv->data->num_of_sch; i++) {
 		snprintf(name, sizeof(name), "qdma_sch%ld", i);
 		debugfs_create_file(name, S_IRUGO, root, (void *)i,
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_nf_hook.c b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_nf_hook.c
index e9976cc57..a3fca8756 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_nf_hook.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_nf_hook.c
@@ -22,6 +22,8 @@
 #include <net/ip.h>
 #include <net/tcp.h>
 #include <net/udp.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_acct.h>
 
 #include "nf_hnat_mtk.h"
 #include "hnat.h"
@@ -257,7 +259,7 @@ void foe_clear_entry(struct neighbour *neigh)
 			*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
 			*((u16 *)&h_dest[4]) =
 				swab16(entry->ipv4_hnapt.dmac_lo);
-			if (!ether_addr_equal(h_dest, neigh->ha)) {
+			if (strncmp(h_dest, neigh->ha, ETH_ALEN) != 0) {
 				pr_info("%s: state=%d\n", __func__,
 					neigh->nud_state);
 				cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SMA,
@@ -356,7 +358,9 @@ unsigned int do_hnat_ext_to_ge(struct sk_buff *skb, const struct net_device *in,
 		}
 
 		/*set where we come from*/
-		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), in->ifindex & VLAN_VID_MASK);
+		skb->vlan_proto = htons(ETH_P_8021Q);
+		skb->vlan_tci =
+			(VLAN_TAG_PRESENT | (in->ifindex & VLAN_VID_MASK));
 		trace_printk(
 			"%s: vlan_prot=0x%x, vlan_tci=%x, in->name=%s, skb->dev->name=%s\n",
 			__func__, ntohs(skb->vlan_proto), skb->vlan_tci,
@@ -394,6 +398,10 @@ unsigned int do_hnat_ext_to_ge2(struct sk_buff *skb, const char *func)
 		}
 		set_from_extge(skb);
 		fix_skb_packet_type(skb, skb->dev, eth);
+
+		if (IS_BOND_MODE && (skb_hnat_entry(skb) != 0x3fff))
+			skb_set_hash(skb, skb_hnat_entry(skb) >> 1, PKT_HASH_TYPE_L4);
+
 		netif_rx(skb);
 		trace_printk("%s: called from %s successfully\n", __func__,
 			     func);
@@ -436,7 +444,7 @@ unsigned int do_hnat_ge_to_ext(struct sk_buff *skb, const char *func)
 
 	skb->dev = get_dev_from_index(index);
 
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 	if (eth_hdr(skb)->h_proto == HQOS_MAGIC_TAG) {
 		skb = skb_unshare(skb, GFP_ATOMIC);
 		if (!skb)
@@ -589,7 +597,9 @@ unsigned int do_hnat_mape_w2l_fast(struct sk_buff *skb, const struct net_device
 		eth->h_proto = htons(ETH_P_IP);
 		set_to_ppe(skb);
 
-		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), in->ifindex & VLAN_VID_MASK);
+		skb->vlan_proto = htons(ETH_P_8021Q);
+		skb->vlan_tci =
+		(VLAN_TAG_PRESENT | (in->ifindex & VLAN_VID_MASK));
 
 		if (!hnat_priv->g_ppdev)
 			hnat_priv->g_ppdev = dev_get_by_name(&init_net, hnat_priv->ppd);
@@ -753,7 +763,7 @@ static unsigned int
 mtk_hnat_br_nf_local_in(void *priv, struct sk_buff *skb,
 			const struct nf_hook_state *state)
 {
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 	struct vlan_ethhdr *veth;
 
 	if (hnat_priv->data->whnat) {
@@ -799,7 +809,7 @@ mtk_hnat_br_nf_local_in(void *priv, struct sk_buff *skb,
 			clr_from_extge(skb);
 
 		/* packets from external devices -> xxx ,step 2, learning stage */
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 		if (do_ext2ge_fast_learn(state->in, skb) && (eth_hdr(skb)->h_proto != HQOS_MAGIC_TAG)) {
 #else
 		if (do_ext2ge_fast_learn(state->in, skb)) {
@@ -988,7 +998,7 @@ struct foe_entry ppe_fill_info_blk(struct ethhdr *eth, struct foe_entry entry,
 		if (is_multicast_ether_addr(&eth->h_dest[0])) {
 			entry.ipv4_hnapt.iblk2.mcast = 1;
 			if (hnat_priv->data->version == MTK_HNAT_V3)
-				{entry.bfib1.sta = 1;}
+				entry.bfib1.sta = 1;
 				entry.ipv4_hnapt.m_timestamp = foe_timestamp(hnat_priv);
 		} else {
 			entry.ipv4_hnapt.iblk2.mcast = 0;
@@ -1003,7 +1013,7 @@ struct foe_entry ppe_fill_info_blk(struct ethhdr *eth, struct foe_entry entry,
 		if (is_multicast_ether_addr(&eth->h_dest[0])) {
 			entry.ipv6_5t_route.iblk2.mcast = 1;
 			if (hnat_priv->data->version == MTK_HNAT_V3)
-				{entry.bfib1.sta = 1;}
+				entry.bfib1.sta = 1;
 				entry.ipv4_hnapt.m_timestamp = foe_timestamp(hnat_priv);
 		} else {
 			entry.ipv6_5t_route.iblk2.mcast = 0;
@@ -1201,6 +1211,8 @@ static unsigned int skb_to_hnat_info(struct sk_buff *skb,
 			if (!mape_toggle &&
 			    entry.bfib1.pkt_type == IPV4_DSLITE) {
 				/* DS-Lite LAN->WAN */
+				entry.ipv4_dslite.bfib1.udp =
+					foe->ipv4_dslite.bfib1.udp;
 				entry.ipv4_dslite.sip = foe->ipv4_dslite.sip;
 				entry.ipv4_dslite.dip = foe->ipv4_dslite.dip;
 				entry.ipv4_dslite.sport =
@@ -1255,7 +1267,7 @@ static unsigned int skb_to_hnat_info(struct sk_buff *skb,
 					foe->ipv4_hnapt.new_dip;
 				entry.ipv4_hnapt.etype = htons(ETH_P_IP);
 
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 				entry.ipv4_hnapt.iblk2.qid = skb->mark & 0x7;
 				if (IS_LAN(dev))
 					entry.ipv4_hnapt.iblk2.qid += 8;
@@ -1327,7 +1339,12 @@ static unsigned int skb_to_hnat_info(struct sk_buff *skb,
 		if (IS_DSA_LAN(dev))
 			hnat_dsa_fill_stag(dev, &entry, hw_path,
 					   ntohs(eth->h_proto), mape);
-		gmac = NR_GMAC1_PORT;
+
+		if (IS_BOND_MODE)
+			gmac = ((skb_hnat_entry(skb) >> 1) % hnat_priv->gmac_num) ?
+				 NR_GMAC2_PORT : NR_GMAC1_PORT;
+		else
+			gmac = NR_GMAC1_PORT;
 	} else if (IS_WAN(dev)) {
 		if (IS_DSA_WAN(dev))
 			hnat_dsa_fill_stag(dev, &entry, hw_path,
@@ -1339,7 +1356,8 @@ static unsigned int skb_to_hnat_info(struct sk_buff *skb,
 		} else {
 			gmac = (IS_GMAC1_MODE) ? NR_GMAC1_PORT : NR_GMAC2_PORT;
 		}
-	} else if (IS_EXT(dev)) {
+	} else if (IS_EXT(dev) && (FROM_GE_PPD(skb) || FROM_GE_LAN(skb) ||
+		   FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb))) {
 		if ((hnat_priv->data->version != MTK_HNAT_V2) && IS_GMAC1_MODE) {
 			entry.bfib1.vpm = 1;
 			entry.bfib1.vlan_layer = 1;
@@ -1376,7 +1394,7 @@ static unsigned int skb_to_hnat_info(struct sk_buff *skb,
 			entry.ipv4_hnapt.iblk2.port_mg = 0x3f;
 		else
 			entry.ipv4_hnapt.iblk2.port_mg = 0;/*unused port_mg*/
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 		/* qid[5:0]= port_mg[1:0]+ qid[3:0] */
 		entry.ipv4_hnapt.iblk2.qid = qid & 0xf;
 		if (hnat_priv->data->version != MTK_HNAT_V1)
@@ -1401,7 +1419,7 @@ static unsigned int skb_to_hnat_info(struct sk_buff *skb,
 			entry.ipv6_5t_route.iblk2.port_mg = 0x3f;
 		else
 			entry.ipv6_5t_route.iblk2.port_mg = 0;/*unused port_mg*/
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 		/* qid[5:0]= port_mg[1:0]+ qid[3:0] */
 		entry.ipv6_5t_route.iblk2.qid = qid & 0xf;
 		if (hnat_priv->data->version != MTK_HNAT_V1)
@@ -1489,37 +1507,68 @@ int mtk_sw_nat_hook_tx(struct sk_buff *skb, int gmac_no)
 	}
 
 	/* MT7622 wifi hw_nat not support QoS */
-	entry->ipv4_hnapt.iblk2w.fqos = 0;
+	if (IS_IPV4_GRP(entry))
+		entry->ipv4_hnapt.iblk2w.fqos = 0;
+	else
+		entry->ipv6_5t_route.iblk2w.fqos = 0;
+
 	if (gmac_no == NR_WHNAT_WDMA_PORT) {
-		entry->ipv4_hnapt.iblk2w.wdmaid =
-			(skb_hnat_wdma_id(skb) & 0x01);
-		entry->ipv4_hnapt.iblk2w.winfoi = 1;
-		entry->ipv4_hnapt.winfo.bssid = skb_hnat_bss_id(skb);
-		entry->ipv4_hnapt.winfo.wcid = skb_hnat_wc_id(skb);
-		entry->ipv4_hnapt.winfo.rxid = skb_hnat_rx_id(skb);
+		if (IS_IPV4_GRP(entry)) {
+			entry->ipv4_hnapt.iblk2w.wdmaid =
+				(skb_hnat_wdma_id(skb) & 0x01);
+			entry->ipv4_hnapt.iblk2w.winfoi = 1;
+			entry->ipv4_hnapt.winfo.bssid = skb_hnat_bss_id(skb);
+			entry->ipv4_hnapt.winfo.wcid = skb_hnat_wc_id(skb);
+			entry->ipv4_hnapt.winfo.rxid = skb_hnat_rx_id(skb);
+		} else {
+			entry->ipv6_5t_route.iblk2w.wdmaid =
+				(skb_hnat_wdma_id(skb) & 0x01);
+			entry->ipv6_5t_route.iblk2w.winfoi = 1;
+			entry->ipv6_5t_route.winfo.bssid = skb_hnat_bss_id(skb);
+			entry->ipv6_5t_route.winfo.wcid = skb_hnat_wc_id(skb);
+			entry->ipv6_5t_route.winfo.rxid = skb_hnat_rx_id(skb);
+		}
 	} else {
 		if (IS_GMAC1_MODE && !hnat_dsa_is_enable(hnat_priv)) {
 			entry->bfib1.vpm = 1;
 			entry->bfib1.vlan_layer = 1;
 
-			if (FROM_GE_LAN(skb))
-				entry->ipv4_hnapt.vlan1 = 1;
-			else if (FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb))
-				entry->ipv4_hnapt.vlan1 = 2;
+			if (FROM_GE_LAN(skb)) {
+				if (IS_IPV4_GRP(entry))
+					entry->ipv4_hnapt.vlan1 = 1;
+				else
+					entry->ipv6_5t_route.vlan1 = 1;
+			} else if (FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb)) {
+				if (IS_IPV4_GRP(entry))
+					entry->ipv4_hnapt.vlan1 = 2;
+				else
+					entry->ipv6_5t_route.vlan1 = 2;
+			}
 		}
 
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 		if (FROM_GE_LAN(skb) || FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb)) {
 			entry->bfib1.vpm = 0;
-			entry->ipv4_hnapt.etype = htons(HQOS_MAGIC_TAG);
-			entry->ipv4_hnapt.vlan1 = skb_hnat_entry(skb);
 			entry->bfib1.vlan_layer = 1;
-			entry->ipv4_hnapt.iblk2w.fqos = 1;
+
+			if (IS_IPV4_GRP(entry)) {
+				entry->ipv4_hnapt.etype = htons(HQOS_MAGIC_TAG);
+				entry->ipv4_hnapt.vlan1 = skb_hnat_entry(skb);
+				entry->ipv4_hnapt.iblk2w.fqos = 1;
+			} else {
+				entry->ipv6_5t_route.etype = htons(HQOS_MAGIC_TAG);
+				entry->ipv6_5t_route.vlan1 = skb_hnat_entry(skb);
+				entry->ipv6_5t_route.iblk2w.fqos = 1;
+			}
 		}
 #endif
 	}
 
-	entry->ipv4_hnapt.iblk2w.dp = gmac_no;
+	if (IS_IPV4_GRP(entry))
+		entry->ipv4_hnapt.iblk2w.dp = gmac_no;
+	else
+		entry->ipv6_5t_route.iblk2w.dp = gmac_no;
+
 	entry->bfib1.state = BIND;
 
 	return NF_ACCEPT;
@@ -1614,6 +1663,28 @@ static unsigned int mtk_hnat_accel_type(struct sk_buff *skb)
 	return 1;
 }
 
+static void mtk_hnat_nf_update(struct sk_buff *skb)
+{
+	struct nf_conn *ct;
+	struct nf_conn_acct *acct;
+	struct nf_conn_counter *counter;
+	enum ip_conntrack_info ctinfo;
+	struct hnat_accounting diff;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	if (ct) {
+		if (!hnat_get_count(hnat_priv, skb_hnat_entry(skb), &diff))
+			return;
+
+		acct = nf_conn_acct_find(ct);
+		if (acct) {
+			counter = acct->counter;
+			atomic64_add(diff.packets, &counter[CTINFO2DIR(ctinfo)].packets);
+			atomic64_add(diff.bytes, &counter[CTINFO2DIR(ctinfo)].bytes);
+		}
+	}
+}
+
 static unsigned int mtk_hnat_nf_post_routing(
 	struct sk_buff *skb, const struct net_device *out,
 	unsigned int (*fn)(struct sk_buff *, const struct net_device *,
@@ -1621,26 +1692,22 @@ static unsigned int mtk_hnat_nf_post_routing(
 	const char *func)
 {
 	struct foe_entry *entry;
-	struct hnat_hw_path hw_path = { .dev = out };
+	struct hnat_hw_path hw_path = { .real_dev = out, .virt_dev = out };
 	const struct net_device *arp_dev = out;
 
-	if (skb->protocol == htons(ETH_P_IPV6) && !hnat_priv->ipv6_en) {
- 		return 0;
- 	}
 	if (skb_hnat_alg(skb) || unlikely(!is_magic_tag_valid(skb) ||
 					  !IS_SPACE_AVAILABLE_HEAD(skb)))
 		return 0;
-	if (unlikely(!skb_mac_header_was_set(skb)))
-		return 0;
-		
+
 	if (unlikely(!skb_hnat_is_hashed(skb)))
 		return 0;
 
 	if (out->netdev_ops->ndo_hnat_check) {
 		if (out->netdev_ops->ndo_hnat_check(&hw_path))
 			return 0;
-		out = hw_path.dev;
+		out = (IS_GMAC1_MODE) ? hw_path.virt_dev : hw_path.real_dev;
 	}
+
 	if (!IS_LAN(out) && !IS_WAN(out) && !IS_EXT(out))
 		return 0;
 
@@ -1663,6 +1730,10 @@ static unsigned int mtk_hnat_nf_post_routing(
 		skb_to_hnat_info(skb, out, entry, &hw_path);
 		break;
 	case HIT_BIND_KEEPALIVE_DUP_OLD_HDR:
+		/* update hnat count to nf_conntrack by keepalive */
+		if (hnat_priv->data->per_flow_accounting && hnat_priv->nf_stat_en)
+			mtk_hnat_nf_update(skb);
+
 		if (fn && !mtk_hnat_accel_type(skb))
 			break;
 
@@ -1778,7 +1849,7 @@ static unsigned int
 mtk_pong_hqos_handler(void *priv, struct sk_buff *skb,
 		      const struct nf_hook_state *state)
 {
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 	struct vlan_ethhdr *veth = (struct vlan_ethhdr *)skb_mac_header(skb);
 
 	if (eth_hdr(skb)->h_proto == HQOS_MAGIC_TAG) {
@@ -1791,7 +1862,7 @@ mtk_pong_hqos_handler(void *priv, struct sk_buff *skb,
 		clr_from_extge(skb);
 
 	/* packets from external devices -> xxx ,step 2, learning stage */
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 	if (do_ext2ge_fast_learn(state->in, skb) && (eth_hdr(skb)->h_proto != HQOS_MAGIC_TAG)) {
 #else
 	if (do_ext2ge_fast_learn(state->in, skb)) {
@@ -1923,13 +1994,13 @@ static struct nf_hook_ops mtk_hnat_nf_ops[] __read_mostly = {
 	{
 		.hook = mtk_hnat_br_nf_local_in,
 		.pf = NFPROTO_BRIDGE,
-		.hooknum = NF_BR_PRE_ROUTING,
+		.hooknum = NF_BR_LOCAL_IN,
 		.priority = NF_BR_PRI_FIRST,
 	},
 	{
 		.hook = mtk_hnat_br_nf_local_out,
 		.pf = NFPROTO_BRIDGE,
-		.hooknum = NF_BR_POST_ROUTING,
+		.hooknum = NF_BR_LOCAL_OUT,
 		.priority = NF_BR_PRI_LAST - 1,
 	},
 	{
@@ -1940,7 +2011,6 @@ static struct nf_hook_ops mtk_hnat_nf_ops[] __read_mostly = {
 	},
 };
 
-
 int hnat_register_nf_hooks(void)
 {
 	return nf_register_hooks(mtk_hnat_nf_ops, ARRAY_SIZE(mtk_hnat_nf_ops));
@@ -1962,6 +2032,7 @@ int whnat_adjust_nf_hooks(void)
 	while (n-- > 0) {
 		if (hook[n].hook == mtk_hnat_br_nf_local_in) {
 			hook[n].hooknum = NF_BR_PRE_ROUTING;
+			hook[n].priority = NF_BR_PRI_FIRST + 1;
 		} else if (hook[n].hook == mtk_hnat_br_nf_local_out) {
 			hook[n].hooknum = NF_BR_POST_ROUTING;
 		} else if (hook[n].hook == mtk_pong_hqos_handler) {
@@ -1974,7 +2045,7 @@ int whnat_adjust_nf_hooks(void)
 	return 0;
 }
 
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 int mtk_hqos_ptype_cb(struct sk_buff *skb, struct net_device *dev,
 		      struct packet_type *pt, struct net_device *unused)
 {
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_sfq.c b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_sfq.c
new file mode 100644
index 000000000..0c06638d4
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_sfq.c
@@ -0,0 +1,109 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (c) 2021 MediaTek Inc.
+ * Author: Henry Yen <henry.yen@mediatek.com>
+ */
+
+#include "hnat.h"
+#include "../mtk_eth_soc.h"
+
+int hnat_sfq_init(void)
+{
+	u32 reg_val, i, j;
+
+	reg_val = readl(hnat_priv->fe_base + MTK_VQTX_GLO);
+	reg_val = reg_val | VQTB_MIB_EN;
+	writel(reg_val, hnat_priv->fe_base + MTK_VQTX_GLO);
+	writel(HASH_PTB_MODE_EN_0 | HASH_PTB_MODE_EN_1 | HASH_PTB_MODE_EN_2 |
+	       HASH_PTB_MODE_EN_3 | HASH_PTB_PRD,
+	       hnat_priv->fe_base + MTK_VQTX_HASH_CFG);
+	writel(VQTX_VLD_STRG_0 | VQTX_VLD_STRG_1 | VQTX_VLD_STRG_2 |
+	       VQTX_VLD_STRG_3 | VQTX_VLD_STRG_4 | VQTX_VLD_STRG_5 |
+	       VQTX_VLD_STRG_6 | VQTX_VLD_STRG_7,
+	       hnat_priv->fe_base + MTK_VQTX_VLD_CFG);
+	writel(HASH_SD, hnat_priv->fe_base + MTK_VQTX_HASH_SD);
+	writel(RING_TH | FREE_TH | SHARE_HW_TH | SHARE_SW_TH |
+	       HW_DROP_EN | HW_DROP_FFA | HW_DROP_FSTVQ | HW_DROP_MODE |
+	       HW_DROP_FSTVQ_MODE | SW_DROP_EN | SW_DROP_FFA |
+	       SW_DROP_FSTVQ | SW_DROP_MODE | SW_DROP_FSTVQ_MODE,
+	       hnat_priv->fe_base + MTK_QDMA_FC_THRES);
+	writel(0, hnat_priv->fe_base + MTK_QDMA_HRED1);
+	writel(0, hnat_priv->fe_base + MTK_QDMA_HRED2);
+	writel(0, hnat_priv->fe_base + MTK_QDMA_SRED1);
+	writel(0, hnat_priv->fe_base + MTK_QDMA_SRED2);
+	writel(VQTX_NUM_0 | VQTX_NUM_1 | VQTX_NUM_2 | VQTX_NUM_3 |
+	       VQTX_NUM_4 | VQTX_NUM_5 | VQTX_NUM_6 | VQTX_NUM_7,
+	       hnat_priv->fe_base + MTK_VQTX_NUM);
+	writel(VQTX_0_BIND_QID(MTK_PQ0) | VQTX_1_BIND_QID(MTK_PQ1) |
+	       VQTX_2_BIND_QID(MTK_PQ2) | VQTX_3_BIND_QID(MTK_PQ3),
+	       hnat_priv->fe_base + MTK_VQTX_0_3_BIND_QID);
+	writel(VQTX_4_BIND_QID(MTK_PQ4) | VQTX_5_BIND_QID(MTK_PQ5) |
+	       VQTX_6_BIND_QID(MTK_PQ6) | VQTX_7_BIND_QID(MTK_PQ7),
+	       hnat_priv->fe_base + MTK_VQTX_4_7_BIND_QID);
+
+	for (i = 0; i < MTK_VQG_NUM; i++) {
+		if (!hnat_priv->sfq_tbl_cpu[i]) {
+			hnat_priv->sfq_tbl_cpu[i] =
+				dma_alloc_coherent(hnat_priv->dev,
+						   MTK_PER_GRP_VQ_NUM *
+						   sizeof(struct mtk_sfq_table),
+						   &hnat_priv->sfq_tbl_dev[i],
+						   GFP_KERNEL);
+
+			if (unlikely(!hnat_priv->sfq_tbl_cpu[i])) {
+				dev_info(hnat_priv->dev,
+					 "QDMA SFQ VQG:%d not available\n", i);
+				return 1;
+			}
+		}
+
+		memset(hnat_priv->sfq_tbl_cpu[i], 0x0,
+		       MTK_PER_GRP_VQ_NUM * sizeof(struct mtk_sfq_table));
+
+		for (j = 0; j < MTK_PER_GRP_VQ_NUM; j++) {
+			hnat_priv->sfq_tbl_cpu[i][j].sfq_info1.vqhptr = 0xdeadbeef;
+			hnat_priv->sfq_tbl_cpu[i][j].sfq_info2.vqtptr = 0xdeadbeef;
+		}
+
+		writel((u32)hnat_priv->sfq_tbl_dev[i],
+		       hnat_priv->fe_base + MTK_VQTX_TB_BASE(i));
+	}
+
+	hnat_sfq_init_hook = hnat_sfq_init;
+
+	return 0;
+}
+
+int hnat_sfq_deinit(void)
+{
+	u32 reg_val, i;
+
+	reg_val = readl(hnat_priv->fe_base + MTK_VQTX_GLO);
+	reg_val = reg_val & ~VQTB_MIB_EN;
+	writel(reg_val, hnat_priv->fe_base + MTK_VQTX_GLO);
+	writel(0, hnat_priv->fe_base + MTK_VQTX_HASH_CFG);
+	writel(0, hnat_priv->fe_base + MTK_VQTX_VLD_CFG);
+	writel(0, hnat_priv->fe_base + MTK_VQTX_HASH_SD);
+	writel(FC_THRES_DROP_MODE | FC_THRES_DROP_EN | FC_THRES_MIN,
+	       hnat_priv->fe_base + MTK_QDMA_FC_THRES);
+	writel(0, hnat_priv->fe_base + MTK_QDMA_HRED1);
+	writel(0, hnat_priv->fe_base + MTK_QDMA_HRED2);
+	writel(0, hnat_priv->fe_base + MTK_QDMA_SRED1);
+	writel(0, hnat_priv->fe_base + MTK_QDMA_SRED2);
+	writel(0, hnat_priv->fe_base + MTK_VQTX_NUM);
+
+	for (i = 0; i < MTK_VQG_NUM; i++) {
+		if (hnat_priv->sfq_tbl_cpu[i])
+			dma_free_coherent(hnat_priv->dev,
+					  MTK_PER_GRP_VQ_NUM *
+					  sizeof(struct mtk_sfq_table),
+					  hnat_priv->sfq_tbl_cpu[i],
+					  hnat_priv->sfq_tbl_dev[i]);
+
+		writel(0, hnat_priv->fe_base + MTK_VQTX_TB_BASE(i));
+	}
+
+	hnat_sfq_init_hook = NULL;
+
+	return 0;
+}
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_sfq.h b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_sfq.h
new file mode 100644
index 000000000..fc57b3466
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/hnat_sfq.h
@@ -0,0 +1,152 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (c) 2021 MediaTek Inc.
+ * Author: Henry Yen <henry.yen@mediatek.com>
+ */
+
+#ifndef NF_HNAT_SFQ_H
+#define NF_HNAT_SFQ_H
+
+/* QDMA SFQ */
+#define MTK_VQG_NUM		8
+#define MTK_PER_GRP_VQ_NUM	128
+#define MTK_SFQ_OFFSET		0x1A80
+#define MTK_VQTX_GLO		MTK_SFQ_OFFSET
+#define MTK_VQTX_INVLD_PTR	(MTK_SFQ_OFFSET + 0x0C)
+#define MTK_VQTX_NUM		(MTK_SFQ_OFFSET + 0x10)
+#define MTK_VQTX_SCH		(MTK_SFQ_OFFSET + 0x18)
+#define MTK_VQTX_HASH_CFG	(MTK_SFQ_OFFSET + 0x20)
+#define MTK_VQTX_HASH_SD	(MTK_SFQ_OFFSET + 0x24)
+#define MTK_VQTX_VLD_CFG	(MTK_SFQ_OFFSET + 0x30)
+#define MTK_VQTX_MIB_IF		(MTK_SFQ_OFFSET + 0x3C)
+#define MTK_VQTX_MIB_PCNT	(MTK_SFQ_OFFSET + 0x40)
+#define MTK_VQTX_MIB_BCNT0	(MTK_SFQ_OFFSET + 0x44)
+#define MTK_VQTX_MIB_BCNT1	(MTK_SFQ_OFFSET + 0x48)
+#define MTK_VQTX_MIB_DPCNT	(MTK_SFQ_OFFSET + 0x4C)
+#define MTK_QTX_MIB_PCNT	(MTK_SFQ_OFFSET + 0x50)
+#define MTK_QTX_MIB_DPCNT	(MTK_SFQ_OFFSET + 0x54)
+#define MTK_VQTX_0_3_BIND_QID	(MTK_SFQ_OFFSET + 0x140)
+#define MTK_VQTX_4_7_BIND_QID	(MTK_SFQ_OFFSET + 0x144)
+#define MTK_VQTX_TB_BASE(x)	(0x1980 + (x) * 0x4)
+
+/* TX Virtual Queue Global Configuration Register*/
+#define VQTB_MIB_EN		BIT(17)
+
+/* TX Virtual Queue Hash Configuration Register*/
+#define HASH_PTB_MODE_EN_0	BIT(24)
+#define HASH_PTB_MODE_EN_1	BIT(25)
+#define HASH_PTB_MODE_EN_2	BIT(26)
+#define HASH_PTB_MODE_EN_3	BIT(27)
+#define HASH_PTB_PRD		0x2710
+
+/* TX Virtual Queue Valid Configuration Register*/
+#define VQTX_VLD_STRG_0		(0 << 0)
+#define VQTX_VLD_STRG_1		(2 << 4)
+#define VQTX_VLD_STRG_2		(4 << 8)
+#define VQTX_VLD_STRG_3		(6 << 12)
+#define VQTX_VLD_STRG_4		(8 << 16)
+#define VQTX_VLD_STRG_5		(10 << 20)
+#define VQTX_VLD_STRG_6		(12 << 24)
+#define VQTX_VLD_STRG_7		(14 << 28)
+
+/* TX Virtual Queue Hash Seed Register*/
+#define HASH_SD			0xD
+
+/* Flow Control Threshold Register*/
+#define HW_DROP_EN		BIT(16)
+#define HW_DROP_FFA		BIT(17)
+#define HW_DROP_FSTVQ		BIT(19)
+#define HW_DROP_MODE		BIT(20)
+#define SW_DROP_EN		BIT(24)
+#define SW_DROP_FFA		BIT(25)
+#define SW_DROP_FSTVQ		BIT(27)
+#define SW_DROP_MODE		BIT(28)
+#define RING_TH			(4 << 0)
+#define FREE_TH			(4 << 4)
+#define SHARE_HW_TH		(4 << 8)
+#define SHARE_SW_TH		(4 << 12)
+#define HW_DROP_FSTVQ_MODE	(2 << 22)
+#define	SW_DROP_FSTVQ_MODE	(2 << 30)
+
+/* Number of TX Virtual Queue Configuration Register*/
+#define VQTX_NUM_0		(3 << 0)
+#define VQTX_NUM_1		(3 << 4)
+#define VQTX_NUM_2		(3 << 8)
+#define VQTX_NUM_3		(3 << 12)
+#define VQTX_NUM_4		(3 << 16)
+#define VQTX_NUM_5		(3 << 20)
+#define VQTX_NUM_6		(3 << 24)
+#define VQTX_NUM_7		(3 << 28)
+
+/* QDMA Virtual Queue Group #0~7 to Physical Queue Binding Register*/
+#define MTK_PQ0			0
+#define MTK_PQ1			1
+#define MTK_PQ2			15
+#define MTK_PQ3			16
+#define MTK_PQ4			30
+#define MTK_PQ5			31
+#define MTK_PQ6			43
+#define MTK_PQ7			63
+#define VQTX_0_BIND_QID(x)	((x) << 0)
+#define VQTX_1_BIND_QID(x)	((x) << 8)
+#define VQTX_2_BIND_QID(x)	((x) << 16)
+#define VQTX_3_BIND_QID(x)	((x) << 24)
+#define VQTX_4_BIND_QID(x)	((x) << 0)
+#define VQTX_5_BIND_QID(x)	((x) << 8)
+#define VQTX_6_BIND_QID(x)	((x) << 16)
+#define VQTX_7_BIND_QID(x)	((x) << 24)
+
+/*--------------------------------------------------------------------------*/
+/* SFQ Table Definition*/
+/*--------------------------------------------------------------------------*/
+
+struct mtk_sfq_info1 {
+	u32	vqhptr;
+};
+
+struct mtk_sfq_info2 {
+	u32	vqtptr;
+};
+
+struct mtk_sfq_info3 {
+	u32	que_depth : 16;
+	u32	deficit_cnt : 16;
+};
+
+struct mtk_sfq_info4 {
+	u32	resv;
+};
+
+struct mtk_sfq_info5 {
+	u32	pkt_cnt;
+};
+
+struct mtk_sfq_info6 {
+	u32	byte_cnt;
+};
+
+struct mtk_sfq_info7 {
+	u32	byte_cnt;
+};
+
+struct mtk_sfq_info8 {
+	u32	resv;
+};
+
+struct mtk_sfq_table {
+	struct mtk_sfq_info1	sfq_info1;
+	struct mtk_sfq_info2	sfq_info2;
+	struct mtk_sfq_info3	sfq_info3;
+	struct mtk_sfq_info4	sfq_info4;
+	struct mtk_sfq_info5	sfq_info5;
+	struct mtk_sfq_info6	sfq_info6;
+	struct mtk_sfq_info7	sfq_info7;
+	struct mtk_sfq_info8	sfq_info8;
+};
+
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
+int hnat_sfq_init(void);
+int hnat_sfq_deinit(void);
+extern int (*hnat_sfq_init_hook)(void);
+#endif
+#endif
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/nf_hnat_mtk.h b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/nf_hnat_mtk.h
index f94d5ad9d..3fd190953 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/nf_hnat_mtk.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_hnat/nf_hnat_mtk.h
@@ -37,7 +37,7 @@ struct hnat_desc {
 	u32 bssid : 6;
 } __packed;
 
-#if (1)
+#if defined(CONFIG_NET_MEDIATEK_HW_QOS)
 #define HQOS_MAGIC_TAG 0x5678
 #define HAS_HQOS_MAGIC_TAG(skb) (skb->protocol == HQOS_MAGIC_TAG)
 #else
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_sgmii.c b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_sgmii.c
index 26d157325..1823e4b1e 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_sgmii.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/mediatek/mtk_sgmii.c
@@ -63,20 +63,29 @@ int mtk_sgmii_setup_mode_an(struct mtk_sgmii *ss, int id)
 	if (!ss->regmap[id])
 		return -EINVAL;
 
+	/* Setup SGMII 1G speed */
+	regmap_read(ss->regmap[id], ss->ana_rgc3, &val);
+	val &= ~GENMASK(3, 2);
+	regmap_write(ss->regmap[id], ss->ana_rgc3, val);
+
 	/* Setup the link timer and QPHY power up inside SGMIISYS */
 	regmap_write(ss->regmap[id], SGMSYS_PCS_LINK_TIMER,
 		     SGMII_LINK_TIMER_DEFAULT);
 
 	regmap_read(ss->regmap[id], SGMSYS_SGMII_MODE, &val);
-	val |= SGMII_REMOTE_FAULT_DIS;
+	val |= SGMII_REMOTE_FAULT_DIS | SGMII_SPEED_DUPLEX_AN;
 	regmap_write(ss->regmap[id], SGMSYS_SGMII_MODE, val);
 
+	/* Setup sgmii configure word */
+	regmap_write(ss->regmap[id], SGMSYS_PCS_SPEED_ABILITY,
+		     SGMII_TX_CONFIG);
+
 	regmap_read(ss->regmap[id], SGMSYS_PCS_CONTROL_1, &val);
-	val |= SGMII_AN_RESTART;
+	val |= SGMII_AN_ENABLE | SGMII_AN_RESTART;
 	regmap_write(ss->regmap[id], SGMSYS_PCS_CONTROL_1, val);
 
 	regmap_read(ss->regmap[id], SGMSYS_QPHY_PWR_STATE_CTRL, &val);
-	val &= ~SGMII_PHYA_PWD;
+	val &= ~SGMII_PHYA_DOWN_IDLE;
 	regmap_write(ss->regmap[id], SGMSYS_QPHY_PWR_STATE_CTRL, val);
 
 	return 0;
@@ -98,7 +107,7 @@ int mtk_sgmii_setup_mode_force(struct mtk_sgmii *ss, int id)
 
 	/* disable SGMII AN */
 	regmap_read(ss->regmap[id], SGMSYS_PCS_CONTROL_1, &val);
-	val &= ~BIT(12);
+	val &= ~SGMII_AN_ENABLE;
 	regmap_write(ss->regmap[id], SGMSYS_PCS_CONTROL_1, val);
 
 	/* SGMII force mode setting */
@@ -107,7 +116,7 @@ int mtk_sgmii_setup_mode_force(struct mtk_sgmii *ss, int id)
 
 	/* Release PHYA power down state */
 	regmap_read(ss->regmap[id], SGMSYS_QPHY_PWR_STATE_CTRL, &val);
-	val &= ~SGMII_PHYA_PWD;
+	val &= ~SGMII_PHYA_DOWN_IDLE;
 	regmap_write(ss->regmap[id], SGMSYS_QPHY_PWR_STATE_CTRL, val);
 
 	return 0;
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Kconfig b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Kconfig
index edeba1cbf..f5be18ef1 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Kconfig
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Kconfig
@@ -36,52 +36,4 @@ config  ETH_PAGE_ALLOC_SKB
 
 endchoice
 
-config  RAETH_ESW_CONTROL
-	bool "Embedded (or MT7530) Switch Control Module (VLAN/Isolation/Status)"
-	default y
-
-config  RAETH_ESW_PORT_WAN
-	int "ESW WAN Port ID (0..4)"
-	depends on RAETH_ESW_CONTROL
-	default 4
-
-config  RAETH_ESW_PORT_LAN1
-	int "ESW LAN1 Port ID (0..4)"
-	depends on RAETH_ESW_CONTROL
-	default 0
-
-config  RAETH_ESW_PORT_LAN2
-	int "ESW LAN2 Port ID (0..4)"
-	depends on RAETH_ESW_CONTROL
-	default 1
-
-config  RAETH_ESW_PORT_LAN3
-	int "ESW LAN3 Port ID (0..4)"
-	depends on RAETH_ESW_CONTROL
-	default 2
-
-config  RAETH_ESW_PORT_LAN4
-	int "ESW LAN4 Port ID (0..4)"
-	depends on RAETH_ESW_CONTROL
-	default 3
-	
-config NET_MEDIATEK_HNAT
-	tristate "MediaTek HW NAT support"
-	depends on  NF_CONNTRACK && NF_CONNTRACK_IPV4 && IP_NF_NAT
-	---help---
-	  This driver supports the hardward
-	  Network Address Translation in the
-	  MediaTek MT2701/MT7622/MT7629/MT7621
-	  chipset family
-
-config NET_MEDIATEK_HW_QOS
-	bool "Mediatek HW QoS support"
-	depends on NET_MEDIATEK_HNAT
-	default y
-	---help---
-	  This driver supports the hardward
-	  quality of service (QoS) control
-	  for the hardware NAT in the
-	  MediaTek chipset family.
-
 endif 	# RAETH
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Makefile b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Makefile
index d1d9c4669..a1b901c15 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Makefile
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/Makefile
@@ -1,4 +1,3 @@
-obj-m += mtk_hnat/
 obj-$(CONFIG_RAETH) += raeth.o
 raeth-objs := raether.o raether_pdma.o ra_mac.o mii_mgr.o ra_switch.o ra_dbg_proc.o
 raeth-objs += raether_qdma.o
@@ -12,10 +11,6 @@ raeth-objs += raether_hwlro.o
 raeth-objs += ra_dbg_hwlro.o
 raeth-objs += ra_dbg_hwioc.o
 
-ifeq ($(CONFIG_RAETH_ESW_CONTROL),y)
-raeth-objs += mtk_esw/ioctl_mt762x.o
-endif
-
 ccflags-y += -Idrivers/net/ethernet/raeth/rtl8367c/include  -D_LITTLE_ENDIAN -DMDC_MDIO_OPERATION
 ccflags-y += -Idrivers/net/ethernet/raeth
 ccflags-y += -Iinclude/linux/
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/esw_common.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/esw_common.h
deleted file mode 100644
index 64e6e7c82..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/esw_common.h
+++ /dev/null
@@ -1,34 +0,0 @@
-#ifndef __MTK_ESW_COMMON__
-#define __MTK_ESW_COMMON__
-
-#define CONFIG_MT7530_GSW 				1
-#define CONFIG_GE2_INTERNAL_GMAC_P5		1
-#define CONFIG_RAETH_BOTH_GMAC			1
-
-//#define CONFIG_RAETH_ESW_IGMP_SNOOP_OFF	1
-#define CONFIG_RAETH_ESW_IGMP_SNOOP_HW	1
-
-#define ESW_PORT_ID_MAX			6
-
-#define REG_ESW_PORT_PCR_P0		0x2004
-#define REG_ESW_PORT_PIC_P0		0x2008
-#define REG_ESW_PORT_PVC_P0		0x2010
-#define REG_ESW_PORT_PPBV1_P0		0x2014
-#define REG_ESW_PORT_BSR_P0		0x201C
-#define REG_ESW_MAC_PMCR_P0		0x3000
-#define REG_ESW_MAC_PMSR_P0		0x3008
-#define REG_ESW_MAC_GMACCR		0x30E0
-#define REG_ESW_IMC			0x1C
-#undef ESW_PORT_PPE
-
-#ifdef __KERNEL__
-typedef union _ULARGE_INTEGER {
-	struct {
-		uint32_t LowPart;
-		uint32_t HighPart;
-	} u;
-	uint64_t QuadPart;
-} ULARGE_INTEGER;
-#endif
-
-#endif
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.c
deleted file mode 100644
index 908f890bc..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.c
+++ /dev/null
@@ -1,238 +0,0 @@
-/*
- * switch control IOCTL implementation (common code)
- */
-
-////////////////////////////////////////////////////////////////////////////////////
-
-extern void (*esw_link_status_hook)(u32 port_id, int port_link);
-
-static void fill_bridge_members(void)
-{
-#if defined (CONFIG_MT7530_GSW)
-	set_bit(1, g_vlan_pool);
-	set_bit(2, g_vlan_pool); // VID2 filled on U-Boot
-#endif
-	memset(g_bwan_member, 0, sizeof(g_bwan_member));
-
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1][LAN_PORT_1].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1][LAN_PORT_1].rule = SWAPI_VLAN_RULE_WAN_LAN1;
-
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN2][LAN_PORT_2].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN2][LAN_PORT_2].rule = SWAPI_VLAN_RULE_WAN_LAN2;
-
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3][LAN_PORT_3].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3][LAN_PORT_3].rule = SWAPI_VLAN_RULE_WAN_LAN3;
-
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN4][LAN_PORT_4].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN4][LAN_PORT_4].rule = SWAPI_VLAN_RULE_WAN_LAN4;
-
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3_LAN4][LAN_PORT_3].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3_LAN4][LAN_PORT_3].rule = SWAPI_VLAN_RULE_WAN_LAN3;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3_LAN4][LAN_PORT_4].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN3_LAN4][LAN_PORT_4].rule = SWAPI_VLAN_RULE_WAN_LAN4;
-
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2][LAN_PORT_1].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2][LAN_PORT_1].rule = SWAPI_VLAN_RULE_WAN_LAN1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2][LAN_PORT_2].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2][LAN_PORT_2].rule = SWAPI_VLAN_RULE_WAN_LAN2;
-
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_1].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_1].rule = SWAPI_VLAN_RULE_WAN_LAN1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_2].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_2].rule = SWAPI_VLAN_RULE_WAN_LAN2;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_3].bwan = 1;
-	g_bwan_member[SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3][LAN_PORT_3].rule = SWAPI_VLAN_RULE_WAN_LAN3;
-}
-
-////////////////////////////////////////////////////////////////////////////////////
-
-static long mtk_esw_ioctl(struct file *file, unsigned int req, unsigned long arg)
-{
-	int ioctl_result = 0;
-	u32 uint_value = 0;
-	u32 uint_result = 0;
-	port_bytes_t port_bytes = {0};
-	esw_mib_counters_t port_counters;
-
-	unsigned int uint_param = (req >> MTK_ESW_IOCTL_CMD_LENGTH_BITS);
-	req &= ((1u << MTK_ESW_IOCTL_CMD_LENGTH_BITS)-1);
-
-	mutex_lock(&esw_access_mutex);
-
-	switch(req)
-	{
-	case MTK_ESW_IOCTL_STATUS_LINK_PORT: /* used by rc */
-		uint_result = esw_status_link_port_uapi(uint_param);
-		put_user(uint_result, (unsigned int __user *)arg);
-		break;
-	case MTK_ESW_IOCTL_STATUS_LINK_PORTS_WAN: /* used by rc */
-		uint_result = esw_status_link_ports(1);
-		put_user(uint_result, (unsigned int __user *)arg);
-		break;
-	case MTK_ESW_IOCTL_STATUS_LINK_PORTS_LAN: /* used by rc */
-		uint_result = esw_status_link_ports(0);
-		put_user(uint_result, (unsigned int __user *)arg);
-		break;
-	case MTK_ESW_IOCTL_STATUS_LINK_CHANGED: /* used by rc */
-		uint_result = esw_status_link_changed();
-		put_user(uint_result, (unsigned int __user *)arg);
-		break;
-
-	case MTK_ESW_IOCTL_STATUS_SPEED_PORT: /* used by rc */
-		uint_result = esw_status_speed_port_uapi(uint_param);
-		put_user(uint_result, (unsigned int __user *)arg);
-		break;
-
-	case MTK_ESW_IOCTL_STATUS_BYTES_PORT: /* used by rc */
-		ioctl_result = esw_status_bytes_port_uapi(uint_param, &port_bytes);
-		copy_to_user((port_bytes_t __user *)arg, &port_bytes, sizeof(port_bytes_t));
-		break;
-
-	case MTK_ESW_IOCTL_STATUS_MIB_PORT: /* used by rc */
-		ioctl_result = esw_status_mib_port_uapi(uint_param, &port_counters);
-		copy_to_user((esw_mib_counters_t __user *)arg, &port_counters, sizeof(esw_mib_counters_t));
-		break;
-
-	case MTK_ESW_IOCTL_PORTS_POWER: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		change_ports_power(uint_param, uint_value);
-		break;
-
-	case MTK_ESW_IOCTL_PORTS_WAN_LAN_POWER: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		change_wan_lan_ports_power(uint_param, uint_value);
-		break;
-	case MTK_ESW_IOCTL_MAC_TABLE_CLEAR: /* used by rc */
-		esw_mac_table_clear();
-		break;
-
-	case MTK_ESW_IOCTL_BRIDGE_MODE: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		ioctl_result = change_bridge_mode(uint_param, uint_value);
-		break;
-
-	case MTK_ESW_IOCTL_VLAN_RESET_TABLE: /* used by rc */
-		esw_vlan_reset_table();
-		break;
-	case MTK_ESW_IOCTL_VLAN_PVID_WAN_GET: /* used by rc */
-		uint_result = g_vlan_pvid_wan_untagged;
-		put_user(uint_result, (unsigned int __user *)arg);
-		break;
-	case MTK_ESW_IOCTL_VLAN_ACCEPT_PORT_MODE:  /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		vlan_accept_port_mode(uint_param, uint_value);
-		break;
-	case MTK_ESW_IOCTL_VLAN_CREATE_PORT_VID: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		vlan_create_entry(uint_param, uint_value, 1);
-		break;
-	case MTK_ESW_IOCTL_VLAN_CREATE_ENTRY: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		vlan_create_entry(uint_param, uint_value, 0);
-		break;
-	case MTK_ESW_IOCTL_VLAN_RULE_SET: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		ioctl_result = change_vlan_rule(uint_param, uint_value);
-		break;
-
-	case MTK_ESW_IOCTL_STORM_BROADCAST:  /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		change_storm_control_broadcast(uint_value);
-		break;
-
-	case MTK_ESW_IOCTL_JUMBO_FRAMES: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		change_jumbo_frames_accept(uint_value);
-		break;
-
-	case MTK_ESW_IOCTL_IGMP_SNOOPING: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		change_igmp_snooping_control(uint_value);
-		break;
-
-	case MTK_ESW_IOCTL_IGMP_STATIC_PORTS: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		change_igmp_static_ports(uint_value);
-		break;
-
-	case MTK_ESW_IOCTL_LED_MODE: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		change_led_mode(uint_value);
-		break;
-
-	case MTK_ESW_IOCTL_SPEED_PORT: /* used by rc */
-		copy_from_user(&uint_value, (int __user *)arg, sizeof(int));
-		ioctl_result = change_port_link_mode_uapi(uint_param, uint_value);
-		break;
-
-	default:
-		ioctl_result = -ENOIOCTLCMD;
-	}
-
-	mutex_unlock(&esw_access_mutex);
-
-	return ioctl_result;
-}
-
-////////////////////////////////////////////////////////////////////////////////////
-
-static int mtk_esw_open(struct inode *inode, struct file *file)
-{
-	try_module_get(THIS_MODULE);
-	return 0;
-}
-
-////////////////////////////////////////////////////////////////////////////////////
-
-static int mtk_esw_release(struct inode *inode, struct file *file)
-{
-	module_put(THIS_MODULE);
-	return 0;
-}
-
-////////////////////////////////////////////////////////////////////////////////////
-
-static const struct file_operations mtk_esw_fops =
-{
-	.owner		= THIS_MODULE,
-	.unlocked_ioctl	= mtk_esw_ioctl,
-	.open		= mtk_esw_open,
-	.release	= mtk_esw_release,
-};
-
-////////////////////////////////////////////////////////////////////////////////////
-
-int esw_ioctl_init(void)
-{
-	int r;
-
-	fill_bridge_members();
-
-	r = register_chrdev(MTK_ESW_DEVMAJOR, MTK_ESW_DEVNAME, &mtk_esw_fops);
-	if (r < 0) {
-		printk(KERN_ERR MTK_ESW_DEVNAME ": unable to register character device\n");
-		return r;
-	}
-
-	esw_link_status_hook = esw_link_status_changed_state;
-
-#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_SW)
-	igmp_sn_init();
-#endif
-
-	return 0;
-}
-
-////////////////////////////////////////////////////////////////////////////////////
-
-void esw_ioctl_uninit(void)
-{
-	esw_link_status_hook = NULL;
-
-#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_SW)
-	igmp_sn_uninit();
-#endif
-
-	unregister_chrdev(MTK_ESW_DEVMAJOR, MTK_ESW_DEVNAME);
-}
-
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.h
deleted file mode 100644
index a3b80986b..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl.h
+++ /dev/null
@@ -1,198 +0,0 @@
-/*
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License as
- * published by the Free Software Foundation; either version 2 of
- * the License, or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
- * MA 02111-1307 USA
- *
- */
-
-#ifndef __MTK_ESW_IOCTL_H__
-#define __MTK_ESW_IOCTL_H__
-
-#include "esw_common.h"
-
-#define MTK_ESW_DEVNAME				"mtk_esw"
-#define MTK_ESW_DEVPATH				"/dev/mtk_esw"
-#define MTK_ESW_DEVMAJOR			(219)
-
-#define MTK_ESW_IOCTL_CMD_LENGTH_BITS		(8)
-
-/////////////////////////////////////////////////
-// SWITCH STATUS
-/////////////////////////////////////////////////
-
-#define MTK_ESW_IOCTL_STATUS_LINK_PORT		10
-#define MTK_ESW_IOCTL_STATUS_LINK_PORTS_WAN	11
-#define MTK_ESW_IOCTL_STATUS_LINK_PORTS_LAN	12
-#define MTK_ESW_IOCTL_STATUS_LINK_CHANGED	17
-
-#define MTK_ESW_IOCTL_STATUS_SPEED_PORT		20
-
-#define MTK_ESW_IOCTL_STATUS_BYTES_PORT		26
-
-#define MTK_ESW_IOCTL_STATUS_MIB_PORT		30
-#define MTK_ESW_IOCTL_STATUS_MIB_RESET_ALL	38
-
-/////////////////////////////////////////////////
-// INIT CONTROL
-/////////////////////////////////////////////////
-
-#define MTK_ESW_IOCTL_RESET_SWITCH		40
-#define MTK_ESW_IOCTL_PORTS_POWER		41
-#define MTK_ESW_IOCTL_PORTS_WAN_LAN_POWER	42
-#define MTK_ESW_IOCTL_MAC_TABLE_CLEAR		43
-
-/////////////////////////////////////////////////
-// BRIDGE CONTROL (WAN/LAN HW ISOLATION)
-/////////////////////////////////////////////////
-
-#define MTK_ESW_IOCTL_BRIDGE_MODE		50
-#define MTK_ESW_IOCTL_PORT_FORWARD_MASK		55
-
-/////////////////////////////////////////////////
-// VLAN CONTROL
-/////////////////////////////////////////////////
-
-#define MTK_ESW_IOCTL_VLAN_RESET_TABLE		60
-#define MTK_ESW_IOCTL_VLAN_PVID_WAN_GET		61
-#define MTK_ESW_IOCTL_VLAN_ACCEPT_PORT_MODE	62
-#define MTK_ESW_IOCTL_VLAN_CREATE_PORT_VID	63
-#define MTK_ESW_IOCTL_VLAN_CREATE_ENTRY		64
-#define MTK_ESW_IOCTL_VLAN_RULE_SET		65
-
-/////////////////////////////////////////////////
-// USER CONTROL
-/////////////////////////////////////////////////
-
-#define MTK_ESW_IOCTL_STORM_BROADCAST		73
-#define MTK_ESW_IOCTL_JUMBO_FRAMES		75
-#define MTK_ESW_IOCTL_EEE_LPI			77
-#define MTK_ESW_IOCTL_IGMP_SNOOPING		78
-#define MTK_ESW_IOCTL_IGMP_STATIC_PORTS		79
-#define MTK_ESW_IOCTL_LED_MODE			80
-#define MTK_ESW_IOCTL_SPEED_PORT		90
-
-// *** VALUES DEFINITION ***
-
-/////////////////////////////////////////////////
-// MAGIC
-/////////////////////////////////////////////////
-
-#define SWAPI_MAGIC_RESET_ASIC			(0x25252525)
-
-/////////////////////////////////////////////////
-// HW INDEPENDENT PORT ID
-/////////////////////////////////////////////////
-
-#define SWAPI_PORT_WAN				0
-#define SWAPI_PORT_LAN1				1
-#define SWAPI_PORT_LAN2				2
-#define SWAPI_PORT_LAN3				3
-#define SWAPI_PORT_LAN4				4
-#define SWAPI_PORT_LAN5				5
-#define SWAPI_PORT_CPU_LAN			14
-#define SWAPI_PORT_CPU_WAN			15
-
-/////////////////////////////////////////////////
-// HW INDEPENDENT PORT MASK
-/////////////////////////////////////////////////
-
-#define SWAPI_PORTMASK_WAN			(1u<<SWAPI_PORT_WAN)
-#define SWAPI_PORTMASK_LAN1			(1u<<SWAPI_PORT_LAN1)
-#define SWAPI_PORTMASK_LAN2			(1u<<SWAPI_PORT_LAN2)
-#define SWAPI_PORTMASK_LAN3			(1u<<SWAPI_PORT_LAN3)
-#define SWAPI_PORTMASK_LAN4			(1u<<SWAPI_PORT_LAN4)
-#define SWAPI_PORTMASK_LAN5			(1u<<SWAPI_PORT_LAN5)
-#define SWAPI_PORTMASK_CPU_LAN			(1u<<SWAPI_PORT_CPU_LAN)
-#define SWAPI_PORTMASK_CPU_WAN			(1u<<SWAPI_PORT_CPU_WAN)
-
-/////////////////////////////////////////////////
-// BRIDGE MODES
-/////////////////////////////////////////////////
-
-#define SWAPI_WAN_BRIDGE_DISABLE		(0)
-#define SWAPI_WAN_BRIDGE_LAN1			(1)
-#define SWAPI_WAN_BRIDGE_LAN2			(2)
-#define SWAPI_WAN_BRIDGE_LAN3			(3)
-#define SWAPI_WAN_BRIDGE_LAN4			(4)
-#define SWAPI_WAN_BRIDGE_LAN3_LAN4		(5)
-#define SWAPI_WAN_BRIDGE_LAN1_LAN2		(6)
-#define SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3		(7)
-#define SWAPI_WAN_BRIDGE_DISABLE_WAN		(8)
-#define SWAPI_WAN_BRIDGE_NUM			(SWAPI_WAN_BRIDGE_DISABLE_WAN+1)
-
-/////////////////////////////////////////////////
-// BRIDGE WAN ISOLATION MODES
-/////////////////////////////////////////////////
-
-#define SWAPI_WAN_BWAN_ISOLATION_NONE		(0)
-#define SWAPI_WAN_BWAN_ISOLATION_FROM_CPU	(1)
-#define SWAPI_WAN_BWAN_ISOLATION_BETWEEN	(2)
-
-/////////////////////////////////////////////////
-// VLAN MODES
-/////////////////////////////////////////////////
-
-#define SWAPI_VLAN_ACCEPT_FRAMES_ALL		(0)
-#define SWAPI_VLAN_ACCEPT_FRAMES_TAG_ONLY	(1)
-#define SWAPI_VLAN_ACCEPT_FRAMES_UNTAG_ONLY	(2)
-
-#define SWAPI_VLAN_RULE_WAN_INET		(0)
-#define SWAPI_VLAN_RULE_WAN_IPTV		(1)
-#define SWAPI_VLAN_RULE_WAN_LAN1		(2)
-#define SWAPI_VLAN_RULE_WAN_LAN2		(3)
-#define SWAPI_VLAN_RULE_WAN_LAN3		(4)
-#define SWAPI_VLAN_RULE_WAN_LAN4		(5)
-#define SWAPI_VLAN_RULE_NUM			(SWAPI_VLAN_RULE_WAN_LAN4+1)
-
-/////////////////////////////////////////////////
-// LINK MODES
-/////////////////////////////////////////////////
-
-#define SWAPI_LINK_SPEED_MODE_AUTO		(0)
-#define SWAPI_LINK_SPEED_MODE_AUTO_1000_FD	(1)
-#define SWAPI_LINK_SPEED_MODE_AUTO_100_FD	(2)
-#define SWAPI_LINK_SPEED_MODE_AUTO_100_HD	(3)
-#define SWAPI_LINK_SPEED_MODE_AUTO_10_FD	(4)
-#define SWAPI_LINK_SPEED_MODE_AUTO_10_HD	(5)
-#define SWAPI_LINK_SPEED_MODE_FORCE_100_FD	(6)
-#define SWAPI_LINK_SPEED_MODE_FORCE_100_HD	(7)
-#define SWAPI_LINK_SPEED_MODE_FORCE_10_FD	(8)
-#define SWAPI_LINK_SPEED_MODE_FORCE_10_HD	(9)
-#define SWAPI_LINK_SPEED_MODE_FORCE_POWER_OFF	(15)
-
-#define SWAPI_LINK_FLOW_CONTROL_TX_RX		(0)
-#define SWAPI_LINK_FLOW_CONTROL_TX_ASYNC	(1)
-#define SWAPI_LINK_FLOW_CONTROL_DISABLE		(2)
-
-/////////////////////////////////////////////////
-// LED MODES
-/////////////////////////////////////////////////
-
-#define SWAPI_LED_PHYMODE_100_ACT		(1)
-#define SWAPI_LED_PHYMODE_10_ACT		(2)
-#define SWAPI_LED_PHYMODE_100			(5)
-#define SWAPI_LED_LINK_ACT			(7)
-#define SWAPI_LED_DUPLEX_COLLISION		(10)
-#define SWAPI_LED_OFF				(11)
-
-/////////////////////////////////////////////////
-
-typedef struct port_bytes_s
-{
-	uint64_t RX;
-	uint64_t TX;
-} port_bytes_t;
-
-#endif
-
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.c
deleted file mode 100644
index b9288ccf0..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.c
+++ /dev/null
@@ -1,1838 +0,0 @@
-/*
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License as
- * published by the Free Software Foundation; either version 2 of
- * the License, or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
- * MA 02111-1307 USA
- *
- */
-
-#include <linux/init.h>
-#include <linux/version.h>
-#include <linux/module.h>
-#include <linux/kernel.h>
-#include <linux/mutex.h>
-#include <linux/fs.h>
-#include <linux/delay.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-
-#include "../raether.h"
-#include "../ra_switch.h"
-
-#include "ioctl.h"
-//#include "ioctl_igmp.h"
-#include "ioctl_mt762x.h"
-
-////////////////////////////////////////////////////////////////////////////////////
-
-static DEFINE_MUTEX(esw_access_mutex);
-static DECLARE_BITMAP(g_vlan_pool, 4096);
-
-
-static u32 g_wan_bridge_mode                     = SWAPI_WAN_BRIDGE_DISABLE;
-static u32 g_wan_bwan_isolation                  = SWAPI_WAN_BWAN_ISOLATION_NONE;
-
-static u32 g_led_phy_mode                        = SWAPI_LED_LINK_ACT;
-
-static u32 g_jumbo_frames_enabled                = ESW_DEFAULT_JUMBO_FRAMES;
-
-#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
-static u32 g_igmp_snooping_enabled               = ESW_DEFAULT_IGMP_SNOOPING;
-static u32 g_igmp_static_ports                   = 0;
-#endif
-
-static u32 g_storm_rate_limit                    = ESW_DEFAULT_STORM_RATE;
-
-static u32 g_port_link_mode[ESW_EPHY_ID_MAX+1]   = {0, 0, 0, 0, 0};
-static u32 g_port_phy_power[ESW_EPHY_ID_MAX+1]   = {0, 0, 0, 0, 0};
-
-static u32 g_vlan_rule[SWAPI_VLAN_RULE_NUM]      = {0x0, 0x0, 0x0, 0x0, 0x0, 0x0};
-static u32 g_vlan_rule_user[SWAPI_VLAN_RULE_NUM] = {0x0, 0x0, 0x0, 0x0, 0x0, 0x0};
-
-////////////////////////////////////////////////////////////////////////////////////
-
-static atomic_t g_switch_inited                  = ATOMIC_INIT(0);
-static atomic_t g_switch_allow_irq               = ATOMIC_INIT(0);
-static atomic_t g_port_link_changed              = ATOMIC_INIT(0);
-
-static bwan_member_t g_bwan_member[SWAPI_WAN_BRIDGE_NUM][ESW_EPHY_ID_MAX+1];
-
-static u32 g_vlan_pvid_wan_untagged              = 2;
-
-////////////////////////////////////////////////////////////////////////////////////
-u32 esw_reg_get(u32 addr)
-{
-	u32 data = 0;
-	if (mii_mgr_read(0x1f, addr, &data))
-		return data;
-	printk("%s: FAILED at read from 0x%08X!\n", __FUNCTION__, addr);
-	return 0;
-
-}
-
-void esw_reg_set(u32 addr, u32 data)
-{
-	if (!mii_mgr_write(0x1f, addr, data))
-		printk("%s: FAILED at write to 0x%08X!\n", __FUNCTION__, addr);
-}
-
-static
-int mt7530_gsw_wait_wt_mac(void)
-{
-	u32 i, atc_val;
-
-	for (i = 0; i < 200; i++) {
-		udelay(100);
-		atc_val = 0;
-		mii_mgr_read(0x1f, 0x80, &atc_val);
-		if (!(atc_val & BIT(15)))
-			return 0;
-	}
-
-	return -1;
-}
-
-static
-int mt7530_gsw_mac_table_clear(int static_only)
-{
-	u32 atc_val;
-
-	/* clear all (non)static MAC entries */
-	atc_val = (static_only) ? 0x8602 : 0x8002;
-
-	mii_mgr_write(0x1f, 0x80, atc_val);
-
-	return mt7530_gsw_wait_wt_mac();
-}
-
-static
-u32 esw_get_port_mib_rgoc(u32 port_id, u32 *HighPart)
-{
-	u32 mib_val = 0;
-	mib_val   = esw_reg_get(0x40A8 + 0x100*port_id);
-	*HighPart = esw_reg_get(0x40AC + 0x100*port_id);
-	return mib_val;
-}
-
-static
-u32 esw_get_port_mib_tgoc(u32 port_id, u32 *HighPart)
-{
-	u32 mib_val = 0;
-	mib_val   = esw_reg_get(0x4048 + 0x100*port_id);
-	*HighPart = esw_reg_get(0x404C + 0x100*port_id);
-	return mib_val;
-}
-
-u32 get_ports_mask_lan(u32 include_cpu, int is_phy_id)
-{
-	u32 i, wan_bridge_mode, portmask_lan;
-
-	wan_bridge_mode = g_wan_bridge_mode;
-
-	portmask_lan = MASK_LAN_PORTS_ALL;
-	if (include_cpu)
-		portmask_lan |= MASK_LAN_PORT_CPU;
-
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if (g_bwan_member[wan_bridge_mode][i].bwan)
-			portmask_lan &= ~(1u << i);
-	}
-
-	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE_WAN) {
-		if (is_phy_id)
-			portmask_lan |= (1u << WAN_PORT_X);
-		else
-			portmask_lan |= MASK_WAN_PORT_X;
-	}
-
-	return portmask_lan;
-}
-
-static u32 get_ports_mask_wan(u32 include_cpu, int is_phy_id)
-{
-	u32 i, wan_bridge_mode, portmask_wan;
-
-	wan_bridge_mode = g_wan_bridge_mode;
-	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE_WAN)
-		return 0;
-
-	if (is_phy_id)
-		portmask_wan = (1u << WAN_PORT_X);
-	else
-		portmask_wan = MASK_WAN_PORT_X;
-
-	if (include_cpu)
-		portmask_wan |= MASK_WAN_PORT_CPU;
-
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if (g_bwan_member[wan_bridge_mode][i].bwan)
-			portmask_wan |= (1u << i);
-	}
-
-	return portmask_wan;
-}
-
-static u32 get_ports_mask_from_uapi(u32 port_mask_uapi, int is_phy_id)
-{
-	u32 gsw_ports_mask = 0;
-
-	if (port_mask_uapi & SWAPI_PORTMASK_WAN) {
-		if (is_phy_id)
-			gsw_ports_mask |= (1u << WAN_PORT_X);
-		else
-			gsw_ports_mask |= MASK_WAN_PORT_X;
-	}
-	if (port_mask_uapi & SWAPI_PORTMASK_LAN1)
-		gsw_ports_mask |= MASK_LAN_PORT_1;
-	if (port_mask_uapi & SWAPI_PORTMASK_LAN2)
-		gsw_ports_mask |= MASK_LAN_PORT_2;
-	if (port_mask_uapi & SWAPI_PORTMASK_LAN3)
-		gsw_ports_mask |= MASK_LAN_PORT_3;
-	if (port_mask_uapi & SWAPI_PORTMASK_LAN4)
-		gsw_ports_mask |= MASK_LAN_PORT_4;
-	if (port_mask_uapi & SWAPI_PORTMASK_LAN5)
-		gsw_ports_mask |= MASK_LAN_PORT_5;
-	if (port_mask_uapi & SWAPI_PORTMASK_CPU_LAN)
-		gsw_ports_mask |= MASK_LAN_PORT_CPU;
-	if (port_mask_uapi & SWAPI_PORTMASK_CPU_WAN)
-		gsw_ports_mask |= MASK_WAN_PORT_CPU;
-
-	return gsw_ports_mask;
-}
-
-static u32 get_port_from_uapi(u32 port_id_uapi)
-{
-	switch (port_id_uapi)
-	{
-	case SWAPI_PORT_WAN:
-		return WAN_PORT_X;
-	case SWAPI_PORT_LAN1:
-		return LAN_PORT_1;
-	case SWAPI_PORT_LAN2:
-		return LAN_PORT_2;
-	case SWAPI_PORT_LAN3:
-		return LAN_PORT_3;
-	case SWAPI_PORT_LAN4:
-		return LAN_PORT_4;
-#if defined (LAN_PORT_5)
-	case SWAPI_PORT_LAN5:
-		return LAN_PORT_5;
-#endif
-	case SWAPI_PORT_CPU_LAN:
-		return LAN_PORT_CPU;
-	case SWAPI_PORT_CPU_WAN:
-		return WAN_PORT_CPU;
-	}
-
-	return ESW_PORT_ID_MAX+1;
-}
-
-static const char* get_port_desc(u32 port_id)
-{
-	const char *port_desc;
-
-	switch (port_id)
-	{
-	case WAN_PORT_X:
-		port_desc = "WAN";
-		break;
-	case LAN_PORT_1:
-		port_desc = "LAN1";
-		break;
-	case LAN_PORT_2:
-		port_desc = "LAN2";
-		break;
-	case LAN_PORT_3:
-		port_desc = "LAN3";
-		break;
-	case LAN_PORT_4:
-		port_desc = "LAN4";
-		break;
-#if defined (LAN_PORT_5)
-	case LAN_PORT_5:
-		port_desc = "LAN5";
-		break;
-#endif
-	case LAN_PORT_CPU:
-	default:
-		port_desc = "CPU";
-		break;
-	}
-
-	return port_desc;
-}
-
-static void esw_show_bridge_partitions(u32 wan_bridge_mode)
-{
-	const char *wanl, *wanr;
-	char lans[8];
-
-	wanl = "W|";
-	wanr = "";
-
-	switch (wan_bridge_mode)
-	{
-	case SWAPI_WAN_BRIDGE_LAN1:
-		strcpy(lans, "WLLL");
-		break;
-	case SWAPI_WAN_BRIDGE_LAN2:
-		strcpy(lans, "LWLL");
-		break;
-	case SWAPI_WAN_BRIDGE_LAN3:
-		strcpy(lans, "LLWL");
-		break;
-	case SWAPI_WAN_BRIDGE_LAN4:
-		strcpy(lans, "LLLW");
-		break;
-	case SWAPI_WAN_BRIDGE_LAN3_LAN4:
-		strcpy(lans, "LLWW");
-		break;
-	case SWAPI_WAN_BRIDGE_LAN1_LAN2:
-		strcpy(lans, "WWLL");
-		break;
-	case SWAPI_WAN_BRIDGE_LAN1_LAN2_LAN3:
-		strcpy(lans, "WWWL");
-		break;
-	case SWAPI_WAN_BRIDGE_DISABLE_WAN:
-		strcpy(lans, "LLLL");
-		wanl = "L";
-		wanr = "";
-		break;
-	default:
-		strcpy(lans, "LLLL");
-		break;
-	}
-
-#if defined (LAN_PORT_5)
-	strcat(lans, "L");
-#endif
-
-	printk("%s - %s: %s%s%s\n", MTK_ESW_DEVNAME, "hw bridge", wanl, lans, wanr);
-}
-
-static void esw_port_matrix_set(u32 port_id, u32 fwd_mask, u32 pvlan_ingress_mode)
-{
-	u32 reg_pcr;
-
-	reg_pcr = esw_reg_get(REG_ESW_PORT_PCR_P0 + 0x100*port_id);
-	reg_pcr &= ~(0xFF << 16);
-	reg_pcr &= ~(0x03);
-	reg_pcr |= ((fwd_mask & 0xFF) << 16);
-	reg_pcr |= (pvlan_ingress_mode & 0x03);
-	esw_reg_set(REG_ESW_PORT_PCR_P0 + 0x100*port_id, reg_pcr);
-}
-
-static void esw_port_ingress_mode_set(u32 port_id, u32 pvlan_ingress_mode)
-{
-	u32 reg_pcr;
-
-	reg_pcr = esw_reg_get(REG_ESW_PORT_PCR_P0 + 0x100*port_id);
-	reg_pcr &= ~(0x03);
-	reg_pcr |= (pvlan_ingress_mode & 0x03);
-	esw_reg_set(REG_ESW_PORT_PCR_P0 + 0x100*port_id, reg_pcr);
-}
-
-static void esw_port_attrib_set(u32 port_id, u32 port_attribute)
-{
-	u32 reg_pvc;
-
-	reg_pvc = esw_reg_get(REG_ESW_PORT_PVC_P0 + 0x100*port_id);
-	reg_pvc &= 0x0000FF3F;
-	reg_pvc |= 0x81000000; // STAG VPID 8100
-	reg_pvc |= ((port_attribute & 0x03) << 6);
-	esw_reg_set(REG_ESW_PORT_PVC_P0 + 0x100*port_id, reg_pvc);
-}
-
-static void esw_port_accept_set(u32 port_id, u32 accept_frames)
-{
-	u32 reg_pvc;
-
-	reg_pvc = esw_reg_get(REG_ESW_PORT_PVC_P0 + 0x100*port_id);
-	reg_pvc &= 0xFFFFFFFC;
-	reg_pvc |= (accept_frames & 0x03);
-	esw_reg_set(REG_ESW_PORT_PVC_P0 + 0x100*port_id, reg_pvc);
-}
-
-static void esw_vlan_pvid_set(u32 port_id, u32 pvid, u32 prio)
-{
-	u32 reg_ppbv = (1u << 16) | ((prio & 0x7) << 13) | (pvid & 0xfff);
-
-	esw_reg_set(REG_ESW_PORT_PPBV1_P0 + 0x100*port_id, reg_ppbv);
-}
-
-#if !defined (CONFIG_RAETH_ESW_IGMP_SNOOP_OFF)
-void esw_igmp_flood_to_cpu(int flood_to_cpu)
-{
-	u32 reg_imc;
-
-	reg_imc = esw_reg_get(REG_ESW_IMC);
-	reg_imc &= ~((0x7<<28)|(0x7<<12));
-	/* Note: TO_CPU applied to P5 port too and IGMP/MLD P5->WAN will be dropped */
-#if !defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) && !defined (CONFIG_GE2_INTERNAL_GMAC_P5)
-	if (flood_to_cpu)
-		reg_imc |= (0x6<<28)|(0x6<<12);
-#endif
-	esw_reg_set(REG_ESW_IMC, reg_imc);
-}
-#endif
-
-#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
-static void esw_igmp_ports_config(u32 wan_bridge_mode)
-{
-	u32 i, reg_isc, mask_no_learn;
-
-	mask_no_learn = 0;
-
-	if (wan_bridge_mode != SWAPI_WAN_BRIDGE_DISABLE_WAN) {
-		mask_no_learn = get_ports_mask_wan(0, 0);
-		for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-			if ((mask_no_learn >> i) & 0x1)
-				esw_reg_set(REG_ESW_PORT_PIC_P0 + 0x100*i, 0x8000);
-		}
-	}
-
-	/* make CPU ports always static */
-	mask_no_learn |= MASK_WAN_PORT_CPU;
-	mask_no_learn |= MASK_LAN_PORT_CPU;
-
-	if (g_igmp_snooping_enabled)
-		mask_no_learn |= g_igmp_static_ports;
-	else
-		mask_no_learn |= get_ports_mask_lan(0, 0);
-
-	reg_isc = esw_reg_get(REG_ESW_ISC);
-	reg_isc &= ~0xFF1C00FF;
-	reg_isc |= mask_no_learn;
-
-	/* also enable upstream router port learning (in AP mode) */
-	if (g_igmp_static_ports)
-		reg_isc |= (1u << 19) | (1u << 18);
-
-	esw_reg_set(REG_ESW_ISC, reg_isc);
-}
-
-static void esw_igmp_mld_snooping(u32 enable_igmp, u32 enable_mld)
-{
-	u32 i, mask_lan, dst_igmp, src_join, reg_pic, reg_pic_lan;
-	u32 mask_static = g_igmp_static_ports;
-
-	dst_igmp = 0;
-	src_join = 0;
-	reg_pic = (2u << 14);			// Robustness = 2
-
-	if (enable_mld) {
-		dst_igmp |= (1u << 9);		// IPM_33
-		
-		src_join |= (1u << 13);		// MLD_HW_LEAVE
-		src_join |= (1u << 7);		// MLD2_JOIN_EN
-		src_join |= (1u << 5);		// MLD_JOIN_EN
-	}
-
-	if (enable_igmp) {
-		dst_igmp |= (1u << 8);		// IPM_01
-		
-		src_join |= (1u << 12);		// IGMP_HW_LEAVE
-		src_join |= (1u << 6);		// IGMP3_JOIN_EN
-		src_join |= (1u << 4);		// IGMP_JOIN_EN
-	}
-
-	mask_lan = get_ports_mask_lan(0, 0);
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if ((mask_lan >> i) & 0x1) {
-			reg_pic_lan = reg_pic;
-			if ((mask_static >> i) & 0x1)
-				reg_pic_lan |= dst_igmp;
-			else
-				reg_pic_lan |= src_join;
-			esw_reg_set(REG_ESW_PORT_PIC_P0 + 0x100*i, reg_pic_lan);
-		}
-	}
-
-	/* make CPU port always static */
-	esw_reg_set(REG_ESW_PORT_PIC_P0 + 0x100*LAN_PORT_CPU, reg_pic | dst_igmp);
-}
-#endif
-
-static void esw_mac_table_clear(void)
-{
-	mt7530_gsw_mac_table_clear(0);
-#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || \
-    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
-	mt7620_esw_mac_table_clear(0);
-#endif
-}
-
-static int esw_write_vtcr(u32 vtcr_cmd, u32 vtcr_val)
-{
-	u32 i, reg_vtcr;
-
-	reg_vtcr = (vtcr_cmd << 12) | vtcr_val | 0x80000000;
-	esw_reg_set(REG_ESW_VLAN_VTCR, reg_vtcr);
-
-	for (i = 0; i < 200; i++) {
-		udelay(100);
-		reg_vtcr = esw_reg_get(REG_ESW_VLAN_VTCR);
-		if (!(reg_vtcr & 0x80000000))
-			return 0;
-	}
-
-	printk("%s: VTCR timeout!\n", MTK_ESW_DEVNAME);
-	return -1;
-}
-
-static void esw_vlan_set(u32 cvid, u32 svid, u32 mask_member, u32 mask_untag, u32 mask_swap, u32 fid)
-{
-	u32 i, reg_val, reg_val2;
-
-	cvid &= 0xfff;
-	svid &= 0xfff;
-	mask_member &= 0x7f;
-	mask_untag &= 0x7f;
-	mask_swap &= 0x7f;
-	fid &= 0x7;
-
-	reg_val2 = 0;
-
-	// set vlan member
-	reg_val = 1;				// VALID
-#if !ESW_USE_IVL_MODE
-	if (fid > 0)
-		reg_val |= (fid << 1);		// FID
-	else
-#endif
-	reg_val |= (1u << 30);			// IVL=1
-	reg_val |= (svid << 4);			// S_TAG
-	reg_val |= (mask_member << 16);		// PORT_MEM
-	if (svid)
-		reg_val |= (1u << 27);		// COPY_PRI
-	reg_val |= (1u << 28);			// VTAG_EN=1
-
-	/* set vlan untag ports */
-	for (i = 0; i < 7; i++) {
-		if (!(mask_member & (1u << i)))
-			continue;
-		
-		if (!(mask_untag & (1u << i))) {
-			if (mask_swap & (1u << i))
-				reg_val2 |= (0x1u << (i*2));	// EG_TAG=Swap
-			else
-				reg_val2 |= (0x2u << (i*2));	// EG_TAG=Tagged
-		}
-	}
-
-	esw_reg_set(REG_ESW_VLAN_VAWD1, reg_val);
-	esw_reg_set(REG_ESW_VLAN_VAWD2, reg_val2);
-
-	esw_write_vtcr(1, cvid);
-	set_bit(cvid, g_vlan_pool);
-}
-
-static void esw_vlan_reset_table(void)
-{
-	u32 i;
-
-	/* Reset VLAN table from VID #2 */
-	for (i = 2; i < 4096; i++) {
-		if (test_and_clear_bit(i, g_vlan_pool))
-			esw_write_vtcr(2, i);
-	}
-}
-
-#define VLAN_ENTRY_ID_MAX	(15)
-static u32 find_vlan_slot(vlan_entry_t *vlan_entry, u32 start_idx, u32 cvid)
-{
-	u32 i;
-
-	for (i = start_idx; i <= VLAN_ENTRY_ID_MAX; i++) {
-		if (!vlan_entry[i].valid || vlan_entry[i].cvid == cvid)
-			return i;
-	}
-
-	return VLAN_ENTRY_ID_MAX + 1; // not found
-}
-
-static u32 find_free_min_pvid(u32 *pvid_list, u32 vid)
-{
-	u32 i, vid_new;
-
-	vid_new = vid;
-	for (i = 0; i < SWAPI_VLAN_RULE_NUM; i++) {
-		if (vid == pvid_list[i]) {
-			/* recursion step */
-			vid_new = find_free_min_pvid(pvid_list, vid+1);
-			break;
-		}
-	}
-	return vid_new;
-}
-
-static int is_vlan_rule_included(u32 wan_bridge_mode, u32 rule_id)
-{
-	u32 i;
-
-	if (rule_id == SWAPI_VLAN_RULE_WAN_INET ||
-	    rule_id == SWAPI_VLAN_RULE_WAN_IPTV)
-		return 1;
-
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if (g_bwan_member[wan_bridge_mode][i].bwan &&
-		    g_bwan_member[wan_bridge_mode][i].rule == (u8)rule_id)
-			return 1;
-	}
-
-	return 0;
-}
-
-static int is_wan_vid_valid(u32 vid)
-{
-	return (vid == 2 || vid >= MIN_EXT_VLAN_VID) ? 1 : 0;
-}
-
-static void esw_vlan_apply_rules(u32 wan_bridge_mode, u32 wan_bwan_isolation)
-{
-	vlan_entry_t vlan_entry[VLAN_ENTRY_ID_MAX+1];
-	pvlan_member_t pvlan_member[ESW_EPHY_ID_MAX+1];
-	u32 pvid[SWAPI_VLAN_RULE_NUM] = {0};
-	u32 prio[SWAPI_VLAN_RULE_NUM] = {0};
-	u32 tagg[SWAPI_VLAN_RULE_NUM] = {0};
-	u32 i, cvid, next_fid, untg_vid, vlan_idx, vlan_filter_on;
-
-#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
-	pvlan_member_t pvlan_member_cpu_wan;
-#endif
-
-	untg_vid = 2;	// default PVID for untagged WAN traffic
-	next_fid = 3;
-	vlan_filter_on = 0;
-
-	memset(vlan_entry, 0, sizeof(vlan_entry));
-	memset(pvlan_member, 0, sizeof(pvlan_member));
-
-	for (i = 0; i < SWAPI_VLAN_RULE_NUM; i++) {
-		if (!is_vlan_rule_included(wan_bridge_mode, i))
-			continue;
-		pvid[i] =  (g_vlan_rule_user[i] & 0xFFF);
-		prio[i] = ((g_vlan_rule_user[i] >> 16) & 0x7);
-		tagg[i] = ((g_vlan_rule_user[i] >> 24) & 0x1);
-		if (is_wan_vid_valid(pvid[i]))
-			vlan_filter_on = 1;
-	}
-
-	/* find minimal unused VID, when VID=2 is used */
-	if (vlan_filter_on) {
-		untg_vid = find_free_min_pvid(pvid, 2);
-	}
-
-	g_vlan_pvid_wan_untagged = untg_vid;
-
-	if (!is_wan_vid_valid(pvid[SWAPI_VLAN_RULE_WAN_INET])) {
-		pvid[SWAPI_VLAN_RULE_WAN_INET] = untg_vid; // VID 2
-		prio[SWAPI_VLAN_RULE_WAN_INET] = 0;
-		tagg[SWAPI_VLAN_RULE_WAN_INET] = 0;
-	} else {
-		tagg[SWAPI_VLAN_RULE_WAN_INET] = 1;
-	}
-
-	if (!is_wan_vid_valid(pvid[SWAPI_VLAN_RULE_WAN_IPTV])) {
-		pvid[SWAPI_VLAN_RULE_WAN_IPTV] = untg_vid; // VID 2
-		prio[SWAPI_VLAN_RULE_WAN_IPTV] = 0;
-		tagg[SWAPI_VLAN_RULE_WAN_IPTV] = 0;
-	} else {
-		tagg[SWAPI_VLAN_RULE_WAN_IPTV] = 1;
-	}
-
-	/* fill WAN port (use PVID 2 for handle untagged traffic -> VID2) */
-	pvlan_member[WAN_PORT_X].pvid = untg_vid;
-
-#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
-	/* fill CPU WAN port (use PVID 2 for handle untagged traffic -> VID2) */
-	pvlan_member_cpu_wan.pvid = untg_vid;
-	pvlan_member_cpu_wan.prio = 0;
-	pvlan_member_cpu_wan.tagg = 0;
-#endif
-
-	/* VID #1 */
-	vlan_entry[0].valid = 1;
-	vlan_entry[0].fid = 1;
-	vlan_entry[0].cvid = 1;
-	vlan_entry[0].port_member |= MASK_LAN_PORT_CPU;
-#if defined (MT7530_P6_UNTAGGED)
-	vlan_entry[0].port_untag  |= MASK_LAN_PORT_CPU;
-#endif
-
-	/* VID #2 */
-	vlan_entry[1].valid = 1;
-	vlan_entry[1].fid = 2;
-	vlan_entry[1].cvid = untg_vid;
-	vlan_entry[1].port_member |= (MASK_WAN_PORT_X | MASK_WAN_PORT_CPU);
-	vlan_entry[1].port_untag  |=  MASK_WAN_PORT_X;
-
-#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || \
-    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
-	/* clear vlan members on MT7620 ESW (slot idx 2..3) */
-	mt7620_esw_vlan_clear_idx(2);
-	mt7620_esw_vlan_clear_idx(3);
-
-	/* update VID=2 members (P7|P6|P4) */
-	mt7620_esw_vlan_set_idx(1, untg_vid, 0xd0);
-
-	/* set P4 PVID */
-	mt7620_esw_pvid_set(4, untg_vid, 0);
-#endif
-
-	/* check IPTV tagged */
-	if (tagg[SWAPI_VLAN_RULE_WAN_IPTV]) {
-		cvid = pvid[SWAPI_VLAN_RULE_WAN_IPTV];
-		vlan_idx = find_vlan_slot(vlan_entry, 2, cvid);
-		if (vlan_idx <= VLAN_ENTRY_ID_MAX) {
-			if (!vlan_entry[vlan_idx].valid) {
-				vlan_entry[vlan_idx].valid = 1;
-				vlan_entry[vlan_idx].fid = next_fid++;
-				vlan_entry[vlan_idx].cvid = cvid;
-				
-#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || \
-    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
-				/* need add vlan members on MT7620 ESW P4 (ESW members P7|P6|P4) */
-				mt7620_esw_vlan_set_idx(2, cvid, 0xd0);
-#endif
-			}
-			vlan_entry[vlan_idx].port_member |= (MASK_WAN_PORT_X | MASK_WAN_PORT_CPU);
-			pvlan_member[WAN_PORT_X].tagg = 1;
-		}
-	}
-
-	/* check INET tagged */
-	if (tagg[SWAPI_VLAN_RULE_WAN_INET]) {
-		cvid = pvid[SWAPI_VLAN_RULE_WAN_INET];
-		vlan_idx = find_vlan_slot(vlan_entry, 2, cvid);
-		if (vlan_idx <= VLAN_ENTRY_ID_MAX) {
-			if (!vlan_entry[vlan_idx].valid) {
-				vlan_entry[vlan_idx].valid = 1;
-				vlan_entry[vlan_idx].fid = next_fid++;
-				vlan_entry[vlan_idx].cvid = cvid;
-				
-#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || \
-    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
-				/* need add vlan members on MT7620 ESW P4 (ESW members P7|P6|P4) */
-				mt7620_esw_vlan_set_idx(3, cvid, 0xd0);
-#endif
-			}
-			vlan_entry[vlan_idx].port_member |= (MASK_WAN_PORT_X | MASK_WAN_PORT_CPU);
-			pvlan_member[WAN_PORT_X].tagg = 1;
-		}
-	}
-
-#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
-	/* if INET and IPTV tagged with common VID, untag WAN_CPU + use PVID */
-	if (tagg[SWAPI_VLAN_RULE_WAN_INET] && pvid[SWAPI_VLAN_RULE_WAN_INET] == pvid[SWAPI_VLAN_RULE_WAN_IPTV]) {
-		/* update VID #2 members (do not forward untagged packets to WAN_CPU) */
-		vlan_entry[1].port_member &= ~(MASK_WAN_PORT_CPU);
-		cvid = pvid[SWAPI_VLAN_RULE_WAN_INET];
-		vlan_idx = find_vlan_slot(vlan_entry, 2, cvid);
-		if (vlan_idx <= VLAN_ENTRY_ID_MAX && vlan_entry[vlan_idx].valid)
-			vlan_entry[vlan_idx].port_untag |= MASK_WAN_PORT_CPU;
-		pvlan_member_cpu_wan.pvid = cvid;
-		pvlan_member_cpu_wan.prio = prio[SWAPI_VLAN_RULE_WAN_IPTV];
-	} else if (!tagg[SWAPI_VLAN_RULE_WAN_INET] && !tagg[SWAPI_VLAN_RULE_WAN_IPTV]) {
-		/* update VID #2 untag members */
-		vlan_entry[1].port_untag |= MASK_WAN_PORT_CPU;
-	} else {
-		/* mark CPU WAN as tagged */
-		pvlan_member_cpu_wan.tagg = 1;
-	}
-#endif
-
-	/* fill physical LAN ports */
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		int rule_id;
-		
-		if (i == WAN_PORT_X)
-			continue;
-		
-		if ((1u << i) & ESW_MASK_EXCLUDE)
-			continue;
-		
-		if (!g_bwan_member[wan_bridge_mode][i].bwan) {
-			pvlan_member[i].pvid = 1;
-			
-			/* VID #1 */
-			vlan_entry[0].port_member |= (1u << i);
-			vlan_entry[0].port_untag  |= (1u << i);
-			
-			continue;
-		}
-		
-		rule_id = g_bwan_member[wan_bridge_mode][i].rule;
-		if (!is_wan_vid_valid(pvid[rule_id])) {
-			pvlan_member[i].pvid = untg_vid;
-			
-			/* VID #2 */
-			vlan_entry[1].port_member |= (1u << i);
-			vlan_entry[1].port_untag  |= (1u << i);
-		} else {
-			cvid = pvid[rule_id];
-			vlan_idx = find_vlan_slot(vlan_entry, 2, cvid);
-			if (vlan_idx <= VLAN_ENTRY_ID_MAX) {
-				if (!vlan_entry[vlan_idx].valid) {
-					vlan_entry[vlan_idx].valid = 1;
-					vlan_entry[vlan_idx].fid = next_fid++;
-					vlan_entry[vlan_idx].cvid = cvid;
-				}
-				vlan_entry[vlan_idx].port_member |= ((1u << i) | MASK_WAN_PORT_X);
-#if !defined (RAETH_GE2_MAC_TO_GPHY)
-				if (wan_bwan_isolation != SWAPI_WAN_BWAN_ISOLATION_FROM_CPU)
-#endif
-				{
-					vlan_entry[vlan_idx].port_member |= MASK_WAN_PORT_CPU;
-#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
-					/* mark CPU WAN as tagged */
-					pvlan_member_cpu_wan.tagg = 1;
-#endif
-				}
-				if (!tagg[rule_id])
-					vlan_entry[vlan_idx].port_untag |= (1u << i);
-				
-				pvlan_member[i].pvid = cvid;
-				pvlan_member[i].prio = prio[rule_id];
-				pvlan_member[i].tagg = tagg[rule_id];
-				
-				pvlan_member[WAN_PORT_X].tagg = 1;
-			} else {
-				pvlan_member[i].pvid = untg_vid;
-				
-				/* VID #2 */
-				vlan_entry[1].port_member |= (1u << i);
-				vlan_entry[1].port_untag  |= (1u << i);
-			}
-		}
-	}
-
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-	for (i = 0; i <= VLAN_ENTRY_ID_MAX; i++) {
-		if (!vlan_entry[i].valid)
-			continue;
-		if (!vlan_entry[i].port_member)
-			continue;
-		if (wan_bridge_mode != SWAPI_WAN_BRIDGE_DISABLE) {
-			vlan_entry[i].port_member |= MASK_LAN_PORT_CPU;
-			vlan_entry[i].port_untag &= ~MASK_LAN_PORT_CPU;
-		}
-	}
-#endif
-
-#if defined (ESW_PORT_PPE)
-	/* add PPE port to members with CPU port */
-	for (i = 0; i <= VLAN_ENTRY_ID_MAX; i++) {
-		if (!vlan_entry[i].valid)
-			continue;
-		if (vlan_entry[i].port_member & (1u << ESW_PORT_CPU))
-			vlan_entry[i].port_member |= (1u << ESW_PORT_PPE);
-		if (vlan_entry[i].port_swap & (1u << ESW_PORT_CPU))
-			vlan_entry[i].port_swap |= (1u << ESW_PORT_PPE);
-	}
-#endif
-
-	/* configure physical LAN/WAN ports */
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if ((1u << i) & ESW_MASK_EXCLUDE)
-			continue;
-		esw_vlan_pvid_set(i, pvlan_member[i].pvid, pvlan_member[i].prio);
-		if (!pvlan_member[i].tagg) {
-			esw_port_attrib_set(i, PORT_ATTRIBUTE_TRANSPARENT);
-			esw_port_accept_set(i, PORT_ACCEPT_FRAMES_UNTAGGED);
-		} else {
-			esw_port_attrib_set(i, PORT_ATTRIBUTE_USER);
-			esw_port_accept_set(i, PORT_ACCEPT_FRAMES_ALL);
-		}
-	}
-
-	/* configure CPU LAN port */
-	esw_vlan_pvid_set(LAN_PORT_CPU, 1, 0);
-	esw_port_accept_set(LAN_PORT_CPU, PORT_ACCEPT_FRAMES_ALL);
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-	esw_port_attrib_set(LAN_PORT_CPU, (wan_bridge_mode != SWAPI_WAN_BRIDGE_DISABLE) ? PORT_ATTRIBUTE_USER : PORT_ATTRIBUTE_TRANSPARENT);
-#elif defined (MT7530_P6_UNTAGGED)
-	esw_port_attrib_set(LAN_PORT_CPU, PORT_ATTRIBUTE_TRANSPARENT);
-#else
-	esw_port_attrib_set(LAN_PORT_CPU, PORT_ATTRIBUTE_USER);
-#endif
-
-	esw_port_ingress_mode_set(LAN_PORT_CPU, PVLAN_INGRESS_MODE_SECURITY);
-
-	/* configure CPU WAN port */
-#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
-	/* [MT7620 P4 -> MT7530 P5] or [MT7621 GE2 -> MT7530 P5] */
-	esw_vlan_pvid_set(WAN_PORT_CPU, pvlan_member_cpu_wan.pvid, pvlan_member_cpu_wan.prio);
-	esw_port_accept_set(WAN_PORT_CPU, PORT_ACCEPT_FRAMES_ALL);
-	esw_port_attrib_set(WAN_PORT_CPU, (pvlan_member_cpu_wan.pvid != untg_vid || pvlan_member_cpu_wan.tagg) ? PORT_ATTRIBUTE_USER : PORT_ATTRIBUTE_TRANSPARENT);
-	esw_port_ingress_mode_set(WAN_PORT_CPU, PVLAN_INGRESS_MODE_SECURITY);
-#endif
-
-	/* reset VLAN table */
-	esw_vlan_reset_table();
-
-	/* fill VLAN table */
-	for (i = 0; i <= VLAN_ENTRY_ID_MAX; i++) {
-		if (!vlan_entry[i].valid)
-			continue;
-		if (!vlan_entry[i].port_member)
-			continue;
-		esw_vlan_set(vlan_entry[i].cvid, vlan_entry[i].svid,
-			vlan_entry[i].port_member, vlan_entry[i].port_untag, 0, vlan_entry[i].fid);
-	}
-
-	/* save VLAN rules */
-	for (i = 0; i < SWAPI_VLAN_RULE_NUM; i++)
-		g_vlan_rule[i] = g_vlan_rule_user[i];
-}
-
-static void esw_vlan_init_vid1(void)
-{
-	u32 i, port_member, port_untag;
-
-	port_member = 0xFF;
-	port_member &= ~(ESW_MASK_EXCLUDE);
-	port_untag = port_member;
-#if defined (ESW_PORT_PPE)
-	port_untag &= ~(1u << ESW_PORT_PPE);
-#endif
-
-	/* configure physical LAN ports */
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if ((1u << i) & ESW_MASK_EXCLUDE)
-			continue;
-		esw_vlan_pvid_set(i, 1, 0);
-		esw_port_attrib_set(i, PORT_ATTRIBUTE_TRANSPARENT);
-		esw_port_accept_set(i, PORT_ACCEPT_FRAMES_UNTAGGED);
-	}
-
-	/* configure CPU port */
-	esw_vlan_pvid_set(LAN_PORT_CPU, 1, 0);
-	esw_port_accept_set(LAN_PORT_CPU, PORT_ACCEPT_FRAMES_ALL);
-#if defined (CONFIG_RALINK_MT7620) && !defined (MT7530_P5_ENABLED)
-	port_untag &= ~(MASK_LAN_PORT_CPU);
-	esw_port_attrib_set(LAN_PORT_CPU, PORT_ATTRIBUTE_USER);
-#else
-	esw_port_attrib_set(LAN_PORT_CPU, PORT_ATTRIBUTE_TRANSPARENT);
-#endif
-
-	esw_port_ingress_mode_set(LAN_PORT_CPU, PVLAN_INGRESS_MODE_SECURITY);
-
-	/* reset VLAN table */
-	esw_vlan_reset_table();
-
-	/* set all ports to VLAN 1 member (no SVID, no SWAP) */
-	esw_vlan_set(1, 0, port_member, port_untag, 0, 1);
-
-}
-
-static void esw_mask_bridge_isolate(u32 wan_bridge_mode, u32 wan_bwan_isolation)
-{
-	u32 i;
-	u32 fwd_mask_bwan_lan;
-	u32 fwd_mask_lan, fwd_mask_wan, fwd_mask;
-
-	fwd_mask_lan = get_ports_mask_lan(1, 0);
-
-	/* LAN forward mask */
-	for (i = 0; i <= ESW_PORT_ID_MAX; i++) {
-		if ((fwd_mask_lan >> i) & 0x1) {
-			fwd_mask = fwd_mask_lan;
-			/* set all port ingress to security mode (VLAN + fwd_mask) */
-			esw_port_matrix_set(i, fwd_mask, PVLAN_INGRESS_MODE_SECURITY);
-		}
-	}
-
-	/* clear forward mask for P5 */
-#if (MASK_WAN_PORT_CPU == 0)
-	esw_port_matrix_set(5, 0, PVLAN_INGRESS_MODE_SECURITY);
-#endif
-
-	/* clear forward mask for P4/P0 */
-#if (MASK_WAN_PORT_X == 0 && WAN_PORT_X < 5)
-	esw_port_matrix_set(WAN_PORT_X, 0, PVLAN_INGRESS_MODE_SECURITY);
-#endif
-
-	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE_WAN)
-		return;
-
-	fwd_mask_wan = get_ports_mask_wan(1, 0);
-	fwd_mask_bwan_lan = fwd_mask_wan & ~(MASK_WAN_PORT_X|MASK_WAN_PORT_CPU);
-
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-	if (wan_bridge_mode != SWAPI_WAN_BRIDGE_DISABLE)
-		fwd_mask_wan |= MASK_LAN_PORT_CPU;
-#endif
-
-	/* WAN forward mask */
-	for (i = 0; i <= ESW_PORT_ID_MAX; i++) {
-		if ((fwd_mask_wan >> i) & 0x1) {
-			fwd_mask = fwd_mask_wan;
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-			/* force add all LAN ports to forward from CPU */
-			if (i == LAN_PORT_CPU)
-				fwd_mask |= MASK_LAN_PORTS_ALL;
-#else
-#if !defined (MT7530_P6_UNTAGGED)
-			/* force add all LAN ports to forward from CPU */
-			if (i == WAN_PORT_CPU)
-				fwd_mask |= MASK_LAN_PORTS_ALL;
-#endif
-			if (wan_bwan_isolation == SWAPI_WAN_BWAN_ISOLATION_FROM_CPU) {
-				if (i == WAN_PORT_CPU)
-					fwd_mask &= ~fwd_mask_bwan_lan;
-				else if ((1u << i) & MASK_LAN_PORTS_ALL)
-					fwd_mask &= ~MASK_WAN_PORT_CPU;
-			} else
-#endif
-			if (wan_bwan_isolation == SWAPI_WAN_BWAN_ISOLATION_BETWEEN) {
-				if (i <= ESW_EPHY_ID_MAX) {
-					fwd_mask &= ~(MASK_WAN_PORT_X|MASK_LAN_PORTS_ALL);
-					fwd_mask |= (1u << i);
-				}
-			}
-			
-			/* set all port ingress to security mode (VLAN + fwd_mask) */
-			esw_port_matrix_set(i, fwd_mask, PVLAN_INGRESS_MODE_SECURITY);
-		}
-	}
-}
-
-static void esw_vlan_bridge_isolate(u32 wan_bridge_mode, u32 wan_bwan_isolation, int bridge_changed, int br_iso_changed, int vlan_rule_changed)
-{
-	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE_WAN) {
-		if (!bridge_changed)
-			return;
-		
-		esw_vlan_init_vid1();
-	} else {
-		if (!bridge_changed && !br_iso_changed && !vlan_rule_changed)
-			return;
-		
-		esw_vlan_apply_rules(wan_bridge_mode, wan_bwan_isolation);
-	}
-
-	if (bridge_changed) {
-#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
-		esw_igmp_ports_config(wan_bridge_mode);
-		if (g_igmp_snooping_enabled)
-			esw_igmp_mld_snooping(1, 1);
-#endif
-		esw_show_bridge_partitions(wan_bridge_mode);
-	}
-
-	esw_mac_table_clear();
-}
-
-static void esw_mac_to_phy_enable(void)
-{
-	u32 i, mac_mask, reg_pmcr;
-
-	/* full AN */
-	reg_pmcr = 0x00056330;
-
-	mac_mask = MASK_WAN_PORT_X | MASK_LAN_PORTS_ALL;
-
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if ((mac_mask >> i) & 0x1)
-			esw_reg_set(REG_ESW_MAC_PMCR_P0 + 0x100*i, reg_pmcr);
-	}
-}
-
-static int esw_port_phy_power(u32 phy_port_id, u32 power_on, int is_force)
-{
-	u32 esw_phy_mcr = 0x3100;
-	u32 phy_mdio_addr = phy_port_id;
-	u32 i_port_speed, is_power_on;
-
-	if (phy_port_id > ESW_EPHY_ID_MAX)
-		return 0;
-
-	/* external GigaPHY */
-#if defined (CONFIG_P4_MAC_TO_PHY_MODE)
-	if (phy_port_id == 4)
-		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2;
-#endif
-#if defined (CONFIG_P5_MAC_TO_PHY_MODE)
-	if (phy_port_id == 5)
-		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR;
-#elif defined (CONFIG_GE2_RGMII_AN)
-	if (phy_port_id == 5)
-		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2;
-#endif
-
-	i_port_speed = (g_port_link_mode[phy_port_id] & 0x0F);
-	if (i_port_speed == SWAPI_LINK_SPEED_MODE_FORCE_POWER_OFF)
-		power_on = 0;
-
-	is_power_on = 0;
-	if (mii_mgr_read(phy_mdio_addr, 0, &esw_phy_mcr)) {
-		is_power_on = (esw_phy_mcr & (1<<11)) ? 0 : 1;
-		esw_phy_mcr &= ~((1<<11)|(1<<9));
-		
-		/* fix PHY init after buggy Uboot 4.3.0.0 */
-		if (i_port_speed < SWAPI_LINK_SPEED_MODE_FORCE_100_FD)
-			esw_phy_mcr |= (1<<12);
-		
-		if (power_on)
-			esw_phy_mcr |= (1<<9);
-		else
-			esw_phy_mcr |= (1<<11);
-		
-		if (is_force || (is_power_on ^ power_on))
-			mii_mgr_write(phy_mdio_addr, 0, esw_phy_mcr);
-	}
-
-	g_port_phy_power[phy_port_id] = (power_on) ? 1 : 0;
-
-	/* return 1 when PHY power is changed */
-	return (is_power_on ^ power_on) ? 1 : 0;
-}
-
-static void esw_storm_control(u32 port_id, int set_bcast, int set_mcast, int set_ucast, u32 rate_mbps)
-{
-	u32 reg_bsr = 0;
-	u32 rate_unit_1000;
-	u32 rate_unit_100;
-	u32 rate_unit_10;
-
-	if (rate_mbps > 0) {
-		if (rate_mbps > (0xff * 4))
-			rate_mbps = (0xff * 4);
-		
-		rate_unit_1000 = rate_mbps;
-		rate_unit_100 = (rate_mbps < 90) ? rate_mbps : 90;
-		rate_unit_10 = (rate_mbps < 9) ? rate_mbps : 9;
-		
-		reg_bsr |= BIT(31);			// STRM_MODE = Rate-based
-		if (set_bcast)
-			reg_bsr |= BIT(30);		// STRM_BC_INC
-		if (set_mcast)
-			reg_bsr |= BIT(29);		// STRM_MC_INC
-		if (set_ucast)
-			reg_bsr |= BIT(28);		// STRM_UC_INC
-		
-		if (rate_mbps > 0xff) {
-			rate_unit_1000 >>= 2;
-			rate_unit_100 >>= 2;
-			rate_unit_10 >>= 2;
-			reg_bsr |= (3u << 24);		// STRM_UNIT = 4 Mbps
-		} else {
-			reg_bsr |= (2u << 24);		// STRM_UNIT = 1 Mbps
-		}
-		
-		reg_bsr |= (rate_unit_1000 << 16);	// STORM_1G
-		reg_bsr |= (rate_unit_100 << 8);	// STORM_100M
-		reg_bsr |= (rate_unit_10);		// STORM_10M
-	}
-
-	esw_reg_set(REG_ESW_PORT_BSR_P0 + 0x100*port_id, reg_bsr);
-}
-
-static void esw_jumbo_control(u32 jumbo_frames_enabled)
-{
-	u32 reg_gmaccr;
-
-	reg_gmaccr = esw_reg_get(REG_ESW_MAC_GMACCR);
-	reg_gmaccr &= ~(0x3f);
-	reg_gmaccr |= (9u << 2);		// MAX_RX_JUMBO = 9 KB
-
-	if (jumbo_frames_enabled) {
-		reg_gmaccr |= 0x3;		// MAX_RX_JUMBO
-	} else {
-		reg_gmaccr |= 0x1;		// 1536 bytes
-	}
-
-	esw_reg_set(REG_ESW_MAC_GMACCR, reg_gmaccr);
-}
-
-
-
-static void esw_led_mode(u32 led_mode)
-{
-	u32 reg_ledc;
-
-	reg_ledc = esw_reg_get(0x7d00);
-	reg_ledc |= 0x77777;
-
-	if (led_mode == SWAPI_LED_OFF)
-		reg_ledc &= ~(0x77777);
-
-	esw_reg_set(0x7d00, reg_ledc);
-}
-
-static u32 esw_status_link_port(u32 port_id)
-{
-	u32 reg_pmsr;
-
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-	if (port_id == WAN_PORT_X)
-		reg_pmsr = sysRegRead(REG_ETH_GE2_MAC_STATUS);	// read state from GE2
-	else
-#elif defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
-	if (port_id == WAN_PORT_X)
-		reg_pmsr = sysRegRead(RALINK_ETH_SW_BASE+REG_ESW_MAC_PMSR_P0 + 0x100*4);	// read state from P4
-	else
-#endif
-		reg_pmsr = esw_reg_get(REG_ESW_MAC_PMSR_P0 + 0x100*port_id);
-
-	return (reg_pmsr & 0x1);
-}
-
-static u32 esw_status_speed_port_uapi(u32 port_id_uapi)
-{
-	u32 port_link, port_duplex, port_speed;
-	u32 port_eee, port_fc_rx, port_fc_tx;
-	u32 reg_pmsr;
-	u32 port_id = get_port_from_uapi(port_id_uapi);
-
-	if (port_id > ESW_EPHY_ID_MAX)
-		return 0;
-
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-	if (port_id == WAN_PORT_X) {
-		reg_pmsr = sysRegRead(REG_ETH_GE2_MAC_STATUS);	// read state from GE2
-#if defined (CONFIG_GE2_RGMII_AN)
-		reg_pmsr |= ext_gphy_fill_pmsr(CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2);
-#endif
-	} else
-#elif defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4)
-	if (port_id == WAN_PORT_X)
-		reg_pmsr = sysRegRead(RALINK_ETH_SW_BASE+REG_ESW_MAC_PMSR_P0 + 0x100*4);	// read state from P4
-	else
-#endif
-		reg_pmsr = esw_reg_get(REG_ESW_MAC_PMSR_P0 + 0x100*port_id);
-
-	port_link = (reg_pmsr & 0x1);
-
-	if (!port_link)
-		return 0;
-
-	port_duplex = (reg_pmsr >> 1) & 0x1;
-	port_speed  = (reg_pmsr >> 2) & 0x3;
-	port_fc_tx  = (reg_pmsr >> 4) & 0x1;
-	port_fc_rx  = (reg_pmsr >> 5) & 0x1;
-	port_eee    = (reg_pmsr >> 6) & 0x3;
-
-	return ((port_link << 16) | (port_eee << 11) | (port_fc_rx << 10) | (port_fc_tx << 9) | (port_duplex << 8) | port_speed);
-}
-
-static u32 esw_status_link_port_uapi(u32 port_id_uapi)
-{
-	u32 port_id = get_port_from_uapi(port_id_uapi);
-
-	if (port_id > ESW_EPHY_ID_MAX)
-		return 0;
-
-	return esw_status_link_port(port_id);
-}
-
-static u32 esw_status_link_ports(int is_wan_ports)
-{
-	int i;
-	u32 port_link = 0;
-	u32 portmask;
-
-	if (is_wan_ports)
-		portmask = get_ports_mask_wan(0, 1);
-	else
-		portmask = get_ports_mask_lan(0, 1);
-
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if ((portmask >> i) & 0x1) {
-			port_link = esw_status_link_port(i);
-			if (port_link)
-				break;
-		}
-	}
-
-	return port_link;
-}
-
-static u32 esw_status_link_changed(void)
-{
-	return atomic_cmpxchg(&g_port_link_changed, 1, 0);
-}
-
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-extern int VirtualIF_get_bytes(port_bytes_t *pb);
-#endif
-
-static int esw_status_mib_port_uapi(u32 port_id_uapi, esw_mib_counters_t *mibc)
-{
-	ULARGE_INTEGER rx_goct, tx_goct;
-	u32 port_id = get_port_from_uapi(port_id_uapi);
-
-	if (port_id > ESW_PORT_ID_MAX)
-		return -EINVAL;
-
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-	if (port_id == WAN_PORT_X || port_id == WAN_PORT_CPU) {
-		port_bytes_t pb;
-		memset(mibc, 0, sizeof(esw_mib_counters_t));
-		if (VirtualIF_get_bytes(&pb) == 0) {
-			mibc->TxGoodOctets = pb.TX;
-			mibc->RxGoodOctets = pb.RX;
-		}
-		return 0;
-	}
-#endif
-
-	rx_goct.u.LowPart = esw_get_port_mib_rgoc(port_id, &rx_goct.u.HighPart);
-	tx_goct.u.LowPart = esw_get_port_mib_tgoc(port_id, &tx_goct.u.HighPart);
-
-	mibc->TxGoodOctets	= tx_goct.QuadPart;
-	mibc->RxGoodOctets	= rx_goct.QuadPart;
-
-	mibc->TxDropFrames	= esw_reg_get(0x4000 + 0x100*port_id);
-	mibc->TxCRCError	= esw_reg_get(0x4004 + 0x100*port_id);
-	mibc->TxUcastFrames	= esw_reg_get(0x4008 + 0x100*port_id);
-	mibc->TxMcastFrames	= esw_reg_get(0x400c + 0x100*port_id);
-	mibc->TxBcastFrames	= esw_reg_get(0x4010 + 0x100*port_id);
-	mibc->TxCollision	= esw_reg_get(0x4014 + 0x100*port_id);
-	mibc->TxPauseFrames	= esw_reg_get(0x402c + 0x100*port_id);
-
-	mibc->RxDropFrames	= esw_reg_get(0x4060 + 0x100*port_id);
-	mibc->RxFilterFrames	= esw_reg_get(0x4064 + 0x100*port_id);
-	mibc->RxUcastFrames	= esw_reg_get(0x4068 + 0x100*port_id);
-	mibc->RxMcastFrames	= esw_reg_get(0x406c + 0x100*port_id);
-	mibc->RxBcastFrames	= esw_reg_get(0x4070 + 0x100*port_id);
-	mibc->RxAligmentError	= esw_reg_get(0x4074 + 0x100*port_id);
-	mibc->RxCRCError	= esw_reg_get(0x4078 + 0x100*port_id);
-//	mibc->RxUndersizeError	= esw_reg_get(0x407c + 0x100*port_id);
-//	mibc->RxFragmentError	= esw_reg_get(0x4080 + 0x100*port_id);
-//	mibc->RxOversizeError	= esw_reg_get(0x4084 + 0x100*port_id);
-//	mibc->RxJabberError	= esw_reg_get(0x4088 + 0x100*port_id);
-	mibc->RxPauseFrames	= esw_reg_get(0x408c + 0x100*port_id);
-	return 0;
-}
-
-static int esw_status_bytes_port_uapi(u32 port_id_uapi, port_bytes_t *pb)
-{
-	ULARGE_INTEGER rx_goct, tx_goct;
-	u32 port_id = get_port_from_uapi(port_id_uapi);
-
-	if (port_id > ESW_PORT_ID_MAX)
-		return -EINVAL;
-
-#if defined (RAETH_GE2_MAC_TO_GPHY)
-	if (port_id == WAN_PORT_X || port_id == WAN_PORT_CPU)
-		return VirtualIF_get_bytes(pb);
-#endif
-
-	rx_goct.u.LowPart = esw_get_port_mib_rgoc(port_id, &rx_goct.u.HighPart);
-	tx_goct.u.LowPart = esw_get_port_mib_tgoc(port_id, &tx_goct.u.HighPart);
-
-	pb->RX = rx_goct.QuadPart;
-	pb->TX = tx_goct.QuadPart;
-
-	return 0;
-}
-
-static void change_ports_power(u32 power_on, u32 ports_mask)
-{
-	u32 i;
-
-	ports_mask = get_ports_mask_from_uapi(ports_mask, 1);
-
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if ((ports_mask >> i) & 0x1)
-			esw_port_phy_power(i, power_on, 0);
-	}
-}
-
-static int change_wan_lan_ports_power(u32 power_on, u32 is_wan)
-{
-	int power_changed = 0;
-	u32 i, ports_mask;
-
-	if (is_wan)
-		ports_mask = get_ports_mask_wan(0, 1);
-	else
-		ports_mask = get_ports_mask_lan(0, 1);
-
-	for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-		if ((ports_mask >> i) & 0x1)
-			power_changed |= esw_port_phy_power(i, power_on, 0);
-	}
-
-	return power_changed;
-}
-
-static int change_bridge_mode(u32 wan_bwan_isolation, u32 wan_bridge_mode)
-{
-	int i, bridge_changed, br_iso_changed, vlan_rule_changed, power_changed;
-
-	if (wan_bridge_mode > SWAPI_WAN_BRIDGE_DISABLE_WAN)
-		return -EINVAL;
-
-	if (wan_bwan_isolation > SWAPI_WAN_BWAN_ISOLATION_BETWEEN)
-		return -EINVAL;
-
-	if (wan_bridge_mode == SWAPI_WAN_BRIDGE_DISABLE)
-		wan_bwan_isolation = SWAPI_WAN_BWAN_ISOLATION_NONE;
-
-	bridge_changed = (g_wan_bridge_mode != wan_bridge_mode) ? 1 : 0;
-	br_iso_changed = (g_wan_bwan_isolation != wan_bwan_isolation) ? 1 : 0;
-	vlan_rule_changed = 0;
-	for (i = 0; i <= SWAPI_VLAN_RULE_WAN_LAN4; i++) {
-		if (g_vlan_rule[i] != g_vlan_rule_user[i]) {
-			vlan_rule_changed = 1;
-			break;
-		}
-	}
-
-	// set global bridge_mode first
-	g_wan_bridge_mode = wan_bridge_mode;
-	g_wan_bwan_isolation = wan_bwan_isolation;
-
-	if (atomic_read(&g_switch_inited) == 0)
-		return 0;
-
-	power_changed = 0;
-	if (bridge_changed || vlan_rule_changed) {
-		power_changed = change_wan_lan_ports_power(0, 1);
-		if (power_changed) {
-			// wait for PHY link down
-			msleep(500);
-		}
-	}
-
-	if (bridge_changed || br_iso_changed)
-		esw_mask_bridge_isolate(wan_bridge_mode, wan_bwan_isolation);
-
-	esw_vlan_bridge_isolate(wan_bridge_mode, wan_bwan_isolation, bridge_changed, br_iso_changed, vlan_rule_changed);
-
-	if (power_changed)
-		change_wan_lan_ports_power(1, 1);
-
-	return 0;
-}
-
-static void vlan_accept_port_mode(u32 accept_mode, u32 port_mask)
-{
-	u32 i, admit_frames = PORT_ACCEPT_FRAMES_ALL;
-
-	switch (accept_mode)
-	{
-	case SWAPI_VLAN_ACCEPT_FRAMES_UNTAG_ONLY:
-		admit_frames = PORT_ACCEPT_FRAMES_UNTAGGED;
-		break;
-	case SWAPI_VLAN_ACCEPT_FRAMES_TAG_ONLY:
-		admit_frames = PORT_ACCEPT_FRAMES_TAGGED;
-		break;
-	}
-
-	port_mask = get_ports_mask_from_uapi(port_mask, 0);
-
-	for (i = 0; i <= ESW_PORT_ID_MAX; i++) {
-		if ((port_mask >> i) & 0x1)
-			esw_port_accept_set(i, admit_frames);
-	}
-}
-
-static void vlan_create_entry(u32 vlan4k_info, u32 vlan4k_mask, int set_port_vid)
-{
-	u32 i, cvid, prio, fid;
-	u32 mask_member, mask_untag;
-
-	cvid = (vlan4k_info & 0x0FFF);
-	prio = ((vlan4k_info >> 12) & 0x7);
-	fid  = ((vlan4k_info >> 16) & 0xFF);
-	mask_member = get_ports_mask_from_uapi((vlan4k_mask & 0xFFFF), 0);
-	mask_untag  = get_ports_mask_from_uapi((vlan4k_mask >> 16) & 0xFFFF, 0);
-#if defined (ESW_PORT_PPE)
-	if (mask_member & (1u << ESW_PORT_CPU))
-		mask_member |= (1u << ESW_PORT_PPE);
-#endif
-	if (cvid < 1)
-		cvid = 1;
-
-	/* set vlan table */
-	esw_vlan_set(cvid, 0, mask_member, mask_untag, 0, fid);
-
-	/* set ports attrib */
-	for (i = 0; i <= ESW_PORT_ID_MAX; i++) {
-		if ((1u << i) & mask_member) {
-			if (!((1u << i) & mask_untag)) {
-				esw_port_attrib_set(i, PORT_ATTRIBUTE_USER);
-			} else {
-				if (set_port_vid)
-					esw_vlan_pvid_set(i, cvid, prio);
-				esw_port_attrib_set(i, PORT_ATTRIBUTE_TRANSPARENT);
-			}
-		}
-	}
-
-	printk("%s - create vlan %s: vid=[%d], prio=[%d], member=[0x%02X], untag=[0x%02X], fid=[%d]\n",
-			MTK_ESW_DEVNAME, (set_port_vid) ? "ports" : "entry", cvid, prio, mask_member, mask_untag, fid);
-}
-
-static int change_port_link_mode_uapi(u32 port_id_uapi, u32 port_link_mode)
-{
-	const char *link_desc = "Auto", *flow_desc = "ON";
-	u32 i_port_speed, i_port_flowc, i_port_power;
-	u32 esw_phy_ana = 0x05e1;
-	u32 esw_phy_mcr = 0x3100; /* 100 FD + auto-negotiation */
-	u32 phy_mdio_addr;
-	u32 port_id = get_port_from_uapi(port_id_uapi);
-
-	if (port_id > ESW_EPHY_ID_MAX)
-		return -EINVAL;
-
-	if (g_port_link_mode[port_id] == port_link_mode)
-		return 0;
-
-	phy_mdio_addr = port_id;
-
-	i_port_speed =  (port_link_mode & 0x0F);
-	i_port_flowc = ((port_link_mode >> 8) & 0x03);
-	i_port_power = (i_port_speed == SWAPI_LINK_SPEED_MODE_FORCE_POWER_OFF) ? 0 : 1;
-
-	if (!i_port_power)
-		i_port_speed = SWAPI_LINK_SPEED_MODE_AUTO;
-
-	switch (i_port_speed)
-	{
-	case SWAPI_LINK_SPEED_MODE_AUTO_100_FD:
-		link_desc = "100FD [AN]";
-		/* disable ability 100 HD, 10 FD, 10 HD */
-		esw_phy_ana &= ~((1<<7)|(1<<6)|(1<<5));
-		break;
-	case SWAPI_LINK_SPEED_MODE_AUTO_100_HD:
-		link_desc = "100HD [AN]";
-		/* disable ability 100 FD, 10 FD, 10 HD */
-		esw_phy_ana &= ~((1<<8)|(1<<6)|(1<<5));
-		/* disable FD */
-		esw_phy_mcr &= ~((1<<8));
-		break;
-	case SWAPI_LINK_SPEED_MODE_AUTO_10_FD:
-		link_desc = "10FD [AN]";
-		/* disable ability 100 FD, 100 HD, 10 HD */
-		esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<5));
-		/* set 10Mbps */
-		esw_phy_mcr &= ~((1<<13));
-		break;
-	case SWAPI_LINK_SPEED_MODE_AUTO_10_HD:
-		link_desc = "10HD [AN]";
-		/* disable ability 100 FD, 100 HD, 10 FD */
-		esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<6));
-		/* set 10Mbps, disable FD */
-		esw_phy_mcr &= ~((1<<13)|(1<<8));
-		break;
-	case SWAPI_LINK_SPEED_MODE_FORCE_100_FD:
-		link_desc = "100FD [Force]";
-		/* disable ability 100 HD, 10 FD, 10 HD */
-		esw_phy_ana &= ~((1<<7)|(1<<6)|(1<<5));
-		/* disable auto-negotiation */
-		esw_phy_mcr &= ~((1<<12));
-		break;
-	case SWAPI_LINK_SPEED_MODE_FORCE_100_HD:
-		link_desc = "100HD [Force]";
-		/* disable ability 100 FD, 10 FD, 10 HD */
-		esw_phy_ana &= ~((1<<8)|(1<<6)|(1<<5));
-		/* disable auto-negotiation, disable FD */
-		esw_phy_mcr &= ~((1<<12)|(1<<8));
-		break;
-	case SWAPI_LINK_SPEED_MODE_FORCE_10_FD:
-		link_desc = "10FD [Force]";
-		/* disable ability 100 FD, 100 HD, 10 HD */
-		esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<5));
-		/* disable auto-negotiation, set 10Mbps */
-		esw_phy_mcr &= ~((1<<13)|(1<<12));
-		break;
-	case SWAPI_LINK_SPEED_MODE_FORCE_10_HD:
-		link_desc = "10HD [Force]";
-		/* disable ability 100 FD, 100 HD, 10 FD */
-		esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<6));
-		/* disable auto-negotiation, set 10Mbps, disable FD */
-		esw_phy_mcr &= ~((1<<13)|(1<<12)|(1<<8));
-		break;
-	}
-
-	switch (i_port_flowc)
-	{
-	case SWAPI_LINK_FLOW_CONTROL_TX_ASYNC:
-	case SWAPI_LINK_FLOW_CONTROL_DISABLE:
-		flow_desc = "OFF";
-		/* disable pause ability (A6,A5) */
-		esw_phy_ana &= ~((1<<11)|(1<<10));
-		break;
-	}
-
-	/* external GigaPHY */
-#if defined (CONFIG_P4_MAC_TO_PHY_MODE)
-	if (port_id == 4)
-		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2;
-#endif
-#if defined (CONFIG_P5_MAC_TO_PHY_MODE)
-	if (port_id == 5)
-		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR;
-#elif defined (CONFIG_GE2_RGMII_AN)
-	if (port_id == 5)
-		phy_mdio_addr = CONFIG_MAC_TO_GIGAPHY_MODE_ADDR2;
-#endif
-
-	/* MT7621/MT7530 GSW or external GigaPHY */
-#if 1
-	{
-		u32 esw_phy_gcr = 0;
-		
-		/* set MII control register [6,13] */
-		if (i_port_speed <= SWAPI_LINK_SPEED_MODE_AUTO_1000_FD) {
-			/* set 1000 Mbps */
-			esw_phy_mcr &= ~(1<<13);
-			esw_phy_mcr |=  (1<<6);
-		}
-		
-		/* set auto-negotiation advertisement register [5,6,7,8] */
-		if (i_port_speed == SWAPI_LINK_SPEED_MODE_AUTO_1000_FD) {
-			/* disable ability 100 FD, 100 HD, 10 FD, 10 HD */
-			esw_phy_ana &= ~((1<<8)|(1<<7)|(1<<6)|(1<<5));
-			link_desc = "1000FD [AN]";
-		}
-		
-		/* set auto-negotiation advertisement register [11] */
-		if (i_port_speed <= SWAPI_LINK_SPEED_MODE_AUTO_1000_FD &&
-		    i_port_flowc == SWAPI_LINK_FLOW_CONTROL_TX_ASYNC) {
-			/* enable asymmetric pause ability (A6) */
-			esw_phy_ana |= (1<<11);
-			flow_desc = "TX Asy";
-		}
-		
-		/* set 1000Base-T control register [8,9] */
-		mii_mgr_read(phy_mdio_addr, 9, &esw_phy_gcr);
-		if (i_port_speed <= SWAPI_LINK_SPEED_MODE_AUTO_1000_FD) {
-			/* enable 1000Base-T Advertisement */
-			esw_phy_gcr |=  ((1<<9)|(1<<8));
-		} else {
-			/* disable 1000Base-T Advertisement */
-			esw_phy_gcr &= ~((1<<9)|(1<<8));
-		}
-		mii_mgr_write(phy_mdio_addr, 9, esw_phy_gcr);
-	}
-#endif
-
-	/* set PHY ability */
-	mii_mgr_write(phy_mdio_addr, 4, esw_phy_ana);
-
-	if (i_port_power) {
-		if (!(esw_phy_mcr & (1<<12))) {
-			/* power-down PHY */
-			esw_phy_mcr |= (1<<11);
-			
-			/* set PHY mode */
-			mii_mgr_write(phy_mdio_addr, 0, esw_phy_mcr);
-			
-			/* wait for PHY down */
-			msleep(500);
-			
-			/* power-up PHY */
-			esw_phy_mcr &= ~(1<<11);
-		} else {
-			/* restart PHY auto-negotiation */
-			esw_phy_mcr |= (1<<9);
-		}
-	} else {
-		/* power-down PHY */
-		esw_phy_mcr |= (1<<11);
-	}
-
-	/* set PHY mode */
-	mii_mgr_write(phy_mdio_addr, 0, esw_phy_mcr);
-
-	g_port_link_mode[port_id] = port_link_mode;
-
-	if (!i_port_power) {
-		link_desc = "Power OFF";
-		flow_desc = "N/A";
-	}
-
-	printk("%s - %s link speed: %s, flow control: %s\n",
-		MTK_ESW_DEVNAME, get_port_desc(port_id), link_desc, flow_desc);
-
-	return 0;
-}
-
-static void change_storm_control_broadcast(u32 control_rate_mbps)
-{
-	u32 i;
-	char rate_desc[16];
-
-	if (control_rate_mbps >= 1024)
-		control_rate_mbps = 0;
-
-	if (g_storm_rate_limit != control_rate_mbps) {
-		g_storm_rate_limit = control_rate_mbps;
-		
-		if (control_rate_mbps > 0)
-			snprintf(rate_desc, sizeof(rate_desc), "%d mbps", control_rate_mbps);
-		else
-			strcpy(rate_desc, "off");
-		
-		printk("%s - set broadcast storm control rate as: %s\n", MTK_ESW_DEVNAME, rate_desc);
-		
-		for (i = 0; i <= ESW_EPHY_ID_MAX; i++) {
-			if ((1u << i) & ESW_MASK_EXCLUDE)
-				continue;
-			esw_storm_control(i, 1, 0, 0, control_rate_mbps);
-		}
-	}
-}
-
-static void change_jumbo_frames_accept(u32 jumbo_frames_enabled)
-{
-	if (jumbo_frames_enabled)
-		jumbo_frames_enabled = 1;
-
-	if (g_jumbo_frames_enabled != jumbo_frames_enabled) {
-		g_jumbo_frames_enabled = jumbo_frames_enabled;
-		printk("%s - jumbo frames accept: %d bytes\n", MTK_ESW_DEVNAME, (jumbo_frames_enabled) ? 9000 : 1536);
-		
-		esw_jumbo_control(jumbo_frames_enabled);
-	}
-}
-
-
-static void change_igmp_static_ports(u32 ports_mask)
-{
-	ports_mask = get_ports_mask_from_uapi(ports_mask, 0);
-
-#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
-	if (g_igmp_static_ports != ports_mask) {
-		g_igmp_static_ports = ports_mask;
-		
-		if (g_igmp_snooping_enabled) {
-			esw_igmp_ports_config(g_wan_bridge_mode);
-			esw_igmp_flood_to_cpu( (!ports_mask) ? 1 : 0 );
-			esw_igmp_mld_snooping(1, 1);
-		}
-	}
-#endif
-}
-
-static void change_igmp_snooping_control(u32 igmp_snooping_enabled)
-{
-#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
-	if (igmp_snooping_enabled)
-		igmp_snooping_enabled = 1;
-
-	if (g_igmp_snooping_enabled != igmp_snooping_enabled) {
-		g_igmp_snooping_enabled = igmp_snooping_enabled;
-		printk("%s - hardware IGMP/MLD snooping: %s\n", MTK_ESW_DEVNAME, (igmp_snooping_enabled) ? "on" : "off");
-		
-		esw_igmp_ports_config(g_wan_bridge_mode);
-		esw_igmp_flood_to_cpu( (igmp_snooping_enabled && !g_igmp_static_ports) ? 1 : 0 );
-		esw_igmp_mld_snooping(igmp_snooping_enabled, igmp_snooping_enabled);
-	}
-#endif
-}
-
-static void change_led_mode(u32 led_mode)
-{
-	if (led_mode != SWAPI_LED_OFF)
-		led_mode = SWAPI_LED_LINK_ACT;
-
-	if (g_led_phy_mode != led_mode) {
-		g_led_phy_mode = led_mode;
-		esw_led_mode(led_mode);
-	}
-}
-
-static int change_vlan_rule(u32 vlan_rule_id, u32 vlan_rule)
-{
-	if (vlan_rule_id > SWAPI_VLAN_RULE_WAN_LAN4)
-		return -EINVAL;
-
-	if ((vlan_rule & 0xFFFF) > 4094)
-		return -EINVAL;
-
-	if (((vlan_rule >> 16) & 0xFF) > 7)
-		return -EINVAL;
-
-	g_vlan_rule_user[vlan_rule_id] = vlan_rule;
-
-	return 0;
-}
-
-static void esw_link_status_changed_state(u32 port_id, int port_link)
-{
-	const char *port_state;
-	u32 wan_ports_mask;
-
-	if (port_id <= ESW_EPHY_ID_MAX)
-		atomic_set(&g_port_link_changed, 1);
-
-	/* only printk wan link change */
-	wan_ports_mask = get_ports_mask_wan(0, 1);
-
-	if (!(wan_ports_mask & (1u << port_id)))
-		return;
-
-	port_state = (port_link) ? "Up" : "Down";
-
-	printk("%s: Link Status Changed - Port %s Link %s\n",
-		MTK_ESW_DEVNAME, get_port_desc(port_id), port_state);
-}
-
-int esw_ioctl_init_post(void)
-{
-	/* configure bridge isolation mode via forwards mask */
-	esw_mask_bridge_isolate(g_wan_bridge_mode, g_wan_bwan_isolation);
-
-	/* enable MAC for all PHY ports */
-	esw_mac_to_phy_enable();
-
-	/* configure bridge isolation mode via VLAN */
-	esw_vlan_bridge_isolate(g_wan_bridge_mode, g_wan_bwan_isolation, 1, 1, 1);
-
-#if defined (CONFIG_RAETH_ESW_IGMP_SNOOP_HW)
-	/* configure igmp/mld snooping */
-	esw_igmp_flood_to_cpu( (g_igmp_snooping_enabled && !g_igmp_static_ports) ? 1 : 0 );
-	esw_igmp_mld_snooping(g_igmp_snooping_enabled, g_igmp_snooping_enabled);
-#endif
-
-	/* configure leds */
-	esw_led_mode(g_led_phy_mode);
-
-	atomic_set(&g_switch_inited, 1);
-	atomic_set(&g_switch_allow_irq, 1);
-
-	return 0;
-}
-
-#if defined (CONFIG_RA_HW_NAT) || defined (CONFIG_RA_HW_NAT_MODULE)
-#if !defined (CONFIG_RAETH_BOTH_GMAC)
-int esw_get_traffic_port_wan(struct rtnl_link_stats64 *stats)
-{
-	ULARGE_INTEGER rx_goct, tx_goct;
-
-	rx_goct.u.LowPart = esw_get_port_mib_rgoc(WAN_PORT_X, &rx_goct.u.HighPart);
-	tx_goct.u.LowPart = esw_get_port_mib_tgoc(WAN_PORT_X, &tx_goct.u.HighPart);
-
-	stats->rx_packets = esw_get_port_mib_rgpc(WAN_PORT_X);
-	stats->tx_packets = esw_get_port_mib_tgpc(WAN_PORT_X);
-
-	stats->rx_bytes = rx_goct.QuadPart;
-	stats->tx_bytes = tx_goct.QuadPart;
-
-	return 0;
-}
-EXPORT_SYMBOL(esw_get_traffic_port_wan);
-#endif
-#endif
-
-////////////////////////////////////////////////////////////////////////////////////
-#include "ioctl.c"
-////////////////////////////////////////////////////////////////////////////////////
-
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.h
deleted file mode 100644
index c76fc6021..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_esw/ioctl_mt762x.h
+++ /dev/null
@@ -1,236 +0,0 @@
-/*
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License as
- * published by the Free Software Foundation; either version 2 of
- * the License, or (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
- * MA 02111-1307 USA
- *
- */
-
-#ifndef __IOCTL_MT762X_H__
-#define __IOCTL_MT762X_H__
-
-#include "esw_common.h"
-////////////////////////////////////////////////////////////////////////////////////
-
-#define LAN_PORT_1			CONFIG_RAETH_ESW_PORT_LAN1
-#define LAN_PORT_2			CONFIG_RAETH_ESW_PORT_LAN2
-#define LAN_PORT_3			CONFIG_RAETH_ESW_PORT_LAN3
-#define LAN_PORT_4			CONFIG_RAETH_ESW_PORT_LAN4
-
-#define MASK_LAN_PORT_1			(1u << LAN_PORT_1)
-#define MASK_LAN_PORT_2			(1u << LAN_PORT_2)
-#define MASK_LAN_PORT_3			(1u << LAN_PORT_3)
-#define MASK_LAN_PORT_4			(1u << LAN_PORT_4)
-
-#if defined (CONFIG_RAETH_ESW_PORT_LAN5) && (CONFIG_RAETH_ESW_PORT_LAN5 >= 0)
-#define LAN_PORT_5			CONFIG_RAETH_ESW_PORT_LAN5
-#define MASK_LAN_PORT_5			(1u << LAN_PORT_5)
-#else
-#define MASK_LAN_PORT_5			0
-#endif
-
-#define MASK_LAN_PORTS_ALL		(MASK_LAN_PORT_1|MASK_LAN_PORT_2|MASK_LAN_PORT_3|MASK_LAN_PORT_4|MASK_LAN_PORT_5)
-
-#define ESW_PORT_CPU			6
-#define LAN_PORT_CPU			6
-#define MASK_LAN_PORT_CPU		(1u << LAN_PORT_CPU)
-
-#if defined (CONFIG_MT7530_GSW)
-#if defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
-#define WAN_PORT_X			CONFIG_RAETH_ESW_PORT_WAN
-#define WAN_PORT_CPU			5	/* P5 = CPU WAN */
-#define MASK_WAN_PORT_X			(1u << WAN_PORT_X)
-#define MASK_WAN_PORT_CPU		(1u << WAN_PORT_CPU)
-#define ESW_EPHY_ID_MAX			4
-#define ESW_MASK_EXCLUDE		0
-#elif defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_GE2_INTERNAL_GPHY_P0)
-#define WAN_PORT_X			0	/* P0 PHY */
-#define WAN_PORT_CPU			5	/* fake */
-#define MASK_WAN_PORT_X			0
-#define MASK_WAN_PORT_CPU		0
-#define ESW_EPHY_ID_MAX			4
-#define ESW_MASK_EXCLUDE		((1<<5)|(1<<0))	/* P5/P0 excluded */
-#elif defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4) || defined (CONFIG_GE2_INTERNAL_GPHY_P4)
-#define WAN_PORT_X			4	/* P4 PHY */
-#define WAN_PORT_CPU			5	/* fake */
-#define MASK_WAN_PORT_X			0
-#define MASK_WAN_PORT_CPU		0
-#define ESW_EPHY_ID_MAX			4
-#define ESW_MASK_EXCLUDE		((1<<5)|(1<<4))	/* P5/P4 excluded */
-#elif defined (CONFIG_GE2_RGMII_AN)
-#define WAN_PORT_X			5	/* External PHY */
-#define WAN_PORT_CPU			5	/* fake */
-#define MASK_WAN_PORT_X			0
-#define MASK_WAN_PORT_CPU		0
-#define ESW_EPHY_ID_MAX			5
-#define ESW_MASK_EXCLUDE		(1<<5)	/* P5 excluded */
-#else
-#define WAN_PORT_X			CONFIG_RAETH_ESW_PORT_WAN
-#define WAN_PORT_CPU			6	/* P6 = CPU LAN + WAN */
-#define MASK_WAN_PORT_X			(1u << WAN_PORT_X)
-#define MASK_WAN_PORT_CPU		(1u << WAN_PORT_CPU)
-#define ESW_EPHY_ID_MAX			4
-#define ESW_MASK_EXCLUDE		(1<<5)	/* P5 excluded */
-#endif
-#else /* !CONFIG_MT7530_GSW */
-#define WAN_PORT_X			CONFIG_RAETH_ESW_PORT_WAN
-#define WAN_PORT_CPU			6	/* P6 = CPU LAN + WAN */
-#define MASK_WAN_PORT_X			(1u << WAN_PORT_X)
-#define MASK_WAN_PORT_CPU		(1u << WAN_PORT_CPU)
-#if defined (CONFIG_P5_MAC_TO_PHY_MODE)
-#define ESW_EPHY_ID_MAX			5
-#define ESW_MASK_EXCLUDE		0
-#else
-#define ESW_EPHY_ID_MAX			4
-#define ESW_MASK_EXCLUDE		(1<<5)	/* P5 excluded */
-#endif
-#endif
-
-#if defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P0) || defined (CONFIG_GE2_INTERNAL_GPHY_P0) || \
-    defined (CONFIG_P4_MAC_TO_MT7530_GPHY_P4) || defined (CONFIG_GE2_INTERNAL_GPHY_P4) || \
-    defined (CONFIG_P4_RGMII_TO_MT7530_GMAC_P5) || defined (CONFIG_GE2_INTERNAL_GMAC_P5)
-#define MT7530_P5_ENABLED
-#endif
-
-#if defined (MT7530_P5_ENABLED) || defined (CONFIG_RAETH_GMAC2)
-#define MT7530_P6_UNTAGGED
-#endif
-
-#if defined (CONFIG_GE2_INTERNAL_GPHY_P0) || defined (CONFIG_GE2_RGMII_AN) || \
-    defined (CONFIG_GE2_INTERNAL_GPHY_P4)
-#define RAETH_GE2_MAC_TO_GPHY
-#endif
-
-////////////////////////////////////////////////////////////////////////////////////
-
-#define ESW_DEFAULT_JUMBO_FRAMES	0
-#define ESW_DEFAULT_EEE_LPI		0
-#define ESW_DEFAULT_STORM_RATE		0
-#define ESW_DEFAULT_IGMP_SNOOPING	1
-
-////////////////////////////////////////////////////////////////////////////////////
-
-#define MIN_EXT_VLAN_VID		2
-#define ESW_USE_IVL_MODE		1	/* always use IVL (instead of SVL) */
-#define ESW_PRINT_LINK_ALL		0	/* printk only WAN link changed */
-
-////////////////////////////////////////////////////////////////////////////////////
-
-enum
-{
-	PVLAN_INGRESS_MODE_MATRIX   = 0x00,
-	PVLAN_INGRESS_MODE_FALLBACK = 0x01,
-	PVLAN_INGRESS_MODE_CHECK    = 0x02,
-	PVLAN_INGRESS_MODE_SECURITY = 0x03
-};
-
-enum
-{
-	PVLAN_EGRESS_UNTAG = 0x00,
-	PVLAN_EGRESS_SWAP  = 0x01,
-	PVLAN_EGRESS_TAG   = 0x02,
-	PVLAN_EGRESS_STACK = 0x03
-};
-
-enum
-{
-	PORT_ACCEPT_FRAMES_ALL      = 0x00,
-	PORT_ACCEPT_FRAMES_TAGGED   = 0x01,
-	PORT_ACCEPT_FRAMES_UNTAGGED = 0x02
-};
-
-enum
-{
-	PORT_ATTRIBUTE_USER         = 0x00,
-	PORT_ATTRIBUTE_STACK        = 0x01,
-	PORT_ATTRIBUTE_TRANSLATION  = 0x02,
-	PORT_ATTRIBUTE_TRANSPARENT  = 0x03
-};
-
-////////////////////////////////////////////////////////////////////////////////////
-
-typedef struct
-{
-	u8 bwan:1;
-	u8 rule:7;
-} bwan_member_t;
-
-typedef struct
-{
-	u16 pvid:12;
-	u16 prio:3;
-	u16 tagg:1;
-} pvlan_member_t;
-
-typedef struct
-{
-	u32 valid:1;
-	u32 fid:3;
-	u32 cvid:12;
-	u32 svid:12;
-	u32 unused1:4;
-	u32 port_member:8;
-	u32 port_untag:8;
-	u32 port_swap:8;
-	u32 unused2:8;
-} vlan_entry_t;
-
-////////////////////////////////////////////////////////////////////////////////////
-
-#if defined (CONFIG_MT7530_GSW)
-typedef struct esw_mib_counters_s
-{
-	uint64_t TxGoodOctets;
-	uint32_t TxUcastFrames;
-	uint32_t TxMcastFrames;
-	uint32_t TxBcastFrames;
-	uint32_t TxDropFrames;
-	uint32_t TxPauseFrames;
-	uint32_t TxCollision;
-	uint32_t TxCRCError;
-	uint64_t RxGoodOctets;
-	uint32_t RxUcastFrames;
-	uint32_t RxMcastFrames;
-	uint32_t RxBcastFrames;
-	uint32_t RxDropFrames;
-	uint32_t RxPauseFrames;
-	uint32_t RxFilterFrames;
-	uint32_t RxCRCError;
-	uint32_t RxAligmentError;
-} esw_mib_counters_t;
-#else
-typedef struct esw_mib_counters_s
-{
-	uint64_t TxGoodOctets;
-	uint32_t TxGoodFrames;
-	uint32_t TxBadOctets;
-	uint32_t TxBadFrames;
-	uint32_t TxDropFrames;
-	uint64_t RxGoodOctets;
-	uint32_t RxGoodFrames;
-	uint32_t RxBadOctets;
-	uint32_t RxBadFrames;
-	uint32_t RxDropFramesFilter;
-	uint32_t RxDropFramesErr;
-} esw_mib_counters_t;
-#endif
-
-////////////////////////////////////////////////////////////////////////////////////
-
-u32 get_ports_mask_lan(u32 include_cpu, int is_phy_id);
-void esw_igmp_flood_to_cpu(int flood_to_cpu);
-
-////////////////////////////////////////////////////////////////////////////////////
-
-#endif
-
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_eth_soc.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_eth_soc.h
deleted file mode 100644
index 336fc690a..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_eth_soc.h
+++ /dev/null
@@ -1,883 +0,0 @@
-/*   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation; version 2 of the License
- *
- *   This program is distributed in the hope that it will be useful,
- *   but WITHOUT ANY WARRANTY; without even the implied warranty of
- *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *   GNU General Public License for more details.
- *
- *   Copyright (C) 2009-2016 John Crispin <blogic@openwrt.org>
- *   Copyright (C) 2009-2016 Felix Fietkau <nbd@openwrt.org>
- *   Copyright (C) 2013-2016 Michael Lee <igvtee@gmail.com>
- */
-
-#ifndef MTK_ETH_H
-#define MTK_ETH_H
-
-#include <linux/dma-mapping.h>
-#include <linux/netdevice.h>
-#include <linux/of_net.h>
-#include <linux/u64_stats_sync.h>
-
-#define MTK_QDMA_PAGE_SIZE	2048
-#define	MTK_MAX_RX_LENGTH	1536
-#define MTK_TX_DMA_BUF_LEN	0x3fff
-#define MTK_DMA_SIZE		2048
-#define MTK_NAPI_WEIGHT		64
-#define MTK_MAC_COUNT		2
-#define MTK_RX_ETH_HLEN		(VLAN_ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN)
-#define MTK_RX_HLEN		(NET_SKB_PAD + MTK_RX_ETH_HLEN + NET_IP_ALIGN)
-#define MTK_DMA_DUMMY_DESC	0xffffffff
-#define MTK_DEFAULT_MSG_ENABLE	(NETIF_MSG_DRV | \
-				 NETIF_MSG_PROBE | \
-				 NETIF_MSG_LINK | \
-				 NETIF_MSG_TIMER | \
-				 NETIF_MSG_IFDOWN | \
-				 NETIF_MSG_IFUP | \
-				 NETIF_MSG_RX_ERR | \
-				 NETIF_MSG_TX_ERR)
-#define MTK_HW_FEATURES		(NETIF_F_IP_CSUM | \
-				 NETIF_F_RXCSUM | \
-				 NETIF_F_HW_VLAN_CTAG_TX | \
-				 NETIF_F_HW_VLAN_CTAG_RX | \
-				 NETIF_F_SG | NETIF_F_TSO | \
-				 NETIF_F_TSO6 | \
-				 NETIF_F_IPV6_CSUM)
-#define NEXT_RX_DESP_IDX(X, Y)	(((X) + 1) & ((Y) - 1))
-
-#define MTK_MAX_RX_RING_NUM	4
-#define MTK_HW_LRO_DMA_SIZE	8
-
-#define	MTK_MAX_LRO_RX_LENGTH		(4096 * 3)
-#define	MTK_MAX_LRO_IP_CNT		2
-#define	MTK_HW_LRO_TIMER_UNIT		1	/* 20 us */
-#define	MTK_HW_LRO_REFRESH_TIME		50000	/* 1 sec. */
-#define	MTK_HW_LRO_AGG_TIME		10	/* 200us */
-#define	MTK_HW_LRO_AGE_TIME		50	/* 1ms */
-#define	MTK_HW_LRO_MAX_AGG_CNT		64
-#define	MTK_HW_LRO_BW_THRE		3000
-#define	MTK_HW_LRO_REPLACE_DELTA	1000
-#define	MTK_HW_LRO_SDL_REMAIN_ROOM	1522
-
-/* Frame Engine Global Reset Register */
-#define MTK_RST_GL		0x04
-#define RST_GL_PSE		BIT(0)
-
-/* Frame Engine Interrupt Status Register */
-#define MTK_INT_STATUS2		0x08
-#define MTK_GDM1_AF		BIT(28)
-#define MTK_GDM2_AF		BIT(29)
-
-/* PDMA HW LRO Alter Flow Timer Register */
-#define MTK_PDMA_LRO_ALT_REFRESH_TIMER	0x1c
-
-/* Frame Engine Interrupt Grouping Register */
-#define MTK_FE_INT_GRP		0x20
-
-/* CDMP Ingress Control Register */
-#define MTK_CDMQ_IG_CTRL	0x1400
-#define MTK_CDMQ_STAG_EN	BIT(0)
-
-/* CDMP Ingress Control Register */
-#define MTK_CDMP_IG_CTRL       0x400
-#define MTK_CDMP_STAG_EN	BIT(0)
-
-/* CDMP Exgress Control Register */
-#define MTK_CDMP_EG_CTRL	0x404
-
-/* GDM Exgress Control Register */
-#define MTK_GDMA_FWD_CFG(x)	(0x500 + (x * 0x1000))
-#define MTK_GDMA_SPEC_TAG	BIT(24)
-#define MTK_GDMA_ICS_EN		BIT(22)
-#define MTK_GDMA_TCS_EN		BIT(21)
-#define MTK_GDMA_UCS_EN		BIT(20)
-#define MTK_GDMA_DROP_ALL       0x7777
-#define MTK_GDMA_PDMA_ALL       0x0
-
-/* Unicast Filter MAC Address Register - Low */
-#define MTK_GDMA_MAC_ADRL(x)	(0x508 + (x * 0x1000))
-
-/* Unicast Filter MAC Address Register - High */
-#define MTK_GDMA_MAC_ADRH(x)	(0x50C + (x * 0x1000))
-
-/* PDMA RX Base Pointer Register */
-#define MTK_PRX_BASE_PTR0	0x900
-#define MTK_PRX_BASE_PTR_CFG(x)	(MTK_PRX_BASE_PTR0 + (x * 0x10))
-
-/* PDMA RX Maximum Count Register */
-#define MTK_PRX_MAX_CNT0	0x904
-#define MTK_PRX_MAX_CNT_CFG(x)	(MTK_PRX_MAX_CNT0 + (x * 0x10))
-
-/* PDMA RX CPU Pointer Register */
-#define MTK_PRX_CRX_IDX0	0x908
-#define MTK_PRX_CRX_IDX_CFG(x)	(MTK_PRX_CRX_IDX0 + (x * 0x10))
-
-/* PDMA HW LRO Control Registers */
-#define MTK_PDMA_LRO_CTRL_DW0	0x980
-#define MTK_LRO_EN			BIT(0)
-#define MTK_L3_CKS_UPD_EN		BIT(7)
-#define MTK_LRO_ALT_PKT_CNT_MODE	BIT(21)
-#define MTK_LRO_RING_RELINQUISH_REQ	(0x7 << 26)
-#define MTK_LRO_RING_RELINQUISH_DONE	(0x7 << 29)
-
-#define MTK_PDMA_LRO_CTRL_DW1	0x984
-#define MTK_PDMA_LRO_CTRL_DW2	0x988
-#define MTK_PDMA_LRO_CTRL_DW3	0x98c
-#define MTK_ADMA_MODE		BIT(15)
-#define MTK_LRO_MIN_RXD_SDL	(MTK_HW_LRO_SDL_REMAIN_ROOM << 16)
-
-/* PDMA Global Configuration Register */
-#define MTK_PDMA_GLO_CFG	0xa04
-#define MTK_MULTI_EN		BIT(10)
-
-/* PDMA Reset Index Register */
-#define MTK_PDMA_RST_IDX	0xa08
-#define MTK_PST_DRX_IDX0	BIT(16)
-#define MTK_PST_DRX_IDX_CFG(x)	(MTK_PST_DRX_IDX0 << (x))
-
-/* PDMA Delay Interrupt Register */
-#define MTK_PDMA_DELAY_INT		0xa0c
-#define MTK_PDMA_DELAY_RX_EN		BIT(15)
-#define MTK_PDMA_DELAY_RX_PINT		4
-#define MTK_PDMA_DELAY_RX_PINT_SHIFT	8
-#define MTK_PDMA_DELAY_RX_PTIME		4
-#define MTK_PDMA_DELAY_RX_DELAY		\
-	(MTK_PDMA_DELAY_RX_EN | MTK_PDMA_DELAY_RX_PTIME | \
-	(MTK_PDMA_DELAY_RX_PINT << MTK_PDMA_DELAY_RX_PINT_SHIFT))
-
-/* PDMA Interrupt Status Register */
-#define MTK_PDMA_INT_STATUS	0xa20
-
-/* PDMA Interrupt Mask Register */
-#define MTK_PDMA_INT_MASK	0xa28
-
-/* PDMA HW LRO Alter Flow Delta Register */
-#define MTK_PDMA_LRO_ALT_SCORE_DELTA	0xa4c
-
-/* PDMA Interrupt grouping registers */
-#define MTK_PDMA_INT_GRP1	0xa50
-#define MTK_PDMA_INT_GRP2	0xa54
-
-/* PDMA HW LRO IP Setting Registers */
-#define MTK_LRO_RX_RING0_DIP_DW0	0xb04
-#define MTK_LRO_DIP_DW0_CFG(x)		(MTK_LRO_RX_RING0_DIP_DW0 + (x * 0x40))
-#define MTK_RING_MYIP_VLD		BIT(9)
-
-/* PDMA HW LRO Ring Control Registers */
-#define MTK_LRO_RX_RING0_CTRL_DW1	0xb28
-#define MTK_LRO_RX_RING0_CTRL_DW2	0xb2c
-#define MTK_LRO_RX_RING0_CTRL_DW3	0xb30
-#define MTK_LRO_CTRL_DW1_CFG(x)		(MTK_LRO_RX_RING0_CTRL_DW1 + (x * 0x40))
-#define MTK_LRO_CTRL_DW2_CFG(x)		(MTK_LRO_RX_RING0_CTRL_DW2 + (x * 0x40))
-#define MTK_LRO_CTRL_DW3_CFG(x)		(MTK_LRO_RX_RING0_CTRL_DW3 + (x * 0x40))
-#define MTK_RING_AGE_TIME_L		((MTK_HW_LRO_AGE_TIME & 0x3ff) << 22)
-#define MTK_RING_AGE_TIME_H		((MTK_HW_LRO_AGE_TIME >> 10) & 0x3f)
-#define MTK_RING_AUTO_LERAN_MODE	(3 << 6)
-#define MTK_RING_VLD			BIT(8)
-#define MTK_RING_MAX_AGG_TIME		((MTK_HW_LRO_AGG_TIME & 0xffff) << 10)
-#define MTK_RING_MAX_AGG_CNT_L		((MTK_HW_LRO_MAX_AGG_CNT & 0x3f) << 26)
-#define MTK_RING_MAX_AGG_CNT_H		((MTK_HW_LRO_MAX_AGG_CNT >> 6) & 0x3)
-
-/* QDMA TX Queue Configuration Registers */
-#define MTK_QTX_CFG(x)		(0x1800 + (x * 0x10))
-#define QDMA_RES_THRES		4
-
-/* QDMA TX Queue Scheduler Registers */
-#define MTK_QTX_SCH(x)		(0x1804 + (x * 0x10))
-
-/* QDMA RX Base Pointer Register */
-#define MTK_QRX_BASE_PTR0	0x1900
-
-/* QDMA RX Maximum Count Register */
-#define MTK_QRX_MAX_CNT0	0x1904
-
-/* QDMA RX CPU Pointer Register */
-#define MTK_QRX_CRX_IDX0	0x1908
-
-/* QDMA RX DMA Pointer Register */
-#define MTK_QRX_DRX_IDX0	0x190C
-
-/* QDMA Global Configuration Register */
-#define MTK_QDMA_GLO_CFG	0x1A04
-#define MTK_RX_2B_OFFSET	BIT(31)
-#define MTK_RX_BT_32DWORDS	(3 << 11)
-#define MTK_NDP_CO_PRO		BIT(10)
-#define MTK_TX_WB_DDONE		BIT(6)
-#define MTK_DMA_SIZE_16DWORDS	(2 << 4)
-#define MTK_RX_DMA_BUSY		BIT(3)
-#define MTK_TX_DMA_BUSY		BIT(1)
-#define MTK_RX_DMA_EN		BIT(2)
-#define MTK_TX_DMA_EN		BIT(0)
-#define MTK_DMA_BUSY_TIMEOUT	HZ
-
-/* QDMA Reset Index Register */
-#define MTK_QDMA_RST_IDX	0x1A08
-
-/* QDMA Delay Interrupt Register */
-#define MTK_QDMA_DELAY_INT	0x1A0C
-
-/* QDMA Flow Control Register */
-#define MTK_QDMA_FC_THRES	0x1A10
-#define FC_THRES_DROP_MODE	BIT(20)
-#define FC_THRES_DROP_EN	(7 << 16)
-#define FC_THRES_MIN		0x4444
-
-/* QDMA Interrupt Status Register */
-#define MTK_QMTK_INT_STATUS	0x1A18
-#define MTK_RX_DONE_DLY		BIT(30)
-#define MTK_RX_DONE_INT3	BIT(19)
-#define MTK_RX_DONE_INT2	BIT(18)
-#define MTK_RX_DONE_INT1	BIT(17)
-#define MTK_RX_DONE_INT0	BIT(16)
-#define MTK_TX_DONE_INT3	BIT(3)
-#define MTK_TX_DONE_INT2	BIT(2)
-#define MTK_TX_DONE_INT1	BIT(1)
-#define MTK_TX_DONE_INT0	BIT(0)
-#define MTK_RX_DONE_INT		MTK_RX_DONE_DLY
-#define MTK_TX_DONE_DLY         BIT(28)
-#define MTK_TX_DONE_INT         MTK_TX_DONE_DLY
-
-
-/* QDMA Interrupt grouping registers */
-#define MTK_QDMA_INT_GRP1	0x1a20
-#define MTK_QDMA_INT_GRP2	0x1a24
-#define MTK_RLS_DONE_INT	BIT(0)
-
-/* QDMA Interrupt Status Register */
-#define MTK_QDMA_INT_MASK	0x1A1C
-
-/* QDMA Interrupt Mask Register */
-#define MTK_QDMA_HRED2		0x1A44
-
-/* QDMA TX Forward CPU Pointer Register */
-#define MTK_QTX_CTX_PTR		0x1B00
-
-/* QDMA TX Forward DMA Pointer Register */
-#define MTK_QTX_DTX_PTR		0x1B04
-
-/* QDMA TX Release CPU Pointer Register */
-#define MTK_QTX_CRX_PTR		0x1B10
-
-/* QDMA TX Release DMA Pointer Register */
-#define MTK_QTX_DRX_PTR		0x1B14
-
-/* QDMA FQ Head Pointer Register */
-#define MTK_QDMA_FQ_HEAD	0x1B20
-
-/* QDMA FQ Head Pointer Register */
-#define MTK_QDMA_FQ_TAIL	0x1B24
-
-/* QDMA FQ Free Page Counter Register */
-#define MTK_QDMA_FQ_CNT		0x1B28
-
-/* QDMA FQ Free Page Buffer Length Register */
-#define MTK_QDMA_FQ_BLEN	0x1B2C
-
-/* GMA1 Received Good Byte Count Register */
-#define MTK_GDM1_TX_GBCNT	0x2400
-#define MTK_STAT_OFFSET		0x40
-
-/* QDMA TX NUM */
-#define MTK_QDMA_TX_NUM		16
-#define MTK_QDMA_TX_MASK	((MTK_QDMA_TX_NUM) - 1)
-#define QID_LOW_BITS(x)		((x) & 0xf)
-#define QID_HIGH_BITS(x)	((((x) >> 4) & 0x3) << 20)
-
-/* QDMA descriptor txd4 */
-#define TX_DMA_CHKSUM		(0x7 << 29)
-#define TX_DMA_TSO		BIT(28)
-#define TX_DMA_FPORT_SHIFT	25
-#define TX_DMA_FPORT_MASK	0x7
-#define TX_DMA_INS_VLAN		BIT(16)
-
-/* QDMA descriptor txd3 */
-#define TX_DMA_OWNER_CPU	BIT(31)
-#define TX_DMA_LS0		BIT(30)
-#define TX_DMA_PLEN0(_x)	(((_x) & MTK_TX_DMA_BUF_LEN) << 16)
-#define TX_DMA_SWC		BIT(14)
-#define TX_DMA_SDL(_x)		(((_x) & 0x3fff) << 16)
-
-/* QDMA descriptor rxd2 */
-#define RX_DMA_DONE		BIT(31)
-#define RX_DMA_PLEN0(_x)	(((_x) & 0x3fff) << 16)
-#define RX_DMA_GET_PLEN0(_x)	(((_x) >> 16) & 0x3fff)
-#define RX_DMA_VTAG             BIT(15)
-
-/* QDMA descriptor rxd3 */
-#define RX_DMA_VID(_x)		((_x) & VLAN_VID_MASK)
-#define RX_DMA_TCI(_x)		((_x) & (VLAN_PRIO_MASK | VLAN_VID_MASK))
-#define RX_DMA_VPID(_x)		(((_x) >> 16) & 0xffff)
-
-/* QDMA descriptor rxd4 */
-#define RX_DMA_L4_VALID		BIT(24)
-#define RX_DMA_FPORT_SHIFT	19
-#define RX_DMA_FPORT_MASK	0x7
-
-/* PHY Indirect Access Control registers */
-#define MTK_PHY_IAC		0x10004
-#define PHY_IAC_ACCESS		BIT(31)
-#define PHY_IAC_READ		BIT(19)
-#define PHY_IAC_WRITE		BIT(18)
-#define PHY_IAC_START		BIT(16)
-#define PHY_IAC_ADDR_SHIFT	20
-#define PHY_IAC_REG_SHIFT	25
-#define PHY_IAC_TIMEOUT		HZ
-
-#define MTK_MAC_MISC		0x1000c
-#define MTK_MUX_TO_ESW		BIT(0)
-
-/* Mac control registers */
-#define MTK_MAC_MCR(x)		(0x10100 + (x * 0x100))
-#define MAC_MCR_MAX_RX_1536	BIT(24)
-#define MAC_MCR_IPG_CFG		(BIT(18) | BIT(16))
-#define MAC_MCR_FORCE_MODE	BIT(15)
-#define MAC_MCR_TX_EN		BIT(14)
-#define MAC_MCR_RX_EN		BIT(13)
-#define MAC_MCR_BACKOFF_EN	BIT(9)
-#define MAC_MCR_BACKPR_EN	BIT(8)
-#define MAC_MCR_MDIO_EEE_1000T  BIT(7)
-#define MAC_MCR_MDIO_EEE_100TX  BIT(6)
-#define MAC_MCR_FORCE_RX_FC	BIT(5)
-#define MAC_MCR_FORCE_TX_FC	BIT(4)
-#define MAC_MCR_SPEED_1000	BIT(3)
-#define MAC_MCR_SPEED_100	BIT(2)
-#define MAC_MCR_FORCE_DPX	BIT(1)
-#define MAC_MCR_FORCE_LINK	BIT(0)
-#define MAC_MCR_FIXED_LINK	(MAC_MCR_MAX_RX_1536 | MAC_MCR_IPG_CFG | \
-				 MAC_MCR_FORCE_MODE | MAC_MCR_TX_EN | \
-				 MAC_MCR_RX_EN | MAC_MCR_BACKOFF_EN | \
-				 MAC_MCR_BACKPR_EN | MAC_MCR_FORCE_RX_FC | \
-				 MAC_MCR_FORCE_TX_FC | MAC_MCR_SPEED_1000 | \
-				 MAC_MCR_FORCE_DPX | MAC_MCR_FORCE_LINK)
-
-/* TRGMII RXC control register */
-#define TRGMII_RCK_CTRL		0x10300
-#define DQSI0(x)		((x << 0) & GENMASK(6, 0))
-#define DQSI1(x)		((x << 8) & GENMASK(14, 8))
-#define RXCTL_DMWTLAT(x)	((x << 16) & GENMASK(18, 16))
-#define RXC_DQSISEL		BIT(30)
-#define RCK_CTRL_RGMII_1000	(RXC_DQSISEL | RXCTL_DMWTLAT(2) | DQSI1(16))
-#define RCK_CTRL_RGMII_10_100	RXCTL_DMWTLAT(2)
-
-/* TRGMII RXC control register */
-#define TRGMII_TCK_CTRL		0x10340
-#define TXCTL_DMWTLAT(x)	((x << 16) & GENMASK(18, 16))
-#define TXC_INV			BIT(30)
-#define TCK_CTRL_RGMII_1000	TXCTL_DMWTLAT(2)
-#define TCK_CTRL_RGMII_10_100	(TXC_INV | TXCTL_DMWTLAT(2))
-
-/* TRGMII Interface mode register */
-#define INTF_MODE		0x10390
-#define TRGMII_INTF_DIS		BIT(0)
-#define TRGMII_MODE		BIT(1)
-#define TRGMII_CENTRAL_ALIGNED	BIT(2)
-#define INTF_MODE_RGMII_1000    (TRGMII_MODE | TRGMII_CENTRAL_ALIGNED)
-#define INTF_MODE_RGMII_10_100  0
-
-/* GPIO port control registers for GMAC 2*/
-#define GPIO_OD33_CTRL8		0x4c0
-#define GPIO_BIAS_CTRL		0xed0
-#define GPIO_DRV_SEL10		0xf00
-
-/* ethernet subsystem chip id register */
-#define ETHSYS_CHIPID0_3	0x0
-#define ETHSYS_CHIPID4_7	0x4
-#define MT7623_ETH		7623
-#define MT7622_ETH		7622
-
-/* ethernet system control register */
-#define ETHSYS_SYSCFG		0x10
-#define SYSCFG_DRAM_TYPE_DDR2	BIT(4)
-
-/* ethernet subsystem config register */
-#define ETHSYS_SYSCFG0		0x14
-#define SYSCFG0_GE_MASK		0x3
-#define SYSCFG0_GE_MODE(x, y)	(x << (12 + (y * 2)))
-#define SYSCFG0_SGMII_MASK	GENMASK(9, 8)
-#define SYSCFG0_SGMII_GMAC1	((2 << 8) & SYSCFG0_SGMII_MASK)
-#define SYSCFG0_SGMII_GMAC2	((3 << 8) & SYSCFG0_SGMII_MASK)
-#define SYSCFG0_SGMII_GMAC1_V2	BIT(9)
-#define SYSCFG0_SGMII_GMAC2_V2	BIT(8)
-
-/* ethernet subsystem clock register */
-#define ETHSYS_CLKCFG0		0x2c
-#define ETHSYS_TRGMII_CLK_SEL362_5	BIT(11)
-#define ETHSYS_TRGMII_MT7621_MASK	(BIT(5) | BIT(6))
-#define ETHSYS_TRGMII_MT7621_APLL	BIT(6)
-#define ETHSYS_TRGMII_MT7621_DDR_PLL	BIT(5)
-
-/* ethernet reset control register */
-#define ETHSYS_RSTCTRL		0x34
-#define RSTCTRL_FE		BIT(6)
-#define RSTCTRL_PPE		BIT(31)
-#define RSTCTRL_ETH		BIT(23)
-
-/* SGMII subsystem config registers */
-/* Register to auto-negotiation restart */
-#define SGMSYS_PCS_CONTROL_1	0x0
-#define SGMII_AN_RESTART	BIT(9)
-
-/* Register to programmable link timer, the unit in 2 * 8ns */
-#define SGMSYS_PCS_LINK_TIMER	0x18
-#define SGMII_LINK_TIMER_DEFAULT	(0x186a0 & GENMASK(19, 0))
-
-/* Register to control remote fault */
-#define SGMSYS_SGMII_MODE	0x20
-#define SGMII_REMOTE_FAULT_DIS	BIT(8)
-
-/* Register to power up QPHY */
-#define SGMSYS_QPHY_PWR_STATE_CTRL 0xe8
-#define	SGMII_PHYA_PWD		BIT(4)
-
-/* Infrasys subsystem config registers */
-#define INFRA_MISC2		0x70c
-#define CO_QPHY_SEL		BIT(0)
-#define GEPHY_MAC_SEL		BIT(1)
-
-/*MDIO control*/
-#define MII_MMD_ACC_CTL_REG             0x0d
-#define MII_MMD_ADDR_DATA_REG           0x0e
-#define MMD_OP_MODE_DATA BIT(14)
-
-struct mtk_rx_dma {
-	unsigned int rxd1;
-	unsigned int rxd2;
-	unsigned int rxd3;
-	unsigned int rxd4;
-} __packed __aligned(4);
-
-struct mtk_tx_dma {
-	unsigned int txd1;
-	unsigned int txd2;
-	unsigned int txd3;
-	unsigned int txd4;
-} __packed __aligned(4);
-
-struct mtk_eth;
-struct mtk_mac;
-
-/* struct mtk_hw_stats - the structure that holds the traffic statistics.
- * @stats_lock:		make sure that stats operations are atomic
- * @reg_offset:		the status register offset of the SoC
- * @syncp:		the refcount
- *
- * All of the supported SoCs have hardware counters for traffic statistics.
- * Whenever the status IRQ triggers we can read the latest stats from these
- * counters and store them in this struct.
- */
-struct mtk_hw_stats {
-	u64 tx_bytes;
-	u64 tx_packets;
-	u64 tx_skip;
-	u64 tx_collisions;
-	u64 rx_bytes;
-	u64 rx_packets;
-	u64 rx_overflow;
-	u64 rx_fcs_errors;
-	u64 rx_short_errors;
-	u64 rx_long_errors;
-	u64 rx_checksum_errors;
-	u64 rx_flow_control_packets;
-
-	spinlock_t		stats_lock;
-	u32			reg_offset;
-	struct u64_stats_sync	syncp;
-};
-
-enum mtk_tx_flags {
-	/* PDMA descriptor can point at 1-2 segments. This enum allows us to
-	 * track how memory was allocated so that it can be freed properly.
-	 */
-	MTK_TX_FLAGS_SINGLE0	= 0x01,
-	MTK_TX_FLAGS_PAGE0	= 0x02,
-
-	/* MTK_TX_FLAGS_FPORTx allows tracking which port the transmitted
-	 * SKB out instead of looking up through hardware TX descriptor.
-	 */
-	MTK_TX_FLAGS_FPORT0	= 0x04,
-	MTK_TX_FLAGS_FPORT1	= 0x08,
-};
-
-/* This enum allows us to identify how the clock is defined on the array of the
- * clock in the order
- */
-enum mtk_clks_map {
-	MTK_CLK_ETHIF,
-	MTK_CLK_SGMIITOP,
-	MTK_CLK_ESW,
-	MTK_CLK_GP0,
-	MTK_CLK_GP1,
-	MTK_CLK_GP2,
-	MTK_CLK_FE,
-	MTK_CLK_TRGPLL,
-	MTK_CLK_SGMII_TX_250M,
-	MTK_CLK_SGMII_RX_250M,
-	MTK_CLK_SGMII_CDR_REF,
-	MTK_CLK_SGMII_CDR_FB,
-	MTK_CLK_SGMII2_TX_250M,
-	MTK_CLK_SGMII2_RX_250M,
-	MTK_CLK_SGMII2_CDR_REF,
-	MTK_CLK_SGMII2_CDR_FB,
-	MTK_CLK_SGMII_CK,
-	MTK_CLK_ETH2PLL,
-	MTK_CLK_MAX
-};
-
-#define MT7623_CLKS_BITMAP	(BIT(MTK_CLK_ETHIF) | BIT(MTK_CLK_ESW) |  \
-				 BIT(MTK_CLK_GP1) | BIT(MTK_CLK_GP2) | \
-				 BIT(MTK_CLK_TRGPLL))
-#define MT7622_CLKS_BITMAP	(BIT(MTK_CLK_ETHIF) | BIT(MTK_CLK_ESW) |  \
-				 BIT(MTK_CLK_GP0) | BIT(MTK_CLK_GP1) | \
-				 BIT(MTK_CLK_GP2) | \
-				 BIT(MTK_CLK_SGMII_TX_250M) | \
-				 BIT(MTK_CLK_SGMII_RX_250M) | \
-				 BIT(MTK_CLK_SGMII_CDR_REF) | \
-				 BIT(MTK_CLK_SGMII_CDR_FB) | \
-				 BIT(MTK_CLK_SGMII_CK) | \
-				 BIT(MTK_CLK_ETH2PLL))
-#define LEOPARD_CLKS_BITMAP     (BIT(MTK_CLK_ETHIF) | BIT(MTK_CLK_ESW) |  \
-				BIT(MTK_CLK_GP0) | BIT(MTK_CLK_GP1) | \
-				BIT(MTK_CLK_GP2) | BIT(MTK_CLK_FE) | \
-				BIT(MTK_CLK_SGMII_TX_250M) | \
-				BIT(MTK_CLK_SGMII_RX_250M) | \
-				BIT(MTK_CLK_SGMII_CDR_REF) | \
-				BIT(MTK_CLK_SGMII_CDR_FB) | \
-				BIT(MTK_CLK_SGMII2_TX_250M) | \
-				BIT(MTK_CLK_SGMII2_RX_250M) | \
-				BIT(MTK_CLK_SGMII2_CDR_REF) | \
-				BIT(MTK_CLK_SGMII2_CDR_FB) | \
-				BIT(MTK_CLK_SGMII_CK) | \
-				BIT(MTK_CLK_ETH2PLL) | BIT(MTK_CLK_SGMIITOP))
-
-#define MT7621_CLKS_BITMAP 0
-
-enum mtk_dev_state {
-	MTK_HW_INIT,
-	MTK_RESETTING
-};
-
-/* struct mtk_tx_buf -	This struct holds the pointers to the memory pointed at
- *			by the TX descriptor	s
- * @skb:		The SKB pointer of the packet being sent
- * @dma_addr0:		The base addr of the first segment
- * @dma_len0:		The length of the first segment
- * @dma_addr1:		The base addr of the second segment
- * @dma_len1:		The length of the second segment
- */
-struct mtk_tx_buf {
-	struct sk_buff *skb;
-	u32 flags;
-	DEFINE_DMA_UNMAP_ADDR(dma_addr0);
-	DEFINE_DMA_UNMAP_LEN(dma_len0);
-	DEFINE_DMA_UNMAP_ADDR(dma_addr1);
-	DEFINE_DMA_UNMAP_LEN(dma_len1);
-};
-
-/* struct mtk_tx_ring -	This struct holds info describing a TX ring
- * @dma:		The descriptor ring
- * @buf:		The memory pointed at by the ring
- * @phys:		The physical addr of tx_buf
- * @next_free:		Pointer to the next free descriptor
- * @last_free:		Pointer to the last free descriptor
- * @thresh:		The threshold of minimum amount of free descriptors
- * @free_count:		QDMA uses a linked list. Track how many free descriptors
- *			are present
- */
-struct mtk_tx_ring {
-	struct mtk_tx_dma *dma;
-	struct mtk_tx_buf *buf;
-	dma_addr_t phys;
-	struct mtk_tx_dma *next_free;
-	struct mtk_tx_dma *last_free;
-	u16 thresh;
-	atomic_t free_count;
-};
-
-/* PDMA rx ring mode */
-enum mtk_rx_flags {
-	MTK_RX_FLAGS_NORMAL = 0,
-	MTK_RX_FLAGS_HWLRO,
-	MTK_RX_FLAGS_QDMA,
-};
-
-/* struct mtk_rx_ring -	This struct holds info describing a RX ring
- * @dma:		The descriptor ring
- * @data:		The memory pointed at by the ring
- * @phys:		The physical addr of rx_buf
- * @frag_size:		How big can each fragment be
- * @buf_size:		The size of each packet buffer
- * @calc_idx:		The current head of ring
- */
-struct mtk_rx_ring {
-	struct mtk_rx_dma *dma;
-	u8 **data;
-	dma_addr_t phys;
-	u16 frag_size;
-	u16 buf_size;
-	u16 dma_size;
-	bool calc_idx_update;
-	u16 calc_idx;
-	u32 crx_idx_reg;
-};
-
-enum mtk_eth_mux {
-	MTK_ETH_MUX_GDM1_TO_GMAC1_ESW,
-	MTK_ETH_MUX_GMAC2_GMAC0_TO_GEPHY,
-	MTK_ETH_MUX_U3_GMAC2_TO_QPHY,
-	MTK_ETH_MUX_GMAC1_GMAC2_TO_SGMII_RGMII,
-	MTK_ETH_MUX_GMAC12_TO_GEPHY_SGMII,
-	MTK_ETH_MUX_MAX,
-};
-
-enum mtk_eth_path {
-	MTK_ETH_PATH_GMAC1_RGMII,
-	MTK_ETH_PATH_GMAC1_TRGMII,
-	MTK_ETH_PATH_GMAC1_SGMII,
-	MTK_ETH_PATH_GMAC2_RGMII,
-	MTK_ETH_PATH_GMAC2_SGMII,
-	MTK_ETH_PATH_GMAC2_GEPHY,
-	MTK_ETH_PATH_GDM1_ESW,
-	MTK_ETH_PATH_MAX,
-};
-
-/* Capability for function group */
-#define MTK_RGMII			BIT(0)
-#define MTK_TRGMII			BIT(1)
-#define MTK_SGMII			BIT(2)
-#define MTK_ESW				BIT(3)
-#define MTK_GEPHY			BIT(4)
-#define MTK_MUX				BIT(5)
-#define MTK_INFRA			BIT(6)
-#define MTK_SHARED_SGMII		BIT(7)
-#define MTK_HWLRO			BIT(8)
-#define MTK_SHARED_INT			BIT(9)
-#define MTK_TRGMII_MT7621_CLK		BIT(10)
-
-/* Capability for features on SoCs */
-#define MTK_PATH_BIT(x)		BIT((x) + 10)
-
-#define MTK_GMAC1_RGMII		\
-	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC1_RGMII) | MTK_RGMII)
-
-#define MTK_GMAC1_TRGMII	\
-	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC1_TRGMII) | MTK_TRGMII)
-
-#define MTK_GMAC1_SGMII		\
-	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC1_SGMII) | MTK_SGMII)
-
-#define MTK_GMAC2_RGMII		\
-	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC2_RGMII) | MTK_RGMII)
-
-#define MTK_GMAC2_SGMII		\
-	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC2_SGMII) | MTK_SGMII)
-
-#define MTK_GMAC2_GEPHY		\
-	(MTK_PATH_BIT(MTK_ETH_PATH_GMAC2_GEPHY) | MTK_GEPHY)
-
-#define MTK_GDM1_ESW		\
-	(MTK_PATH_BIT(MTK_ETH_PATH_GDM1_ESW) | MTK_ESW)
-
-#define MTK_MUX_BIT(x)		BIT((x) + 20)
-
-/* Capability for MUXes present on SoCs */
-/* 0: GDM1 -> GMAC1, 1: GDM1 -> ESW */
-#define MTK_MUX_GDM1_TO_GMAC1_ESW	\
-	(MTK_MUX_BIT(MTK_ETH_MUX_GDM1_TO_GMAC1_ESW) | MTK_MUX)
-
-/* 0: GMAC2 -> GEPHY, 1: GMAC0 -> GePHY */
-#define MTK_MUX_GMAC2_GMAC0_TO_GEPHY	\
-	(MTK_MUX_BIT(MTK_ETH_MUX_GMAC2_GMAC0_TO_GEPHY) | MTK_MUX | MTK_INFRA)
-
-/* 0: U3 -> QPHY, 1: GMAC2 -> QPHY */
-#define MTK_MUX_U3_GMAC2_TO_QPHY	\
-	(MTK_MUX_BIT(MTK_ETH_MUX_U3_GMAC2_TO_QPHY) | MTK_MUX | MTK_INFRA)
-
-/* 2: GMAC1 -> SGMII, 3: GMAC2 -> SGMII */
-#define MTK_MUX_GMAC1_GMAC2_TO_SGMII_RGMII	\
-	(MTK_MUX_BIT(MTK_ETH_MUX_GMAC1_GMAC2_TO_SGMII_RGMII) | MTK_MUX | \
-	 MTK_SHARED_SGMII)
-
-/* 0: GMACx -> GEPHY, 1: GMACx -> SGMII where x is 1 or 2 */
-#define MTK_MUX_GMAC12_TO_GEPHY_SGMII	\
-	(MTK_MUX_BIT(MTK_ETH_MUX_GMAC12_TO_GEPHY_SGMII) | MTK_MUX)
-
-#define MTK_HAS_CAPS(caps, _x)		(((caps) & (_x)) == (_x))
-
-#define MT7622_CAPS  (MTK_GMAC1_RGMII | MTK_GMAC1_SGMII | MTK_GMAC2_RGMII | \
-		      MTK_GMAC2_SGMII | MTK_GDM1_ESW | \
-		      MTK_MUX_GDM1_TO_GMAC1_ESW | \
-		      MTK_MUX_GMAC1_GMAC2_TO_SGMII_RGMII)
-
-#define MT7623_CAPS  (MTK_GMAC1_RGMII | MTK_GMAC1_TRGMII | MTK_GMAC2_RGMII)
-
-#define LEOPARD_CAPS  (MTK_GMAC1_SGMII | MTK_GMAC2_SGMII | MTK_GMAC2_GEPHY | \
-		      MTK_GDM1_ESW | MTK_MUX_GDM1_TO_GMAC1_ESW | \
-		      MTK_MUX_GMAC2_GMAC0_TO_GEPHY | \
-		      MTK_MUX_U3_GMAC2_TO_QPHY | \
-		      MTK_MUX_GMAC12_TO_GEPHY_SGMII)
-
-#define MT7621_CAPS  (MTK_GMAC1_RGMII | MTK_GMAC1_TRGMII | MTK_GMAC2_RGMII | \
-		      MTK_SHARED_INT | MTK_TRGMII_MT7621_CLK)
-
-/* struct mtk_eth_data -	This is the structure holding all differences
- *				among various plaforms
- * @ana_rgc3:			The offset for register ANA_RGC3 related to
- *				sgmiisys syscon
- * @caps			Flags shown the extra capability for the SoC
- * @required_clks		Flags shown the bitmap for required clocks on
- *				the target SoC
- * @required_pctl		A bool value to show whether the SoC requires
- *				the extra setup for those pins used by GMAC.
- * @irq_num			total eth irq num support in target SoC
- */
-struct mtk_soc_data {
-	u32		ana_rgc3;
-	u32		caps;
-	u32		required_clks;
-	bool		required_pctl;
-	u32             irq_num;
-};
-
-/* currently no SoC has more than 2 macs */
-#define MTK_MAX_DEVS			2
-
-struct mtk_eth_debug {
-	struct dentry *root;
-};
-
-#define MTK_SGMII_PHYSPEED_AN		BIT(31)
-#define MTK_SGMII_PHYSPEED_MASK		GENMASK(2, 0)
-#define MTK_SGMII_PHYSPEED_1000		BIT(0)
-#define MTK_SGMII_PHYSPEED_2500		BIT(1)
-#define MTK_HAS_FLAGS(flags, _x)	(((flags) & (_x)) == (_x))
-
-/* struct mtk_sgmii -	This is the structure holding sgmii regmap and its
- *			characteristics
- * @regmap:		The register map pointing at the range used to setup
- *			SGMII modes
- * @flags:		The enum refers to which mode the sgmii wants to run on
- * @ana_rgc3:		The offset refers to register ANA_RGC3 related to regmap
- */
-
-struct mtk_sgmii {
-	struct regmap	*regmap[MTK_MAX_DEVS];
-	u32		flags[MTK_MAX_DEVS];
-	u32		ana_rgc3;
-};
-
-/* struct mtk_eth -	This is the main datasructure for holding the state
- *			of the driver
- * @dev:		The device pointer
- * @base:		The mapped register i/o base
- * @page_lock:		Make sure that register operations are atomic
- * @tx_irq__lock:	Make sure that IRQ register operations are atomic
- * @rx_irq__lock:	Make sure that IRQ register operations are atomic
- * @dummy_dev:		we run 2 netdevs on 1 physical DMA ring and need a
- *			dummy for NAPI to work
- * @netdev:		The netdev instances
- * @mac:		Each netdev is linked to a physical MAC
- * @irq:		The IRQ that we are using
- * @msg_enable:		Ethtool msg level
- * @ethsys:		The register map pointing at the range used to setup
- *			MII modes
- * @infra:		The register map pointing at the range used to setup
- *			SGMII and GePHY path
- * @pctl:		The register map pointing at the range used to setup
- *			GMAC port drive/slew values
- * @dma_refcnt:		track how many netdevs are using the DMA engine
- * @tx_ring:		Pointer to the memory holding info about the TX ring
- * @rx_ring:		Pointer to the memory holding info about the RX ring
- * @rx_ring_qdma:	Pointer to the memory holding info about the QDMA RX
- *			ring
- * @tx_napi:		The TX NAPI struct
- * @rx_napi:		The RX NAPI struct
- * @scratch_ring:	Newer SoCs need memory for a second HW managed TX ring
- * @phy_scratch_ring:	physical address of scratch_ring
- * @scratch_head:	The scratch memory that scratch_ring points to.
- * @clks:		clock array for all clocks required
- * @mii_bus:		If there is a bus we need to create an instance for it
- * @pending_work:	The workqueue used to reset the dma ring
- * @state:		Initialization and runtime state of the device
- * @soc:		Holding specific data among vaious SoCs
- * @debug:		Holding specific data for mtk_eth_dbg usage.
- */
-
-struct mtk_eth {
-	struct device			*dev;
-	void __iomem			*base;
-	spinlock_t			page_lock;
-	/* spin_lock for enable/disable tx irq critial section */
-	spinlock_t			tx_irq_lock;
-	/* spin_lock for enable/disable rx irq critial section */
-	spinlock_t			rx_irq_lock;
-	struct net_device		dummy_dev;
-	struct net_device		*netdev[MTK_MAX_DEVS];
-	struct mtk_mac			*mac[MTK_MAX_DEVS];
-	int				irq[3];
-	u32				msg_enable;
-	unsigned long			sysclk;
-	struct regmap			*ethsys;
-	struct regmap			*infra;
-	struct mtk_sgmii		*sgmii;
-	struct regmap			*pctl;
-	bool				hwlro;
-	atomic_t			dma_refcnt;
-	struct mtk_tx_ring		tx_ring;
-	struct mtk_rx_ring		rx_ring[MTK_MAX_RX_RING_NUM];
-	struct mtk_rx_ring		rx_ring_qdma;
-	struct napi_struct		tx_napi;
-	struct napi_struct		rx_napi;
-	struct mtk_tx_dma		*scratch_ring;
-	dma_addr_t			phy_scratch_ring;
-	void				*scratch_head;
-	struct clk			*clks[MTK_CLK_MAX];
-
-	struct mii_bus			*mii_bus;
-	struct work_struct		pending_work;
-	unsigned long			state;
-
-	const struct mtk_soc_data	*soc;
-	struct mtk_eth_debug		debug;
-};
-
-/* struct mtk_mac -	the structure that holds the info about the MACs of the
- *			SoC
- * @id:			The number of the MAC
- * @ge_mode:            Interface mode kept for setup restoring
- * @of_node:		Our devicetree node
- * @hw:			Backpointer to our main datastruture
- * @hw_stats:		Packet statistics counter
- * @trgmii		Indicate if the MAC uses TRGMII connected to internal
-			switch
- * @phy_dev:		The attached PHY if available
- */
-struct mtk_mac {
-	int				id;
-	int				ge_mode;
-	struct device_node		*of_node;
-	struct mtk_eth			*hw;
-	struct mtk_hw_stats		*hw_stats;
-	__be32				hwlro_ip[MTK_MAX_LRO_IP_CNT];
-	int				hwlro_ip_cnt;
-	bool				trgmii;
-	struct phy_device		*phy_dev;
-	phy_interface_t			phymode;
-};
-
-/* the struct describing the SoC. these are declared in the soc_xyz.c files */
-extern const struct of_device_id of_mtk_match[];
-
-/* read the hardware status register */
-void mtk_stats_update_mac(struct mtk_mac *mac);
-
-void mtk_w32(struct mtk_eth *eth, u32 val, unsigned reg);
-u32 mtk_r32(struct mtk_eth *eth, unsigned reg);
-
-int mtk_sgmii_init(struct mtk_sgmii *ss, struct device_node *np,
-		   u32 ana_rgc3);
-int mtk_sgmii_setup_mode_an(struct mtk_sgmii *ss, int id);
-int mtk_sgmii_setup_mode_force(struct mtk_sgmii *ss, int id);
-int mtk_setup_hw_path(struct mtk_eth *eth, int mac_id, int phymode);
-
-#endif /* MTK_ETH_H */
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/Makefile b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/Makefile
deleted file mode 100644
index 1bbd891b9..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/Makefile
+++ /dev/null
@@ -1,4 +0,0 @@
-ccflags-y=-Werror
-
-obj-m         += hw_nat.o
-hw_nat-objs := hnat.o hnat_nf_hook.o hnat_debugfs.o hnat_mcast.o
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat.c
deleted file mode 100644
index 7104a2133..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat.c
+++ /dev/null
@@ -1,641 +0,0 @@
-/*   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation; version 2 of the License
- *
- *   This program is distributed in the hope that it will be useful,
- *   but WITHOUT ANY WARRANTY; without even the implied warranty of
- *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *   GNU General Public License for more details.
- *
- *   Copyright (C) 2014-2016 Sean Wang <sean.wang@mediatek.com>
- *   Copyright (C) 2016-2017 John Crispin <blogic@openwrt.org>
- */
-
-#include <linux/dma-mapping.h>
-#include <linux/delay.h>
-#include <linux/if.h>
-#include <linux/io.h>
-#include <linux/module.h>
-#include <linux/of_device.h>
-#include <linux/platform_device.h>
-#include <linux/reset.h>
-
-#include "nf_hnat_mtk.h"
-#include "hnat.h"
-
-struct mtk_hnat *hnat_priv;
-
-int (*ra_sw_nat_hook_rx)(struct sk_buff *skb) = NULL;
-EXPORT_SYMBOL(ra_sw_nat_hook_rx);
-int (*ra_sw_nat_hook_tx)(struct sk_buff *skb, int gmac_no) = NULL;
-EXPORT_SYMBOL(ra_sw_nat_hook_tx);
-
-void (*ppe_dev_register_hook)(struct net_device *dev) = NULL;
-EXPORT_SYMBOL(ppe_dev_register_hook);
-void (*ppe_dev_unregister_hook)(struct net_device *dev) = NULL;
-EXPORT_SYMBOL(ppe_dev_unregister_hook);
-
-static void hnat_sma_build_entry(unsigned long data)
-{
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SMA, SMA_FWD_CPU_BUILD_ENTRY);
-}
-
-void hnat_cache_ebl(int enable)
-{
-	cr_set_field(hnat_priv->ppe_base + PPE_CAH_CTRL, CAH_X_MODE, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_CAH_CTRL, CAH_X_MODE, 0);
-	cr_set_field(hnat_priv->ppe_base + PPE_CAH_CTRL, CAH_EN, enable);
-}
-
-static void hnat_reset_timestamp(unsigned long data)
-{
-	struct foe_entry *entry;
-	int hash_index;
-
-	hnat_cache_ebl(0);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, TCP_AGE, 0);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, UDP_AGE, 0);
-	writel(0, hnat_priv->fe_base + 0x0010);
-
-	for (hash_index = 0; hash_index < hnat_priv->foe_etry_num; hash_index++) {
-		entry = hnat_priv->foe_table_cpu + hash_index;
-		if (entry->bfib1.state == BIND)
-			entry->bfib1.time_stamp =
-				readl(hnat_priv->fe_base + 0x0010) & (0xFFFF);
-	}
-
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, TCP_AGE, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, UDP_AGE, 1);
-	hnat_cache_ebl(1);
-
-	mod_timer(&hnat_priv->hnat_reset_timestamp_timer, jiffies + 14400 * HZ);
-}
-
-static void cr_set_bits(void __iomem *reg, u32 bs)
-{
-	u32 val = readl(reg);
-
-	val |= bs;
-	writel(val, reg);
-}
-
-static void cr_clr_bits(void __iomem *reg, u32 bs)
-{
-	u32 val = readl(reg);
-
-	val &= ~bs;
-	writel(val, reg);
-}
-
-void cr_set_field(void __iomem *reg, u32 field, u32 val)
-{
-	unsigned int tv = readl(reg);
-
-	tv &= ~field;
-	tv |= ((val) << (ffs((unsigned int)field) - 1));
-	writel(tv, reg);
-}
-
-/*boundary entry can't be used to accelerate data flow*/
-static void exclude_boundary_entry(struct foe_entry *foe_table_cpu)
-{
-	int entry_base = 0;
-	int bad_entry, i, j;
-	struct foe_entry *foe_entry;
-	/*these entries are boundary every 128 entries*/
-	int boundary_entry_offset[8] = { 12, 25, 38, 51, 76, 89, 102, 115};
-
-	if (!foe_table_cpu)
-		return;
-
-	for (i = 0; entry_base < hnat_priv->foe_etry_num; i++) {
-		/* set boundary entries as static*/
-		for (j = 0; j < 8; j++) {
-			bad_entry = entry_base + boundary_entry_offset[j];
-			foe_entry = &foe_table_cpu[bad_entry];
-			foe_entry->udib1.sta = 1;
-		}
-		entry_base = (i + 1) * 128;
-	}
-}
-
-void set_gmac_ppe_fwd(int id, int enable)
-{
-	void __iomem *reg;
-	u32 val;
-
-	reg = hnat_priv->fe_base + (id ? GDMA2_FWD_CFG : GDMA1_FWD_CFG);
-
-	if (enable) {
-		cr_set_bits(reg, BITS_GDM_ALL_FRC_P_PPE);
-
-		return;
-	}
-
-	/*disabled */
-	val = readl(reg);
-	if ((val & GDM_ALL_FRC_MASK) == BITS_GDM_ALL_FRC_P_PPE)
-		cr_set_field(reg, GDM_ALL_FRC_MASK,
-			     BITS_GDM_ALL_FRC_P_CPU_PDMA);
-}
-
-static int hnat_start(void)
-{
-	u32 foe_table_sz;
-	u32 foe_mib_tb_sz;
-	int etry_num_cfg;
-
-	/* mapp the FOE table */
-	for (etry_num_cfg = DEF_ETRY_NUM_CFG ; etry_num_cfg >= 0 ; etry_num_cfg--, hnat_priv->foe_etry_num /= 2) {
-		foe_table_sz = hnat_priv->foe_etry_num * sizeof(struct foe_entry);
-		hnat_priv->foe_table_cpu = dma_alloc_coherent(
-			hnat_priv->dev, foe_table_sz, &hnat_priv->foe_table_dev, GFP_KERNEL);
-
-		if (hnat_priv->foe_table_cpu)
-			break;
-	}
-
-	if (!hnat_priv->foe_table_cpu)
-		return -1;
-	dev_info(hnat_priv->dev, "FOE entry number = %d\n", hnat_priv->foe_etry_num);
-
-	writel(hnat_priv->foe_table_dev, hnat_priv->ppe_base + PPE_TB_BASE);
-	memset(hnat_priv->foe_table_cpu, 0, foe_table_sz);
-
-	if (hnat_priv->data->version == MTK_HNAT_V1)
-		exclude_boundary_entry(hnat_priv->foe_table_cpu);
-
-	if (hnat_priv->data->per_flow_accounting) {
-		foe_mib_tb_sz = hnat_priv->foe_etry_num * sizeof(struct mib_entry);
-		hnat_priv->foe_mib_cpu = dma_alloc_coherent(hnat_priv->dev, foe_mib_tb_sz,
-						       &hnat_priv->foe_mib_dev, GFP_KERNEL);
-		if (!hnat_priv->foe_mib_cpu)
-			return -1;
-		writel(hnat_priv->foe_mib_dev, hnat_priv->ppe_base + PPE_MIB_TB_BASE);
-		memset(hnat_priv->foe_mib_cpu, 0, foe_mib_tb_sz);
-
-		hnat_priv->acct =
-			kzalloc(hnat_priv->foe_etry_num * sizeof(struct hnat_accounting),
-				GFP_KERNEL);
-		if (!hnat_priv->acct)
-			return -1;
-	}
-	/* setup hashing */
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, TB_ETRY_NUM, etry_num_cfg);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, HASH_MODE, HASH_MODE_1);
-	writel(HASH_SEED_KEY, hnat_priv->ppe_base + PPE_HASH_SEED);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, XMODE, 0);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, TB_ENTRY_SIZE, ENTRY_80B);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SMA, SMA_FWD_CPU_BUILD_ENTRY);
-
-	/* set ip proto */
-	writel(0xFFFFFFFF, hnat_priv->ppe_base + PPE_IP_PROT_CHK);
-
-	/* setup caching */
-	hnat_cache_ebl(1);
-
-	/* enable FOE */
-	cr_set_bits(hnat_priv->ppe_base + PPE_FLOW_CFG,
-		    BIT_UDP_IP4F_NAT_EN | BIT_IPV4_NAT_EN | BIT_IPV4_NAPT_EN |
-		    BIT_IPV4_NAT_FRAG_EN | BIT_IPV4_HASH_GREK |
-		    BIT_IPV4_DSL_EN | BIT_IPV6_6RD_EN |
-		    BIT_IPV6_3T_ROUTE_EN | BIT_IPV6_5T_ROUTE_EN);
-
-	/* setup FOE aging */
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, NTU_AGE, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, UNBD_AGE, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_UNB_AGE, UNB_MNP, 1000);
-	cr_set_field(hnat_priv->ppe_base + PPE_UNB_AGE, UNB_DLTA, 3);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, TCP_AGE, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, UDP_AGE, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, FIN_AGE, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_BND_AGE_0, UDP_DLTA, 12);
-	cr_set_field(hnat_priv->ppe_base + PPE_BND_AGE_0, NTU_DLTA, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_BND_AGE_1, FIN_DLTA, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_BND_AGE_1, TCP_DLTA, 7);
-
-	/* setup FOE ka */
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SCAN_MODE, 2);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, KA_CFG, 3);
-	cr_set_field(hnat_priv->ppe_base + PPE_KA, KA_T, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_KA, TCP_KA, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_KA, UDP_KA, 1);
-	cr_set_field(hnat_priv->ppe_base + PPE_BIND_LMT_1, NTU_KA, 1);
-
-	/* setup FOE rate limit */
-	cr_set_field(hnat_priv->ppe_base + PPE_BIND_LMT_0, QURT_LMT, 16383);
-	cr_set_field(hnat_priv->ppe_base + PPE_BIND_LMT_0, HALF_LMT, 16383);
-	cr_set_field(hnat_priv->ppe_base + PPE_BIND_LMT_1, FULL_LMT, 16383);
-	/* setup binding threshold as 30 packets per second */
-	cr_set_field(hnat_priv->ppe_base + PPE_BNDR, BIND_RATE, 0x1E);
-
-	/* setup FOE cf gen */
-	cr_set_field(hnat_priv->ppe_base + PPE_GLO_CFG, PPE_EN, 1);
-	writel(0, hnat_priv->ppe_base + PPE_DFT_CPORT); /* pdma */
-	/* writel(0x55555555, hnat_priv->ppe_base + PPE_DFT_CPORT); */ /* qdma */
-	cr_set_field(hnat_priv->ppe_base + PPE_GLO_CFG, TTL0_DRP, 0);
-
-	/*enable ppe mib counter*/
-	if (hnat_priv->data->per_flow_accounting) {
-		cr_set_field(hnat_priv->ppe_base + PPE_MIB_CFG, MIB_EN, 1);
-		cr_set_field(hnat_priv->ppe_base + PPE_MIB_CFG, MIB_READ_CLEAR, 1);
-		cr_set_field(hnat_priv->ppe_base + PPE_MIB_CAH_CTRL, MIB_CAH_EN, 1);
-	}
-
-	hnat_priv->g_ppdev = dev_get_by_name(&init_net, hnat_priv->ppd);
-
-	dev_info(hnat_priv->dev, "hwnat start\n");
-
-	return 0;
-}
-
-static int ppe_busy_wait(void)
-{
-	unsigned long t_start = jiffies;
-	u32 r = 0;
-
-	while (1) {
-		r = readl((hnat_priv->ppe_base + 0x0));
-		if (!(r & BIT(31)))
-			return 0;
-		if (time_after(jiffies, t_start + HZ))
-			break;
-		usleep_range(10, 20);
-	}
-
-	dev_notice(hnat_priv->dev, "ppe:%s timeout\n", __func__);
-
-	return -1;
-}
-
-static void hnat_stop(void)
-{
-	u32 foe_table_sz;
-	u32 foe_mib_tb_sz;
-	struct foe_entry *entry, *end;
-	u32 r1 = 0, r2 = 0;
-
-	/* send all traffic back to the DMA engine */
-	set_gmac_ppe_fwd(0, 0);
-	set_gmac_ppe_fwd(1, 0);
-
-	dev_info(hnat_priv->dev, "hwnat stop\n");
-
-	if (hnat_priv->foe_table_cpu) {
-		entry = hnat_priv->foe_table_cpu;
-		end = hnat_priv->foe_table_cpu + hnat_priv->foe_etry_num;
-		while (entry < end) {
-			entry->bfib1.state = INVALID;
-			entry++;
-		}
-	}
-	/* disable caching */
-	hnat_cache_ebl(0);
-
-	/* flush cache has to be ahead of hnat disable --*/
-	cr_set_field(hnat_priv->ppe_base + PPE_GLO_CFG, PPE_EN, 0);
-
-	/* disable scan mode and keep-alive */
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SCAN_MODE, 0);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, KA_CFG, 0);
-
-	ppe_busy_wait();
-
-	/* disable FOE */
-	cr_clr_bits(hnat_priv->ppe_base + PPE_FLOW_CFG,
-		    BIT_IPV4_NAPT_EN | BIT_IPV4_NAT_EN | BIT_IPV4_NAT_FRAG_EN |
-		    BIT_IPV6_HASH_GREK | BIT_IPV4_DSL_EN |
-		    BIT_IPV6_6RD_EN | BIT_IPV6_3T_ROUTE_EN |
-		    BIT_IPV6_5T_ROUTE_EN | BIT_FUC_FOE | BIT_FMC_FOE |
-		    BIT_FUC_FOE);
-
-	/* disable FOE aging */
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, NTU_AGE, 0);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, UNBD_AGE, 0);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, TCP_AGE, 0);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, UDP_AGE, 0);
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, FIN_AGE, 0);
-
-	r1 = readl(hnat_priv->fe_base + 0x100);
-	r2 = readl(hnat_priv->fe_base + 0x10c);
-
-	dev_info(hnat_priv->dev, "0x100 = 0x%x, 0x10c = 0x%x\n", r1, r2);
-
-	if (((r1 & 0xff00) >> 0x8) >= (r1 & 0xff) ||
-	    ((r1 & 0xff00) >> 0x8) >= (r2 & 0xff)) {
-		dev_info(hnat_priv->dev, "reset pse\n");
-		writel(0x1, hnat_priv->fe_base + 0x4);
-	}
-
-	/* free the FOE table */
-	foe_table_sz = hnat_priv->foe_etry_num * sizeof(struct foe_entry);
-	if (hnat_priv->foe_table_cpu)
-		dma_free_coherent(hnat_priv->dev, foe_table_sz, hnat_priv->foe_table_cpu,
-				  hnat_priv->foe_table_dev);
-	writel(0, hnat_priv->ppe_base + PPE_TB_BASE);
-
-	if (hnat_priv->data->per_flow_accounting) {
-		foe_mib_tb_sz = hnat_priv->foe_etry_num * sizeof(struct mib_entry);
-		if (hnat_priv->foe_mib_cpu)
-			dma_free_coherent(hnat_priv->dev, foe_mib_tb_sz,
-					  hnat_priv->foe_mib_cpu, hnat_priv->foe_mib_dev);
-		writel(0, hnat_priv->ppe_base + PPE_MIB_TB_BASE);
-		kfree(hnat_priv->acct);
-	}
-}
-
-static void hnat_release_netdev(void)
-{
-	int i;
-	struct extdev_entry *ext_entry;
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		if (ext_entry->dev)
-			dev_put(ext_entry->dev);
-		ext_if_del(ext_entry);
-		kfree(ext_entry);
-	}
-
-	if (hnat_priv->g_ppdev)
-		dev_put(hnat_priv->g_ppdev);
-}
-
-static struct notifier_block nf_hnat_netdevice_nb __read_mostly = {
-	.notifier_call = nf_hnat_netdevice_event,
-};
-
-static struct notifier_block nf_hnat_netevent_nb __read_mostly = {
-	.notifier_call = nf_hnat_netevent_handler,
-};
-
-int hnat_enable_hook(void)
-{
-	/* register hook functions used by WHNAT module.
-	 */
-	if (hnat_priv->data->version == MTK_HNAT_V2) {
-		ra_sw_nat_hook_tx = mtk_sw_nat_hook_tx;
-		ra_sw_nat_hook_rx = NULL;
-		ppe_dev_register_hook = mtk_ppe_dev_register_hook;
-		ppe_dev_unregister_hook = mtk_ppe_dev_unregister_hook;
-	}
-
-	if (hnat_register_nf_hooks())
-		return -1;
-
-	hook_toggle = 1;
-
-	return 0;
-}
-
-int hnat_disable_hook(void)
-{
-	int hash_index;
-	struct foe_entry *entry;
-
-	ra_sw_nat_hook_tx = NULL;
-	hnat_unregister_nf_hooks();
-
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SMA, SMA_ONLY_FWD_CPU);
-	for (hash_index = 0; hash_index < hnat_priv->foe_etry_num; hash_index++) {
-		entry = hnat_priv->foe_table_cpu + hash_index;
-		if (entry->bfib1.state == BIND) {
-			entry->ipv4_hnapt.udib1.state = INVALID;
-			entry->ipv4_hnapt.udib1.time_stamp =
-				readl((hnat_priv->fe_base + 0x0010)) & 0xFF;
-		}
-	}
-
-	/* clear HWNAT cache */
-	hnat_cache_ebl(1);
-
-	mod_timer(&hnat_priv->hnat_sma_build_entry_timer, jiffies + 3 * HZ);
-	hook_toggle = 0;
-
-	return 0;
-}
-
-#if (1)
-static struct packet_type mtk_pack_type __read_mostly = {
-	.type   = HQOS_MAGIC_TAG,
-	.func   = mtk_hqos_ptype_cb,
-};
-#endif
-
-static int hnat_probe(struct platform_device *pdev)
-{
-	int i;
-	int err = 0;
-	int index = 0;
-	struct resource *res;
-	const char *name;
-	struct device_node *np;
-	unsigned int val;
-	struct property *prop;
-	struct extdev_entry *ext_entry;
-	const struct of_device_id *match;
-
-	hnat_priv = devm_kzalloc(&pdev->dev, sizeof(struct mtk_hnat), GFP_KERNEL);
-	if (!hnat_priv)
-		return -ENOMEM;
-
-	hnat_priv->foe_etry_num = DEF_ETRY_NUM;
-
-	match = of_match_device(of_hnat_match, &pdev->dev);
-	hnat_priv->data = (struct mtk_hnat_data *)match->data;
-
-	hnat_priv->dev = &pdev->dev;
-	np = hnat_priv->dev->of_node;
-
-	err = of_property_read_string(np, "mtketh-wan", &name);
-	if (err < 0)
-		return -EINVAL;
-
-	strncpy(hnat_priv->wan, (char *)name, IFNAMSIZ);
-	dev_info(&pdev->dev, "wan = %s\n", hnat_priv->wan);
-
-	err = of_property_read_string(np, "mtketh-lan", &name);
-	if (err < 0)
-		strncpy(hnat_priv->lan, "eth2", IFNAMSIZ);
-	else
-		strncpy(hnat_priv->lan, (char *)name, IFNAMSIZ);
-	dev_info(&pdev->dev, "lan = %s\n", hnat_priv->lan);
-
-	err = of_property_read_string(np, "mtketh-ppd", &name);
-	if (err < 0)
-		strncpy(hnat_priv->ppd, "eth2", IFNAMSIZ);
-	else
-		strncpy(hnat_priv->ppd, (char *)name, IFNAMSIZ);
-	dev_info(&pdev->dev, "ppd = %s\n", hnat_priv->ppd);
-
-	/*get total gmac num in hnat*/
-	err = of_property_read_u32_index(np, "mtketh-max-gmac", 0, &val);
-
-	if (err < 0)
-		return -EINVAL;
-
-	hnat_priv->gmac_num = val;
-
-	dev_info(&pdev->dev, "gmac num = %d\n", hnat_priv->gmac_num);
-
-	err = of_property_read_u32_index(np, "mtkdsa-wan-port", 0, &val);
-
-	if (err < 0) {
-		hnat_priv->wan_dsa_port = NONE_DSA_PORT;
-	} else {
-		hnat_priv->wan_dsa_port = val;
-		dev_info(&pdev->dev, "wan dsa port = %d\n", hnat_priv->wan_dsa_port);
-	}
-
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	if (!res)
-		return -ENOENT;
-
-	hnat_priv->fe_base = devm_ioremap_nocache(&pdev->dev, res->start,
-					     res->end - res->start + 1);
-	if (!hnat_priv->fe_base)
-		return -EADDRNOTAVAIL;
-
-	hnat_priv->ppe_base = hnat_priv->fe_base + 0xe00;
-	err = hnat_init_debugfs(hnat_priv);
-	if (err)
-		return err;
-
-	prop = of_find_property(np, "ext-devices", NULL);
-	for (name = of_prop_next_string(prop, NULL); name;
-	     name = of_prop_next_string(prop, name), index++) {
-		ext_entry = kzalloc(sizeof(*ext_entry), GFP_KERNEL);
-		if (!ext_entry) {
-			err = -ENOMEM;
-			goto err_out1;
-		}
-		strncpy(ext_entry->name, (char *)name, IFNAMSIZ);
-		ext_if_add(ext_entry);
-	}
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		dev_info(&pdev->dev, "ext devices = %s\n", ext_entry->name);
-	}
-
-	hnat_priv->lvid = 1;
-	hnat_priv->wvid = 2;
-
-	err = hnat_start();
-	if (err)
-		goto err_out;
-
-	if (hnat_priv->data->whnat) {
-		err = whnat_adjust_nf_hooks();
-		if (err)
-			goto err_out;
-	}
-
-	err = hnat_enable_hook();
-	if (err)
-		goto err_out;
-
-	register_netdevice_notifier(&nf_hnat_netdevice_nb);
-	register_netevent_notifier(&nf_hnat_netevent_nb);
-	if (hnat_priv->data->mcast)
-		hnat_mcast_enable();
-	init_timer(&hnat_priv->hnat_sma_build_entry_timer);
-	hnat_priv->hnat_sma_build_entry_timer.function = hnat_sma_build_entry;
-	if (hnat_priv->data->version == MTK_HNAT_V3) {
-		init_timer(&hnat_priv->hnat_reset_timestamp_timer);
-		hnat_priv->hnat_reset_timestamp_timer.function = hnat_reset_timestamp;
-		hnat_priv->hnat_reset_timestamp_timer.expires = jiffies;
-		add_timer(&hnat_priv->hnat_reset_timestamp_timer);
-	}
-
-#if (1)
-	if (IS_GMAC1_MODE)
-		dev_add_pack(&mtk_pack_type);
-#endif
-
-	return 0;
-
-err_out:
-	hnat_stop();
-err_out1:
-	hnat_deinit_debugfs(hnat_priv);
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		ext_if_del(ext_entry);
-		kfree(ext_entry);
-	}
-	return err;
-}
-
-static int hnat_remove(struct platform_device *pdev)
-{
-	unregister_netdevice_notifier(&nf_hnat_netdevice_nb);
-	unregister_netevent_notifier(&nf_hnat_netevent_nb);
-	hnat_disable_hook();
-
-	if (hnat_priv->data->mcast)
-		hnat_mcast_disable();
-
-	hnat_stop();
-	hnat_deinit_debugfs(hnat_priv);
-	hnat_release_netdev();
-	del_timer_sync(&hnat_priv->hnat_sma_build_entry_timer);
-	if (hnat_priv->data->version == MTK_HNAT_V3)
-		del_timer_sync(&hnat_priv->hnat_reset_timestamp_timer);
-
-#if (1)
-	if (IS_GMAC1_MODE)
-		dev_remove_pack(&mtk_pack_type);
-#endif
-
-	return 0;
-}
-
-static const struct mtk_hnat_data hnat_data_v1 = {
-	.num_of_sch = 2,
-	.whnat = false,
-	.per_flow_accounting = false,
-	.mcast = false,
-	.version = MTK_HNAT_V1,
-};
-
-static const struct mtk_hnat_data hnat_data_v2 = {
-	.num_of_sch = 2,
-	.whnat = true,
-	.per_flow_accounting = true,
-	.mcast = false,
-	.version = MTK_HNAT_V2,
-};
-
-static const struct mtk_hnat_data hnat_data_v3 = {
-	.num_of_sch = 4,
-	.whnat = false,
-	.per_flow_accounting = false,
-	.mcast = false,
-	.version = MTK_HNAT_V3,
-};
-
-const struct of_device_id of_hnat_match[] = {
-	{ .compatible = "mediatek,mtk-hnat", .data = &hnat_data_v3 },
-	{ .compatible = "mediatek,mtk-hnat_v1", .data = &hnat_data_v1 },
-	{ .compatible = "mediatek,mtk-hnat_v2", .data = &hnat_data_v2 },
-	{ .compatible = "mediatek,mtk-hnat_v3", .data = &hnat_data_v3 },
-	{},
-};
-MODULE_DEVICE_TABLE(of, of_hnat_match);
-
-static struct platform_driver hnat_driver = {
-	.probe = hnat_probe,
-	.remove = hnat_remove,
-	.driver = {
-		.name = "mediatek_soc_hnat",
-		.of_match_table = of_hnat_match,
-	},
-};
-
-module_platform_driver(hnat_driver);
-
-MODULE_LICENSE("GPL v2");
-MODULE_AUTHOR("Sean Wang <sean.wang@mediatek.com>");
-MODULE_AUTHOR("John Crispin <john@phrozen.org>");
-MODULE_DESCRIPTION("Mediatek Hardware NAT");
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat.h
deleted file mode 100644
index af9934bd0..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat.h
+++ /dev/null
@@ -1,814 +0,0 @@
-/*   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation; version 2 of the License
- *
- *   This program is distributed in the hope that it will be useful,
- *   but WITHOUT ANY WARRANTY; without even the implied warranty of
- *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *   GNU General Public License for more details.
- *
- *   Copyright (C) 2014-2016 Sean Wang <sean.wang@mediatek.com>
- *   Copyright (C) 2016-2017 John Crispin <blogic@openwrt.org>
- */
-
-#include <linux/debugfs.h>
-#include <linux/string.h>
-#include <linux/if.h>
-#include <linux/if_ether.h>
-#include <net/netevent.h>
-#include <net/netfilter/nf_hnat.h>
-#include "hnat_mcast.h"
-
-/*--------------------------------------------------------------------------*/
-/* Register Offset*/
-/*--------------------------------------------------------------------------*/
-#define PPE_GLO_CFG 0x00
-#define PPE_FLOW_CFG 0x04
-#define PPE_IP_PROT_CHK 0x08
-#define PPE_IP_PROT_0 0x0C
-#define PPE_IP_PROT_1 0x10
-#define PPE_IP_PROT_2 0x14
-#define PPE_IP_PROT_3 0x18
-#define PPE_TB_CFG 0x1C
-#define PPE_TB_BASE 0x20
-#define PPE_TB_USED 0x24
-#define PPE_BNDR 0x28
-#define PPE_BIND_LMT_0 0x2C
-#define PPE_BIND_LMT_1 0x30
-#define PPE_KA 0x34
-#define PPE_UNB_AGE 0x38
-#define PPE_BND_AGE_0 0x3C
-#define PPE_BND_AGE_1 0x40
-#define PPE_HASH_SEED 0x44
-#define PPE_DFT_CPORT 0x48
-#define PPE_MCAST_PPSE 0x84
-#define PPE_MCAST_L_0 0x88
-#define PPE_MCAST_H_0 0x8C
-#define PPE_MCAST_L_1 0x90
-#define PPE_MCAST_H_1 0x94
-#define PPE_MCAST_L_2 0x98
-#define PPE_MCAST_H_2 0x9C
-#define PPE_MCAST_L_3 0xA0
-#define PPE_MCAST_H_3 0xA4
-#define PPE_MCAST_L_4 0xA8
-#define PPE_MCAST_H_4 0xAC
-#define PPE_MCAST_L_5 0xB0
-#define PPE_MCAST_H_5 0xB4
-#define PPE_MCAST_L_6 0xBC
-#define PPE_MCAST_H_6 0xC0
-#define PPE_MCAST_L_7 0xC4
-#define PPE_MCAST_H_7 0xC8
-#define PPE_MCAST_L_8 0xCC
-#define PPE_MCAST_H_8 0xD0
-#define PPE_MCAST_L_9 0xD4
-#define PPE_MCAST_H_9 0xD8
-#define PPE_MCAST_L_A 0xDC
-#define PPE_MCAST_H_A 0xE0
-#define PPE_MCAST_L_B 0xE4
-#define PPE_MCAST_H_B 0xE8
-#define PPE_MCAST_L_C 0xEC
-#define PPE_MCAST_H_C 0xF0
-#define PPE_MCAST_L_D 0xF4
-#define PPE_MCAST_H_D 0xF8
-#define PPE_MCAST_L_E 0xFC
-#define PPE_MCAST_H_E 0xE0
-#define PPE_MCAST_L_F 0x100
-#define PPE_MCAST_H_F 0x104
-#define PPE_MCAST_L_10 0xC00
-#define PPE_MCAST_H_10 0xC04
-#define PPE_MTU_DRP 0x108
-#define PPE_MTU_VLYR_0 0x10C
-#define PPE_MTU_VLYR_1 0x110
-#define PPE_MTU_VLYR_2 0x114
-#define PPE_VPM_TPID 0x118
-#define PPE_CAH_CTRL 0x120
-#define PPE_CAH_TAG_SRH 0x124
-#define PPE_CAH_LINE_RW 0x128
-#define PPE_CAH_WDATA 0x12C
-#define PPE_CAH_RDATA 0x130
-
-#define PPE_MIB_CFG 0X134
-#define PPE_MIB_TB_BASE 0X138
-#define PPE_MIB_SER_CR 0X13C
-#define PPE_MIB_SER_R0 0X140
-#define PPE_MIB_SER_R1 0X144
-#define PPE_MIB_SER_R2 0X148
-#define PPE_MIB_CAH_CTRL 0X150
-#define PPE_MIB_CAH_TAG_SRH 0X154
-#define PPE_MIB_CAH_LINE_RW 0X158
-#define PPE_MIB_CAH_WDATA 0X15C
-#define PPE_MIB_CAH_RDATA 0X160
-
-#define GDMA1_FWD_CFG 0x500
-#define GDMA2_FWD_CFG 0x1500
-
-#define QTX_CFG(x) (0x1800 + ((x) * 0x10))
-#define QTX_SCH(x) (0x1804 + ((x) * 0x10))
-#define QDMA_PAGE 0x19f0
-#define QDMA_TX_2SCH_BASE 0x1a14
-#define QTX_MIB_IF 0x1abc
-#define QDMA_TX_4SCH_BASE(x) (0x1b98 + (((x) >> 1) * 0x4))
-/*--------------------------------------------------------------------------*/
-/* Register Mask*/
-/*--------------------------------------------------------------------------*/
-/* PPE_TB_CFG mask */
-#define TB_ETRY_NUM (0x7 << 0) /* RW */
-#define TB_ENTRY_SIZE (0x1 << 3) /* RW */
-#define SMA (0x3 << 4) /* RW */
-#define NTU_AGE (0x1 << 7) /* RW */
-#define UNBD_AGE (0x1 << 8) /* RW */
-#define TCP_AGE (0x1 << 9) /* RW */
-#define UDP_AGE (0x1 << 10) /* RW */
-#define FIN_AGE (0x1 << 11) /* RW */
-#define KA_CFG (0x3 << 12)
-#define HASH_MODE (0x3 << 14) /* RW */
-#define SCAN_MODE (0x3 << 16) /* RW */
-#define XMODE (0x3 << 18) /* RW */
-
-/*PPE_CAH_CTRL mask*/
-#define CAH_EN (0x1 << 0) /* RW */
-#define CAH_X_MODE (0x1 << 9) /* RW */
-
-/*PPE_UNB_AGE mask*/
-#define UNB_DLTA (0xff << 0) /* RW */
-#define UNB_MNP (0xffff << 16) /* RW */
-
-/*PPE_BND_AGE_0 mask*/
-#define UDP_DLTA (0xffff << 0) /* RW */
-#define NTU_DLTA (0xffff << 16) /* RW */
-
-/*PPE_BND_AGE_1 mask*/
-#define TCP_DLTA (0xffff << 0) /* RW */
-#define FIN_DLTA (0xffff << 16) /* RW */
-
-/*PPE_KA mask*/
-#define KA_T (0xffff << 0) /* RW */
-#define TCP_KA (0xff << 16) /* RW */
-#define UDP_KA (0xff << 24) /* RW */
-
-/*PPE_BIND_LMT_0 mask*/
-#define QURT_LMT (0x3ff << 0) /* RW */
-#define HALF_LMT (0x3ff << 16) /* RW */
-
-/*PPE_BIND_LMT_1 mask*/
-#define FULL_LMT (0x3fff << 0) /* RW */
-#define NTU_KA (0xff << 16) /* RW */
-
-/*PPE_BNDR mask*/
-#define BIND_RATE (0xffff << 0) /* RW */
-#define PBND_RD_PRD (0xffff << 16) /* RW */
-
-/*PPE_GLO_CFG mask*/
-#define PPE_EN (0x1 << 0) /* RW */
-#define TTL0_DRP (0x1 << 4) /* RW */
-#define MCAST_TB_EN (0x1 << 7) /* RW */
-#define MCAST_HASH (0x3 << 12) /* RW */
-
-#define MC_P3_PPSE (0xf << 12) /* RW */
-#define MC_P2_PPSE (0xf << 8) /* RW */
-#define MC_P1_PPSE (0xf << 4) /* RW */
-#define MC_P0_PPSE (0xf << 0) /* RW */
-
-#define MIB_EN (0x1 << 0) /* RW */
-#define MIB_READ_CLEAR (0X1 << 1) /* RW */
-#define MIB_CAH_EN (0X1 << 0) /* RW */
-
-/*GDMA_FWD_CFG mask */
-#define GDM_UFRC_MASK (0x7 << 12) /* RW */
-#define GDM_BFRC_MASK (0x7 << 8) /*RW*/
-#define GDM_MFRC_MASK (0x7 << 4) /*RW*/
-#define GDM_OFRC_MASK (0x7 << 0) /*RW*/
-#define GDM_ALL_FRC_MASK                                                      \
-	(GDM_UFRC_MASK | GDM_BFRC_MASK | GDM_MFRC_MASK | GDM_OFRC_MASK)
-
-/*QDMA_PAGE mask*/
-#define QTX_CFG_PAGE (0xf << 0) /* RW */
-
-/*QTX_MIB_IF mask*/
-#define MIB_ON_QTX_CFG (0x1 << 31) /* RW */
-#define VQTX_MIB_EN (0x1 << 28) /* RW */
-
-/*--------------------------------------------------------------------------*/
-/* Descriptor Structure */
-/*--------------------------------------------------------------------------*/
-struct hnat_unbind_info_blk {
-	u32 time_stamp : 8;
-	u32 pcnt : 16; /* packet count */
-	u32 preb : 1;
-	u32 pkt_type : 3;
-	u32 state : 2;
-	u32 udp : 1;
-	u32 sta : 1; /* static entry */
-} __packed;
-
-struct hnat_bind_info_blk {
-	u32 time_stamp : 15;
-	u32 ka : 1; /* keep alive */
-	u32 vlan_layer : 3;
-	u32 psn : 1; /* egress packet has PPPoE session */
-	u32 vpm : 1; /* 0:ethertype remark, 1:0x8100(CR default) */
-	u32 ps : 1; /* packet sampling */
-	u32 cah : 1; /* cacheable flag */
-	u32 rmt : 1; /* remove tunnel ip header (6rd/dslite only) */
-	u32 ttl : 1;
-	u32 pkt_type : 3;
-	u32 state : 2;
-	u32 udp : 1;
-	u32 sta : 1; /* static entry */
-} __packed;
-
-struct hnat_info_blk2 {
-	u32 qid : 4; /* QID in Qos Port */
-	u32 fqos : 1; /* force to PSE QoS port */
-	u32 dp : 3; /* force to PSE port x
-		     * 0:PSE,1:GSW, 2:GMAC,4:PPE,5:QDMA,7=DROP
-		     */
-	u32 mcast : 1; /* multicast this packet to CPU */
-	u32 pcpl : 1; /* OSBN */
-	u32 mibf : 1; /* 0:off 1:on PPE MIB counter */
-	u32 alen : 1; /* 0:post 1:pre packet length in accounting */
-	u32 port_mg : 6; /* port meter group */
-	u32 port_ag : 6; /* port account group */
-	u32 dscp : 8; /* DSCP value */
-} __packed;
-
-/* info blk2 for WHNAT */
-struct hnat_info_blk2_whnat {
-	u32 qid : 4; /* QID[3:0] in Qos Port */
-	u32 fqos : 1; /* force to PSE QoS port */
-	u32 dp : 3; /* force to PSE port x
-		     * 0:PSE,1:GSW, 2:GMAC,4:PPE,5:QDMA,7=DROP
-		     */
-	u32 mcast : 1; /* multicast this packet to CPU */
-	u32 pcpl : 1; /* OSBN */
-	u32 mibf : 1; /* 0:off 1:on PPE MIB counter */
-	u32 alen : 1; /* 0:post 1:pre packet length in accounting */
-	u32 qid2 : 2; /* QID[5:4] in Qos Port */
-	u32 resv : 2;
-	u32 wdmaid : 1; /* 0:to pcie0 dev 1:to pcie1 dev */
-	u32 winfoi : 1; /* 0:off 1:on Wi-Fi hwnat support */
-	u32 port_ag : 6; /* port account group */
-	u32 dscp : 8; /* DSCP value */
-} __packed;
-
-struct hnat_winfo {
-	u32 bssid : 6; /* WiFi Bssidx */
-	u32 wcid : 8; /* WiFi wtable Idx */
-	u32 rxid : 2; /* WiFi Ring idx */
-} __packed;
-struct hnat_ipv4_hnapt {
-	union {
-		struct hnat_bind_info_blk bfib1;
-		struct hnat_unbind_info_blk udib1;
-		u32 info_blk1;
-	};
-	u32 sip;
-	u32 dip;
-	u16 dport;
-	u16 sport;
-	union {
-		struct hnat_info_blk2 iblk2;
-		struct hnat_info_blk2_whnat iblk2w;
-		u32 info_blk2;
-	};
-	u32 new_sip;
-	u32 new_dip;
-	u16 new_dport;
-	u16 new_sport;
-	u16 m_timestamp; /* For mcast*/
-	u16 resv1;
-	u32 resv2;
-	u32 resv3 : 26;
-	u32 act_dp : 6; /* UDF */
-	u16 vlan1;
-	u16 etype;
-	u32 dmac_hi;
-	union {
-		struct hnat_winfo winfo;
-		u16 vlan2;
-	};
-	u16 dmac_lo;
-	u32 smac_hi;
-	u16 pppoe_id;
-	u16 smac_lo;
-} __packed;
-
-struct hnat_ipv4_dslite {
-	union {
-		struct hnat_bind_info_blk bfib1;
-		struct hnat_unbind_info_blk udib1;
-		u32 info_blk1;
-	};
-	u32 sip;
-	u32 dip;
-	u16 dport;
-	u16 sport;
-
-	u32 tunnel_sipv6_0;
-	u32 tunnel_sipv6_1;
-	u32 tunnel_sipv6_2;
-	u32 tunnel_sipv6_3;
-
-	u32 tunnel_dipv6_0;
-	u32 tunnel_dipv6_1;
-	u32 tunnel_dipv6_2;
-	u32 tunnel_dipv6_3;
-
-	u8 flow_lbl[3]; /* in order to consist with Linux kernel (should be 20bits) */
-	u8 priority;    /* in order to consist with Linux kernel (should be 8bits) */
-	u32 hop_limit : 8;
-	u32 resv2 : 18;
-	u32 act_dp : 6; /* UDF */
-
-	union {
-		struct hnat_info_blk2 iblk2;
-		struct hnat_info_blk2_whnat iblk2w;
-		u32 info_blk2;
-	};
-
-	u16 vlan1;
-	u16 etype;
-	u32 dmac_hi;
-	union {
-		struct hnat_winfo winfo;
-		u16 vlan2;
-	};
-	u16 dmac_lo;
-	u32 smac_hi;
-	u16 pppoe_id;
-	u16 smac_lo;
-} __packed;
-
-struct hnat_ipv6_3t_route {
-	union {
-		struct hnat_bind_info_blk bfib1;
-		struct hnat_unbind_info_blk udib1;
-		u32 info_blk1;
-	};
-	u32 ipv6_sip0;
-	u32 ipv6_sip1;
-	u32 ipv6_sip2;
-	u32 ipv6_sip3;
-	u32 ipv6_dip0;
-	u32 ipv6_dip1;
-	u32 ipv6_dip2;
-	u32 ipv6_dip3;
-	u32 prot : 8;
-	u32 resv : 24;
-
-	u32 resv1;
-	u32 resv2;
-	u32 resv3;
-	u32 resv4 : 26;
-	u32 act_dp : 6; /* UDF */
-
-	union {
-		struct hnat_info_blk2 iblk2;
-		struct hnat_info_blk2_whnat iblk2w;
-		u32 info_blk2;
-	};
-	u16 vlan1;
-	u16 etype;
-	u32 dmac_hi;
-	union {
-		struct hnat_winfo winfo;
-		u16 vlan2;
-	};
-	u16 dmac_lo;
-	u32 smac_hi;
-	u16 pppoe_id;
-	u16 smac_lo;
-} __packed;
-
-struct hnat_ipv6_5t_route {
-	union {
-		struct hnat_bind_info_blk bfib1;
-		struct hnat_unbind_info_blk udib1;
-		u32 info_blk1;
-	};
-	u32 ipv6_sip0;
-	u32 ipv6_sip1;
-	u32 ipv6_sip2;
-	u32 ipv6_sip3;
-	u32 ipv6_dip0;
-	u32 ipv6_dip1;
-	u32 ipv6_dip2;
-	u32 ipv6_dip3;
-	u16 dport;
-	u16 sport;
-
-	u32 resv1;
-	u32 resv2;
-	u32 resv3;
-	u32 resv4 : 26;
-	u32 act_dp : 6; /* UDF */
-
-	union {
-		struct hnat_info_blk2 iblk2;
-		struct hnat_info_blk2_whnat iblk2w;
-		u32 info_blk2;
-	};
-
-	u16 vlan1;
-	u16 etype;
-	u32 dmac_hi;
-	union {
-		struct hnat_winfo winfo;
-		u16 vlan2;
-	};
-	u16 dmac_lo;
-	u32 smac_hi;
-	u16 pppoe_id;
-	u16 smac_lo;
-} __packed;
-
-struct hnat_ipv6_6rd {
-	union {
-		struct hnat_bind_info_blk bfib1;
-		struct hnat_unbind_info_blk udib1;
-		u32 info_blk1;
-	};
-	u32 ipv6_sip0;
-	u32 ipv6_sip1;
-	u32 ipv6_sip2;
-	u32 ipv6_sip3;
-	u32 ipv6_dip0;
-	u32 ipv6_dip1;
-	u32 ipv6_dip2;
-	u32 ipv6_dip3;
-	u16 dport;
-	u16 sport;
-
-	u32 tunnel_sipv4;
-	u32 tunnel_dipv4;
-	u32 hdr_chksum : 16;
-	u32 dscp : 8;
-	u32 ttl : 8;
-	u32 flag : 3;
-	u32 resv1 : 13;
-	u32 per_flow_6rd_id : 1;
-	u32 resv2 : 9;
-	u32 act_dp : 6; /* UDF */
-
-	union {
-		struct hnat_info_blk2 iblk2;
-		struct hnat_info_blk2_whnat iblk2w;
-		u32 info_blk2;
-	};
-
-	u16 vlan1;
-	u16 etype;
-	u32 dmac_hi;
-	union {
-		struct hnat_winfo winfo;
-		u16 vlan2;
-	};
-	u16 dmac_lo;
-	u32 smac_hi;
-	u16 pppoe_id;
-	u16 smac_lo;
-} __packed;
-
-struct foe_entry {
-	union {
-		struct hnat_unbind_info_blk udib1;
-		struct hnat_bind_info_blk bfib1;
-		struct hnat_ipv4_hnapt ipv4_hnapt;
-		struct hnat_ipv4_dslite ipv4_dslite;
-		struct hnat_ipv6_3t_route ipv6_3t_route;
-		struct hnat_ipv6_5t_route ipv6_5t_route;
-		struct hnat_ipv6_6rd ipv6_6rd;
-	};
-};
-
-/* If user wants to change default FOE entry number, both DEF_ETRY_NUM and
- * DEF_ETRY_NUM_CFG need to be modified.
- */
-#define DEF_ETRY_NUM		16384
-/* feasible values : 16384, 8192, 4096, 2048, 1024 */
-#define DEF_ETRY_NUM_CFG	TABLE_16K
-/* corresponding values : TABLE_16K, TABLE_8K, TABLE_4K, TABLE_2K, TABLE_1K */
-#define MAX_EXT_DEVS		(0x3fU)
-#define MAX_IF_NUM		64
-
-struct mib_entry {
-	u32 byt_cnt_l;
-	u16 byt_cnt_h;
-	u32 pkt_cnt_l;
-	u8 pkt_cnt_h;
-	u8 resv0;
-	u32 resv1;
-} __packed;
-
-struct hnat_accounting {
-	u64 bytes;
-	u64 packets;
-};
-
-enum mtk_hnat_version {
-	MTK_HNAT_V1 = 1, /* version 1: mt7621, mt7623 */
-	MTK_HNAT_V2, /* version 2: mt7622 */
-	MTK_HNAT_V3, /* version 3: mt7629 */
-};
-
-struct mtk_hnat_data {
-	u8 num_of_sch;
-	bool whnat;
-	bool per_flow_accounting;
-	bool mcast;
-	enum mtk_hnat_version version;
-};
-
-struct mtk_hnat {
-	struct device *dev;
-	void __iomem *fe_base;
-	void __iomem *ppe_base;
-	struct foe_entry *foe_table_cpu;
-	dma_addr_t foe_table_dev;
-	u8 enable;
-	u8 enable1;
-	struct dentry *root;
-	struct debugfs_regset32 *regset;
-
-	struct mib_entry *foe_mib_cpu;
-	dma_addr_t foe_mib_dev;
-	struct hnat_accounting *acct;
-	const struct mtk_hnat_data *data;
-
-	/*devices we plays for*/
-	char wan[IFNAMSIZ];
-	char lan[IFNAMSIZ];
-	char ppd[IFNAMSIZ];
-	u16 lvid;
-	u16 wvid;
-
-	struct reset_control *rstc;
-
-	u8 gmac_num;
-	u8 wan_dsa_port;
-	struct ppe_mcast_table *pmcast;
-
-	u32 foe_etry_num;
-	struct net_device *g_ppdev;
-	struct net_device *wifi_hook_if[MAX_IF_NUM];
-	struct extdev_entry *ext_if[MAX_EXT_DEVS];
-	struct timer_list hnat_sma_build_entry_timer;
-	struct timer_list hnat_reset_timestamp_timer;
-	struct timer_list hnat_mcast_check_timer;
-	bool ipv6_en;
-};
-
-struct extdev_entry {
-	char name[IFNAMSIZ];
-	struct net_device *dev;
-};
-
-struct tcpudphdr {
-	__be16 src;
-	__be16 dst;
-};
-
-enum FoeEntryState { INVALID = 0, UNBIND = 1, BIND = 2, FIN = 3 };
-
-enum FoeIpAct {
-	IPV4_HNAPT = 0,
-	IPV4_HNAT = 1,
-	IPV4_DSLITE = 3,
-	IPV6_3T_ROUTE = 4,
-	IPV6_5T_ROUTE = 5,
-	IPV6_6RD = 7,
-};
-
-/*--------------------------------------------------------------------------*/
-/* Common Definition*/
-/*--------------------------------------------------------------------------*/
-
-#define HNAT_SW_VER   "1.1.0"
-#define HASH_SEED_KEY 0x12345678
-
-/*PPE_TB_CFG value*/
-#define ENTRY_80B 1
-#define ENTRY_64B 0
-#define TABLE_1K 0
-#define TABLE_2K 1
-#define TABLE_4K 2
-#define TABLE_8K 3
-#define TABLE_16K 4
-#define SMA_DROP 0 /* Drop the packet */
-#define SMA_DROP2 1 /* Drop the packet */
-#define SMA_ONLY_FWD_CPU 2 /* Only Forward to CPU */
-#define SMA_FWD_CPU_BUILD_ENTRY 3 /* Forward to CPU and build new FOE entry */
-#define HASH_MODE_0 0
-#define HASH_MODE_1 1
-#define HASH_MODE_2 2
-#define HASH_MODE_3 3
-
-/*PPE_FLOW_CFG*/
-#define BIT_FUC_FOE BIT(2)
-#define BIT_FMC_FOE BIT(1)
-#define BIT_FBC_FOE BIT(0)
-#define BIT_UDP_IP4F_NAT_EN BIT(7) /*Enable IPv4 fragment + UDP packet NAT*/
-#define BIT_IPV6_3T_ROUTE_EN BIT(8)
-#define BIT_IPV6_5T_ROUTE_EN BIT(9)
-#define BIT_IPV6_6RD_EN BIT(10)
-#define BIT_IPV4_NAT_EN BIT(12)
-#define BIT_IPV4_NAPT_EN BIT(13)
-#define BIT_IPV4_DSL_EN BIT(14)
-#define BIT_IPV4_NAT_FRAG_EN BIT(17)
-#define BIT_IPV4_HASH_GREK BIT(19)
-#define BIT_IPV6_HASH_GREK BIT(20)
-
-#define BIT_MIB_BUSY BIT(16)
-
-/*GDMA_FWD_CFG value*/
-#define BITS_GDM_UFRC_P_PPE (NR_PPE_PORT << 12)
-#define BITS_GDM_BFRC_P_PPE (NR_PPE_PORT << 8)
-#define BITS_GDM_MFRC_P_PPE (NR_PPE_PORT << 4)
-#define BITS_GDM_OFRC_P_PPE (NR_PPE_PORT << 0)
-#define BITS_GDM_ALL_FRC_P_PPE                                              \
-	(BITS_GDM_UFRC_P_PPE | BITS_GDM_BFRC_P_PPE | BITS_GDM_MFRC_P_PPE |  \
-	 BITS_GDM_OFRC_P_PPE)
-
-#define BITS_GDM_UFRC_P_CPU_PDMA (NR_PDMA_PORT << 12)
-#define BITS_GDM_BFRC_P_CPU_PDMA (NR_PDMA_PORT << 8)
-#define BITS_GDM_MFRC_P_CPU_PDMA (NR_PDMA_PORT << 4)
-#define BITS_GDM_OFRC_P_CPU_PDMA (NR_PDMA_PORT << 0)
-#define BITS_GDM_ALL_FRC_P_CPU_PDMA                                           \
-	(BITS_GDM_UFRC_P_CPU_PDMA | BITS_GDM_BFRC_P_CPU_PDMA |               \
-	 BITS_GDM_MFRC_P_CPU_PDMA | BITS_GDM_OFRC_P_CPU_PDMA)
-
-#define BITS_GDM_UFRC_P_CPU_QDMA (NR_QDMA_PORT << 12)
-#define BITS_GDM_BFRC_P_CPU_QDMA (NR_QDMA_PORT << 8)
-#define BITS_GDM_MFRC_P_CPU_QDMA (NR_QDMA_PORT << 4)
-#define BITS_GDM_OFRC_P_CPU_QDMA (NR_QDMA_PORT << 0)
-#define BITS_GDM_ALL_FRC_P_CPU_QDMA                                           \
-	(BITS_GDM_UFRC_P_CPU_QDMA | BITS_GDM_BFRC_P_CPU_QDMA |               \
-	 BITS_GDM_MFRC_P_CPU_QDMA | BITS_GDM_OFRC_P_CPU_QDMA)
-
-#define BITS_GDM_UFRC_P_DISCARD (NR_DISCARD << 12)
-#define BITS_GDM_BFRC_P_DISCARD (NR_DISCARD << 8)
-#define BITS_GDM_MFRC_P_DISCARD (NR_DISCARD << 4)
-#define BITS_GDM_OFRC_P_DISCARD (NR_DISCARD << 0)
-#define BITS_GDM_ALL_FRC_P_DISCARD                                            \
-	(BITS_GDM_UFRC_P_DISCARD | BITS_GDM_BFRC_P_DISCARD |                 \
-	 BITS_GDM_MFRC_P_DISCARD | BITS_GDM_OFRC_P_DISCARD)
-
-#define hnat_is_enabled(hnat_priv) (hnat_priv->enable)
-#define hnat_enabled(hnat_priv) (hnat_priv->enable = 1)
-#define hnat_disabled(hnat_priv) (hnat_priv->enable = 0)
-#define hnat_is_enabled1(hnat_priv) (hnat_priv->enable1)
-#define hnat_enabled1(hnat_priv) (hnat_priv->enable1 = 1)
-#define hnat_disabled1(hnat_priv) (hnat_priv->enable1 = 0)
-
-#define entry_hnat_is_bound(e) (e->bfib1.state == BIND)
-#define entry_hnat_state(e) (e->bfib1.state)
-
-#define skb_hnat_is_hashed(skb)                                                \
-	(skb_hnat_entry(skb) != 0x3fff && skb_hnat_entry(skb) < hnat_priv->foe_etry_num)
-#define FROM_GE_LAN(skb) (skb_hnat_iface(skb) == FOE_MAGIC_GE_LAN)
-#define FROM_GE_WAN(skb) (skb_hnat_iface(skb) == FOE_MAGIC_GE_WAN)
-#define FROM_GE_PPD(skb) (skb_hnat_iface(skb) == FOE_MAGIC_GE_PPD)
-#define FROM_GE_VIRTUAL(skb) (skb_hnat_iface(skb) == FOE_MAGIC_GE_VIRTUAL)
-#define FROM_EXT(skb) (skb_hnat_iface(skb) == FOE_MAGIC_EXT)
-#define FOE_MAGIC_GE_LAN 0x1
-#define FOE_MAGIC_GE_WAN 0x2
-#define FOE_MAGIC_EXT 0x3
-#define FOE_MAGIC_GE_VIRTUAL 0x4
-#define FOE_MAGIC_GE_PPD 0x5
-#define FOE_INVALID 0xf
-#define index6b(i) (0x3fU - i)
-
-#define IPV4_HNAPT 0
-#define IPV4_HNAT 1
-#define IP_FORMAT(addr)                                                        \
-	(((unsigned char *)&addr)[3], ((unsigned char *)&addr)[2],              \
-	((unsigned char *)&addr)[1], ((unsigned char *)&addr)[0])
-
-/*PSE Ports*/
-#define NR_PDMA_PORT 0
-#define NR_GMAC1_PORT 1
-#define NR_GMAC2_PORT 2
-#define NR_WHNAT_WDMA_PORT 3
-#define NR_PPE_PORT 4
-#define NR_QDMA_PORT 5
-#define NR_DISCARD 7
-#define LAN_DEV_NAME hnat_priv->lan
-#define IS_WAN(dev)                                                            \
-	(!strncmp((dev)->name, hnat_priv->wan, strlen(hnat_priv->wan)))
-#define IS_LAN(dev) (!strncmp(dev->name, LAN_DEV_NAME, strlen(LAN_DEV_NAME)))
-#define IS_BR(dev) (!strncmp(dev->name, "br", 2))
-#define IS_WHNAT(dev)							       \
-	((hnat_priv->data->version == MTK_HNAT_V2 &&			       \
-	 (get_wifi_hook_if_index_from_dev(dev) != 0)) ? 1 : 0)
-#define IS_EXT(dev) ((get_index_from_dev(dev) != 0) ? 1 : 0)
-#define IS_PPD(dev) (!strcmp(dev->name, hnat_priv->ppd))
-#define IS_IPV4_HNAPT(x) (((x)->bfib1.pkt_type == IPV4_HNAPT) ? 1 : 0)
-#define IS_IPV4_HNAT(x) (((x)->bfib1.pkt_type == IPV4_HNAT) ? 1 : 0)
-#define IS_IPV4_GRP(x) (IS_IPV4_HNAPT(x) | IS_IPV4_HNAT(x))
-#define IS_IPV4_DSLITE(x) (((x)->bfib1.pkt_type == IPV4_DSLITE) ? 1 : 0)
-#define IS_IPV6_3T_ROUTE(x) (((x)->bfib1.pkt_type == IPV6_3T_ROUTE) ? 1 : 0)
-#define IS_IPV6_5T_ROUTE(x) (((x)->bfib1.pkt_type == IPV6_5T_ROUTE) ? 1 : 0)
-#define IS_IPV6_6RD(x) (((x)->bfib1.pkt_type == IPV6_6RD) ? 1 : 0)
-#define IS_IPV6_GRP(x)                                                         \
-	(IS_IPV6_3T_ROUTE(x) | IS_IPV6_5T_ROUTE(x) | IS_IPV6_6RD(x) |          \
-	 IS_IPV4_DSLITE(x))
-#define IS_GMAC1_MODE ((hnat_priv->gmac_num == 1) ? 1 : 0)
-
-#define es(entry) (entry_state[entry->bfib1.state])
-#define ei(entry, end) (hnat_priv->foe_etry_num - (int)(end - entry))
-#define pt(entry) (packet_type[entry->ipv4_hnapt.bfib1.pkt_type])
-#define ipv4_smac(mac, e)                                                      \
-	({                                                                     \
-		mac[0] = e->ipv4_hnapt.smac_hi[3];                             \
-		mac[1] = e->ipv4_hnapt.smac_hi[2];                             \
-		mac[2] = e->ipv4_hnapt.smac_hi[1];                             \
-		mac[3] = e->ipv4_hnapt.smac_hi[0];                             \
-		mac[4] = e->ipv4_hnapt.smac_lo[1];                             \
-		mac[5] = e->ipv4_hnapt.smac_lo[0];                             \
-	})
-#define ipv4_dmac(mac, e)                                                      \
-	({                                                                     \
-		mac[0] = e->ipv4_hnapt.dmac_hi[3];                             \
-		mac[1] = e->ipv4_hnapt.dmac_hi[2];                             \
-		mac[2] = e->ipv4_hnapt.dmac_hi[1];                             \
-		mac[3] = e->ipv4_hnapt.dmac_hi[0];                             \
-		mac[4] = e->ipv4_hnapt.dmac_lo[1];                             \
-		mac[5] = e->ipv4_hnapt.dmac_lo[0];                             \
-	})
-
-#define IS_DSA_LAN(dev) (!strncmp(dev->name, "lan", 3))
-#define IS_DSA_WAN(dev) (!strncmp(dev->name, "wan", 3))
-#define NONE_DSA_PORT 0xff
-#define MAX_CRSN_NUM 32
-#define IPV6_HDR_LEN 40
-
-/*QDMA_PAGE value*/
-#define NUM_OF_Q_PER_PAGE 16
-
-/*IPv6 Header*/
-#ifndef NEXTHDR_IPIP
-#define NEXTHDR_IPIP 4
-#endif
-
-extern const struct of_device_id of_hnat_match[];
-extern struct mtk_hnat *hnat_priv;
-
-#if defined(CONFIG_NET_DSA_MT7530)
-void hnat_dsa_fill_stag(const struct net_device *netdev,
-			struct foe_entry *entry,
-			struct hnat_hw_path *hw_path,
-			u16 eth_proto, int mape);
-
-static inline bool hnat_dsa_is_enable(struct mtk_hnat *priv)
-{
-	return (priv->wan_dsa_port != NONE_DSA_PORT);
-}
-#else
-static inline void hnat_dsa_fill_stag(const struct net_device *netdev,
-				      struct foe_entry *entry,
-				      struct hnat_hw_path *hw_path,
-				      u16 eth_proto, int mape)
-{
-}
-
-static inline bool hnat_dsa_is_enable(struct mtk_hnat *priv)
-{
-	return false;
-}
-#endif
-
-void hnat_deinit_debugfs(struct mtk_hnat *h);
-int __init hnat_init_debugfs(struct mtk_hnat *h);
-int hnat_register_nf_hooks(void);
-void hnat_unregister_nf_hooks(void);
-int whnat_adjust_nf_hooks(void);
-int mtk_hqos_ptype_cb(struct sk_buff *skb, struct net_device *dev,
-		      struct packet_type *pt, struct net_device *unused);
-extern int dbg_cpu_reason;
-extern int debug_level;
-extern int hook_toggle;
-extern int mape_toggle;
-
-int ext_if_add(struct extdev_entry *ext_entry);
-int ext_if_del(struct extdev_entry *ext_entry);
-void cr_set_field(void __iomem *reg, u32 field, u32 val);
-int mtk_sw_nat_hook_tx(struct sk_buff *skb, int gmac_no);
-int mtk_sw_nat_hook_rx(struct sk_buff *skb);
-void mtk_ppe_dev_register_hook(struct net_device *dev);
-void mtk_ppe_dev_unregister_hook(struct net_device *dev);
-int nf_hnat_netdevice_event(struct notifier_block *unused, unsigned long event,
-			    void *ptr);
-int nf_hnat_netevent_handler(struct notifier_block *unused, unsigned long event,
-			     void *ptr);
-uint32_t foe_dump_pkt(struct sk_buff *skb);
-uint32_t hnat_cpu_reason_cnt(struct sk_buff *skb);
-int hnat_enable_hook(void);
-int hnat_disable_hook(void);
-void hnat_cache_ebl(int enable);
-void set_gmac_ppe_fwd(int gmac_no, int enable);
-int entry_delete(int index);
-
-static inline u16 foe_timestamp(struct mtk_hnat *h)
-{
-	return (readl(hnat_priv->fe_base + 0x0010)) & 0xffff;
-}
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_debugfs.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_debugfs.c
deleted file mode 100644
index d92fa0a5a..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_debugfs.c
+++ /dev/null
@@ -1,1903 +0,0 @@
-/*   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation; version 2 of the License
- *
- *   This program is distributed in the hope that it will be useful,
- *   but WITHOUT ANY WARRANTY; without even the implied warranty of
- *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *   GNU General Public License for more details.
- *
- *   Copyright (C) 2014-2016 Sean Wang <sean.wang@mediatek.com>
- *   Copyright (C) 2016-2017 John Crispin <blogic@openwrt.org>
- */
-
-#include <linux/kernel.h>
-#include <linux/slab.h>
-#include <linux/dma-mapping.h>
-#include <linux/netdevice.h>
-#include <linux/iopoll.h>
-
-#include "hnat.h"
-#include "nf_hnat_mtk.h"
-#include "../mtk_eth_soc.h"
-
-int dbg_entry_state = BIND;
-typedef int (*debugfs_write_func)(int par1);
-int debug_level;
-int dbg_cpu_reason;
-int hook_toggle;
-int mape_toggle;
-unsigned int dbg_cpu_reason_cnt[MAX_CRSN_NUM];
-
-static const char * const entry_state[] = { "INVALID", "UNBIND", "BIND", "FIN" };
-
-static const char * const packet_type[] = {
-	"IPV4_HNAPT",    "IPV4_HNAT",     "IPV6_1T_ROUTE", "IPV4_DSLITE",
-	"IPV6_3T_ROUTE", "IPV6_5T_ROUTE", "REV",	   "IPV6_6RD",
-};
-
-static uint8_t *show_cpu_reason(struct sk_buff *skb)
-{
-	static u8 buf[32];
-
-	switch (skb_hnat_reason(skb)) {
-	case TTL_0:
-		return "IPv4(IPv6) TTL(hop limit)\n";
-	case HAS_OPTION_HEADER:
-		return "Ipv4(IPv6) has option(extension) header\n";
-	case NO_FLOW_IS_ASSIGNED:
-		return "No flow is assigned\n";
-	case IPV4_WITH_FRAGMENT:
-		return "IPv4 HNAT doesn't support IPv4 /w fragment\n";
-	case IPV4_HNAPT_DSLITE_WITH_FRAGMENT:
-		return "IPv4 HNAPT/DS-Lite doesn't support IPv4 /w fragment\n";
-	case IPV4_HNAPT_DSLITE_WITHOUT_TCP_UDP:
-		return "IPv4 HNAPT/DS-Lite can't find TCP/UDP sport/dport\n";
-	case IPV6_5T_6RD_WITHOUT_TCP_UDP:
-		return "IPv6 5T-route/6RD can't find TCP/UDP sport/dport\n";
-	case TCP_FIN_SYN_RST:
-		return "Ingress packet is TCP fin/syn/rst\n";
-	case UN_HIT:
-		return "FOE Un-hit\n";
-	case HIT_UNBIND:
-		return "FOE Hit unbind\n";
-	case HIT_UNBIND_RATE_REACH:
-		return "FOE Hit unbind & rate reach\n";
-	case HIT_BIND_TCP_FIN:
-		return "Hit bind PPE TCP FIN entry\n";
-	case HIT_BIND_TTL_1:
-		return "Hit bind PPE entry and TTL(hop limit) = 1 and TTL(hot limit) - 1\n";
-	case HIT_BIND_WITH_VLAN_VIOLATION:
-		return "Hit bind and VLAN replacement violation\n";
-	case HIT_BIND_KEEPALIVE_UC_OLD_HDR:
-		return "Hit bind and keep alive with unicast old-header packet\n";
-	case HIT_BIND_KEEPALIVE_MC_NEW_HDR:
-		return "Hit bind and keep alive with multicast new-header packet\n";
-	case HIT_BIND_KEEPALIVE_DUP_OLD_HDR:
-		return "Hit bind and keep alive with duplicate old-header packet\n";
-	case HIT_BIND_FORCE_TO_CPU:
-		return "FOE Hit bind & force to CPU\n";
-	case HIT_BIND_EXCEED_MTU:
-		return "Hit bind and exceed MTU\n";
-	case HIT_BIND_MULTICAST_TO_CPU:
-		return "Hit bind multicast packet to CPU\n";
-	case HIT_BIND_MULTICAST_TO_GMAC_CPU:
-		return "Hit bind multicast packet to GMAC & CPU\n";
-	case HIT_PRE_BIND:
-		return "Pre bind\n";
-	}
-
-	sprintf(buf, "CPU Reason Error - %X\n", skb_hnat_entry(skb));
-	return buf;
-}
-
-uint32_t foe_dump_pkt(struct sk_buff *skb)
-{
-	struct foe_entry *entry;
-
-	entry = &hnat_priv->foe_table_cpu[skb_hnat_entry(skb)];
-	pr_info("\nRx===<FOE_Entry=%d>=====\n", skb_hnat_entry(skb));
-	pr_info("RcvIF=%s\n", skb->dev->name);
-	pr_info("FOE_Entry=%d\n", skb_hnat_entry(skb));
-	pr_info("CPU Reason=%s", show_cpu_reason(skb));
-	pr_info("ALG=%d\n", skb_hnat_alg(skb));
-	pr_info("SP=%d\n", skb_hnat_sport(skb));
-
-	/* some special alert occurred, so entry_num is useless (just skip it) */
-	if (skb_hnat_entry(skb) == 0x3fff)
-		return 1;
-
-	/* PPE: IPv4 packet=IPV4_HNAT IPv6 packet=IPV6_ROUTE */
-	if (IS_IPV4_GRP(entry)) {
-		__be32 saddr = htonl(entry->ipv4_hnapt.sip);
-		__be32 daddr = htonl(entry->ipv4_hnapt.dip);
-
-		pr_info("Information Block 1=%x\n",
-			entry->ipv4_hnapt.info_blk1);
-		pr_info("SIP=%pI4\n", &saddr);
-		pr_info("DIP=%pI4\n", &daddr);
-		pr_info("SPORT=%d\n", entry->ipv4_hnapt.sport);
-		pr_info("DPORT=%d\n", entry->ipv4_hnapt.dport);
-		pr_info("Information Block 2=%x\n",
-			entry->ipv4_hnapt.info_blk2);
-		pr_info("State = %s, proto = %s\n", entry->bfib1.state == 0 ?
-			"Invalid" : entry->bfib1.state == 1 ?
-			"Unbind" : entry->bfib1.state == 2 ?
-			"BIND" : entry->bfib1.state == 3 ?
-			"FIN" : "Unknown",
-			entry->ipv4_hnapt.bfib1.udp == 0 ?
-			"TCP" : entry->ipv4_hnapt.bfib1.udp == 1 ?
-			"UDP" : "Unknown");
-	} else if (IS_IPV6_GRP(entry)) {
-		pr_info("Information Block 1=%x\n",
-			entry->ipv6_5t_route.info_blk1);
-		pr_info("IPv6_SIP=%08X:%08X:%08X:%08X\n",
-			entry->ipv6_5t_route.ipv6_sip0,
-			entry->ipv6_5t_route.ipv6_sip1,
-			entry->ipv6_5t_route.ipv6_sip2,
-			entry->ipv6_5t_route.ipv6_sip3);
-		pr_info("IPv6_DIP=%08X:%08X:%08X:%08X\n",
-			entry->ipv6_5t_route.ipv6_dip0,
-			entry->ipv6_5t_route.ipv6_dip1,
-			entry->ipv6_5t_route.ipv6_dip2,
-			entry->ipv6_5t_route.ipv6_dip3);
-		pr_info("SPORT=%d\n", entry->ipv6_5t_route.sport);
-		pr_info("DPORT=%d\n", entry->ipv6_5t_route.dport);
-		pr_info("Information Block 2=%x\n",
-			entry->ipv6_5t_route.info_blk2);
-		pr_info("State = %s, proto = %s\n", entry->bfib1.state == 0 ?
-			"Invalid" : entry->bfib1.state == 1 ?
-			"Unbind" : entry->bfib1.state == 2 ?
-			"BIND" : entry->bfib1.state == 3 ?
-			"FIN" : "Unknown",
-			entry->ipv6_5t_route.bfib1.udp == 0 ?
-			"TCP" : entry->ipv6_5t_route.bfib1.udp == 1 ?
-			"UDP" :	"Unknown");
-	} else {
-		pr_info("unknown Pkt_type=%d\n", entry->bfib1.pkt_type);
-	}
-
-	pr_info("==================================\n");
-	return 1;
-}
-
-uint32_t hnat_cpu_reason_cnt(struct sk_buff *skb)
-{
-	switch (skb_hnat_reason(skb)) {
-	case TTL_0:
-		dbg_cpu_reason_cnt[0]++;
-		return 0;
-	case HAS_OPTION_HEADER:
-		dbg_cpu_reason_cnt[1]++;
-		return 0;
-	case NO_FLOW_IS_ASSIGNED:
-		dbg_cpu_reason_cnt[2]++;
-		return 0;
-	case IPV4_WITH_FRAGMENT:
-		dbg_cpu_reason_cnt[3]++;
-		return 0;
-	case IPV4_HNAPT_DSLITE_WITH_FRAGMENT:
-		dbg_cpu_reason_cnt[4]++;
-		return 0;
-	case IPV4_HNAPT_DSLITE_WITHOUT_TCP_UDP:
-		dbg_cpu_reason_cnt[5]++;
-		return 0;
-	case IPV6_5T_6RD_WITHOUT_TCP_UDP:
-		dbg_cpu_reason_cnt[6]++;
-		return 0;
-	case TCP_FIN_SYN_RST:
-		dbg_cpu_reason_cnt[7]++;
-		return 0;
-	case UN_HIT:
-		dbg_cpu_reason_cnt[8]++;
-		return 0;
-	case HIT_UNBIND:
-		dbg_cpu_reason_cnt[9]++;
-		return 0;
-	case HIT_UNBIND_RATE_REACH:
-		dbg_cpu_reason_cnt[10]++;
-		return 0;
-	case HIT_BIND_TCP_FIN:
-		dbg_cpu_reason_cnt[11]++;
-		return 0;
-	case HIT_BIND_TTL_1:
-		dbg_cpu_reason_cnt[12]++;
-		return 0;
-	case HIT_BIND_WITH_VLAN_VIOLATION:
-		dbg_cpu_reason_cnt[13]++;
-		return 0;
-	case HIT_BIND_KEEPALIVE_UC_OLD_HDR:
-		dbg_cpu_reason_cnt[14]++;
-		return 0;
-	case HIT_BIND_KEEPALIVE_MC_NEW_HDR:
-		dbg_cpu_reason_cnt[15]++;
-		return 0;
-	case HIT_BIND_KEEPALIVE_DUP_OLD_HDR:
-		dbg_cpu_reason_cnt[16]++;
-		return 0;
-	case HIT_BIND_FORCE_TO_CPU:
-		dbg_cpu_reason_cnt[17]++;
-		return 0;
-	case HIT_BIND_EXCEED_MTU:
-		dbg_cpu_reason_cnt[18]++;
-		return 0;
-	case HIT_BIND_MULTICAST_TO_CPU:
-		dbg_cpu_reason_cnt[19]++;
-		return 0;
-	case HIT_BIND_MULTICAST_TO_GMAC_CPU:
-		dbg_cpu_reason_cnt[20]++;
-		return 0;
-	case HIT_PRE_BIND:
-		dbg_cpu_reason_cnt[21]++;
-		return 0;
-	}
-
-	return 0;
-}
-
-int hnat_set_usage(int level)
-{
-	debug_level = level;
-	pr_info("Read cpu_reason count: cat /sys/kernel/debug/hnat/cpu_reason\n\n");
-	pr_info("====================Advanced Settings====================\n");
-	pr_info("Usage: echo [type] [option] > /sys/kernel/debug/hnat/cpu_reason\n\n");
-	pr_info("Commands:   [type] [option]\n");
-	pr_info("              0       0~7      Set debug_level(0~7), current debug_level=%d\n",
-		debug_level);
-	pr_info("              1    cpu_reason  Track entries of the set cpu_reason\n");
-	pr_info("                               Set type=1 will change debug_level=7\n");
-	pr_info("cpu_reason list:\n");
-	pr_info("                       2       IPv4(IPv6) TTL(hop limit) = 0\n");
-	pr_info("                       3       IPv4(IPv6) has option(extension) header\n");
-	pr_info("                       7       No flow is assigned\n");
-	pr_info("                       8       IPv4 HNAT doesn't support IPv4 /w fragment\n");
-	pr_info("                       9       IPv4 HNAPT/DS-Lite doesn't support IPv4 /w fragment\n");
-	pr_info("                      10       IPv4 HNAPT/DS-Lite can't find TCP/UDP sport/dport\n");
-	pr_info("                      11       IPv6 5T-route/6RD can't find TCP/UDP sport/dport\n");
-	pr_info("                      12       Ingress packet is TCP fin/syn/rst\n");
-	pr_info("                      13       FOE Un-hit\n");
-	pr_info("                      14       FOE Hit unbind\n");
-	pr_info("                      15       FOE Hit unbind & rate reach\n");
-	pr_info("                      16       Hit bind PPE TCP FIN entry\n");
-	pr_info("                      17       Hit bind PPE entry and TTL(hop limit) = 1\n");
-	pr_info("                      18       Hit bind and VLAN replacement violation\n");
-	pr_info("                      19       Hit bind and keep alive with unicast old-header packet\n");
-	pr_info("                      20       Hit bind and keep alive with multicast new-header packet\n");
-	pr_info("                      21       Hit bind and keep alive with duplicate old-header packet\n");
-	pr_info("                      22       FOE Hit bind & force to CPU\n");
-	pr_info("                      23       HIT_BIND_WITH_OPTION_HEADER\n");
-	pr_info("                      24       Switch clone multicast packet to CPU\n");
-	pr_info("                      25       Switch clone multicast packet to GMAC1 & CPU\n");
-	pr_info("                      26       HIT_PRE_BIND\n");
-	pr_info("                      27       HIT_BIND_PACKET_SAMPLING\n");
-	pr_info("                      28       Hit bind and exceed MTU\n");
-
-	return 0;
-}
-
-int hnat_cpu_reason(int cpu_reason)
-{
-	dbg_cpu_reason = cpu_reason;
-	debug_level = 7;
-	pr_info("show cpu reason = %d\n", cpu_reason);
-
-	return 0;
-}
-
-int entry_set_usage(int level)
-{
-	debug_level = level;
-	pr_info("Show all entries(default state=bind): cat /sys/kernel/debug/hnat/hnat_entry\n\n");
-	pr_info("====================Advanced Settings====================\n");
-	pr_info("Usage: echo [type] [option] > /sys/kernel/debug/hnat/hnat_entry\n\n");
-	pr_info("Commands:   [type] [option]\n");
-	pr_info("              0       0~7      Set debug_level(0~7), current debug_level=%d\n",
-		debug_level);
-	pr_info("              1       0~3      Change tracking state\n");
-	pr_info("                               (0:invalid; 1:unbind; 2:bind; 3:fin)\n");
-	pr_info("              2   <entry_idx>  Show specific foe entry info. of assigned <entry_idx>\n");
-	pr_info("              3   <entry_idx>  Delete specific foe entry of assigned <entry_idx>\n");
-
-	return 0;
-}
-
-int entry_set_state(int state)
-{
-	dbg_entry_state = state;
-	pr_info("ENTRY STATE = %s\n", dbg_entry_state == 0 ?
-		"Invalid" : dbg_entry_state == 1 ?
-		"Unbind" : dbg_entry_state == 2 ?
-		"BIND" : dbg_entry_state == 3 ?
-		"FIN" : "Unknown");
-	return 0;
-}
-
-int entry_detail(int index)
-{
-	struct foe_entry *entry;
-	struct mtk_hnat *h = hnat_priv;
-	u32 *p;
-	u32 i = 0;
-	u32 print_cnt;
-	unsigned char h_dest[ETH_ALEN];
-	unsigned char h_source[ETH_ALEN];
-	__be32 saddr, daddr, nsaddr, ndaddr;
-
-	entry = h->foe_table_cpu + index;
-	saddr = htonl(entry->ipv4_hnapt.sip);
-	daddr = htonl(entry->ipv4_hnapt.dip);
-	nsaddr = htonl(entry->ipv4_hnapt.new_sip);
-	ndaddr = htonl(entry->ipv4_hnapt.new_dip);
-	p = (uint32_t *)entry;
-	pr_info("==========<Flow Table Entry=%d (%p)>===============\n", index,
-		entry);
-	if (debug_level >= 2) {
-		print_cnt = 20;
-		for (i = 0; i < print_cnt; i++)
-			pr_info("%02d: %08X\n", i, *(p + i));
-	}
-	pr_info("-----------------<Flow Info>------------------\n");
-	pr_info("Information Block 1: %08X\n", entry->ipv4_hnapt.info_blk1);
-
-	if (IS_IPV4_HNAPT(entry)) {
-		pr_info("Information Block 2: %08X (FP=%d FQOS=%d QID=%d)",
-			entry->ipv4_hnapt.info_blk2,
-			entry->ipv4_hnapt.info_blk2 >> 5 & 0x7,
-			entry->ipv4_hnapt.info_blk2 >> 4 & 0x1,
-			entry->ipv4_hnapt.iblk2.qid);
-		pr_info("Create IPv4 HNAPT entry\n");
-		pr_info("IPv4 Org IP/Port: %pI4:%d->%pI4:%d\n", &saddr,
-			entry->ipv4_hnapt.sport, &daddr,
-			entry->ipv4_hnapt.dport);
-		pr_info("IPv4 New IP/Port: %pI4:%d->%pI4:%d\n", &nsaddr,
-			entry->ipv4_hnapt.new_sport, &ndaddr,
-			entry->ipv4_hnapt.new_dport);
-	} else if (IS_IPV4_HNAT(entry)) {
-		pr_info("Information Block 2: %08X\n",
-			entry->ipv4_hnapt.info_blk2);
-		pr_info("Create IPv4 HNAT entry\n");
-		pr_info("IPv4 Org IP: %pI4->%pI4\n", &saddr, &daddr);
-		pr_info("IPv4 New IP: %pI4->%pI4\n", &nsaddr, &ndaddr);
-	} else if (IS_IPV4_DSLITE(entry)) {
-		pr_info("Information Block 2: %08X\n",
-			entry->ipv4_dslite.info_blk2);
-		pr_info("Create IPv4 Ds-Lite entry\n");
-		pr_info("IPv4 Ds-Lite: %pI4:%d->%pI4:%d\n", &saddr,
-			entry->ipv4_dslite.sport, &daddr,
-			entry->ipv4_dslite.dport);
-		pr_info("EG DIPv6: %08X:%08X:%08X:%08X->%08X:%08X:%08X:%08X\n",
-			entry->ipv4_dslite.tunnel_sipv6_0,
-			entry->ipv4_dslite.tunnel_sipv6_1,
-			entry->ipv4_dslite.tunnel_sipv6_2,
-			entry->ipv4_dslite.tunnel_sipv6_3,
-			entry->ipv4_dslite.tunnel_dipv6_0,
-			entry->ipv4_dslite.tunnel_dipv6_1,
-			entry->ipv4_dslite.tunnel_dipv6_2,
-			entry->ipv4_dslite.tunnel_dipv6_3);
-	} else if (IS_IPV6_3T_ROUTE(entry)) {
-		pr_info("Information Block 2: %08X\n",
-			entry->ipv6_3t_route.info_blk2);
-		pr_info("Create IPv6 3-Tuple entry\n");
-		pr_info("ING SIPv6->DIPv6: %08X:%08X:%08X:%08X-> %08X:%08X:%08X:%08X (Prot=%d)\n",
-			entry->ipv6_3t_route.ipv6_sip0,
-			entry->ipv6_3t_route.ipv6_sip1,
-			entry->ipv6_3t_route.ipv6_sip2,
-			entry->ipv6_3t_route.ipv6_sip3,
-			entry->ipv6_3t_route.ipv6_dip0,
-			entry->ipv6_3t_route.ipv6_dip1,
-			entry->ipv6_3t_route.ipv6_dip2,
-			entry->ipv6_3t_route.ipv6_dip3,
-			entry->ipv6_3t_route.prot);
-	} else if (IS_IPV6_5T_ROUTE(entry)) {
-		pr_info("Information Block 2: %08X\n",
-			entry->ipv6_5t_route.info_blk2);
-		pr_info("Create IPv6 5-Tuple entry\n");
-		pr_info("ING SIPv6->DIPv6: %08X:%08X:%08X:%08X:%d-> %08X:%08X:%08X:%08X:%d\n",
-			entry->ipv6_5t_route.ipv6_sip0,
-			entry->ipv6_5t_route.ipv6_sip1,
-			entry->ipv6_5t_route.ipv6_sip2,
-			entry->ipv6_5t_route.ipv6_sip3,
-			entry->ipv6_5t_route.sport,
-			entry->ipv6_5t_route.ipv6_dip0,
-			entry->ipv6_5t_route.ipv6_dip1,
-			entry->ipv6_5t_route.ipv6_dip2,
-			entry->ipv6_5t_route.ipv6_dip3,
-			entry->ipv6_5t_route.dport);
-	} else if (IS_IPV6_6RD(entry)) {
-		pr_info("Information Block 2: %08X\n",
-			entry->ipv6_6rd.info_blk2);
-		pr_info("Create IPv6 6RD entry\n");
-		pr_info("ING SIPv6->DIPv6: %08X:%08X:%08X:%08X:%d-> %08X:%08X:%08X:%08X:%d\n",
-			entry->ipv6_6rd.ipv6_sip0, entry->ipv6_6rd.ipv6_sip1,
-			entry->ipv6_6rd.ipv6_sip2, entry->ipv6_6rd.ipv6_sip3,
-			entry->ipv6_6rd.sport, entry->ipv6_6rd.ipv6_dip0,
-			entry->ipv6_6rd.ipv6_dip1, entry->ipv6_6rd.ipv6_dip2,
-			entry->ipv6_6rd.ipv6_dip3, entry->ipv6_6rd.dport);
-	}
-	if (IS_IPV4_HNAPT(entry) || IS_IPV4_HNAT(entry)) {
-		*((u32 *)h_source) = swab32(entry->ipv4_hnapt.smac_hi);
-		*((u16 *)&h_source[4]) = swab16(entry->ipv4_hnapt.smac_lo);
-		*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
-		*((u16 *)&h_dest[4]) = swab16(entry->ipv4_hnapt.dmac_lo);
-		pr_info("SMAC=%pM => DMAC=%pM\n", h_source, h_dest);
-		pr_info("State = %s, ",	entry->bfib1.state == 0 ?
-			"Invalid" : entry->bfib1.state == 1 ?
-			"Unbind" : entry->bfib1.state == 2 ?
-			"BIND" : entry->bfib1.state == 3 ?
-			"FIN" : "Unknown");
-		pr_info("Vlan_Layer = %u, ", entry->bfib1.vlan_layer);
-		pr_info("Eth_type = 0x%x, Vid1 = 0x%x, Vid2 = 0x%x\n",
-			entry->ipv4_hnapt.etype, entry->ipv4_hnapt.vlan1,
-			entry->ipv4_hnapt.vlan2);
-		pr_info("multicast = %d, pppoe = %d, proto = %s\n",
-			entry->ipv4_hnapt.iblk2.mcast,
-			entry->ipv4_hnapt.bfib1.psn,
-			entry->ipv4_hnapt.bfib1.udp == 0 ?
-			"TCP" :	entry->ipv4_hnapt.bfib1.udp == 1 ?
-			"UDP" : "Unknown");
-		pr_info("=========================================\n\n");
-	} else {
-		*((u32 *)h_source) = swab32(entry->ipv6_5t_route.smac_hi);
-		*((u16 *)&h_source[4]) = swab16(entry->ipv6_5t_route.smac_lo);
-		*((u32 *)h_dest) = swab32(entry->ipv6_5t_route.dmac_hi);
-		*((u16 *)&h_dest[4]) = swab16(entry->ipv6_5t_route.dmac_lo);
-		pr_info("SMAC=%pM => DMAC=%pM\n", h_source, h_dest);
-		pr_info("State = %s, ",	entry->bfib1.state == 0 ?
-			"Invalid" : entry->bfib1.state == 1 ?
-			"Unbind" : entry->bfib1.state == 2 ?
-			"BIND" : entry->bfib1.state == 3 ?
-			"FIN" : "Unknown");
-
-		pr_info("Vlan_Layer = %u, ", entry->bfib1.vlan_layer);
-		pr_info("Eth_type = 0x%x, Vid1 = 0x%x, Vid2 = 0x%x\n",
-			entry->ipv6_5t_route.etype, entry->ipv6_5t_route.vlan1,
-			entry->ipv6_5t_route.vlan2);
-		pr_info("multicast = %d, pppoe = %d, proto = %s\n",
-			entry->ipv6_5t_route.iblk2.mcast,
-			entry->ipv6_5t_route.bfib1.psn,
-			entry->ipv6_5t_route.bfib1.udp == 0 ?
-			"TCP" :	entry->ipv6_5t_route.bfib1.udp == 1 ?
-			"UDP" :	"Unknown");
-		pr_info("=========================================\n\n");
-	}
-	return 0;
-}
-
-int entry_delete(int index)
-{
-	struct foe_entry *entry;
-	struct mtk_hnat *h = hnat_priv;
-
-	entry = h->foe_table_cpu + index;
-	memset(entry, 0, sizeof(struct foe_entry));
-
-	/* clear HWNAT cache */
-	hnat_cache_ebl(1);
-
-	pr_info("delete entry idx = %d\n", index);
-
-	return 0;
-}
-EXPORT_SYMBOL(entry_delete);
-
-int cr_set_usage(int level)
-{
-	debug_level = level;
-	pr_info("Dump hnat CR: cat /sys/kernel/debug/hnat/hnat_setting\n\n");
-	pr_info("====================Advanced Settings====================\n");
-	pr_info("Usage: echo [type] [option] > /sys/kernel/debug/hnat/hnat_setting\n\n");
-	pr_info("Commands:   [type] [option]\n");
-	pr_info("              0     0~7        Set debug_level(0~7), current debug_level=%d\n",
-		debug_level);
-	pr_info("              1     0~65535    Set binding threshold\n");
-	pr_info("              2     0~65535    Set TCP bind lifetime\n");
-	pr_info("              3     0~65535    Set FIN bind lifetime\n");
-	pr_info("              4     0~65535    Set UDP bind lifetime\n");
-	pr_info("              5     0~255      Set TCP keep alive interval\n");
-	pr_info("              6     0~255      Set UDP keep alive interval\n");
-	pr_info("              7     0~1        Set hnat disable/enable ipv6\n");
-
-	return 0;
-}
-
-int binding_threshold(int threshold)
-{
-	pr_info("Binding Threshold =%d\n", threshold);
-	writel(threshold, hnat_priv->ppe_base + PPE_BNDR);
-	return 0;
-}
-
-int tcp_bind_lifetime(int tcp_life)
-{
-	pr_info("tcp_life = %d\n", tcp_life);
-	/* set Delta time for aging out an bind TCP FOE entry */
-	cr_set_field(hnat_priv->ppe_base + PPE_BND_AGE_1, TCP_DLTA, tcp_life);
-
-	return 0;
-}
-
-int fin_bind_lifetime(int fin_life)
-{
-	pr_info("fin_life = %d\n", fin_life);
-	/* set Delta time for aging out an bind TCP FIN FOE entry */
-	cr_set_field(hnat_priv->ppe_base + PPE_BND_AGE_1, FIN_DLTA, fin_life);
-
-	return 0;
-}
-
-int udp_bind_lifetime(int udp_life)
-{
-	pr_info("udp_life = %d\n", udp_life);
-	/* set Delta time for aging out an bind UDP FOE entry */
-	cr_set_field(hnat_priv->ppe_base + PPE_BND_AGE_0, UDP_DLTA, udp_life);
-
-	return 0;
-}
-
-int tcp_keep_alive(int tcp_interval)
-{
-	if (tcp_interval > 255) {
-		tcp_interval = 255;
-		pr_info("TCP keep alive max interval = 255\n");
-	} else {
-		pr_info("tcp_interval = %d\n", tcp_interval);
-	}
-	/* Keep alive time for bind FOE TCP entry */
-	cr_set_field(hnat_priv->ppe_base + PPE_KA, TCP_KA, tcp_interval);
-
-	return 0;
-}
-
-int udp_keep_alive(int udp_interval)
-{
-	if (udp_interval > 255) {
-		udp_interval = 255;
-		pr_info("TCP/UDP keep alive max interval = 255\n");
-	} else {
-		pr_info("udp_interval = %d\n", udp_interval);
-	}
-	/* Keep alive timer for bind FOE UDP entry */
-	cr_set_field(hnat_priv->ppe_base + PPE_KA, UDP_KA, udp_interval);
-
-	return 0;
-}
-
-int set_ipv6_toggle(int toggle)
- {
- 	struct mtk_hnat *h = hnat_priv;
-
- 	if (toggle == 1)
- 		pr_info("Enable hnat ipv6\n");
- 	else if (toggle == 0)
- 		pr_info("Disable hnat ipv6\n");
- 	else
- 		pr_info("input error\n");
- 	h->ipv6_en = toggle;
-
- 	return 0;
- }
-
- void mtk_ppe_dev_hook(const char *name, int toggle)
- {
- 	struct net_device *dev;
- 	dev = dev_get_by_name(&init_net, name);
- 	if (dev) {
- 		if (toggle) {
- 			mtk_ppe_dev_register_hook(dev);
- 		} else {
- 			mtk_ppe_dev_unregister_hook(dev);
- 		}
- 	}
- 	return;
- }
-
-
-static const debugfs_write_func hnat_set_func[] = {
-	[0] = hnat_set_usage,
-	[1] = hnat_cpu_reason,
-};
-
-static const debugfs_write_func entry_set_func[] = {
-	[0] = entry_set_usage,
-	[1] = entry_set_state,
-	[2] = entry_detail,
-	[3] = entry_delete,
-};
-
-static const debugfs_write_func cr_set_func[] = {
-	[0] = cr_set_usage,      [1] = binding_threshold,
-	[2] = tcp_bind_lifetime, [3] = fin_bind_lifetime,
-	[4] = udp_bind_lifetime, [5] = tcp_keep_alive,
-	[6] = udp_keep_alive,	[7] = set_ipv6_toggle, 
-};
-
-static struct hnat_accounting *hnat_get_count(struct mtk_hnat *h, u32 index)
-{
-	struct hnat_accounting *acount;
-	u32 val, cnt_r0, cnt_r1, cnt_r2;
-	int ret = -1;
-
-	if (!hnat_priv->data->per_flow_accounting)
-		return NULL;
-
-	writel(index | (1 << 16), h->ppe_base + PPE_MIB_SER_CR);
-	ret = readx_poll_timeout_atomic(readl, h->ppe_base + PPE_MIB_SER_CR, val,
-					!(val & BIT_MIB_BUSY), 20, 10000);
-	if (ret < 0) {
-		pr_notice("mib busy,please check later\n");
-		return NULL;
-	}
-	cnt_r0 = readl(h->ppe_base + PPE_MIB_SER_R0);
-	cnt_r1 = readl(h->ppe_base + PPE_MIB_SER_R1);
-	cnt_r2 = readl(h->ppe_base + PPE_MIB_SER_R2);
-	acount = &h->acct[index];
-	acount->bytes += cnt_r0 + ((u64)(cnt_r1 & 0xffff) << 32);
-	acount->packets +=
-		((cnt_r1 & 0xffff0000) >> 16) + ((cnt_r2 & 0xffffff) << 16);
-
-	return acount;
-}
-
-#define PRINT_COUNT(m, acount) {if (acount) \
-		seq_printf(m, "bytes=%llu|packets=%llu|", \
-			   acount->bytes, acount->packets); }
-static int hnat_debug_show(struct seq_file *m, void *private)
-{
-	struct mtk_hnat *h = hnat_priv;
-	struct foe_entry *entry, *end;
-	unsigned char h_dest[ETH_ALEN];
-	unsigned char h_source[ETH_ALEN];
-	struct hnat_accounting *acount;
-	u32 entry_index = 0;
-
-	entry = h->foe_table_cpu;
-	end = h->foe_table_cpu + hnat_priv->foe_etry_num;
-	while (entry < end) {
-		if (!entry->bfib1.state) {
-			entry++;
-			entry_index++;
-			continue;
-		}
-		acount = hnat_get_count(h, entry_index);
-		if (IS_IPV4_HNAPT(entry)) {
-			__be32 saddr = htonl(entry->ipv4_hnapt.sip);
-			__be32 daddr = htonl(entry->ipv4_hnapt.dip);
-			__be32 nsaddr = htonl(entry->ipv4_hnapt.new_sip);
-			__be32 ndaddr = htonl(entry->ipv4_hnapt.new_dip);
-
-			*((u32 *)h_source) = swab32(entry->ipv4_hnapt.smac_hi);
-			*((u16 *)&h_source[4]) =
-				swab16(entry->ipv4_hnapt.smac_lo);
-			*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
-			*((u16 *)&h_dest[4]) =
-				swab16(entry->ipv4_hnapt.dmac_lo);
-			PRINT_COUNT(m, acount);
-			seq_printf(m,
-				   "addr=0x%p|index=%d|state=%s|type=%s|%pI4:%d->%pI4:%d=>%pI4:%d->%pI4:%d|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x|vlan1=%d|vlan2=%d\n",
-				   entry, ei(entry, end), es(entry), pt(entry), &saddr,
-				   entry->ipv4_hnapt.sport, &daddr,
-				   entry->ipv4_hnapt.dport, &nsaddr,
-				   entry->ipv4_hnapt.new_sport, &ndaddr,
-				   entry->ipv4_hnapt.new_dport, h_source, h_dest,
-				   ntohs(entry->ipv4_hnapt.etype),
-				   entry->ipv4_hnapt.info_blk1,
-				   entry->ipv4_hnapt.info_blk2,
-				   entry->ipv4_hnapt.vlan1,
-				   entry->ipv4_hnapt.vlan2);
-		} else if (IS_IPV4_HNAT(entry)) {
-			__be32 saddr = htonl(entry->ipv4_hnapt.sip);
-			__be32 daddr = htonl(entry->ipv4_hnapt.dip);
-			__be32 nsaddr = htonl(entry->ipv4_hnapt.new_sip);
-			__be32 ndaddr = htonl(entry->ipv4_hnapt.new_dip);
-
-			*((u32 *)h_source) = swab32(entry->ipv4_hnapt.smac_hi);
-			*((u16 *)&h_source[4]) =
-				swab16(entry->ipv4_hnapt.smac_lo);
-			*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
-			*((u16 *)&h_dest[4]) =
-				swab16(entry->ipv4_hnapt.dmac_lo);
-			PRINT_COUNT(m, acount);
-			seq_printf(m,
-				   "addr=0x%p|index=%d|state=%s|type=%s|%pI4->%pI4=>%pI4->%pI4|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x|vlan1=%d|vlan2=%d\n",
-				   entry, ei(entry, end), es(entry), pt(entry), &saddr,
-				   &daddr, &nsaddr, &ndaddr, h_source, h_dest,
-				   ntohs(entry->ipv4_hnapt.etype),
-				   entry->ipv4_hnapt.info_blk1,
-				   entry->ipv4_hnapt.info_blk2,
-				   entry->ipv4_hnapt.vlan1,
-				   entry->ipv4_hnapt.vlan2);
-		} else if (IS_IPV6_5T_ROUTE(entry)) {
-			u32 ipv6_sip0 = entry->ipv6_3t_route.ipv6_sip0;
-			u32 ipv6_sip1 = entry->ipv6_3t_route.ipv6_sip1;
-			u32 ipv6_sip2 = entry->ipv6_3t_route.ipv6_sip2;
-			u32 ipv6_sip3 = entry->ipv6_3t_route.ipv6_sip3;
-			u32 ipv6_dip0 = entry->ipv6_3t_route.ipv6_dip0;
-			u32 ipv6_dip1 = entry->ipv6_3t_route.ipv6_dip1;
-			u32 ipv6_dip2 = entry->ipv6_3t_route.ipv6_dip2;
-			u32 ipv6_dip3 = entry->ipv6_3t_route.ipv6_dip3;
-
-			*((u32 *)h_source) =
-				swab32(entry->ipv6_5t_route.smac_hi);
-			*((u16 *)&h_source[4]) =
-				swab16(entry->ipv6_5t_route.smac_lo);
-			*((u32 *)h_dest) = swab32(entry->ipv6_5t_route.dmac_hi);
-			*((u16 *)&h_dest[4]) =
-				swab16(entry->ipv6_5t_route.dmac_lo);
-			PRINT_COUNT(m, acount);
-			seq_printf(m,
-				   "addr=0x%p|index=%d|state=%s|type=%s|SIP=%08x:%08x:%08x:%08x(sp=%d)->DIP=%08x:%08x:%08x:%08x(dp=%d)|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x\n",
-				   entry, ei(entry, end), es(entry), pt(entry), ipv6_sip0,
-				   ipv6_sip1, ipv6_sip2, ipv6_sip3,
-				   entry->ipv6_5t_route.sport, ipv6_dip0,
-				   ipv6_dip1, ipv6_dip2, ipv6_dip3,
-				   entry->ipv6_5t_route.dport, h_source, h_dest,
-				   ntohs(entry->ipv6_5t_route.etype),
-				   entry->ipv6_5t_route.info_blk1,
-				   entry->ipv6_5t_route.info_blk2);
-		} else if (IS_IPV6_3T_ROUTE(entry)) {
-			u32 ipv6_sip0 = entry->ipv6_3t_route.ipv6_sip0;
-			u32 ipv6_sip1 = entry->ipv6_3t_route.ipv6_sip1;
-			u32 ipv6_sip2 = entry->ipv6_3t_route.ipv6_sip2;
-			u32 ipv6_sip3 = entry->ipv6_3t_route.ipv6_sip3;
-			u32 ipv6_dip0 = entry->ipv6_3t_route.ipv6_dip0;
-			u32 ipv6_dip1 = entry->ipv6_3t_route.ipv6_dip1;
-			u32 ipv6_dip2 = entry->ipv6_3t_route.ipv6_dip2;
-			u32 ipv6_dip3 = entry->ipv6_3t_route.ipv6_dip3;
-
-			*((u32 *)h_source) =
-				swab32(entry->ipv6_5t_route.smac_hi);
-			*((u16 *)&h_source[4]) =
-				swab16(entry->ipv6_5t_route.smac_lo);
-			*((u32 *)h_dest) = swab32(entry->ipv6_5t_route.dmac_hi);
-			*((u16 *)&h_dest[4]) =
-				swab16(entry->ipv6_5t_route.dmac_lo);
-			PRINT_COUNT(m, acount);
-			seq_printf(m,
-				   "addr=0x%p|index=%d|state=%s|type=%s|SIP=%08x:%08x:%08x:%08x->DIP=%08x:%08x:%08x:%08x|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x\n",
-				   entry, ei(entry, end), es(entry), pt(entry), ipv6_sip0,
-				   ipv6_sip1, ipv6_sip2, ipv6_sip3, ipv6_dip0,
-				   ipv6_dip1, ipv6_dip2, ipv6_dip3, h_source,
-				   h_dest, ntohs(entry->ipv6_5t_route.etype),
-				   entry->ipv6_5t_route.info_blk1,
-				   entry->ipv6_5t_route.info_blk2);
-		} else if (IS_IPV6_6RD(entry)) {
-			u32 ipv6_sip0 = entry->ipv6_3t_route.ipv6_sip0;
-			u32 ipv6_sip1 = entry->ipv6_3t_route.ipv6_sip1;
-			u32 ipv6_sip2 = entry->ipv6_3t_route.ipv6_sip2;
-			u32 ipv6_sip3 = entry->ipv6_3t_route.ipv6_sip3;
-			u32 ipv6_dip0 = entry->ipv6_3t_route.ipv6_dip0;
-			u32 ipv6_dip1 = entry->ipv6_3t_route.ipv6_dip1;
-			u32 ipv6_dip2 = entry->ipv6_3t_route.ipv6_dip2;
-			u32 ipv6_dip3 = entry->ipv6_3t_route.ipv6_dip3;
-			__be32 tsaddr = htonl(entry->ipv6_6rd.tunnel_sipv4);
-			__be32 tdaddr = htonl(entry->ipv6_6rd.tunnel_dipv4);
-
-			*((u32 *)h_source) =
-				swab32(entry->ipv6_5t_route.smac_hi);
-			*((u16 *)&h_source[4]) =
-				swab16(entry->ipv6_5t_route.smac_lo);
-			*((u32 *)h_dest) = swab32(entry->ipv6_5t_route.dmac_hi);
-			*((u16 *)&h_dest[4]) =
-				swab16(entry->ipv6_5t_route.dmac_lo);
-			PRINT_COUNT(m, acount);
-			seq_printf(m,
-				   "addr=0x%p|index=%d|state=%s|type=%s|SIP=%08x:%08x:%08x:%08x(sp=%d)->DIP=%08x:%08x:%08x:%08x(dp=%d)|TSIP=%pI4->TDIP=%pI4|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x\n",
-				   entry, ei(entry, end), es(entry), pt(entry), ipv6_sip0,
-				   ipv6_sip1, ipv6_sip2, ipv6_sip3,
-				   entry->ipv6_5t_route.sport, ipv6_dip0,
-				   ipv6_dip1, ipv6_dip2, ipv6_dip3,
-				   entry->ipv6_5t_route.dport, &tsaddr, &tdaddr,
-				   h_source, h_dest,
-				   ntohs(entry->ipv6_5t_route.etype),
-				   entry->ipv6_5t_route.info_blk1,
-				   entry->ipv6_5t_route.info_blk2);
-		} else if (IS_IPV4_DSLITE(entry)) {
-			__be32 saddr = htonl(entry->ipv4_hnapt.sip);
-			__be32 daddr = htonl(entry->ipv4_hnapt.dip);
-			u32 ipv6_tsip0 = entry->ipv4_dslite.tunnel_sipv6_0;
-			u32 ipv6_tsip1 = entry->ipv4_dslite.tunnel_sipv6_1;
-			u32 ipv6_tsip2 = entry->ipv4_dslite.tunnel_sipv6_2;
-			u32 ipv6_tsip3 = entry->ipv4_dslite.tunnel_sipv6_3;
-			u32 ipv6_tdip0 = entry->ipv4_dslite.tunnel_dipv6_0;
-			u32 ipv6_tdip1 = entry->ipv4_dslite.tunnel_dipv6_1;
-			u32 ipv6_tdip2 = entry->ipv4_dslite.tunnel_dipv6_2;
-			u32 ipv6_tdip3 = entry->ipv4_dslite.tunnel_dipv6_3;
-
-			*((u32 *)h_source) = swab32(entry->ipv4_hnapt.smac_hi);
-			*((u16 *)&h_source[4]) =
-				swab16(entry->ipv4_hnapt.smac_lo);
-			*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
-			*((u16 *)&h_dest[4]) =
-				swab16(entry->ipv4_hnapt.dmac_lo);
-			PRINT_COUNT(m, acount);
-			seq_printf(m,
-				   "addr=0x%p|index=%d|state=%s|type=%s|SIP=%pI4->DIP=%pI4|TSIP=%08x:%08x:%08x:%08x->TDIP=%08x:%08x:%08x:%08x|%pM=>%pM|etype=0x%04x|info1=0x%x|info2=0x%x\n",
-				   entry, ei(entry, end), es(entry), pt(entry), &saddr,
-				   &daddr, ipv6_tsip0, ipv6_tsip1, ipv6_tsip2,
-				   ipv6_tsip3, ipv6_tdip0, ipv6_tdip1, ipv6_tdip2,
-				   ipv6_tdip3, h_source, h_dest,
-				   ntohs(entry->ipv6_5t_route.etype),
-				   entry->ipv6_5t_route.info_blk1,
-				   entry->ipv6_5t_route.info_blk2);
-		} else
-			seq_printf(m, "addr=0x%p|index=%d state=%s\n", entry, ei(entry, end),
-				   es(entry));
-		entry++;
-		entry_index++;
-	}
-
-	return 0;
-}
-
-static int hnat_debug_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_debug_show, file->private_data);
-}
-
-static const struct file_operations hnat_debug_fops = {
-	.open = hnat_debug_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.release = single_release,
-};
-
-static int hnat_whnat_show(struct seq_file *m, void *private)
-{
-	int i;
-	struct net_device *dev;
-
-	for (i = 0; i < MAX_IF_NUM; i++) {
-		dev = hnat_priv->wifi_hook_if[i];
-		if (dev)
-			seq_printf(m, "%d:%s\n", i, dev->name);
-		else
-			continue;
-	}
-
-	return 0;
-}
-
-static int hnat_whnat_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_whnat_show, file->private_data);
-}
-
-static const struct file_operations hnat_whnat_fops = {
-	.open = hnat_whnat_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.release = single_release,
-};
-
-int cpu_reason_read(struct seq_file *m, void *private)
-{
-	int i;
-
-	pr_info("============ CPU REASON =========\n");
-	pr_info("(2)IPv4(IPv6) TTL(hop limit) = %u\n", dbg_cpu_reason_cnt[0]);
-	pr_info("(3)Ipv4(IPv6) has option(extension) header = %u\n",
-		dbg_cpu_reason_cnt[1]);
-	pr_info("(7)No flow is assigned = %u\n", dbg_cpu_reason_cnt[2]);
-	pr_info("(8)IPv4 HNAT doesn't support IPv4 /w fragment = %u\n",
-		dbg_cpu_reason_cnt[3]);
-	pr_info("(9)IPv4 HNAPT/DS-Lite doesn't support IPv4 /w fragment = %u\n",
-		dbg_cpu_reason_cnt[4]);
-	pr_info("(10)IPv4 HNAPT/DS-Lite can't find TCP/UDP sport/dport = %u\n",
-		dbg_cpu_reason_cnt[5]);
-	pr_info("(11)IPv6 5T-route/6RD can't find TCP/UDP sport/dport = %u\n",
-		dbg_cpu_reason_cnt[6]);
-	pr_info("(12)Ingress packet is TCP fin/syn/rst = %u\n",
-		dbg_cpu_reason_cnt[7]);
-	pr_info("(13)FOE Un-hit = %u\n", dbg_cpu_reason_cnt[8]);
-	pr_info("(14)FOE Hit unbind = %u\n", dbg_cpu_reason_cnt[9]);
-	pr_info("(15)FOE Hit unbind & rate reach = %u\n",
-		dbg_cpu_reason_cnt[10]);
-	pr_info("(16)Hit bind PPE TCP FIN entry = %u\n",
-		dbg_cpu_reason_cnt[11]);
-	pr_info("(17)Hit bind PPE entry and TTL(hop limit) = 1 and TTL(hot limit) - 1 = %u\n",
-		dbg_cpu_reason_cnt[12]);
-	pr_info("(18)Hit bind and VLAN replacement violation = %u\n",
-		dbg_cpu_reason_cnt[13]);
-	pr_info("(19)Hit bind and keep alive with unicast old-header packet = %u\n",
-		dbg_cpu_reason_cnt[14]);
-	pr_info("(20)Hit bind and keep alive with multicast new-header packet = %u\n",
-		dbg_cpu_reason_cnt[15]);
-	pr_info("(21)Hit bind and keep alive with duplicate old-header packet = %u\n",
-		dbg_cpu_reason_cnt[16]);
-	pr_info("(22)FOE Hit bind & force to CPU = %u\n",
-		dbg_cpu_reason_cnt[17]);
-	pr_info("(28)Hit bind and exceed MTU =%u\n", dbg_cpu_reason_cnt[18]);
-	pr_info("(24)Hit bind multicast packet to CPU = %u\n",
-		dbg_cpu_reason_cnt[19]);
-	pr_info("(25)Hit bind multicast packet to GMAC & CPU = %u\n",
-		dbg_cpu_reason_cnt[20]);
-	pr_info("(26)Pre bind = %u\n", dbg_cpu_reason_cnt[21]);
-
-	for (i = 0; i < 22; i++)
-		dbg_cpu_reason_cnt[i] = 0;
-	return 0;
-}
-
-static int cpu_reason_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, cpu_reason_read, file->private_data);
-}
-
-ssize_t cpu_reason_write(struct file *file, const char __user *buffer,
-			 size_t count, loff_t *data)
-{
-	char buf[32];
-	char *p_buf;
-	int len = count;
-	long arg0 = 0, arg1 = 0;
-	char *p_token = NULL;
-	char *p_delimiter = " \t";
-	int ret;
-
-	if (len >= sizeof(buf)) {
-		pr_info("input handling fail!\n");
-		len = sizeof(buf) - 1;
-		return -1;
-	}
-
-	if (copy_from_user(buf, buffer, len))
-		return -EFAULT;
-
-	buf[len] = '\0';
-
-	p_buf = buf;
-	p_token = strsep(&p_buf, p_delimiter);
-	if (!p_token)
-		arg0 = 0;
-	else
-		ret = kstrtol(p_token, 10, &arg0);
-
-	switch (arg0) {
-	case 0:
-	case 1:
-		p_token = strsep(&p_buf, p_delimiter);
-		if (!p_token)
-			arg1 = 0;
-		else
-			ret = kstrtol(p_token, 10, &arg1);
-		break;
-	default:
-		pr_info("no handler defined for command id(0x%08lx)\n\r", arg0);
-		arg0 = 0;
-		arg1 = 0;
-		break;
-	}
-
-	(*hnat_set_func[arg0])(arg1);
-
-	return len;
-}
-
-static const struct file_operations cpu_reason_fops = {
-	.open = cpu_reason_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.write = cpu_reason_write,
-	.release = single_release,
-};
-
-void dbg_dump_entry(struct seq_file *m, struct foe_entry *entry,
-		    uint32_t index)
-{
-	__be32 saddr, daddr, nsaddr, ndaddr;
-
-	saddr = htonl(entry->ipv4_hnapt.sip);
-	daddr = htonl(entry->ipv4_hnapt.dip);
-	nsaddr = htonl(entry->ipv4_hnapt.new_sip);
-	ndaddr = htonl(entry->ipv4_hnapt.new_dip);
-
-	if (IS_IPV4_HNAPT(entry)) {
-		seq_printf(m,
-			   "NAPT(%d): %pI4:%d->%pI4:%d => %pI4:%d->%pI4:%d\n",
-			   index, &saddr, entry->ipv4_hnapt.sport, &daddr,
-			   entry->ipv4_hnapt.dport, &nsaddr,
-			   entry->ipv4_hnapt.new_sport, &ndaddr,
-			   entry->ipv4_hnapt.new_dport);
-	} else if (IS_IPV4_HNAT(entry)) {
-		seq_printf(m, "NAT(%d): %pI4->%pI4 => %pI4->%pI4\n",
-			   index, &saddr, &daddr, &nsaddr, &ndaddr);
-	}
-
-	if (IS_IPV4_DSLITE(entry)) {
-		seq_printf(m,
-			   "IPv4 Ds-Lite(%d): %pI4:%d->%pI4:%d => %08X:%08X:%08X:%08X->%08X:%08X:%08X:%08X\n",
-			   index, &saddr, entry->ipv4_dslite.sport, &daddr,
-			   entry->ipv4_dslite.dport,
-			   entry->ipv4_dslite.tunnel_sipv6_0,
-			   entry->ipv4_dslite.tunnel_sipv6_1,
-			   entry->ipv4_dslite.tunnel_sipv6_2,
-			   entry->ipv4_dslite.tunnel_sipv6_3,
-			   entry->ipv4_dslite.tunnel_dipv6_0,
-			   entry->ipv4_dslite.tunnel_dipv6_1,
-			   entry->ipv4_dslite.tunnel_dipv6_2,
-			   entry->ipv4_dslite.tunnel_dipv6_3);
-	} else if (IS_IPV6_3T_ROUTE(entry)) {
-		seq_printf(m,
-			   "IPv6_3T(%d): %08X:%08X:%08X:%08X => %08X:%08X:%08X:%08X (Prot=%d)\n",
-			   index, entry->ipv6_3t_route.ipv6_sip0,
-			   entry->ipv6_3t_route.ipv6_sip1,
-			   entry->ipv6_3t_route.ipv6_sip2,
-			   entry->ipv6_3t_route.ipv6_sip3,
-			   entry->ipv6_3t_route.ipv6_dip0,
-			   entry->ipv6_3t_route.ipv6_dip1,
-			   entry->ipv6_3t_route.ipv6_dip2,
-			   entry->ipv6_3t_route.ipv6_dip3,
-			   entry->ipv6_3t_route.prot);
-	} else if (IS_IPV6_5T_ROUTE(entry)) {
-		seq_printf(m,
-			   "IPv6_5T(%d): %08X:%08X:%08X:%08X:%d => %08X:%08X:%08X:%08X:%d\n",
-			   index, entry->ipv6_5t_route.ipv6_sip0,
-			   entry->ipv6_5t_route.ipv6_sip1,
-			   entry->ipv6_5t_route.ipv6_sip2,
-			   entry->ipv6_5t_route.ipv6_sip3,
-			   entry->ipv6_5t_route.sport,
-			   entry->ipv6_5t_route.ipv6_dip0,
-			   entry->ipv6_5t_route.ipv6_dip1,
-			   entry->ipv6_5t_route.ipv6_dip2,
-			   entry->ipv6_5t_route.ipv6_dip3,
-			   entry->ipv6_5t_route.dport);
-	} else if (IS_IPV6_6RD(entry)) {
-		seq_printf(m,
-			   "IPv6_6RD(%d): %08X:%08X:%08X:%08X:%d => %08X:%08X:%08X:%08X:%d\n",
-			   index, entry->ipv6_6rd.ipv6_sip0,
-			   entry->ipv6_6rd.ipv6_sip1, entry->ipv6_6rd.ipv6_sip2,
-			   entry->ipv6_6rd.ipv6_sip3, entry->ipv6_6rd.sport,
-			   entry->ipv6_6rd.ipv6_dip0, entry->ipv6_6rd.ipv6_dip1,
-			   entry->ipv6_6rd.ipv6_dip2, entry->ipv6_6rd.ipv6_dip3,
-			   entry->ipv6_6rd.dport);
-	}
-}
-
-int hnat_entry_read(struct seq_file *m, void *private)
-{
-	struct mtk_hnat *h = hnat_priv;
-	struct foe_entry *entry, *end;
-	int hash_index;
-	int cnt;
-
-	hash_index = 0;
-	cnt = 0;
-	entry = h->foe_table_cpu;
-	end = h->foe_table_cpu + hnat_priv->foe_etry_num;
-
-	while (entry < end) {
-		if (entry->bfib1.state == dbg_entry_state) {
-			cnt++;
-			dbg_dump_entry(m, entry, hash_index);
-		}
-		hash_index++;
-		entry++;
-	}
-
-	seq_printf(m, "Total State = %s cnt = %d\n",
-		   dbg_entry_state == 0 ?
-		   "Invalid" : dbg_entry_state == 1 ?
-		   "Unbind" : dbg_entry_state == 2 ?
-		   "BIND" : dbg_entry_state == 3 ?
-		   "FIN" : "Unknown", cnt);
-
-	return 0;
-}
-
-ssize_t hnat_entry_write(struct file *file, const char __user *buffer,
-			 size_t count, loff_t *data)
-{
-	char buf[32];
-	char *p_buf;
-	int len = count;
-	long arg0 = 0, arg1 = 0;
-	char *p_token = NULL;
-	char *p_delimiter = " \t";
-	int ret;
-
-	if (len >= sizeof(buf)) {
-		pr_info("input handling fail!\n");
-		len = sizeof(buf) - 1;
-		return -1;
-	}
-
-	if (copy_from_user(buf, buffer, len))
-		return -EFAULT;
-
-	buf[len] = '\0';
-
-	p_buf = buf;
-	p_token = strsep(&p_buf, p_delimiter);
-	if (!p_token)
-		arg0 = 0;
-	else
-		ret = kstrtol(p_token, 10, &arg0);
-
-	switch (arg0) {
-	case 0:
-	case 1:
-	case 2:
-	case 3:
-		p_token = strsep(&p_buf, p_delimiter);
-		if (!p_token)
-			arg1 = 0;
-		else
-			ret = kstrtol(p_token, 10, &arg1);
-		break;
-	default:
-		pr_info("no handler defined for command id(0x%08lx)\n\r", arg0);
-		arg0 = 0;
-		arg1 = 0;
-		break;
-	}
-
-	(*entry_set_func[arg0])(arg1);
-
-	return len;
-}
-
-static int hnat_entry_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_entry_read, file->private_data);
-}
-
-static const struct file_operations hnat_entry_fops = {
-	.open = hnat_entry_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.write = hnat_entry_write,
-	.release = single_release,
-};
-
-int hnat_setting_read(struct seq_file *m, void *private)
-{
-	struct mtk_hnat *h = hnat_priv;
-	int i;
-	int cr_max;
-
-	cr_max = 319 * 4;
-	for (i = 0; i < cr_max; i = i + 0x10) {
-		pr_info("0x%p : 0x%08x 0x%08x 0x%08x 0x%08x\n",
-			(void *)h->foe_table_dev + i, readl(h->ppe_base + i),
-			readl(h->ppe_base + i + 4), readl(h->ppe_base + i + 8),
-			readl(h->ppe_base + i + 0xc));
-	}
-
-	return 0;
-}
-
-static int hnat_setting_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_setting_read, file->private_data);
-}
-
-ssize_t hnat_setting_write(struct file *file, const char __user *buffer,
-			   size_t count, loff_t *data)
-{
-	char buf[32];
-	char *p_buf;
-	int len = count;
-	long arg0 = 0, arg1 = 0;
-	char *p_token = NULL;
-	char *p_delimiter = " \t";
-	int ret;
-
-	if (len >= sizeof(buf)) {
-		pr_info("input handling fail!\n");
-		len = sizeof(buf) - 1;
-		return -1;
-	}
-
-	if (copy_from_user(buf, buffer, len))
-		return -EFAULT;
-
-	buf[len] = '\0';
-
-	p_buf = buf;
-	p_token = strsep(&p_buf, p_delimiter);
-	if (!p_token)
-		arg0 = 0;
-	else
-		ret = kstrtol(p_token, 10, &arg0);
-
-	switch (arg0) {
-	case 0:
-	case 1:
-	case 2:
-	case 3:
-	case 4:
-	case 5:
-	case 6:
-	case 7:
-		p_token = strsep(&p_buf, p_delimiter);
-		if (!p_token)
-			arg1 = 0;
-		else
-			ret = kstrtol(p_token, 10, &arg1);
-		break;
-	default:
-		pr_info("no handler defined for command id(0x%08lx)\n\r", arg0);
-		arg0 = 0;
-		arg1 = 0;
-		break;
-	}
-
-	(*cr_set_func[arg0])(arg1);
-
-	return len;
-}
-
-static const struct file_operations hnat_setting_fops = {
-	.open = hnat_setting_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.write = hnat_setting_write,
-	.release = single_release,
-};
-
-int mcast_table_dump(struct seq_file *m, void *private)
-{
-	struct mtk_hnat *h = hnat_priv;
-	struct ppe_mcast_h mcast_h;
-	struct ppe_mcast_l mcast_l;
-	u8 i, max;
-	void __iomem *reg;
-
-	if (!h->pmcast)
-		return 0;
-
-	max = h->pmcast->max_entry;
-	pr_info("MAC | VID | PortMask | QosPortMask\n");
-	for (i = 0; i < max; i++) {
-		if (i < 0x10) {
-			reg = h->ppe_base + PPE_MCAST_H_0 + i * 8;
-			mcast_h.u.value = readl(reg);
-			reg = h->ppe_base + PPE_MCAST_L_0 + i * 8;
-			mcast_l.addr = readl(reg);
-		} else {
-			reg = h->fe_base + PPE_MCAST_H_10 + (i - 0x10) * 8;
-			mcast_h.u.value = readl(reg);
-			reg = h->fe_base + PPE_MCAST_L_10 + (i - 0x10) * 8;
-			mcast_l.addr = readl(reg);
-		}
-		pr_info("%08x %d %c%c%c%c %c%c%c%c (QID=%d, mc_mpre_sel=%d)\n",
-			mcast_l.addr,
-			mcast_h.u.info.mc_vid,
-			(mcast_h.u.info.mc_px_en & 0x08) ? '1' : '-',
-			(mcast_h.u.info.mc_px_en & 0x04) ? '1' : '-',
-			(mcast_h.u.info.mc_px_en & 0x02) ? '1' : '-',
-			(mcast_h.u.info.mc_px_en & 0x01) ? '1' : '-',
-			(mcast_h.u.info.mc_px_qos_en & 0x08) ? '1' : '-',
-			(mcast_h.u.info.mc_px_qos_en & 0x04) ? '1' : '-',
-			(mcast_h.u.info.mc_px_qos_en & 0x02) ? '1' : '-',
-			(mcast_h.u.info.mc_px_qos_en & 0x01) ? '1' : '-',
-			mcast_h.u.info.mc_qos_qid +
-			((mcast_h.u.info.mc_qos_qid54) << 4),
-			mcast_h.u.info.mc_mpre_sel);
-	}
-
-	return 0;
-}
-
-static int mcast_table_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, mcast_table_dump, file->private_data);
-}
-
-static const struct file_operations hnat_mcast_fops = {
-	.open = mcast_table_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.release = single_release,
-};
-
-static int hnat_ext_show(struct seq_file *m, void *private)
-{
-	int i;
-	struct extdev_entry *ext_entry;
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		if (ext_entry->dev)
-			seq_printf(m, "ext devices [%d] = %s  (dev=%p, ifindex=%d)\n",
-				   i, ext_entry->name, ext_entry->dev,
-				   ext_entry->dev->ifindex);
-	}
-
-	return 0;
-}
-
-static int hnat_ext_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_ext_show, file->private_data);
-}
-
-static const struct file_operations hnat_ext_fops = {
-	.open = hnat_ext_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.release = single_release,
-};
-
-static ssize_t hnat_sched_show(struct file *file, char __user *user_buf,
-			       size_t count, loff_t *ppos)
-{
-	long id = (long)file->private_data;
-	struct mtk_hnat *h = hnat_priv;
-	u32 qdma_tx_sch;
-	int enable;
-	int scheduling;
-	int max_rate;
-	char *buf;
-	unsigned int len = 0, buf_len = 1500;
-	ssize_t ret_cnt;
-	int scheduler, i;
-	u32 sch_reg;
-
-	buf = kzalloc(buf_len, GFP_KERNEL);
-	if (!buf)
-		return -ENOMEM;
-
-	if (hnat_priv->data->num_of_sch == 4)
-		qdma_tx_sch = readl(h->fe_base + QDMA_TX_4SCH_BASE(id));
-	else
-		qdma_tx_sch = readl(h->fe_base + QDMA_TX_2SCH_BASE);
-
-	if (id & 0x1)
-		qdma_tx_sch >>= 16;
-	qdma_tx_sch &= 0xffff;
-	enable = !!(qdma_tx_sch & BIT(11));
-	scheduling = !!(qdma_tx_sch & BIT(15));
-	max_rate = ((qdma_tx_sch >> 4) & 0x7f);
-	qdma_tx_sch &= 0xf;
-	while (qdma_tx_sch--)
-		max_rate *= 10;
-
-	len += scnprintf(buf + len, buf_len - len,
-			 "EN\tScheduling\tMAX\tQueue#\n%d\t%s%16d\t", enable,
-			 (scheduling == 1) ? "WRR" : "SP", max_rate);
-
-	for (i = 0; i < MTK_QDMA_TX_NUM; i++) {
-		cr_set_field(h->fe_base + QDMA_PAGE, QTX_CFG_PAGE,
-			     (i / NUM_OF_Q_PER_PAGE));
-		sch_reg = readl(h->fe_base + QTX_SCH(i % NUM_OF_Q_PER_PAGE));
-		if (hnat_priv->data->num_of_sch == 4)
-			scheduler = (sch_reg >> 30) & 0x3;
-		else
-			scheduler = !!(sch_reg & BIT(31));
-		if (id == scheduler)
-			len += scnprintf(buf + len, buf_len - len, "%d  ", i);
-	}
-
-	len += scnprintf(buf + len, buf_len - len, "\n");
-	if (len > buf_len)
-		len = buf_len;
-
-	ret_cnt = simple_read_from_buffer(user_buf, count, ppos, buf, len);
-
-	kfree(buf);
-	return ret_cnt;
-}
-
-static ssize_t hnat_sched_write(struct file *file, const char __user *buf,
-				size_t length, loff_t *offset)
-{
-	long id = (long)file->private_data;
-	struct mtk_hnat *h = hnat_priv;
-	char line[64];
-	int enable, rate, exp = 0, shift = 0;
-	char scheduling[32];
-	size_t size;
-	u32 qdma_tx_sch;
-	u32 val = 0;
-
-	if (length > sizeof(line))
-		return -EINVAL;
-
-	if (copy_from_user(line, buf, length))
-		return -EFAULT;
-
-	if (sscanf(line, "%d %s %d", &enable, scheduling, &rate) != 3)
-		return -EFAULT;
-
-	while (rate > 127) {
-		rate /= 10;
-		exp++;
-	}
-
-	if (enable)
-		val |= BIT(11);
-	if (strcmp(scheduling, "sp") != 0)
-		val |= BIT(15);
-	val |= (rate & 0x7f) << 4;
-	val |= exp & 0xf;
-	if (id & 0x1)
-		shift = 16;
-
-	if (hnat_priv->data->num_of_sch == 4)
-		qdma_tx_sch = readl(h->fe_base + QDMA_TX_4SCH_BASE(id));
-	else
-		qdma_tx_sch = readl(h->fe_base + QDMA_TX_2SCH_BASE);
-
-	qdma_tx_sch &= ~(0xffff << shift);
-	qdma_tx_sch |= val << shift;
-	if (hnat_priv->data->num_of_sch == 4)
-		writel(qdma_tx_sch, h->fe_base + QDMA_TX_4SCH_BASE(id));
-	else
-		writel(qdma_tx_sch, h->fe_base + QDMA_TX_2SCH_BASE);
-
-	size = strlen(line);
-	*offset += size;
-
-	return length;
-}
-
-static const struct file_operations hnat_sched_fops = {
-	.open = simple_open,
-	.read = hnat_sched_show,
-	.write = hnat_sched_write,
-	.llseek = default_llseek,
-};
-
-static ssize_t hnat_queue_show(struct file *file, char __user *user_buf,
-			       size_t count, loff_t *ppos)
-{
-	struct mtk_hnat *h = hnat_priv;
-	long id = (long)file->private_data;
-	u32 qtx_sch;
-	u32 qtx_cfg;
-	int scheduler;
-	int min_rate_en;
-	int min_rate;
-	int min_rate_exp;
-	int max_rate_en;
-	int max_weight;
-	int max_rate;
-	int max_rate_exp;
-	char *buf;
-	unsigned int len = 0, buf_len = 1500;
-	ssize_t ret_cnt;
-
-	buf = kzalloc(buf_len, GFP_KERNEL);
-	if (!buf)
-		return -ENOMEM;
-
-	cr_set_field(h->fe_base + QDMA_PAGE, QTX_CFG_PAGE, (id / NUM_OF_Q_PER_PAGE));
-	qtx_cfg = readl(h->fe_base + QTX_CFG(id % NUM_OF_Q_PER_PAGE));
-	qtx_sch = readl(h->fe_base + QTX_SCH(id % NUM_OF_Q_PER_PAGE));
-	if (hnat_priv->data->num_of_sch == 4)
-		scheduler = (qtx_sch >> 30) & 0x3;
-	else
-		scheduler = !!(qtx_sch & BIT(31));
-	min_rate_en = !!(qtx_sch & BIT(27));
-	min_rate = (qtx_sch >> 20) & 0x7f;
-	min_rate_exp = (qtx_sch >> 16) & 0xf;
-	max_rate_en = !!(qtx_sch & BIT(11));
-	max_weight = (qtx_sch >> 12) & 0xf;
-	max_rate = (qtx_sch >> 4) & 0x7f;
-	max_rate_exp = qtx_sch & 0xf;
-	while (min_rate_exp--)
-		min_rate *= 10;
-
-	while (max_rate_exp--)
-		max_rate *= 10;
-
-	len += scnprintf(buf + len, buf_len - len,
-			 "scheduler: %d\nhw resv: %d\nsw resv: %d\n", scheduler,
-			 (qtx_cfg >> 8) & 0xff, qtx_cfg & 0xff);
-
-	if (hnat_priv->data->version != MTK_HNAT_V1) {
-		/* Switch to debug mode */
-		cr_set_field(h->fe_base + QTX_MIB_IF, MIB_ON_QTX_CFG, 1);
-		cr_set_field(h->fe_base + QTX_MIB_IF, VQTX_MIB_EN, 1);
-		qtx_cfg = readl(h->fe_base + QTX_CFG(id % NUM_OF_Q_PER_PAGE));
-		qtx_sch = readl(h->fe_base + QTX_SCH(id % NUM_OF_Q_PER_PAGE));
-		len += scnprintf(buf + len, buf_len - len,
-				 "packet count: %u\n", qtx_cfg);
-		len += scnprintf(buf + len, buf_len - len,
-				 "packet drop: %u\n\n", qtx_sch);
-
-		/* Recover to normal mode */
-		cr_set_field(hnat_priv->fe_base + QTX_MIB_IF,
-			     MIB_ON_QTX_CFG, 0);
-		cr_set_field(hnat_priv->fe_base + QTX_MIB_IF, VQTX_MIB_EN, 0);
-	}
-
-	len += scnprintf(buf + len, buf_len - len,
-			 "      EN     RATE     WEIGHT\n");
-	len += scnprintf(buf + len, buf_len - len,
-			 "----------------------------\n");
-	len += scnprintf(buf + len, buf_len - len,
-			 "max%5d%9d%9d\n", max_rate_en, max_rate, max_weight);
-	len += scnprintf(buf + len, buf_len - len,
-			 "min%5d%9d        -\n", min_rate_en, min_rate);
-
-	if (len > buf_len)
-		len = buf_len;
-
-	ret_cnt = simple_read_from_buffer(user_buf, count, ppos, buf, len);
-
-	kfree(buf);
-	return ret_cnt;
-}
-
-static ssize_t hnat_queue_write(struct file *file, const char __user *buf,
-				size_t length, loff_t *offset)
-{
-	long id = (long)file->private_data;
-	struct mtk_hnat *h = hnat_priv;
-	char line[64];
-	int max_enable, max_rate, max_exp = 0;
-	int min_enable, min_rate, min_exp = 0;
-	int weight;
-	int resv;
-	int scheduler;
-	size_t size;
-	u32 qtx_sch;
-
-	cr_set_field(h->fe_base + QDMA_PAGE, QTX_CFG_PAGE, (id / NUM_OF_Q_PER_PAGE));
-	qtx_sch = readl(h->fe_base + QTX_SCH(id % NUM_OF_Q_PER_PAGE));
-	if (length > sizeof(line))
-		return -EINVAL;
-
-	if (copy_from_user(line, buf, length))
-		return -EFAULT;
-
-	if (sscanf(line, "%d %d %d %d %d %d %d", &scheduler, &min_enable, &min_rate,
-		   &max_enable, &max_rate, &weight, &resv) != 7)
-		return -EFAULT;
-
-	while (max_rate > 127) {
-		max_rate /= 10;
-		max_exp++;
-	}
-
-	while (min_rate > 127) {
-		min_rate /= 10;
-		min_exp++;
-	}
-
-	qtx_sch &= 0x70000000;
-	if (hnat_priv->data->num_of_sch == 4)
-		qtx_sch |= (scheduler & 0x3) << 30;
-	else
-		qtx_sch |= (scheduler & 0x1) << 31;
-	if (min_enable)
-		qtx_sch |= BIT(27);
-	qtx_sch |= (min_rate & 0x7f) << 20;
-	qtx_sch |= (min_exp & 0xf) << 16;
-	if (max_enable)
-		qtx_sch |= BIT(11);
-	qtx_sch |= (weight & 0xf) << 12;
-	qtx_sch |= (max_rate & 0x7f) << 4;
-	qtx_sch |= max_exp & 0xf;
-	writel(qtx_sch, h->fe_base + QTX_SCH(id % NUM_OF_Q_PER_PAGE));
-
-	resv &= 0xff;
-	qtx_sch = readl(h->fe_base + QTX_CFG(id % NUM_OF_Q_PER_PAGE));
-	qtx_sch &= 0xffff0000;
-	qtx_sch |= (resv << 8) | resv;
-	writel(qtx_sch, h->fe_base + QTX_CFG(id % NUM_OF_Q_PER_PAGE));
-
-	size = strlen(line);
-	*offset += size;
-
-	return length;
-}
-
-static const struct file_operations hnat_queue_fops = {
-	.open = simple_open,
-	.read = hnat_queue_show,
-	.write = hnat_queue_write,
-	.llseek = default_llseek,
-};
-
-static ssize_t hnat_ppd_if_write(struct file *file, const char __user *buffer,
-				 size_t count, loff_t *data)
-{
-	char buf[IFNAMSIZ];
-	struct net_device *dev;
-	char *p, *tmp;
-
-	if (count >= IFNAMSIZ)
-		return -EFAULT;
-
-	memset(buf, 0, IFNAMSIZ);
-	if (copy_from_user(buf, buffer, count))
-		return -EFAULT;
-
-	tmp = buf;
-	p = strsep(&tmp, "\n\r ");
-	dev = dev_get_by_name(&init_net, p);
-
-	if (dev) {
-		if (hnat_priv->g_ppdev)
-			dev_put(hnat_priv->g_ppdev);
-		hnat_priv->g_ppdev = dev;
-
-		strncpy(hnat_priv->ppd, p, IFNAMSIZ);
-		pr_info("hnat_priv ppd = %s\n", hnat_priv->ppd);
-	} else {
-		pr_info("no such device!\n");
-	}
-
-	return count;
-}
-
-static int hnat_ppd_if_read(struct seq_file *m, void *private)
-{
-	pr_info("hnat_priv ppd = %s\n", hnat_priv->ppd);
-
-	if (hnat_priv->g_ppdev) {
-		pr_info("hnat_priv g_ppdev name = %s\n",
-			hnat_priv->g_ppdev->name);
-	} else {
-		pr_info("hnat_priv g_ppdev is null!\n");
-	}
-
-	return 0;
-}
-
-static int hnat_ppd_if_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_ppd_if_read, file->private_data);
-}
-
-static const struct file_operations hnat_ppd_if_fops = {
-	.open = hnat_ppd_if_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.write = hnat_ppd_if_write,
-	.release = single_release,
-};
-
-static int hnat_mape_toggle_read(struct seq_file *m, void *private)
-{
-	pr_info("value=%d, %s is enabled now!\n", mape_toggle, (mape_toggle) ? "mape" : "ds-lite");
-
-	return 0;
-}
-
-static int hnat_mape_toggle_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_mape_toggle_read, file->private_data);
-}
-
-static ssize_t hnat_mape_toggle_write(struct file *file, const char __user *buffer,
-				      size_t count, loff_t *data)
-{
-	char buf;
-	int len = count;
-
-	if (copy_from_user(&buf, buffer, len))
-		return -EFAULT;
-
-	if (buf == '1' && !mape_toggle) {
-		pr_info("mape is going to be enabled, ds-lite is going to be disabled !\n");
-		mape_toggle = 1;
-	} else if (buf == '0' && mape_toggle) {
-		pr_info("ds-lite is going to be enabled, mape is going to be disabled !\n");
-		mape_toggle = 0;
-	}
-
-	return len;
-}
-
-static const struct file_operations hnat_mape_toggle_fops = {
-	.open = hnat_mape_toggle_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.write = hnat_mape_toggle_write,
-	.release = single_release,
-};
-
-static int hnat_hook_toggle_read(struct seq_file *m, void *private)
-{
-	pr_info("value=%d, hook is %s now!\n", hook_toggle, (hook_toggle) ? "enabled" : "disabled");
-
-	return 0;
-}
-
-static int hnat_hook_toggle_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_hook_toggle_read, file->private_data);
-}
-
-static ssize_t hnat_hook_toggle_write(struct file *file, const char __user *buffer,
-				      size_t count, loff_t *data)
-{
-	char buf;
-	int len = count;
-
-	if (copy_from_user(&buf, buffer, len))
-		return -EFAULT;
-
-	if (buf == '1' && !hook_toggle) {
-		pr_info("hook is going to be enabled !\n");
-		hnat_enable_hook();
-	} else if (buf == '0' && hook_toggle) {
-		pr_info("hook is going to be disabled !\n");
-		hnat_disable_hook();
-	}
-
-	return len;
-}
-
-static const struct file_operations hnat_hook_toggle_fops = {
-	.open = hnat_hook_toggle_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.write = hnat_hook_toggle_write,
-	.release = single_release,
-};
-
-static int hnat_version_read(struct seq_file *m, void *private)
-{
-	pr_info("HNAT SW version : %s\nHNAT HW version : %d\n", HNAT_SW_VER, hnat_priv->data->version);
-
-	return 0;
-}
-
-static int hnat_version_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, hnat_version_read, file->private_data);
-}
-
-static const struct file_operations hnat_version_fops = {
-	.open = hnat_version_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.release = single_release,
-};
-
-int get_ppe_mib(int index, u64 *pkt_cnt, u64 *byte_cnt)
-{
-	struct mtk_hnat *h = hnat_priv;
-	struct hnat_accounting *acount;
-	struct foe_entry *entry;
-
-	acount = hnat_get_count(h, index);
-	entry = hnat_priv->foe_table_cpu + index;
-
-	if (!acount)
-		return -1;
-
-	if (entry->bfib1.state != BIND)
-		return -1;
-
-	*pkt_cnt = acount->packets;
-	*byte_cnt = acount->bytes;
-
-	return 0;
-}
-EXPORT_SYMBOL(get_ppe_mib);
-
-int is_entry_binding(int index)
-{
-	struct foe_entry *entry;
-
-	entry = hnat_priv->foe_table_cpu + index;
-
-	return entry->bfib1.state == BIND;
-}
-EXPORT_SYMBOL(is_entry_binding);
-
-#define dump_register(nm)                                                      \
-	{                                                                      \
-		.name = __stringify(nm), .offset = PPE_##nm,                   \
-	}
-
-static const struct debugfs_reg32 hnat_regs[] = {
-	dump_register(GLO_CFG),     dump_register(FLOW_CFG),
-	dump_register(IP_PROT_CHK), dump_register(IP_PROT_0),
-	dump_register(IP_PROT_1),   dump_register(IP_PROT_2),
-	dump_register(IP_PROT_3),   dump_register(TB_CFG),
-	dump_register(TB_BASE),     dump_register(TB_USED),
-	dump_register(BNDR),	dump_register(BIND_LMT_0),
-	dump_register(BIND_LMT_1),  dump_register(KA),
-	dump_register(UNB_AGE),     dump_register(BND_AGE_0),
-	dump_register(BND_AGE_1),   dump_register(HASH_SEED),
-	dump_register(DFT_CPORT),   dump_register(MCAST_PPSE),
-	dump_register(MCAST_L_0),   dump_register(MCAST_H_0),
-	dump_register(MCAST_L_1),   dump_register(MCAST_H_1),
-	dump_register(MCAST_L_2),   dump_register(MCAST_H_2),
-	dump_register(MCAST_L_3),   dump_register(MCAST_H_3),
-	dump_register(MCAST_L_4),   dump_register(MCAST_H_4),
-	dump_register(MCAST_L_5),   dump_register(MCAST_H_5),
-	dump_register(MCAST_L_6),   dump_register(MCAST_H_6),
-	dump_register(MCAST_L_7),   dump_register(MCAST_H_7),
-	dump_register(MCAST_L_8),   dump_register(MCAST_H_8),
-	dump_register(MCAST_L_9),   dump_register(MCAST_H_9),
-	dump_register(MCAST_L_A),   dump_register(MCAST_H_A),
-	dump_register(MCAST_L_B),   dump_register(MCAST_H_B),
-	dump_register(MCAST_L_C),   dump_register(MCAST_H_C),
-	dump_register(MCAST_L_D),   dump_register(MCAST_H_D),
-	dump_register(MCAST_L_E),   dump_register(MCAST_H_E),
-	dump_register(MCAST_L_F),   dump_register(MCAST_H_F),
-	dump_register(MTU_DRP),     dump_register(MTU_VLYR_0),
-	dump_register(MTU_VLYR_1),  dump_register(MTU_VLYR_2),
-	dump_register(VPM_TPID),    dump_register(VPM_TPID),
-	dump_register(CAH_CTRL),    dump_register(CAH_TAG_SRH),
-	dump_register(CAH_LINE_RW), dump_register(CAH_WDATA),
-	dump_register(CAH_RDATA),
-};
-
-int __init hnat_init_debugfs(struct mtk_hnat *h)
-{
-	int ret = 0;
-	struct dentry *root;
-	struct dentry *file;
-	long i;
-	char name[16];
-
-	root = debugfs_create_dir("hnat", NULL);
-	if (!root) {
-		dev_notice(h->dev, "%s:err at %d\n", __func__, __LINE__);
-		ret = -ENOMEM;
-		goto err0;
-	}
-	h->root = root;
-	h->regset = kzalloc(sizeof(*h->regset), GFP_KERNEL);
-	if (!h->regset) {
-		dev_notice(h->dev, "%s:err at %d\n", __func__, __LINE__);
-		ret = -ENOMEM;
-		goto err1;
-	}
-	h->regset->regs = hnat_regs;
-	h->regset->nregs = ARRAY_SIZE(hnat_regs);
-	h->regset->base = h->ppe_base;
-
-	file = debugfs_create_regset32("regdump", S_IRUGO, root, h->regset);
-	if (!file) {
-		dev_notice(h->dev, "%s:err at %d\n", __func__, __LINE__);
-		ret = -ENOMEM;
-		goto err1;
-	}
-	debugfs_create_file("all_entry", S_IRUGO, root, h, &hnat_debug_fops);
-	debugfs_create_file("external_interface", S_IRUGO, root, h,
-			    &hnat_ext_fops);
-	debugfs_create_file("whnat_interface", S_IRUGO, root, h,
-			    &hnat_whnat_fops);
-	debugfs_create_file("cpu_reason", S_IFREG | S_IRUGO, root, h,
-			    &cpu_reason_fops);
-	debugfs_create_file("hnat_entry", S_IRUGO | S_IRUGO, root, h,
-			    &hnat_entry_fops);
-	debugfs_create_file("hnat_setting", S_IRUGO | S_IRUGO, root, h,
-			    &hnat_setting_fops);
-	debugfs_create_file("mcast_table", S_IRUGO | S_IRUGO, root, h,
-			    &hnat_mcast_fops);
-	debugfs_create_file("hook_toggle", S_IRUGO | S_IRUGO, root, h,
-			    &hnat_hook_toggle_fops);
-	debugfs_create_file("mape_toggle", S_IRUGO | S_IRUGO, root, h,
-			    &hnat_mape_toggle_fops);
-	debugfs_create_file("hnat_version", S_IRUGO | S_IRUGO, root, h,
-			    &hnat_version_fops);
-	debugfs_create_file("hnat_ppd_if", S_IRUGO | S_IRUGO, root, h,
-			    &hnat_ppd_if_fops);
-
-	for (i = 0; i < hnat_priv->data->num_of_sch; i++) {
-		snprintf(name, sizeof(name), "qdma_sch%ld", i);
-		debugfs_create_file(name, S_IRUGO, root, (void *)i,
-				    &hnat_sched_fops);
-	}
-
-	for (i = 0; i < MTK_QDMA_TX_NUM; i++) {
-		snprintf(name, sizeof(name), "qdma_txq%ld", i);
-		debugfs_create_file(name, S_IRUGO, root, (void *)i,
-				    &hnat_queue_fops);
-	}
-
-	return 0;
-
-err1:
-	debugfs_remove_recursive(root);
-err0:
-	return ret;
-}
-
-void hnat_deinit_debugfs(struct mtk_hnat *h)
-{
-	debugfs_remove_recursive(h->root);
-	h->root = NULL;
-	kfree(h->regset);
-}
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_mcast.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_mcast.c
deleted file mode 100644
index 68fbe91c1..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_mcast.c
+++ /dev/null
@@ -1,348 +0,0 @@
-/*   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation; version 2 of the License
- *
- *   This program is distributed in the hope that it will be useful,
- *   but WITHOUT ANY WARRANTY; without even the implied warranty of
- *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *   GNU General Public License for more details.
- *
- *   Copyright (C) 2014-2016 Zhiqiang Yang <zhiqiang.yang@mediatek.com>
- */
-#include <net/sock.h>
-#include <linux/netlink.h>
-#include <linux/rtnetlink.h>
-#include <linux/if_bridge.h>
-#include "hnat.h"
-
-/* *
- * mcast_entry_get - Returns the index of an unused entry
- * or an already existed entry in mtbl
- */
-static int mcast_entry_get(u16 vlan_id, u32 dst_mac)
-{
-	int index = -1;
-	u8 i;
-	struct ppe_mcast_group *p = hnat_priv->pmcast->mtbl;
-	u8 max = hnat_priv->pmcast->max_entry;
-
-	for (i = 0; i < max; i++) {
-		if ((index == -1) && (!p->valid)) {
-			index = i; /*get the first unused entry index*/
-			continue;
-		}
-		if ((p->vid == vlan_id) && (p->mac_hi == dst_mac)) {
-			index = i;
-			break;
-		}
-		p++;
-	}
-	if (index == -1)
-		pr_info("%s:group table is full\n", __func__);
-
-	return index;
-}
-
-static void get_mac_from_mdb_entry(struct br_mdb_entry *entry,
-				   u32 *mac_hi, u16 *mac_lo)
-{
-	switch (ntohs(entry->addr.proto)) {
-	case ETH_P_IP:
-		*mac_lo = 0x0100;
-		*mac_hi = swab32((entry->addr.u.ip4 & 0xfffffe00) + 0x5e);
-		break;
-	case ETH_P_IPV6:
-		*mac_lo = 0x3333;
-		*mac_hi = swab32(entry->addr.u.ip6.s6_addr32[3]);
-		break;
-	}
-	trace_printk("%s:group mac_h=0x%08x, mac_l=0x%04x\n",
-		     __func__, *mac_hi, *mac_lo);
-}
-
-/*set_hnat_mtbl - set ppe multicast register*/
-static int set_hnat_mtbl(struct ppe_mcast_group *group, int index)
-{
-	struct ppe_mcast_h mcast_h;
-	struct ppe_mcast_l mcast_l;
-	u16 mac_lo = group->mac_lo;
-	u32 mac_hi = group->mac_hi;
-	u8 mc_port = group->mc_port;
-	void __iomem *reg;
-
-	mcast_h.u.value = 0;
-	mcast_l.addr = 0;
-	if (mac_lo == 0x0100)
-		mcast_h.u.info.mc_mpre_sel = 0;
-	else if (mac_lo == 0x3333)
-		mcast_h.u.info.mc_mpre_sel = 1;
-
-	mcast_h.u.info.mc_px_en = mc_port;
-	mcast_l.addr = mac_hi;
-	mcast_h.u.info.valid = group->valid;
-	trace_printk("%s:index=%d,group info=0x%x,addr=0x%x\n",
-		     __func__, index, mcast_h.u.value, mcast_l.addr);
-	if (index < 0x10) {
-		reg = hnat_priv->ppe_base + PPE_MCAST_H_0 + ((index) * 8);
-		writel(mcast_h.u.value, reg);
-		reg = hnat_priv->ppe_base + PPE_MCAST_L_0 + ((index) * 8);
-		writel(mcast_l.addr, reg);
-	} else {
-		index = index - 0x10;
-		reg = hnat_priv->fe_base + PPE_MCAST_H_10 + ((index) * 8);
-		writel(mcast_h.u.value, reg);
-		reg = hnat_priv->fe_base + PPE_MCAST_L_10 + ((index) * 8);
-		writel(mcast_h.u.value, reg);
-	}
-
-	return 0;
-}
-
-/**
- * hnat_mcast_table_update -
- *	1.get a valid group entry
- *	2.update group info
- *		a.update eif&oif count
- *		b.eif ==0 & oif == 0,delete it from group table
- *		c.oif != 0,set mc forward port to cpu,else do not forward to cpu
- *	3.set the group info to ppe register
- */
-static int hnat_mcast_table_update(int type, struct br_mdb_entry *entry)
-{
-	struct net_device *dev;
-	u32 mac_hi;
-	u16 mac_lo;
-	int index;
-	struct ppe_mcast_group *group;
-
-	rcu_read_lock();
-	dev = dev_get_by_index_rcu(&init_net, entry->ifindex);
-	if (!dev) {
-		rcu_read_unlock();
-		return -ENODEV;
-	}
-	rcu_read_unlock();
-
-	get_mac_from_mdb_entry(entry, &mac_hi, &mac_lo);
-	index = mcast_entry_get(entry->vid, mac_hi);
-	if (index == -1)
-		return -1;
-
-	group = &hnat_priv->pmcast->mtbl[index];
-	group->mac_hi = mac_hi;
-	group->mac_lo = mac_lo;
-	switch (type) {
-	case RTM_NEWMDB:
-		if (IS_LAN(dev) || IS_WAN(dev))
-			group->eif++;
-		else
-			group->oif++;
-		group->vid = entry->vid;
-		group->valid = true;
-		break;
-	case RTM_DELMDB:
-		if (group->valid) {
-			if (IS_LAN(dev) || IS_WAN(dev))
-				group->eif--;
-			else
-				group->oif--;
-			}
-		break;
-	}
-	trace_printk("%s:devname=%s,eif=%d,oif=%d\n", __func__,
-		     dev->name, group->eif, group->oif);
-	if (group->valid) {
-		if (group->oif && group->eif)
-			/*eth&wifi both in group,forward to cpu&GDMA1*/
-			group->mc_port = (MCAST_TO_PDMA || MCAST_TO_GDMA1);
-		else if (group->oif)
-			/*only wifi in group,forward to cpu only*/
-			group->mc_port = MCAST_TO_PDMA;
-		else
-			/*only eth in group,forward to GDMA1 only*/
-			group->mc_port = MCAST_TO_GDMA1;
-		if (!group->oif && !group->eif)
-			/*nobody in this group,clear the entry*/
-			memset(group, 0, sizeof(struct ppe_mcast_group));
-		set_hnat_mtbl(group, index);
-	}
-
-	return 0;
-}
-
-static void hnat_mcast_nlmsg_handler(struct work_struct *work)
-{
-	struct sk_buff *skb = NULL;
-	struct nlmsghdr *nlh;
-	struct nlattr *nest, *nest2, *info;
-	struct br_port_msg *bpm;
-	struct br_mdb_entry *entry;
-	struct ppe_mcast_table *pmcast;
-	struct sock *sk;
-
-	pmcast = container_of(work, struct ppe_mcast_table, work);
-	sk = pmcast->msock->sk;
-
-	while ((skb = skb_dequeue(&sk->sk_receive_queue))) {
-		nlh = nlmsg_hdr(skb);
-		if (!nlmsg_ok(nlh, skb->len)) {
-			kfree_skb(skb);
-			continue;
-		}
-		bpm = nlmsg_data(nlh);
-		nest = nlmsg_find_attr(nlh, sizeof(bpm), MDBA_MDB);
-		if (!nest) {
-			kfree_skb(skb);
-			continue;
-		}
-		nest2 = nla_find_nested(nest, MDBA_MDB_ENTRY);
-		if (nest2) {
-			info = nla_find_nested(nest2, MDBA_MDB_ENTRY_INFO);
-			if (!info) {
-				kfree_skb(skb);
-				continue;
-			}
-
-			entry = (struct br_mdb_entry *)nla_data(info);
-			trace_printk("%s:cmd=0x%2x,ifindex=0x%x,state=0x%x",
-				     __func__, nlh->nlmsg_type,
-				     entry->ifindex, entry->state);
-			trace_printk("vid=0x%x,ip=0x%x,proto=0x%x\n",
-				     entry->vid, entry->addr.u.ip4,
-				     entry->addr.proto);
-			hnat_mcast_table_update(nlh->nlmsg_type, entry);
-		}
-		kfree_skb(skb);
-	}
-}
-
-static void hnat_mcast_nlmsg_rcv(struct sock *sk)
-{
-	struct ppe_mcast_table *pmcast = hnat_priv->pmcast;
-	struct workqueue_struct *queue = pmcast->queue;
-	struct work_struct *work = &pmcast->work;
-
-	queue_work(queue, work);
-}
-
-static struct socket *hnat_mcast_netlink_open(struct net *net)
-{
-	struct socket *sock = NULL;
-	int ret;
-	struct sockaddr_nl addr;
-
-	ret = sock_create_kern(net, PF_NETLINK, SOCK_RAW, NETLINK_ROUTE, &sock);
-	if (ret < 0)
-		goto out;
-
-	sock->sk->sk_data_ready = hnat_mcast_nlmsg_rcv;
-	addr.nl_family = PF_NETLINK;
-	addr.nl_pid = 65536; /*fix me:how to get an unique id?*/
-	addr.nl_groups = RTMGRP_MDB;
-	ret = sock->ops->bind(sock, (struct sockaddr *)&addr, sizeof(addr));
-	if (ret < 0)
-		goto out;
-
-	return sock;
-out:
-	if (sock)
-		sock_release(sock);
-
-	return NULL;
-}
-
-static void hnat_mcast_check_timestamp(unsigned long data)
-{
-	struct foe_entry *entry;
-	int hash_index;
-	u16 e_ts, foe_ts;
-
-	for (hash_index = 0; hash_index < hnat_priv->foe_etry_num; hash_index++) {
-		entry = hnat_priv->foe_table_cpu + hash_index;
-		if (entry->bfib1.sta == 1) {
-			e_ts = (entry->ipv4_hnapt.m_timestamp) & 0xffff;
-			foe_ts = foe_timestamp(hnat_priv);
-			if ((foe_ts - e_ts) > 0x3000)
-				foe_ts = (~(foe_ts)) & 0xffff;
-			if (abs(foe_ts - e_ts) > 20)
-				entry_delete(hash_index);
-		}
-	}
-	mod_timer(&hnat_priv->hnat_mcast_check_timer, jiffies + 10 * HZ);
-}
-
-int hnat_mcast_enable(void)
-{
-	struct ppe_mcast_table *pmcast;
-
-	pmcast = kzalloc(sizeof(*pmcast), GFP_KERNEL);
-	if (!pmcast)
-		goto err;
-
-	if (hnat_priv->data->version == MTK_HNAT_V1)
-		pmcast->max_entry = 0x10;
-	else
-		pmcast->max_entry = MAX_MCAST_ENTRY;
-
-	INIT_WORK(&pmcast->work, hnat_mcast_nlmsg_handler);
-	pmcast->queue = create_singlethread_workqueue("ppe_mcast");
-	if (!pmcast->queue)
-		goto err;
-
-	pmcast->msock = hnat_mcast_netlink_open(&init_net);
-	if (!pmcast->msock)
-		goto err;
-
-	hnat_priv->pmcast = pmcast;
-
-	/* mt7629 should checkout mcast entry life time manualy */
-	if (hnat_priv->data->version == MTK_HNAT_V3) {
-		init_timer(&hnat_priv->hnat_mcast_check_timer);
-		hnat_priv->hnat_mcast_check_timer.function =
-			hnat_mcast_check_timestamp;
-		hnat_priv->hnat_mcast_check_timer.expires = jiffies;
-		add_timer(&hnat_priv->hnat_mcast_check_timer);
-	}
-
-	/* Enable multicast table lookup */
-	cr_set_field(hnat_priv->ppe_base + PPE_GLO_CFG, MCAST_TB_EN, 1);
-	/* multicast port0 map to PDMA */
-	cr_set_field(hnat_priv->ppe_base + PPE_MCAST_PPSE, MC_P0_PPSE, 0);
-	/* multicast port1 map to GMAC1 */
-	cr_set_field(hnat_priv->ppe_base + PPE_MCAST_PPSE, MC_P1_PPSE, 1);
-	/* multicast port2 map to GMAC2 */
-	cr_set_field(hnat_priv->ppe_base + PPE_MCAST_PPSE, MC_P2_PPSE, 2);
-	/* multicast port3 map to QDMA */
-	cr_set_field(hnat_priv->ppe_base + PPE_MCAST_PPSE, MC_P3_PPSE, 5);
-
-	return 0;
-err:
-	if (pmcast->queue)
-		destroy_workqueue(pmcast->queue);
-	if (pmcast->msock)
-		sock_release(pmcast->msock);
-	kfree(pmcast);
-
-	return -1;
-}
-
-int hnat_mcast_disable(void)
-{
-	struct ppe_mcast_table *pmcast = hnat_priv->pmcast;
-	struct socket *sock = pmcast->msock;
-	struct workqueue_struct *queue = pmcast->queue;
-	struct work_struct *work = &pmcast->work;
-
-	if (hnat_priv->data->version == MTK_HNAT_V3)
-		del_timer_sync(&hnat_priv->hnat_mcast_check_timer);
-
-	if (pmcast) {
-		flush_work(work);
-		destroy_workqueue(queue);
-		sock_release(sock);
-		kfree(pmcast);
-	}
-
-	return 0;
-}
-
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_mcast.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_mcast.h
deleted file mode 100644
index 048bc5868..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_mcast.h
+++ /dev/null
@@ -1,69 +0,0 @@
-/*   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation; version 2 of the License
- *
- *   This program is distributed in the hope that it will be useful,
- *   but WITHOUT ANY WARRANTY; without even the implied warranty of
- *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *   GNU General Public License for more details.
- *
- *   Copyright (C) 2014-2016 Zhiqiang Yang <zhiqiang.yang@mediatek.com>
- */
-
-#ifndef NF_HNAT_MCAST_H
-#define NF_HNAT_MCAST_H
-
-#define RTMGRP_IPV4_MROUTE 0x20
-#define RTMGRP_MDB 0x2000000
-
-#define MAX_MCAST_ENTRY 64
-
-#define MCAST_TO_PDMA (0x1 << 0)
-#define MCAST_TO_GDMA1 (0x1 << 1)
-#define MCAST_TO_GDMA2 (0x1 << 2)
-
-struct ppe_mcast_group {
-	u32 mac_hi; /*multicast mac addr*/
-	u16 mac_lo; /*multicast mac addr*/
-	u16 vid;
-	u8 mc_port; /*1:forward to cpu,2:forward to GDMA1,4:forward to GDMA2*/
-	u8 eif; /*num of eth if added to multi group. */
-	u8 oif; /* num of other if added to multi group ,ex wifi.*/
-	bool valid;
-};
-
-struct ppe_mcast_table {
-	struct workqueue_struct *queue;
-	struct work_struct work;
-	struct socket *msock;
-	struct ppe_mcast_group mtbl[MAX_MCAST_ENTRY];
-	u8 max_entry;
-};
-
-struct ppe_mcast_h {
-	union {
-		u32 value;
-		struct {
-			u32 mc_vid:12;
-			u32 mc_qos_qid54:2; /* mt7622 only */
-			u32 valid:1;
-			u32 rev1:1;
-			/*0:forward to cpu,1:forward to GDMA1*/
-			u32 mc_px_en:4;
-			u32 mc_mpre_sel:2; /* 0=01:00, 2=33:33 */
-			u32 mc_vid_cmp:1;
-			u32 rev2:1;
-			u32 mc_px_qos_en:4;
-			u32 mc_qos_qid:4;
-		} info;
-	} u;
-};
-
-struct ppe_mcast_l {
-	u32 addr;
-};
-
-int hnat_mcast_enable(void);
-int hnat_mcast_disable(void);
-
-#endif
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_nf_hook.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_nf_hook.c
deleted file mode 100644
index e9976cc57..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_nf_hook.c
+++ /dev/null
@@ -1,1991 +0,0 @@
-/*   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation; version 2 of the License
- *
- *   This program is distributed in the hope that it will be useful,
- *   but WITHOUT ANY WARRANTY; without even the implied warranty of
- *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *   GNU General Public License for more details.
- *
- *   Copyright (C) 2014-2016 Sean Wang <sean.wang@mediatek.com>
- *   Copyright (C) 2016-2017 John Crispin <blogic@openwrt.org>
- */
-
-#include <linux/netfilter_bridge.h>
-#include <linux/netfilter_ipv6.h>
-
-#include <net/arp.h>
-#include <net/neighbour.h>
-#include <net/netfilter/nf_conntrack_helper.h>
-#include <net/ipv6.h>
-#include <net/ip6_route.h>
-#include <net/ip.h>
-#include <net/tcp.h>
-#include <net/udp.h>
-
-#include "nf_hnat_mtk.h"
-#include "hnat.h"
-
-#include "../mtk_eth_soc.h"
-
-#define do_ge2ext_fast(dev, skb)                                               \
-	((IS_LAN(dev) || IS_WAN(dev) || IS_PPD(dev)) && \
-	 skb_hnat_is_hashed(skb) && \
-	 skb_hnat_reason(skb) == HIT_BIND_FORCE_TO_CPU)
-#define do_ext2ge_fast_learn(dev, skb)                                         \
-	(IS_PPD(dev) &&                                                        \
-	 (skb_hnat_sport(skb) == NR_PDMA_PORT ||                           \
-	  skb_hnat_sport(skb) == NR_QDMA_PORT) &&                       \
-	  ((get_dev_from_index(skb->vlan_tci & VLAN_VID_MASK)) ||   \
-		 get_wandev_from_index(skb->vlan_tci & VLAN_VID_MASK)))
-#define do_mape_w2l_fast(dev, skb)                                          \
-		(mape_toggle && IS_WAN(dev) && (!is_from_mape(skb)))
-
-static struct ipv6hdr mape_l2w_v6h;
-static struct ipv6hdr mape_w2l_v6h;
-static inline uint8_t get_wifi_hook_if_index_from_dev(const struct net_device *dev)
-{
-	int i;
-
-	for (i = 1; i < MAX_IF_NUM; i++) {
-		if (hnat_priv->wifi_hook_if[i] == dev)
-			return i;
-	}
-
-	return 0;
-}
-
-static inline int get_ext_device_number(void)
-{
-	int i, number = 0;
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++)
-		number += 1;
-	return number;
-}
-
-static inline int find_extif_from_devname(const char *name)
-{
-	int i;
-	struct extdev_entry *ext_entry;
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		if (!strcmp(name, ext_entry->name))
-			return 1;
-	}
-	return 0;
-}
-
-static inline int get_index_from_dev(const struct net_device *dev)
-{
-	int i;
-	struct extdev_entry *ext_entry;
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		if (dev == ext_entry->dev)
-			return ext_entry->dev->ifindex;
-	}
-	return 0;
-}
-
-static inline struct net_device *get_dev_from_index(int index)
-{
-	int i;
-	struct extdev_entry *ext_entry;
-	struct net_device *dev = 0;
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		if (ext_entry->dev && index == ext_entry->dev->ifindex) {
-			dev = ext_entry->dev;
-			break;
-		}
-	}
-	return dev;
-}
-
-static inline struct net_device *get_wandev_from_index(int index)
-{
-	struct net_device *wandev = 0;
-
-	wandev = dev_get_by_name(&init_net, hnat_priv->wan);
-	if (wandev->ifindex == index)
-		return wandev;
-	return NULL;
-}
-
-static inline int extif_set_dev(struct net_device *dev)
-{
-	int i;
-	struct extdev_entry *ext_entry;
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		if (!strcmp(dev->name, ext_entry->name) && !ext_entry->dev) {
-			dev_hold(dev);
-			ext_entry->dev = dev;
-			pr_info("%s(%s)\n", __func__, dev->name);
-
-			return ext_entry->dev->ifindex;
-		}
-	}
-
-	return -1;
-}
-
-static inline int extif_put_dev(struct net_device *dev)
-{
-	int i;
-	struct extdev_entry *ext_entry;
-
-	for (i = 0; i < MAX_EXT_DEVS && hnat_priv->ext_if[i]; i++) {
-		ext_entry = hnat_priv->ext_if[i];
-		if (ext_entry->dev == dev) {
-			ext_entry->dev = NULL;
-			dev_put(dev);
-			pr_info("%s(%s)\n", __func__, dev->name);
-
-			return 0;
-		}
-	}
-
-	return -1;
-}
-
-int ext_if_add(struct extdev_entry *ext_entry)
-{
-	int len = get_ext_device_number();
-
-	hnat_priv->ext_if[len++] = ext_entry;
-	return len;
-}
-
-int ext_if_del(struct extdev_entry *ext_entry)
-{
-	int i, j;
-
-	for (i = 0; i < MAX_EXT_DEVS; i++) {
-		if (hnat_priv->ext_if[i] == ext_entry) {
-			for (j = i; hnat_priv->ext_if[j] && j < MAX_EXT_DEVS - 1; j++)
-				hnat_priv->ext_if[j] = hnat_priv->ext_if[j + 1];
-			hnat_priv->ext_if[j] = NULL;
-			break;
-		}
-	}
-
-	return i;
-}
-
-void foe_clear_all_bind_entries(struct net_device *dev)
-{
-	int hash_index;
-	struct foe_entry *entry;
-
-	if (!IS_LAN(dev) && !IS_WAN(dev) &&
-	    !find_extif_from_devname(dev->name) &&
-	    !dev->netdev_ops->ndo_hnat_check)
-		return;
-
-	cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SMA, SMA_ONLY_FWD_CPU);
-	for (hash_index = 0; hash_index < hnat_priv->foe_etry_num; hash_index++) {
-		entry = hnat_priv->foe_table_cpu + hash_index;
-		if (entry->bfib1.state == BIND) {
-			entry->ipv4_hnapt.udib1.state = INVALID;
-			entry->ipv4_hnapt.udib1.time_stamp =
-				readl((hnat_priv->fe_base + 0x0010)) & 0xFF;
-		}
-	}
-
-	/* clear HWNAT cache */
-	hnat_cache_ebl(1);
-
-	mod_timer(&hnat_priv->hnat_sma_build_entry_timer, jiffies + 3 * HZ);
-}
-
-static void gmac_ppe_fwd_enable(struct net_device *dev)
-{
-	if (IS_LAN(dev) || IS_GMAC1_MODE)
-		set_gmac_ppe_fwd(0, 1);
-	else if (IS_WAN(dev))
-		set_gmac_ppe_fwd(1, 1);
-}
-
-int nf_hnat_netdevice_event(struct notifier_block *unused, unsigned long event,
-			    void *ptr)
-{
-	struct net_device *dev;
-
-	dev = netdev_notifier_info_to_dev(ptr);
-
-	switch (event) {
-	case NETDEV_UP:
-		gmac_ppe_fwd_enable(dev);
-
-		extif_set_dev(dev);
-
-		break;
-	case NETDEV_GOING_DOWN:
-		if (!get_wifi_hook_if_index_from_dev(dev))
-			extif_put_dev(dev);
-
-		foe_clear_all_bind_entries(dev);
-
-		break;
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-void foe_clear_entry(struct neighbour *neigh)
-{
-	u32 *daddr = (u32 *)neigh->primary_key;
-	unsigned char h_dest[ETH_ALEN];
-	struct foe_entry *entry;
-	int hash_index;
-	u32 dip;
-
-	dip = (u32)(*daddr);
-
-	for (hash_index = 0; hash_index < hnat_priv->foe_etry_num; hash_index++) {
-		entry = hnat_priv->foe_table_cpu + hash_index;
-		if (entry->bfib1.state == BIND &&
-		    entry->ipv4_hnapt.new_dip == ntohl(dip)) {
-			*((u32 *)h_dest) = swab32(entry->ipv4_hnapt.dmac_hi);
-			*((u16 *)&h_dest[4]) =
-				swab16(entry->ipv4_hnapt.dmac_lo);
-			if (!ether_addr_equal(h_dest, neigh->ha)) {
-				pr_info("%s: state=%d\n", __func__,
-					neigh->nud_state);
-				cr_set_field(hnat_priv->ppe_base + PPE_TB_CFG, SMA,
-					     SMA_ONLY_FWD_CPU);
-
-				entry->ipv4_hnapt.udib1.state = INVALID;
-				entry->ipv4_hnapt.udib1.time_stamp =
-					readl((hnat_priv->fe_base + 0x0010)) & 0xFF;
-
-				/* clear HWNAT cache */
-				hnat_cache_ebl(1);
-
-				mod_timer(&hnat_priv->hnat_sma_build_entry_timer,
-					  jiffies + 3 * HZ);
-
-				pr_info("Delete old entry: dip =%pI4\n", &dip);
-				pr_info("Old mac= %pM\n", h_dest);
-				pr_info("New mac= %pM\n", neigh->ha);
-			}
-		}
-	}
-}
-
-int nf_hnat_netevent_handler(struct notifier_block *unused, unsigned long event,
-			     void *ptr)
-{
-	struct net_device *dev = NULL;
-	struct neighbour *neigh = NULL;
-
-	switch (event) {
-	case NETEVENT_NEIGH_UPDATE:
-		neigh = ptr;
-		dev = neigh->dev;
-		if (dev)
-			foe_clear_entry(neigh);
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-unsigned int mape_add_ipv6_hdr(struct sk_buff *skb, struct ipv6hdr mape_ip6h)
-{
-	struct ethhdr *eth = NULL;
-	struct ipv6hdr *ip6h = NULL;
-	struct iphdr *iph = NULL;
-
-	if (skb_headroom(skb) < IPV6_HDR_LEN || skb_shared(skb) ||
-	    (skb_cloned(skb) && !skb_clone_writable(skb, 0))) {
-		return -1;
-	}
-
-	/* point to L3 */
-	memcpy(skb->data - IPV6_HDR_LEN - ETH_HLEN, skb_push(skb, ETH_HLEN), ETH_HLEN);
-	memcpy(skb_push(skb, IPV6_HDR_LEN - ETH_HLEN), &mape_ip6h, IPV6_HDR_LEN);
-
-	eth = (struct ethhdr *)(skb->data - ETH_HLEN);
-	eth->h_proto = htons(ETH_P_IPV6);
-	skb->protocol = htons(ETH_P_IPV6);
-
-	iph = (struct iphdr *)(skb->data + IPV6_HDR_LEN);
-	ip6h = (struct ipv6hdr *)(skb->data);
-	ip6h->payload_len = iph->tot_len; /* maybe different with ipv4 */
-
-	skb_set_network_header(skb, 0);
-	skb_set_transport_header(skb, iph->ihl * 4 + IPV6_HDR_LEN);
-	return 0;
-}
-
-static void fix_skb_packet_type(struct sk_buff *skb, struct net_device *dev,
-				struct ethhdr *eth)
-{
-	skb->pkt_type = PACKET_HOST;
-	if (unlikely(is_multicast_ether_addr(eth->h_dest))) {
-		if (ether_addr_equal_64bits(eth->h_dest, dev->broadcast))
-			skb->pkt_type = PACKET_BROADCAST;
-		else
-			skb->pkt_type = PACKET_MULTICAST;
-	}
-}
-
-unsigned int do_hnat_ext_to_ge(struct sk_buff *skb, const struct net_device *in,
-			       const char *func)
-{
-	if (hnat_priv->g_ppdev && hnat_priv->g_ppdev->flags & IFF_UP) {
-		u16 vlan_id = 0;
-		skb_set_network_header(skb, 0);
-		skb_push(skb, ETH_HLEN);
-		set_to_ppe(skb);
-
-		vlan_id = skb_vlan_tag_get_id(skb);
-		if (vlan_id) {
-			skb = vlan_insert_tag(skb, skb->vlan_proto, skb->vlan_tci);
-			if (!skb)
-				return -1;
-		}
-
-		/*set where we come from*/
-		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), in->ifindex & VLAN_VID_MASK);
-		trace_printk(
-			"%s: vlan_prot=0x%x, vlan_tci=%x, in->name=%s, skb->dev->name=%s\n",
-			__func__, ntohs(skb->vlan_proto), skb->vlan_tci,
-			in->name, hnat_priv->g_ppdev->name);
-		skb->dev = hnat_priv->g_ppdev;
-		dev_queue_xmit(skb);
-		trace_printk("%s: called from %s successfully\n", __func__, func);
-		return 0;
-	}
-
-	trace_printk("%s: called from %s fail\n", __func__, func);
-	return -1;
-}
-
-unsigned int do_hnat_ext_to_ge2(struct sk_buff *skb, const char *func)
-{
-	struct ethhdr *eth = eth_hdr(skb);
-	struct net_device *dev;
-	struct foe_entry *entry;
-
-	trace_printk("%s: vlan_prot=0x%x, vlan_tci=%x\n", __func__,
-		     ntohs(skb->vlan_proto), skb->vlan_tci);
-
-	dev = get_dev_from_index(skb->vlan_tci & VLAN_VID_MASK);
-
-	if (dev) {
-		/*set where we to go*/
-		skb->dev = dev;
-		skb->vlan_proto = 0;
-		skb->vlan_tci = 0;
-		if (ntohs(eth->h_proto) == ETH_P_8021Q) {
-			skb = skb_vlan_untag(skb);
-			if (unlikely(!skb))
-				return -1;
-		}
-		set_from_extge(skb);
-		fix_skb_packet_type(skb, skb->dev, eth);
-		netif_rx(skb);
-		trace_printk("%s: called from %s successfully\n", __func__,
-			     func);
-		return 0;
-	} else {
-		/* MapE WAN --> LAN/WLAN PingPong. */
-		dev = get_wandev_from_index(skb->vlan_tci & VLAN_VID_MASK);
-		if (mape_toggle && dev) {
-			if (!mape_add_ipv6_hdr(skb, mape_w2l_v6h)) {
-				skb_set_mac_header(skb, -ETH_HLEN);
-				skb->dev = dev;
-				set_from_mape(skb);
-				skb->vlan_proto = 0;
-				skb->vlan_tci = 0;
-				fix_skb_packet_type(skb, skb->dev, eth_hdr(skb));
-				entry = &hnat_priv->foe_table_cpu[skb_hnat_entry(skb)];
-				entry->bfib1.pkt_type = IPV4_HNAPT;
-				netif_rx(skb);
-				return 0;
-			}
-		}
-		trace_printk("%s: called from %s fail\n", __func__, func);
-		return -1;
-	}
-}
-
-unsigned int do_hnat_ge_to_ext(struct sk_buff *skb, const char *func)
-{
-	/*set where we to go*/
-	u8 index;
-	struct foe_entry *entry;
-	struct net_device *dev;
-
-	entry = &hnat_priv->foe_table_cpu[skb_hnat_entry(skb)];
-
-	if (IS_IPV4_GRP(entry))
-		index = entry->ipv4_hnapt.act_dp;
-	else
-		index = entry->ipv6_5t_route.act_dp;
-
-	skb->dev = get_dev_from_index(index);
-
-#if (1)
-	if (eth_hdr(skb)->h_proto == HQOS_MAGIC_TAG) {
-		skb = skb_unshare(skb, GFP_ATOMIC);
-		if (!skb)
-			return NF_ACCEPT;
-
-		if (unlikely(!pskb_may_pull(skb, VLAN_HLEN)))
-			return NF_ACCEPT;
-
-		skb_pull_rcsum(skb, VLAN_HLEN);
-
-		memmove(skb->data - ETH_HLEN, skb->data - ETH_HLEN - VLAN_HLEN,
-			2 * ETH_ALEN);
-	}
-#endif
-
-	if (skb->dev) {
-		skb_set_network_header(skb, 0);
-		skb_push(skb, ETH_HLEN);
-		dev_queue_xmit(skb);
-		trace_printk("%s: called from %s successfully\n", __func__,
-			     func);
-		return 0;
-	} else {
-		if (mape_toggle) {
-			/* Add ipv6 header mape for lan/wlan -->wan */
-			dev = get_wandev_from_index(index);
-			if (dev) {
-				if (!mape_add_ipv6_hdr(skb, mape_l2w_v6h)) {
-					skb_set_network_header(skb, 0);
-					skb_push(skb, ETH_HLEN);
-					skb_set_mac_header(skb, 0);
-					skb->dev = dev;
-					dev_queue_xmit(skb);
-					return 0;
-				}
-				trace_printk("%s: called from %s fail[MapE]\n", __func__,
-					     func);
-				return -1;
-			}
-		}
-	}
-	/*if external devices is down, invalidate related ppe entry*/
-	if (entry_hnat_is_bound(entry)) {
-		entry->bfib1.state = INVALID;
-		if (IS_IPV4_GRP(entry))
-			entry->ipv4_hnapt.act_dp = 0;
-		else
-			entry->ipv6_5t_route.act_dp = 0;
-
-		/* clear HWNAT cache */
-		hnat_cache_ebl(1);
-	}
-	trace_printk("%s: called from %s fail, index=%x\n", __func__,
-		     func, index);
-	return -1;
-}
-
-static void pre_routing_print(struct sk_buff *skb, const struct net_device *in,
-			      const struct net_device *out, const char *func)
-{
-	trace_printk(
-		"[%s]: %s(iif=0x%x CB2=0x%x)-->%s (ppe_hash=0x%x) sport=0x%x reason=0x%x alg=0x%x from %s\n",
-		__func__, in->name, skb_hnat_iface(skb),
-		HNAT_SKB_CB2(skb)->magic, out->name, skb_hnat_entry(skb),
-		skb_hnat_sport(skb), skb_hnat_reason(skb), skb_hnat_alg(skb),
-		func);
-}
-
-static void post_routing_print(struct sk_buff *skb, const struct net_device *in,
-			       const struct net_device *out, const char *func)
-{
-	trace_printk(
-		"[%s]: %s(iif=0x%x, CB2=0x%x)-->%s (ppe_hash=0x%x) sport=0x%x reason=0x%x alg=0x%x from %s\n",
-		__func__, in->name, skb_hnat_iface(skb),
-		HNAT_SKB_CB2(skb)->magic, out->name, skb_hnat_entry(skb),
-		skb_hnat_sport(skb), skb_hnat_reason(skb), skb_hnat_alg(skb),
-		func);
-}
-
-static inline void hnat_set_iif(const struct nf_hook_state *state,
-				struct sk_buff *skb, int val)
-{
-	if (IS_LAN(state->in)) {
-		skb_hnat_iface(skb) = FOE_MAGIC_GE_LAN;
-	} else if (IS_PPD(state->in)) {
-		skb_hnat_iface(skb) = FOE_MAGIC_GE_PPD;
-	} else if (IS_EXT(state->in)) {
-		skb_hnat_iface(skb) = FOE_MAGIC_EXT;
-	} else if (IS_WAN(state->in)) {
-		skb_hnat_iface(skb) = FOE_MAGIC_GE_WAN;
-	} else if (state->in->netdev_ops->ndo_hnat_check) {
-		skb_hnat_iface(skb) = FOE_MAGIC_GE_VIRTUAL;
-	} else if (!IS_BR(state->in)) {
-		skb_hnat_iface(skb) = FOE_INVALID;
-
-		if (is_magic_tag_valid(skb) && IS_SPACE_AVAILABLE_HEAD(skb))
-			memset(skb_hnat_info(skb), 0, FOE_INFO_LEN);
-	}
-}
-
-static inline void hnat_set_alg(const struct nf_hook_state *state,
-				struct sk_buff *skb, int val)
-{
-	skb_hnat_alg(skb) = val;
-}
-
-static inline void hnat_set_head_frags(const struct nf_hook_state *state,
-				       struct sk_buff *head_skb, int val,
-				       void (*fn)(const struct nf_hook_state *state,
-						  struct sk_buff *skb, int val))
-{
-	struct sk_buff *segs = skb_shinfo(head_skb)->frag_list;
-
-	fn(state, head_skb, val);
-	while (segs) {
-		fn(state, segs, val);
-		segs = segs->next;
-	}
-}
-
-unsigned int do_hnat_mape_w2l_fast(struct sk_buff *skb, const struct net_device *in,
-				   const char *func)
-{
-	struct ipv6hdr *ip6h = ipv6_hdr(skb);
-	struct iphdr _iphdr;
-	struct iphdr *iph;
-	struct ethhdr *eth;
-
-	/* WAN -> LAN/WLAN MapE. */
-	if (mape_toggle && (ip6h->nexthdr == NEXTHDR_IPIP)) {
-		iph = skb_header_pointer(skb, IPV6_HDR_LEN, sizeof(_iphdr), &_iphdr);
-		switch (iph->protocol) {
-		case IPPROTO_UDP:
-		case IPPROTO_TCP:
-			break;
-		default:
-			return -1;
-		}
-		mape_w2l_v6h = *ip6h;
-
-		/* Remove ipv6 header. */
-		memcpy(skb->data + IPV6_HDR_LEN - ETH_HLEN,
-		       skb->data - ETH_HLEN, ETH_HLEN);
-		skb_pull(skb, IPV6_HDR_LEN - ETH_HLEN);
-		skb_set_mac_header(skb, 0);
-		skb_set_network_header(skb, ETH_HLEN);
-		skb_set_transport_header(skb, ETH_HLEN + sizeof(_iphdr));
-
-		eth = eth_hdr(skb);
-		eth->h_proto = htons(ETH_P_IP);
-		set_to_ppe(skb);
-
-		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), in->ifindex & VLAN_VID_MASK);
-
-		if (!hnat_priv->g_ppdev)
-			hnat_priv->g_ppdev = dev_get_by_name(&init_net, hnat_priv->ppd);
-
-		skb->dev = hnat_priv->g_ppdev;
-		skb->protocol = htons(ETH_P_IP);
-
-		dev_queue_xmit(skb);
-
-		return 0;
-	}
-	return -1;
-}
-
-static unsigned int is_ppe_support_type(struct sk_buff *skb)
-{
-	struct ethhdr *eth = NULL;
-	struct iphdr *iph = NULL;
-	struct ipv6hdr *ip6h = NULL;
-	struct iphdr _iphdr;
-
-	eth = eth_hdr(skb);
-	if (is_broadcast_ether_addr(eth->h_dest))
-		return 0;
-
-	switch (ntohs(skb->protocol)) {
-	case ETH_P_IP:
-		iph = ip_hdr(skb);
-
-		/* do not accelerate non tcp/udp traffic */
-		if ((iph->protocol == IPPROTO_TCP) ||
-		    (iph->protocol == IPPROTO_UDP) ||
-		    (iph->protocol == IPPROTO_IPV6)) {
-			return 1;
-		}
-
-		break;
-	case ETH_P_IPV6:
-		ip6h = ipv6_hdr(skb);
-
-		if ((ip6h->nexthdr == NEXTHDR_TCP) ||
-		    (ip6h->nexthdr == NEXTHDR_UDP)) {
-			return 1;
-		} else if (ip6h->nexthdr == NEXTHDR_IPIP) {
-			iph = skb_header_pointer(skb, IPV6_HDR_LEN,
-						 sizeof(_iphdr), &_iphdr);
-
-			if ((iph->protocol == IPPROTO_TCP) ||
-			    (iph->protocol == IPPROTO_UDP)) {
-				return 1;
-			}
-
-		}
-
-		break;
-	case ETH_P_8021Q:
-		return 1;
-	}
-
-	return 0;
-}
-
-static unsigned int
-mtk_hnat_ipv6_nf_pre_routing(void *priv, struct sk_buff *skb,
-			     const struct nf_hook_state *state)
-{
-	if (!is_ppe_support_type(skb)) {
-		hnat_set_head_frags(state, skb, 1, hnat_set_alg);
-		return NF_ACCEPT;
-	}
-
-	hnat_set_head_frags(state, skb, -1, hnat_set_iif);
-
-	pre_routing_print(skb, state->in, state->out, __func__);
-
-	/* packets from external devices -> xxx ,step 1 , learning stage & bound stage*/
-	if (do_ext2ge_fast_try(state->in, skb)) {
-		if (!do_hnat_ext_to_ge(skb, state->in, __func__))
-			return NF_STOLEN;
-		if (!skb)
-			goto drop;
-		return NF_ACCEPT;
-	}
-
-	/* packets form ge -> external device
-	 * For standalone wan interface
-	 */
-	if (do_ge2ext_fast(state->in, skb)) {
-		if (!do_hnat_ge_to_ext(skb, __func__))
-			return NF_STOLEN;
-		goto drop;
-	}
-
-	/* MapE need remove ipv6 header and pingpong. */
-	if (do_mape_w2l_fast(state->in, skb)) {
-		if (!do_hnat_mape_w2l_fast(skb, state->in, __func__))
-			return NF_STOLEN;
-		else
-			return NF_ACCEPT;
-	}
-
-	if (is_from_mape(skb))
-		clr_from_extge(skb);
-
-	return NF_ACCEPT;
-drop:
-	printk_ratelimited(KERN_WARNING
-				"%s:drop (in_dev=%s, iif=0x%x, CB2=0x%x, ppe_hash=0x%x, sport=0x%x, reason=0x%x, alg=0x%x)\n",
-				__func__, state->in->name, skb_hnat_iface(skb),
-				HNAT_SKB_CB2(skb)->magic, skb_hnat_entry(skb),
-				skb_hnat_sport(skb), skb_hnat_reason(skb),
-				skb_hnat_alg(skb));
-
-	return NF_DROP;
-}
-
-static unsigned int
-mtk_hnat_ipv4_nf_pre_routing(void *priv, struct sk_buff *skb,
-			     const struct nf_hook_state *state)
-{
-	if (!is_ppe_support_type(skb)) {
-		hnat_set_head_frags(state, skb, 1, hnat_set_alg);
-		return NF_ACCEPT;
-	}
-
-	hnat_set_head_frags(state, skb, -1, hnat_set_iif);
-
-	pre_routing_print(skb, state->in, state->out, __func__);
-
-	/* packets from external devices -> xxx ,step 1 , learning stage & bound stage*/
-	if (do_ext2ge_fast_try(state->in, skb)) {
-		if (!do_hnat_ext_to_ge(skb, state->in, __func__))
-			return NF_STOLEN;
-		if (!skb)
-			goto drop;
-		return NF_ACCEPT;
-	}
-
-	/* packets form ge -> external device
-	 * For standalone wan interface
-	 */
-	if (do_ge2ext_fast(state->in, skb)) {
-		if (!do_hnat_ge_to_ext(skb, __func__))
-			return NF_STOLEN;
-		goto drop;
-	}
-
-	return NF_ACCEPT;
-drop:
-	printk_ratelimited(KERN_WARNING
-				"%s:drop (in_dev=%s, iif=0x%x, CB2=0x%x, ppe_hash=0x%x, sport=0x%x, reason=0x%x, alg=0x%x)\n",
-				__func__, state->in->name, skb_hnat_iface(skb),
-				HNAT_SKB_CB2(skb)->magic, skb_hnat_entry(skb),
-				skb_hnat_sport(skb), skb_hnat_reason(skb),
-				skb_hnat_alg(skb));
-
-	return NF_DROP;
-}
-
-static unsigned int
-mtk_hnat_br_nf_local_in(void *priv, struct sk_buff *skb,
-			const struct nf_hook_state *state)
-{
-#if (1)
-	struct vlan_ethhdr *veth;
-
-	if (hnat_priv->data->whnat) {
-		veth = (struct vlan_ethhdr *)skb_mac_header(skb);
-
-		if (eth_hdr(skb)->h_proto == HQOS_MAGIC_TAG) {
-			skb_hnat_entry(skb) = ntohs(veth->h_vlan_TCI) & 0x3fff;
-			skb_hnat_reason(skb) = HIT_BIND_FORCE_TO_CPU;
-		}
-	}
-#endif
-
-	if (!HAS_HQOS_MAGIC_TAG(skb) && !is_ppe_support_type(skb)) {
-		hnat_set_head_frags(state, skb, 1, hnat_set_alg);
-		return NF_ACCEPT;
-	}
-
-	hnat_set_head_frags(state, skb, -1, hnat_set_iif);
-
-	pre_routing_print(skb, state->in, state->out, __func__);
-
-	if (unlikely(debug_level >= 7)) {
-		hnat_cpu_reason_cnt(skb);
-		if (skb_hnat_reason(skb) == dbg_cpu_reason)
-			foe_dump_pkt(skb);
-	}
-
-	/* packets from external devices -> xxx ,step 1 , learning stage & bound stage*/
-	if ((skb_hnat_iface(skb) == FOE_MAGIC_EXT) && !is_from_extge(skb) &&
-	    !is_multicast_ether_addr(eth_hdr(skb)->h_dest)) {
-		if (!hnat_priv->g_ppdev)
-			hnat_priv->g_ppdev = dev_get_by_name(&init_net, hnat_priv->ppd);
-
-		if (!do_hnat_ext_to_ge(skb, state->in, __func__))
-			return NF_STOLEN;
-		if (!skb)
-			goto drop;
-		return NF_ACCEPT;
-	}
-
-	if (hnat_priv->data->whnat) {
-		if (skb_hnat_iface(skb) == FOE_MAGIC_EXT)
-			clr_from_extge(skb);
-
-		/* packets from external devices -> xxx ,step 2, learning stage */
-#if (1)
-		if (do_ext2ge_fast_learn(state->in, skb) && (eth_hdr(skb)->h_proto != HQOS_MAGIC_TAG)) {
-#else
-		if (do_ext2ge_fast_learn(state->in, skb)) {
-#endif
-			if (!do_hnat_ext_to_ge2(skb, __func__))
-				return NF_STOLEN;
-			goto drop;
-		}
-
-		/* packets form ge -> external device */
-		if (do_ge2ext_fast(state->in, skb)) {
-			if (!do_hnat_ge_to_ext(skb, __func__))
-				return NF_STOLEN;
-			goto drop;
-		}
-	}
-
-	/* MapE need remove ipv6 header and pingpong. (bridge mode) */
-	if (do_mape_w2l_fast(state->in, skb)) {
-		if (!do_hnat_mape_w2l_fast(skb, state->in, __func__))
-			return NF_STOLEN;
-		else
-			return NF_ACCEPT;
-	}
-
-	return NF_ACCEPT;
-drop:
-	printk_ratelimited(KERN_WARNING
-				"%s:drop (in_dev=%s, iif=0x%x, CB2=0x%x, ppe_hash=0x%x, sport=0x%x, reason=0x%x, alg=0x%x)\n",
-				__func__, state->in->name, skb_hnat_iface(skb),
-				HNAT_SKB_CB2(skb)->magic, skb_hnat_entry(skb),
-				skb_hnat_sport(skb), skb_hnat_reason(skb),
-				skb_hnat_alg(skb));
-
-	return NF_DROP;
-}
-
-static unsigned int hnat_ipv6_get_nexthop(struct sk_buff *skb,
-					  const struct net_device *out,
-					  struct hnat_hw_path *hw_path)
-{
-	struct in6_addr *ipv6_nexthop;
-	struct neighbour *neigh = NULL;
-	struct dst_entry *dst = skb_dst(skb);
-	struct ethhdr *eth;
-
-	if (hw_path->flags & HNAT_PATH_PPPOE) {
-		memcpy(eth_hdr(skb)->h_source, hw_path->eth_src, ETH_ALEN);
-		memcpy(eth_hdr(skb)->h_dest, hw_path->eth_dest, ETH_ALEN);
-		return 0;
-	}
-
-	rcu_read_lock_bh();
-	ipv6_nexthop =
-		rt6_nexthop((struct rt6_info *)dst, &ipv6_hdr(skb)->daddr);
-	neigh = __ipv6_neigh_lookup_noref(dst->dev, ipv6_nexthop);
-	if (unlikely(!neigh)) {
-		dev_notice(hnat_priv->dev, "%s:No neigh (daddr=%pI6)\n", __func__,
-			   &ipv6_hdr(skb)->daddr);
-		rcu_read_unlock_bh();
-		return -1;
-	}
-
-	/* why do we get all zero ethernet address ? */
-	if (!is_valid_ether_addr(neigh->ha)) {
-		rcu_read_unlock_bh();
-		return -1;
-	}
-
-	if (ipv6_hdr(skb)->nexthdr == NEXTHDR_IPIP) {
-		/*copy ether type for DS-Lite and MapE */
-		eth = (struct ethhdr *)(skb->data - ETH_HLEN);
-		eth->h_proto = skb->protocol;
-	} else {
-		eth = eth_hdr(skb);
-	}
-
-	ether_addr_copy(eth->h_dest, neigh->ha);
-	ether_addr_copy(eth->h_source, out->dev_addr);
-
-	rcu_read_unlock_bh();
-
-	return 0;
-}
-
-static unsigned int hnat_ipv4_get_nexthop(struct sk_buff *skb,
-					  const struct net_device *out,
-					  struct hnat_hw_path *hw_path)
-{
-	u32 nexthop;
-	struct neighbour *neigh;
-	struct dst_entry *dst = skb_dst(skb);
-	struct rtable *rt = (struct rtable *)dst;
-	struct net_device *dev = (__force struct net_device *)out;
-
-	if (hw_path->flags & HNAT_PATH_PPPOE) {
-		memcpy(eth_hdr(skb)->h_source, hw_path->eth_src, ETH_ALEN);
-		memcpy(eth_hdr(skb)->h_dest, hw_path->eth_dest, ETH_ALEN);
-		return 0;
-	}
-
-	rcu_read_lock_bh();
-	nexthop = (__force u32)rt_nexthop(rt, ip_hdr(skb)->daddr);
-	neigh = __ipv4_neigh_lookup_noref(dev, nexthop);
-	if (unlikely(!neigh)) {
-		dev_notice(hnat_priv->dev, "%s:No neigh (daddr=%pI4)\n", __func__,
-			   &ip_hdr(skb)->daddr);
-		rcu_read_unlock_bh();
-		return -1;
-	}
-
-	/* why do we get all zero ethernet address ? */
-	if (!is_valid_ether_addr(neigh->ha)) {
-		rcu_read_unlock_bh();
-		return -1;
-	}
-
-	memcpy(eth_hdr(skb)->h_dest, neigh->ha, ETH_ALEN);
-	memcpy(eth_hdr(skb)->h_source, out->dev_addr, ETH_ALEN);
-
-	rcu_read_unlock_bh();
-
-	return 0;
-}
-
-static u16 ppe_get_chkbase(struct iphdr *iph)
-{
-	u16 org_chksum = ntohs(iph->check);
-	u16 org_tot_len = ntohs(iph->tot_len);
-	u16 org_id = ntohs(iph->id);
-	u16 chksum_tmp, tot_len_tmp, id_tmp;
-	u32 tmp = 0;
-	u16 chksum_base = 0;
-
-	chksum_tmp = ~(org_chksum);
-	tot_len_tmp = ~(org_tot_len);
-	id_tmp = ~(org_id);
-	tmp = chksum_tmp + tot_len_tmp + id_tmp;
-	tmp = ((tmp >> 16) & 0x7) + (tmp & 0xFFFF);
-	tmp = ((tmp >> 16) & 0x7) + (tmp & 0xFFFF);
-	chksum_base = tmp & 0xFFFF;
-
-	return chksum_base;
-}
-
-struct foe_entry ppe_fill_L2_info(struct ethhdr *eth, struct foe_entry entry,
-				  struct hnat_hw_path *hw_path)
-{
-	switch (entry.bfib1.pkt_type) {
-	case IPV4_HNAPT:
-	case IPV4_HNAT:
-		entry.ipv4_hnapt.dmac_hi = swab32(*((u32 *)eth->h_dest));
-		entry.ipv4_hnapt.dmac_lo = swab16(*((u16 *)&eth->h_dest[4]));
-		entry.ipv4_hnapt.smac_hi = swab32(*((u32 *)eth->h_source));
-		entry.ipv4_hnapt.smac_lo = swab16(*((u16 *)&eth->h_source[4]));
-		entry.ipv4_hnapt.pppoe_id = hw_path->pppoe_sid;
-		break;
-	case IPV4_DSLITE:
-	case IPV6_6RD:
-	case IPV6_5T_ROUTE:
-	case IPV6_3T_ROUTE:
-		entry.ipv6_5t_route.dmac_hi = swab32(*((u32 *)eth->h_dest));
-		entry.ipv6_5t_route.dmac_lo = swab16(*((u16 *)&eth->h_dest[4]));
-		entry.ipv6_5t_route.smac_hi = swab32(*((u32 *)eth->h_source));
-		entry.ipv6_5t_route.smac_lo =
-			swab16(*((u16 *)&eth->h_source[4]));
-		entry.ipv6_5t_route.pppoe_id = hw_path->pppoe_sid;
-		break;
-	}
-	return entry;
-}
-
-struct foe_entry ppe_fill_info_blk(struct ethhdr *eth, struct foe_entry entry,
-				   struct hnat_hw_path *hw_path)
-{
-	entry.bfib1.psn = (hw_path->flags & HNAT_PATH_PPPOE) ? 1 : 0;
-	entry.bfib1.vlan_layer += (hw_path->flags & HNAT_PATH_VLAN) ? 1 : 0;
-	entry.bfib1.vpm = (entry.bfib1.vlan_layer) ? 1 : 0;
-	entry.bfib1.time_stamp = readl((hnat_priv->fe_base + 0x0010)) & (0xFFFF);
-	entry.bfib1.ttl = 1;
-	entry.bfib1.cah = 1;
-	entry.bfib1.ka = 1;
-	switch (entry.bfib1.pkt_type) {
-	case IPV4_HNAPT:
-	case IPV4_HNAT:
-		if (is_multicast_ether_addr(&eth->h_dest[0])) {
-			entry.ipv4_hnapt.iblk2.mcast = 1;
-			if (hnat_priv->data->version == MTK_HNAT_V3)
-				{entry.bfib1.sta = 1;}
-				entry.ipv4_hnapt.m_timestamp = foe_timestamp(hnat_priv);
-		} else {
-			entry.ipv4_hnapt.iblk2.mcast = 0;
-		}
-
-		entry.ipv4_hnapt.iblk2.port_ag = 0x3f;
-		break;
-	case IPV4_DSLITE:
-	case IPV6_6RD:
-	case IPV6_5T_ROUTE:
-	case IPV6_3T_ROUTE:
-		if (is_multicast_ether_addr(&eth->h_dest[0])) {
-			entry.ipv6_5t_route.iblk2.mcast = 1;
-			if (hnat_priv->data->version == MTK_HNAT_V3)
-				{entry.bfib1.sta = 1;}
-				entry.ipv4_hnapt.m_timestamp = foe_timestamp(hnat_priv);
-		} else {
-			entry.ipv6_5t_route.iblk2.mcast = 0;
-		}
-
-		entry.ipv6_5t_route.iblk2.port_ag = 0x3f;
-		break;
-	}
-	return entry;
-}
-
-static void ppe_fill_flow_lbl(struct foe_entry *entry, struct ipv6hdr *ip6h)
-{
-	entry->ipv4_dslite.flow_lbl[0] = ip6h->flow_lbl[2];
-	entry->ipv4_dslite.flow_lbl[1] = ip6h->flow_lbl[1];
-	entry->ipv4_dslite.flow_lbl[2] = ip6h->flow_lbl[0];
-}
-
-static unsigned int skb_to_hnat_info(struct sk_buff *skb,
-				     const struct net_device *dev,
-				     struct foe_entry *foe,
-				     struct hnat_hw_path *hw_path)
-{
-	struct foe_entry entry = { 0 };
-	int whnat = IS_WHNAT(dev);
-	struct ethhdr *eth;
-	struct iphdr *iph;
-	struct ipv6hdr *ip6h;
-	struct tcpudphdr _ports;
-	const struct tcpudphdr *pptr;
-	u32 gmac = NR_DISCARD;
-	int udp = 0;
-	u32 qid = 0;
-	int mape = 0;
-
-	if (ipv6_hdr(skb)->nexthdr == NEXTHDR_IPIP)
-		/* point to ethernet header for DS-Lite and MapE */
-		eth = (struct ethhdr *)(skb->data - ETH_HLEN);
-	else
-		eth = eth_hdr(skb);
-	if (is_multicast_ether_addr(eth->h_dest)) {
-		/*do not bind multicast if PPE mcast not enable*/
-		if (!hnat_priv->pmcast)
-			return 0;
-	}
-	entry.bfib1.pkt_type = foe->udib1.pkt_type; /* Get packte type state*/
-	switch (ntohs(eth->h_proto)) {
-	case ETH_P_IP:
-		iph = ip_hdr(skb);
-		switch (iph->protocol) {
-		case IPPROTO_UDP:
-			udp = 1;
-		case IPPROTO_TCP:
-			entry.ipv4_hnapt.etype = htons(ETH_P_IP);
-
-			/* DS-Lite WAN->LAN */
-			if (entry.ipv4_hnapt.bfib1.pkt_type == IPV4_DSLITE) {
-				entry.ipv4_dslite.sip = foe->ipv4_dslite.sip;
-				entry.ipv4_dslite.dip = foe->ipv4_dslite.dip;
-				entry.ipv4_dslite.sport =
-					foe->ipv4_dslite.sport;
-				entry.ipv4_dslite.dport =
-					foe->ipv4_dslite.dport;
-
-				entry.ipv4_dslite.tunnel_sipv6_0 =
-					foe->ipv4_dslite.tunnel_sipv6_0;
-				entry.ipv4_dslite.tunnel_sipv6_1 =
-					foe->ipv4_dslite.tunnel_sipv6_1;
-				entry.ipv4_dslite.tunnel_sipv6_2 =
-					foe->ipv4_dslite.tunnel_sipv6_2;
-				entry.ipv4_dslite.tunnel_sipv6_3 =
-					foe->ipv4_dslite.tunnel_sipv6_3;
-
-				entry.ipv4_dslite.tunnel_dipv6_0 =
-					foe->ipv4_dslite.tunnel_dipv6_0;
-				entry.ipv4_dslite.tunnel_dipv6_1 =
-					foe->ipv4_dslite.tunnel_dipv6_1;
-				entry.ipv4_dslite.tunnel_dipv6_2 =
-					foe->ipv4_dslite.tunnel_dipv6_2;
-				entry.ipv4_dslite.tunnel_dipv6_3 =
-					foe->ipv4_dslite.tunnel_dipv6_3;
-
-				entry.ipv4_dslite.bfib1.rmt = 1;
-				entry.ipv4_dslite.iblk2.dscp = iph->tos;
-				entry.ipv4_dslite.vlan1 = hw_path->vlan_id;
-				if (hnat_priv->data->per_flow_accounting)
-					entry.ipv4_dslite.iblk2.mibf = 1;
-
-			} else {
-				entry.ipv4_hnapt.iblk2.dscp = iph->tos;
-				if (hnat_priv->data->per_flow_accounting)
-					entry.ipv4_hnapt.iblk2.mibf = 1;
-
-				entry.ipv4_hnapt.vlan1 = hw_path->vlan_id;
-
-				if (skb->vlan_tci && FROM_GE_WAN(skb) && IS_LAN(dev)) {
-					entry.bfib1.vlan_layer += 1;
-
-					if (entry.ipv4_hnapt.vlan1)
-						entry.ipv4_hnapt.vlan2 = (skb->vlan_tci & VLAN_VID_MASK);
-					else
-						entry.ipv4_hnapt.vlan1 = (skb->vlan_tci & VLAN_VID_MASK);
-				}
-
-				entry.ipv4_hnapt.sip = foe->ipv4_hnapt.sip;
-				entry.ipv4_hnapt.dip = foe->ipv4_hnapt.dip;
-				entry.ipv4_hnapt.sport = foe->ipv4_hnapt.sport;
-				entry.ipv4_hnapt.dport = foe->ipv4_hnapt.dport;
-
-				entry.ipv4_hnapt.new_sip = ntohl(iph->saddr);
-				entry.ipv4_hnapt.new_dip = ntohl(iph->daddr);
-			}
-
-			entry.ipv4_hnapt.bfib1.udp = udp;
-			if (IS_IPV4_HNAPT(foe)) {
-				pptr = skb_header_pointer(skb, iph->ihl * 4,
-							  sizeof(_ports),
-							  &_ports);
-				entry.ipv4_hnapt.new_sport = ntohs(pptr->src);
-				entry.ipv4_hnapt.new_dport = ntohs(pptr->dst);
-			}
-
-			break;
-
-		default:
-			return -1;
-		}
-		trace_printk(
-			"[%s]skb->head=%p, skb->data=%p,ip_hdr=%p, skb->len=%d, skb->data_len=%d\n",
-			__func__, skb->head, skb->data, iph, skb->len,
-			skb->data_len);
-		break;
-
-	case ETH_P_IPV6:
-		ip6h = ipv6_hdr(skb);
-		switch (ip6h->nexthdr) {
-		case NEXTHDR_UDP:
-			udp = 1;
-		case NEXTHDR_TCP: /* IPv6-5T or IPv6-3T */
-			entry.ipv6_5t_route.etype = htons(ETH_P_IPV6);
-
-			entry.ipv6_5t_route.vlan1 = hw_path->vlan_id;
-
-			if (skb->vlan_tci && FROM_GE_WAN(skb) && IS_LAN(dev)) {
-				entry.bfib1.vlan_layer += 1;
-
-				if (entry.ipv6_5t_route.vlan1)
-					entry.ipv6_5t_route.vlan2 = (skb->vlan_tci & VLAN_VID_MASK);
-				else
-					entry.ipv6_5t_route.vlan1 = (skb->vlan_tci & VLAN_VID_MASK);
-			}
-
-			if (hnat_priv->data->per_flow_accounting)
-				entry.ipv6_5t_route.iblk2.mibf = 1;
-			entry.ipv6_5t_route.bfib1.udp = udp;
-
-			if (IS_IPV6_6RD(foe)) {
-				entry.ipv6_5t_route.bfib1.rmt = 1;
-				entry.ipv6_6rd.tunnel_sipv4 =
-					foe->ipv6_6rd.tunnel_sipv4;
-				entry.ipv6_6rd.tunnel_dipv4 =
-					foe->ipv6_6rd.tunnel_dipv4;
-			}
-
-			entry.ipv6_3t_route.ipv6_sip0 =
-				foe->ipv6_3t_route.ipv6_sip0;
-			entry.ipv6_3t_route.ipv6_sip1 =
-				foe->ipv6_3t_route.ipv6_sip1;
-			entry.ipv6_3t_route.ipv6_sip2 =
-				foe->ipv6_3t_route.ipv6_sip2;
-			entry.ipv6_3t_route.ipv6_sip3 =
-				foe->ipv6_3t_route.ipv6_sip3;
-
-			entry.ipv6_3t_route.ipv6_dip0 =
-				foe->ipv6_3t_route.ipv6_dip0;
-			entry.ipv6_3t_route.ipv6_dip1 =
-				foe->ipv6_3t_route.ipv6_dip1;
-			entry.ipv6_3t_route.ipv6_dip2 =
-				foe->ipv6_3t_route.ipv6_dip2;
-			entry.ipv6_3t_route.ipv6_dip3 =
-				foe->ipv6_3t_route.ipv6_dip3;
-
-			if (IS_IPV6_5T_ROUTE(foe) || IS_IPV6_6RD(foe)) {
-				entry.ipv6_5t_route.sport =
-					foe->ipv6_5t_route.sport;
-				entry.ipv6_5t_route.dport =
-					foe->ipv6_5t_route.dport;
-			}
-			entry.ipv6_5t_route.iblk2.dscp =
-				(ip6h->priority << 4 |
-				 (ip6h->flow_lbl[0] >> 4));
-			break;
-
-		case NEXTHDR_IPIP:
-			if (!mape_toggle &&
-			    entry.bfib1.pkt_type == IPV4_DSLITE) {
-				/* DS-Lite LAN->WAN */
-				entry.ipv4_dslite.sip = foe->ipv4_dslite.sip;
-				entry.ipv4_dslite.dip = foe->ipv4_dslite.dip;
-				entry.ipv4_dslite.sport =
-					foe->ipv4_dslite.sport;
-				entry.ipv4_dslite.dport =
-					foe->ipv4_dslite.dport;
-
-				entry.ipv4_dslite.tunnel_sipv6_0 =
-					ntohl(ip6h->saddr.s6_addr32[0]);
-				entry.ipv4_dslite.tunnel_sipv6_1 =
-					ntohl(ip6h->saddr.s6_addr32[1]);
-				entry.ipv4_dslite.tunnel_sipv6_2 =
-					ntohl(ip6h->saddr.s6_addr32[2]);
-				entry.ipv4_dslite.tunnel_sipv6_3 =
-					ntohl(ip6h->saddr.s6_addr32[3]);
-
-				entry.ipv4_dslite.tunnel_dipv6_0 =
-					ntohl(ip6h->daddr.s6_addr32[0]);
-				entry.ipv4_dslite.tunnel_dipv6_1 =
-					ntohl(ip6h->daddr.s6_addr32[1]);
-				entry.ipv4_dslite.tunnel_dipv6_2 =
-					ntohl(ip6h->daddr.s6_addr32[2]);
-				entry.ipv4_dslite.tunnel_dipv6_3 =
-					ntohl(ip6h->daddr.s6_addr32[3]);
-
-				ppe_fill_flow_lbl(&entry, ip6h);
-
-				entry.ipv4_dslite.priority = ip6h->priority;
-				entry.ipv4_dslite.hop_limit = ip6h->hop_limit;
-				entry.ipv4_dslite.vlan1 = hw_path->vlan_id;
-				if (hnat_priv->data->per_flow_accounting)
-					entry.ipv4_dslite.iblk2.mibf = 1;
-			} else if (mape_toggle &&
-				   entry.bfib1.pkt_type == IPV4_HNAPT) {
-				/* MapE LAN -> WAN */
-				mape = 1;
-				entry.ipv4_hnapt.iblk2.dscp =
-					foe->ipv4_hnapt.iblk2.dscp;
-				if (hnat_priv->data->per_flow_accounting)
-					entry.ipv4_hnapt.iblk2.mibf = 1;
-
-				entry.ipv4_hnapt.vlan1 = hw_path->vlan_id;
-
-				entry.ipv4_hnapt.sip = foe->ipv4_hnapt.sip;
-				entry.ipv4_hnapt.dip = foe->ipv4_hnapt.dip;
-				entry.ipv4_hnapt.sport = foe->ipv4_hnapt.sport;
-				entry.ipv4_hnapt.dport = foe->ipv4_hnapt.dport;
-
-				entry.ipv4_hnapt.new_sip =
-					foe->ipv4_hnapt.new_sip;
-				entry.ipv4_hnapt.new_dip =
-					foe->ipv4_hnapt.new_dip;
-				entry.ipv4_hnapt.etype = htons(ETH_P_IP);
-
-#if (1)
-				entry.ipv4_hnapt.iblk2.qid = skb->mark & 0x7;
-				if (IS_LAN(dev))
-					entry.ipv4_hnapt.iblk2.qid += 8;
-				entry.ipv4_hnapt.iblk2.fqos = 1;
-#endif
-
-				entry.ipv4_hnapt.bfib1.udp =
-					foe->ipv4_hnapt.bfib1.udp;
-
-				entry.ipv4_hnapt.new_sport =
-					foe->ipv4_hnapt.new_sport;
-				entry.ipv4_hnapt.new_dport =
-					foe->ipv4_hnapt.new_dport;
-				mape_l2w_v6h = *ip6h;
-			}
-			break;
-
-		default:
-			return -1;
-		}
-
-		trace_printk(
-			"[%s]skb->head=%p, skb->data=%p,ipv6_hdr=%p, skb->len=%d, skb->data_len=%d\n",
-			__func__, skb->head, skb->data, ip6h, skb->len,
-			skb->data_len);
-		break;
-
-	default:
-		ip6h = ipv6_hdr(skb);
-		iph = ip_hdr(skb);
-		switch (entry.bfib1.pkt_type) {
-		case IPV6_6RD: /* 6RD LAN->WAN */
-			entry.ipv6_6rd.ipv6_sip0 = foe->ipv6_6rd.ipv6_sip0;
-			entry.ipv6_6rd.ipv6_sip1 = foe->ipv6_6rd.ipv6_sip1;
-			entry.ipv6_6rd.ipv6_sip2 = foe->ipv6_6rd.ipv6_sip2;
-			entry.ipv6_6rd.ipv6_sip3 = foe->ipv6_6rd.ipv6_sip3;
-
-			entry.ipv6_6rd.ipv6_dip0 = foe->ipv6_6rd.ipv6_dip0;
-			entry.ipv6_6rd.ipv6_dip1 = foe->ipv6_6rd.ipv6_dip1;
-			entry.ipv6_6rd.ipv6_dip2 = foe->ipv6_6rd.ipv6_dip2;
-			entry.ipv6_6rd.ipv6_dip3 = foe->ipv6_6rd.ipv6_dip3;
-
-			entry.ipv6_6rd.sport = foe->ipv6_6rd.sport;
-			entry.ipv6_6rd.dport = foe->ipv6_6rd.dport;
-			entry.ipv6_6rd.tunnel_sipv4 = ntohl(iph->saddr);
-			entry.ipv6_6rd.tunnel_dipv4 = ntohl(iph->daddr);
-			entry.ipv6_6rd.hdr_chksum = ppe_get_chkbase(iph);
-			entry.ipv6_6rd.flag = (ntohs(iph->frag_off) >> 13);
-			entry.ipv6_6rd.ttl = iph->ttl;
-			entry.ipv6_6rd.dscp = iph->tos;
-			entry.ipv6_6rd.per_flow_6rd_id = 1;
-			entry.ipv6_6rd.vlan1 = hw_path->vlan_id;
-			if (hnat_priv->data->per_flow_accounting)
-				entry.ipv6_6rd.iblk2.mibf = 1;
-			break;
-
-		default:
-			return -1;
-		}
-	}
-
-	/* Fill Layer2 Info.*/
-	entry = ppe_fill_L2_info(eth, entry, hw_path);
-
-	/* Fill Info Blk*/
-	entry = ppe_fill_info_blk(eth, entry, hw_path);
-
-	if (IS_LAN(dev)) {
-		if (IS_DSA_LAN(dev))
-			hnat_dsa_fill_stag(dev, &entry, hw_path,
-					   ntohs(eth->h_proto), mape);
-		gmac = NR_GMAC1_PORT;
-	} else if (IS_WAN(dev)) {
-		if (IS_DSA_WAN(dev))
-			hnat_dsa_fill_stag(dev, &entry, hw_path,
-					   ntohs(eth->h_proto), mape);
-		if (mape_toggle && mape == 1) {
-			gmac = NR_PDMA_PORT;
-			/* Set act_dp = wan_dev */
-			entry.ipv4_hnapt.act_dp = dev->ifindex;
-		} else {
-			gmac = (IS_GMAC1_MODE) ? NR_GMAC1_PORT : NR_GMAC2_PORT;
-		}
-	} else if (IS_EXT(dev)) {
-		if ((hnat_priv->data->version != MTK_HNAT_V2) && IS_GMAC1_MODE) {
-			entry.bfib1.vpm = 1;
-			entry.bfib1.vlan_layer = 1;
-
-			if (FROM_GE_LAN(skb))
-				entry.ipv4_hnapt.vlan1 = 1;
-			else if (FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb))
-				entry.ipv4_hnapt.vlan1 = 2;
-		}
-
-		trace_printk("learn of lan or wan(iif=%x) --> %s(ext)\n",
-			     skb_hnat_iface(skb), dev->name);
-		/* To CPU then stolen by pre-routing hant hook of LAN/WAN
-		 * Current setting is PDMA RX.
-		 */
-		gmac = NR_PDMA_PORT;
-		if (IS_IPV4_GRP(foe))
-			entry.ipv4_hnapt.act_dp = dev->ifindex;
-		else
-			entry.ipv6_5t_route.act_dp = dev->ifindex;
-	} else {
-		printk_ratelimited(KERN_WARNING
-					"Unknown case of dp, iif=%x --> %s\n",
-					skb_hnat_iface(skb), dev->name);
-
-		return 0;
-	}
-
-	qid = skb->mark & (MTK_QDMA_TX_MASK);
-
-	if (IS_IPV4_GRP(foe)) {
-		entry.ipv4_hnapt.iblk2.dp = gmac;
-		if (hnat_priv->data->version == MTK_HNAT_V1)
-			entry.ipv4_hnapt.iblk2.port_mg = 0x3f;
-		else
-			entry.ipv4_hnapt.iblk2.port_mg = 0;/*unused port_mg*/
-#if (1)
-		/* qid[5:0]= port_mg[1:0]+ qid[3:0] */
-		entry.ipv4_hnapt.iblk2.qid = qid & 0xf;
-		if (hnat_priv->data->version != MTK_HNAT_V1)
-			entry.ipv4_hnapt.iblk2.port_mg |= ((qid >> 4) & 0x3);
-		if (((IS_EXT(dev) && (FROM_GE_LAN(skb) || FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb))) ||
-		     ((mape_toggle && mape == 1) && !FROM_EXT(skb))) &&
-		    (!whnat)) {
-			entry.ipv4_hnapt.etype = htons(HQOS_MAGIC_TAG);
-			entry.ipv4_hnapt.vlan1 = skb_hnat_entry(skb);
-			entry.bfib1.vlan_layer = 1;
-		}
-		if (FROM_EXT(skb) || skb_hnat_sport(skb) == NR_QDMA_PORT)
-			entry.ipv4_hnapt.iblk2.fqos = 0;
-		else
-			entry.ipv4_hnapt.iblk2.fqos = 1;
-#else
-		entry.ipv4_hnapt.iblk2.fqos = 0;
-#endif
-	} else {
-		entry.ipv6_5t_route.iblk2.dp = gmac;
-		if (hnat_priv->data->version == MTK_HNAT_V1)
-			entry.ipv6_5t_route.iblk2.port_mg = 0x3f;
-		else
-			entry.ipv6_5t_route.iblk2.port_mg = 0;/*unused port_mg*/
-#if (1)
-		/* qid[5:0]= port_mg[1:0]+ qid[3:0] */
-		entry.ipv6_5t_route.iblk2.qid = qid & 0xf;
-		if (hnat_priv->data->version != MTK_HNAT_V1)
-			entry.ipv6_5t_route.iblk2.port_mg |=
-							((qid >> 4) & 0x3);
-		if (IS_EXT(dev) && (FROM_GE_LAN(skb) || FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb)) &&
-		    (!whnat)) {
-			entry.ipv6_5t_route.etype = htons(HQOS_MAGIC_TAG);
-			entry.ipv6_5t_route.vlan1 = skb_hnat_entry(skb);
-			entry.bfib1.vlan_layer = 1;
-		}
-		if (FROM_EXT(skb))
-			entry.ipv6_5t_route.iblk2.fqos = 0;
-		else
-			entry.ipv6_5t_route.iblk2.fqos = 1;
-#else
-		entry.ipv6_5t_route.iblk2.fqos = 0;
-#endif
-	}
-
-	memcpy(foe, &entry, sizeof(entry));
-	/*reset statistic for this entry*/
-	if (hnat_priv->data->per_flow_accounting)
-		memset(&hnat_priv->acct[skb_hnat_entry(skb)], 0,
-		       sizeof(struct mib_entry));
-
-	wmb();
-	/* The INFO2.port_mg and 2nd VLAN ID fields of PPE entry are redefined
-	 * by Wi-Fi whnat engine. These data and INFO2.dp will be updated and
-	 * the entry is set to BIND state in mtk_sw_nat_hook_tx().
-	 */
-	if (!whnat)
-		foe->bfib1.state = BIND;
-
-	return 0;
-}
-
-int mtk_sw_nat_hook_tx(struct sk_buff *skb, int gmac_no)
-{
-	struct foe_entry *entry;
-	struct ethhdr *eth;
-
-	if (skb_hnat_alg(skb) || !is_magic_tag_valid(skb) || !IS_SPACE_AVAILABLE_HEAD(skb))
-		return NF_ACCEPT;
-
-	trace_printk(
-		"[%s]entry=%x reason=%x gmac_no=%x wdmaid=%x rxid=%x wcid=%x bssid=%x\n",
-		__func__, skb_hnat_entry(skb), skb_hnat_reason(skb), gmac_no,
-		skb_hnat_wdma_id(skb), skb_hnat_bss_id(skb),
-		skb_hnat_wc_id(skb), skb_hnat_rx_id(skb));
-
-	if (!skb_hnat_is_hashed(skb))
-		return NF_ACCEPT;
-
-	entry = &hnat_priv->foe_table_cpu[skb_hnat_entry(skb)];
-	if (entry_hnat_is_bound(entry))
-		return NF_ACCEPT;
-
-	if (skb_hnat_reason(skb) != HIT_UNBIND_RATE_REACH)
-		return NF_ACCEPT;
-
-	eth = eth_hdr(skb);
-	if (is_multicast_ether_addr(eth->h_dest)) {
-		/*not bind multicast if PPE mcast not enable*/
-		if (!hnat_priv->pmcast)
-			return NF_ACCEPT;
-	}
-
-	/* Some mt_wifi virtual interfaces, such as apcli,
-	 * will change the smac for specail purpose.
-	 */
-	switch (entry->bfib1.pkt_type) {
-	case IPV4_HNAPT:
-	case IPV4_HNAT:
-		entry->ipv4_hnapt.smac_hi = swab32(*((u32 *)eth->h_source));
-		entry->ipv4_hnapt.smac_lo = swab16(*((u16 *)&eth->h_source[4]));
-		break;
-	case IPV4_DSLITE:
-	case IPV6_6RD:
-	case IPV6_5T_ROUTE:
-	case IPV6_3T_ROUTE:
-		entry->ipv6_5t_route.smac_hi = swab32(*((u32 *)eth->h_source));
-		entry->ipv6_5t_route.smac_lo = swab16(*((u16 *)&eth->h_source[4]));
-		break;
-	}
-
-	/* MT7622 wifi hw_nat not support QoS */
-	entry->ipv4_hnapt.iblk2w.fqos = 0;
-	if (gmac_no == NR_WHNAT_WDMA_PORT) {
-		entry->ipv4_hnapt.iblk2w.wdmaid =
-			(skb_hnat_wdma_id(skb) & 0x01);
-		entry->ipv4_hnapt.iblk2w.winfoi = 1;
-		entry->ipv4_hnapt.winfo.bssid = skb_hnat_bss_id(skb);
-		entry->ipv4_hnapt.winfo.wcid = skb_hnat_wc_id(skb);
-		entry->ipv4_hnapt.winfo.rxid = skb_hnat_rx_id(skb);
-	} else {
-		if (IS_GMAC1_MODE && !hnat_dsa_is_enable(hnat_priv)) {
-			entry->bfib1.vpm = 1;
-			entry->bfib1.vlan_layer = 1;
-
-			if (FROM_GE_LAN(skb))
-				entry->ipv4_hnapt.vlan1 = 1;
-			else if (FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb))
-				entry->ipv4_hnapt.vlan1 = 2;
-		}
-
-#if (1)
-		if (FROM_GE_LAN(skb) || FROM_GE_WAN(skb) || FROM_GE_VIRTUAL(skb)) {
-			entry->bfib1.vpm = 0;
-			entry->ipv4_hnapt.etype = htons(HQOS_MAGIC_TAG);
-			entry->ipv4_hnapt.vlan1 = skb_hnat_entry(skb);
-			entry->bfib1.vlan_layer = 1;
-			entry->ipv4_hnapt.iblk2w.fqos = 1;
-		}
-#endif
-	}
-
-	entry->ipv4_hnapt.iblk2w.dp = gmac_no;
-	entry->bfib1.state = BIND;
-
-	return NF_ACCEPT;
-}
-
-void mtk_ppe_dev_register_hook(struct net_device *dev)
-{
-	int i, number = 0;
-	struct extdev_entry *ext_entry;
-
-	if (!strncmp(dev->name, "wds", 3))
-		return;
-
-	for (i = 1; i < MAX_IF_NUM; i++) {
-		if (hnat_priv->wifi_hook_if[i] == dev) {
-			pr_info("%s : %s has been registered in wifi_hook_if table[%d]\n",
-				__func__, dev->name, i);
-			return;
-		}
-		if (!hnat_priv->wifi_hook_if[i]) {
-			if (find_extif_from_devname(dev->name)) {
-				extif_set_dev(dev);
-				goto add_wifi_hook_if;
-			}
-
-			number = get_ext_device_number();
-			if (number >= MAX_EXT_DEVS) {
-				pr_info("%s : extdev array is full. %s is not registered\n",
-					__func__, dev->name);
-				return;
-			}
-
-			ext_entry = kzalloc(sizeof(*ext_entry), GFP_KERNEL);
-			if (!ext_entry)
-				return;
-
-			strncpy(ext_entry->name, dev->name, IFNAMSIZ);
-			dev_hold(dev);
-			ext_entry->dev = dev;
-			ext_if_add(ext_entry);
-
-add_wifi_hook_if:
-			dev_hold(dev);
-			hnat_priv->wifi_hook_if[i] = dev;
-
-			break;
-		}
-	}
-	pr_info("%s : ineterface %s register (%d)\n", __func__, dev->name, i);
-}
-
-void mtk_ppe_dev_unregister_hook(struct net_device *dev)
-{
-	int i;
-
-	for (i = 1; i < MAX_IF_NUM; i++) {
-		if (hnat_priv->wifi_hook_if[i] == dev) {
-			hnat_priv->wifi_hook_if[i] = NULL;
-			dev_put(dev);
-
-			break;
-		}
-	}
-
-	extif_put_dev(dev);
-	pr_info("%s : ineterface %s set null (%d)\n", __func__, dev->name, i);
-}
-
-static unsigned int mtk_hnat_accel_type(struct sk_buff *skb)
-{
-	struct dst_entry *dst;
-	struct nf_conn *ct;
-	enum ip_conntrack_info ctinfo;
-	const struct nf_conn_help *help;
-
-	/* Do not accelerate 1st round of xfrm flow, and 2nd round of xfrm flow
-	 * is from local_out which is also filtered in sanity check.
-	 */
-	dst = skb_dst(skb);
-	if (dst && dst_xfrm(dst))
-		return 0;
-
-	ct = nf_ct_get(skb, &ctinfo);
-	if (!ct)
-		return 1;
-
-	/* rcu_read_lock()ed by nf_hook_slow */
-	help = nfct_help(ct);
-	if (help && rcu_dereference(help->helper))
-		return 0;
-
-	return 1;
-}
-
-static unsigned int mtk_hnat_nf_post_routing(
-	struct sk_buff *skb, const struct net_device *out,
-	unsigned int (*fn)(struct sk_buff *, const struct net_device *,
-			   struct hnat_hw_path *),
-	const char *func)
-{
-	struct foe_entry *entry;
-	struct hnat_hw_path hw_path = { .dev = out };
-	const struct net_device *arp_dev = out;
-
-	if (skb->protocol == htons(ETH_P_IPV6) && !hnat_priv->ipv6_en) {
- 		return 0;
- 	}
-	if (skb_hnat_alg(skb) || unlikely(!is_magic_tag_valid(skb) ||
-					  !IS_SPACE_AVAILABLE_HEAD(skb)))
-		return 0;
-	if (unlikely(!skb_mac_header_was_set(skb)))
-		return 0;
-		
-	if (unlikely(!skb_hnat_is_hashed(skb)))
-		return 0;
-
-	if (out->netdev_ops->ndo_hnat_check) {
-		if (out->netdev_ops->ndo_hnat_check(&hw_path))
-			return 0;
-		out = hw_path.dev;
-	}
-	if (!IS_LAN(out) && !IS_WAN(out) && !IS_EXT(out))
-		return 0;
-
-	trace_printk("[%s] case hit, %x-->%s, reason=%x\n", __func__,
-		     skb_hnat_iface(skb), out->name, skb_hnat_reason(skb));
-
-	entry = &hnat_priv->foe_table_cpu[skb_hnat_entry(skb)];
-
-	switch (skb_hnat_reason(skb)) {
-	case HIT_UNBIND_RATE_REACH:
-		if (entry_hnat_is_bound(entry))
-			break;
-
-		if (fn && !mtk_hnat_accel_type(skb))
-			break;
-
-		if (fn && fn(skb, arp_dev, &hw_path))
-			break;
-
-		skb_to_hnat_info(skb, out, entry, &hw_path);
-		break;
-	case HIT_BIND_KEEPALIVE_DUP_OLD_HDR:
-		if (fn && !mtk_hnat_accel_type(skb))
-			break;
-
-		/* update mcast timestamp*/
-		if (hnat_priv->data->version == MTK_HNAT_V3 &&
-		    hnat_priv->data->mcast && entry->bfib1.sta == 1)
-			entry->ipv4_hnapt.m_timestamp = foe_timestamp(hnat_priv);
-
-		if (entry_hnat_is_bound(entry)) {
-			memset(skb_hnat_info(skb), 0, FOE_INFO_LEN);
-
-			return -1;
-		}
-		break;
-	case HIT_BIND_MULTICAST_TO_CPU:
-	case HIT_BIND_MULTICAST_TO_GMAC_CPU:
-		/*do not forward to gdma again,if ppe already done it*/
-		if (IS_LAN(out) || IS_WAN(out))
-			return -1;
-		break;
-	}
-
-	return 0;
-}
-
-static unsigned int
-mtk_hnat_ipv6_nf_local_out(void *priv, struct sk_buff *skb,
-			   const struct nf_hook_state *state)
-{
-	struct foe_entry *entry;
-	struct ipv6hdr *ip6h;
-	struct iphdr _iphdr;
-	const struct iphdr *iph;
-	struct tcpudphdr _ports;
-	const struct tcpudphdr *pptr;
-	int udp = 0;
-
-	if (unlikely(!skb_hnat_is_hashed(skb)))
-		return NF_ACCEPT;
-
-	entry = &hnat_priv->foe_table_cpu[skb_hnat_entry(skb)];
-	if (skb_hnat_reason(skb) == HIT_UNBIND_RATE_REACH) {
-		ip6h = ipv6_hdr(skb);
-		if (ip6h->nexthdr == NEXTHDR_IPIP) {
-			/* Map-E LAN->WAN: need to record orig info before fn. */
-			if (mape_toggle) {
-				iph = skb_header_pointer(skb, IPV6_HDR_LEN,
-							 sizeof(_iphdr), &_iphdr);
-				switch (iph->protocol) {
-				case IPPROTO_UDP:
-					udp = 1;
-				case IPPROTO_TCP:
-				break;
-
-				default:
-					return NF_ACCEPT;
-				}
-				entry->ipv4_hnapt.iblk2.dscp = iph->tos;
-				entry->ipv4_hnapt.bfib1.udp = udp;
-				entry->ipv4_hnapt.new_sip = ntohl(iph->saddr);
-				entry->ipv4_hnapt.new_dip = ntohl(iph->daddr);
-				pptr = skb_header_pointer(skb, IPV6_HDR_LEN + iph->ihl * 4,
-							  sizeof(_ports), &_ports);
-				entry->ipv4_hnapt.new_sport = ntohs(pptr->src);
-				entry->ipv4_hnapt.new_dport = ntohs(pptr->dst);
-			} else {
-				entry->bfib1.pkt_type = IPV4_DSLITE;
-			}
-		}
-	}
-	return NF_ACCEPT;
-}
-
-static unsigned int
-mtk_hnat_ipv6_nf_post_routing(void *priv, struct sk_buff *skb,
-			      const struct nf_hook_state *state)
-{
-	post_routing_print(skb, state->in, state->out, __func__);
-
-	if (!mtk_hnat_nf_post_routing(skb, state->out, hnat_ipv6_get_nexthop,
-				      __func__))
-		return NF_ACCEPT;
-
-	trace_printk(
-		"%s:drop (iif=0x%x, out_dev=%s, CB2=0x%x, ppe_hash=0x%x, sport=0x%x, reason=0x%x, alg=0x%x)\n",
-		__func__, skb_hnat_iface(skb), state->out->name, HNAT_SKB_CB2(skb)->magic,
-		skb_hnat_entry(skb), skb_hnat_sport(skb), skb_hnat_reason(skb),
-		skb_hnat_alg(skb));
-
-	return NF_DROP;
-}
-
-static unsigned int
-mtk_hnat_ipv4_nf_post_routing(void *priv, struct sk_buff *skb,
-			      const struct nf_hook_state *state)
-{
-	post_routing_print(skb, state->in, state->out, __func__);
-
-	if (!mtk_hnat_nf_post_routing(skb, state->out, hnat_ipv4_get_nexthop,
-				      __func__))
-		return NF_ACCEPT;
-
-	trace_printk(
-		"%s:drop (iif=0x%x, out_dev=%s, CB2=0x%x, ppe_hash=0x%x, sport=0x%x, reason=0x%x, alg=0x%x)\n",
-		__func__, skb_hnat_iface(skb), state->out->name, HNAT_SKB_CB2(skb)->magic,
-		skb_hnat_entry(skb), skb_hnat_sport(skb), skb_hnat_reason(skb),
-		skb_hnat_alg(skb));
-
-	return NF_DROP;
-}
-
-static unsigned int
-mtk_pong_hqos_handler(void *priv, struct sk_buff *skb,
-		      const struct nf_hook_state *state)
-{
-#if (1)
-	struct vlan_ethhdr *veth = (struct vlan_ethhdr *)skb_mac_header(skb);
-
-	if (eth_hdr(skb)->h_proto == HQOS_MAGIC_TAG) {
-		skb_hnat_entry(skb) = ntohs(veth->h_vlan_TCI) & 0x3fff;
-		skb_hnat_reason(skb) = HIT_BIND_FORCE_TO_CPU;
-	}
-#endif
-
-	if (skb_hnat_iface(skb) == FOE_MAGIC_EXT)
-		clr_from_extge(skb);
-
-	/* packets from external devices -> xxx ,step 2, learning stage */
-#if (1)
-	if (do_ext2ge_fast_learn(state->in, skb) && (eth_hdr(skb)->h_proto != HQOS_MAGIC_TAG)) {
-#else
-	if (do_ext2ge_fast_learn(state->in, skb)) {
-#endif
-		if (!do_hnat_ext_to_ge2(skb, __func__))
-			return NF_STOLEN;
-		goto drop;
-	}
-
-	/* packets form ge -> external device */
-	if (do_ge2ext_fast(state->in, skb)) {
-		if (!do_hnat_ge_to_ext(skb, __func__))
-			return NF_STOLEN;
-		goto drop;
-	}
-
-	return NF_ACCEPT;
-drop:
-	printk_ratelimited(KERN_WARNING
-				"%s:drop (in_dev=%s, iif=0x%x, CB2=0x%x, ppe_hash=0x%x, sport=0x%x, reason=0x%x, alg=0x%x)\n",
-				__func__, state->in->name, skb_hnat_iface(skb),
-				HNAT_SKB_CB2(skb)->magic, skb_hnat_entry(skb),
-				skb_hnat_sport(skb), skb_hnat_reason(skb),
-				skb_hnat_alg(skb));
-
-	return NF_DROP;
-}
-
-static unsigned int
-mtk_hnat_br_nf_local_out(void *priv, struct sk_buff *skb,
-			 const struct nf_hook_state *state)
-{
-	post_routing_print(skb, state->in, state->out, __func__);
-
-	if (!mtk_hnat_nf_post_routing(skb, state->out, 0, __func__))
-		return NF_ACCEPT;
-
-	trace_printk(
-		"%s:drop (iif=0x%x, out_dev=%s, CB2=0x%x, ppe_hash=0x%x, sport=0x%x, reason=0x%x, alg=0x%x)\n",
-		__func__, skb_hnat_iface(skb), state->out->name, HNAT_SKB_CB2(skb)->magic,
-		skb_hnat_entry(skb), skb_hnat_sport(skb), skb_hnat_reason(skb),
-		skb_hnat_alg(skb));
-
-	return NF_DROP;
-}
-
-static unsigned int
-mtk_hnat_ipv4_nf_local_out(void *priv, struct sk_buff *skb,
-			   const struct nf_hook_state *state)
-{
-	struct sk_buff *new_skb;
-	struct foe_entry *entry;
-	struct iphdr *iph;
-
-	if (!skb_hnat_is_hashed(skb))
-		return NF_ACCEPT;
-
-	entry = &hnat_priv->foe_table_cpu[skb_hnat_entry(skb)];
-
-	if (unlikely(skb_headroom(skb) < FOE_INFO_LEN)) {
-		new_skb = skb_realloc_headroom(skb, FOE_INFO_LEN);
-		if (!new_skb) {
-			dev_info(hnat_priv->dev, "%s:drop\n", __func__);
-			return NF_DROP;
-		}
-		dev_kfree_skb(skb);
-		skb = new_skb;
-	}
-
-	/* Make the flow from local not be bound. */
-	iph = ip_hdr(skb);
-	if (iph->protocol == IPPROTO_IPV6) {
-		entry->udib1.pkt_type = IPV6_6RD;
-		hnat_set_head_frags(state, skb, 0, hnat_set_alg);
-	} else {
-		hnat_set_head_frags(state, skb, 1, hnat_set_alg);
-	}
-
-	return NF_ACCEPT;
-}
-
-static unsigned int mtk_hnat_br_nf_forward(void *priv,
-					   struct sk_buff *skb,
-					   const struct nf_hook_state *state)
-{
-	if (unlikely(IS_EXT(state->in) && IS_EXT(state->out)))
-		hnat_set_head_frags(state, skb, 1, hnat_set_alg);
-
-	return NF_ACCEPT;
-}
-
-static struct nf_hook_ops mtk_hnat_nf_ops[] __read_mostly = {
-	{
-		.hook = mtk_hnat_ipv4_nf_pre_routing,
-		.pf = NFPROTO_IPV4,
-		.hooknum = NF_INET_PRE_ROUTING,
-		.priority = NF_IP_PRI_FIRST + 1,
-	},
-	{
-		.hook = mtk_hnat_ipv6_nf_pre_routing,
-		.pf = NFPROTO_IPV6,
-		.hooknum = NF_INET_PRE_ROUTING,
-		.priority = NF_IP_PRI_FIRST + 1,
-	},
-	{
-		.hook = mtk_hnat_ipv6_nf_post_routing,
-		.pf = NFPROTO_IPV6,
-		.hooknum = NF_INET_POST_ROUTING,
-		.priority = NF_IP_PRI_LAST,
-	},
-	{
-		.hook = mtk_hnat_ipv6_nf_local_out,
-		.pf = NFPROTO_IPV6,
-		.hooknum = NF_INET_LOCAL_OUT,
-		.priority = NF_IP_PRI_LAST,
-	},
-	{
-		.hook = mtk_hnat_ipv4_nf_post_routing,
-		.pf = NFPROTO_IPV4,
-		.hooknum = NF_INET_POST_ROUTING,
-		.priority = NF_IP_PRI_LAST,
-	},
-	{
-		.hook = mtk_hnat_ipv4_nf_local_out,
-		.pf = NFPROTO_IPV4,
-		.hooknum = NF_INET_LOCAL_OUT,
-		.priority = NF_IP_PRI_LAST,
-	},
-	{
-		.hook = mtk_hnat_br_nf_local_in,
-		.pf = NFPROTO_BRIDGE,
-		.hooknum = NF_BR_PRE_ROUTING,
-		.priority = NF_BR_PRI_FIRST,
-	},
-	{
-		.hook = mtk_hnat_br_nf_local_out,
-		.pf = NFPROTO_BRIDGE,
-		.hooknum = NF_BR_POST_ROUTING,
-		.priority = NF_BR_PRI_LAST - 1,
-	},
-	{
-		.hook = mtk_pong_hqos_handler,
-		.pf = NFPROTO_BRIDGE,
-		.hooknum = NF_BR_PRE_ROUTING,
-		.priority = NF_BR_PRI_FIRST + 1,
-	},
-};
-
-
-int hnat_register_nf_hooks(void)
-{
-	return nf_register_hooks(mtk_hnat_nf_ops, ARRAY_SIZE(mtk_hnat_nf_ops));
-}
-
-void hnat_unregister_nf_hooks(void)
-{
-	nf_unregister_hooks(mtk_hnat_nf_ops, ARRAY_SIZE(mtk_hnat_nf_ops));
-}
-
-int whnat_adjust_nf_hooks(void)
-{
-	struct nf_hook_ops *hook = mtk_hnat_nf_ops;
-	unsigned int n = ARRAY_SIZE(mtk_hnat_nf_ops);
-
-	if (!hook)
-		return -1;
-
-	while (n-- > 0) {
-		if (hook[n].hook == mtk_hnat_br_nf_local_in) {
-			hook[n].hooknum = NF_BR_PRE_ROUTING;
-		} else if (hook[n].hook == mtk_hnat_br_nf_local_out) {
-			hook[n].hooknum = NF_BR_POST_ROUTING;
-		} else if (hook[n].hook == mtk_pong_hqos_handler) {
-			hook[n].hook = mtk_hnat_br_nf_forward;
-			hook[n].hooknum = NF_BR_FORWARD;
-			hook[n].priority = NF_BR_PRI_LAST - 1;
-		}
-	}
-
-	return 0;
-}
-
-#if (1)
-int mtk_hqos_ptype_cb(struct sk_buff *skb, struct net_device *dev,
-		      struct packet_type *pt, struct net_device *unused)
-{
-	struct vlan_ethhdr *veth = (struct vlan_ethhdr *)skb_mac_header(skb);
-
-	skb_hnat_entry(skb) = ntohs(veth->h_vlan_TCI) & 0x3fff;
-	skb_hnat_reason(skb) = HIT_BIND_FORCE_TO_CPU;
-
-	do_hnat_ge_to_ext(skb, __func__);
-
-	return 0;
-}
-#endif
-
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_stag.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_stag.c
deleted file mode 100644
index 6e70f45d5..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/hnat_stag.c
+++ /dev/null
@@ -1,55 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0
- *
- * Copyright (c) 2020 MediaTek Inc.
- * Author: Landen Chao <landen.chao@mediatek.com>
- */
-
-#include "hnat.h"
-
-void hnat_dsa_fill_stag(const struct net_device *netdev,
-			struct foe_entry *entry,
-			struct hnat_hw_path *hw_path,
-			u16 eth_proto,
-			int mape)
-{
-	const struct net_device *ndev;
-	const unsigned int *port_reg;
-	int port_index;
-	u16 sp_tag;
-
-	if (hw_path->flags & HNAT_PATH_VLAN)
-		ndev = hw_path->real_dev;
-	else
-		ndev = netdev;
-
-	port_reg = of_get_property(ndev->dev.of_node, "reg", NULL);
-	port_index = be32_to_cpup(port_reg);
-	sp_tag = BIT(port_index);
-
-	if (!entry->bfib1.vlan_layer)
-		entry->bfib1.vlan_layer = 1;
-	else
-		/* VLAN existence indicator */
-		sp_tag |= BIT(8);
-	entry->bfib1.vpm = 0;
-
-	switch (eth_proto) {
-	case ETH_P_IP:
-		if (entry->ipv4_hnapt.bfib1.pkt_type == IPV4_DSLITE)
-			entry->ipv4_dslite.etype = sp_tag;
-		else
-			entry->ipv4_hnapt.etype = sp_tag;
-		break;
-	case ETH_P_IPV6:
-		/* In the case MAPE LAN --> WAN, binding entry is to CPU.
-		 * Do not add special tag.
-		 */
-		if (!mape)
-			/* etype offset of ipv6 entries are the same. */
-			entry->ipv6_5t_route.etype = sp_tag;
-
-		break;
-	default:
-		pr_info("DSA + HNAT unsupport protocol\n");
-	}
-}
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/nf_hnat_mtk.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/nf_hnat_mtk.h
deleted file mode 100644
index f94d5ad9d..000000000
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/mtk_hnat/nf_hnat_mtk.h
+++ /dev/null
@@ -1,107 +0,0 @@
-/*   This program is free software; you can redistribute it and/or modify
- *   it under the terms of the GNU General Public License as published by
- *   the Free Software Foundation; version 2 of the License
- *
- *   This program is distributed in the hope that it will be useful,
- *   but WITHOUT ANY WARRANTY; without even the implied warranty of
- *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *   GNU General Public License for more details.
- *
- *   Copyright (C) 2014-2016 Sean Wang <sean.wang@mediatek.com>
- *   Copyright (C) 2016-2017 John Crispin <blogic@openwrt.org>
- */
-
-#ifndef NF_HNAT_MTK_H
-#define NF_HNAT_MTK_H
-
-#include <linux/dma-mapping.h>
-#include <linux/netdevice.h>
-
-#define HNAT_SKB_CB2(__skb) ((struct hnat_skb_cb2 *)&((__skb)->cb[44]))
-struct hnat_skb_cb2 {
-	__u32 magic;
-};
-
-struct hnat_desc {
-	u32 entry : 14;
-	u32 crsn : 5;
-	u32 sport : 3;
-	u32 rev : 1;
-	u32 alg : 1;
-	u32 iface : 4;
-	u32 resv : 4;
-	u32 magic_tag_protect : 16;
-	u32 wdmaid : 8;
-	u32 rxid : 2;
-	u32 wcid : 8;
-	u32 bssid : 6;
-} __packed;
-
-#if (1)
-#define HQOS_MAGIC_TAG 0x5678
-#define HAS_HQOS_MAGIC_TAG(skb) (skb->protocol == HQOS_MAGIC_TAG)
-#else
-#define HAS_HQOS_MAGIC_TAG(skb) NULL
-#endif
-
-#define HNAT_MAGIC_TAG 0x6789
-#define WIFI_INFO_LEN 3
-#define FOE_INFO_LEN (10 + WIFI_INFO_LEN)
-#define IS_SPACE_AVAILABLE_HEAD(skb)                                           \
-	((((skb_headroom(skb) >= FOE_INFO_LEN) ? 1 : 0)))
-
-#define skb_hnat_info(skb) ((struct hnat_desc *)(skb->head))
-#define skb_hnat_magic(skb) (((struct hnat_desc *)(skb->head))->magic)
-#define skb_hnat_reason(skb) (((struct hnat_desc *)(skb->head))->crsn)
-#define skb_hnat_entry(skb) (((struct hnat_desc *)(skb->head))->entry)
-#define skb_hnat_sport(skb) (((struct hnat_desc *)(skb->head))->sport)
-#define skb_hnat_alg(skb) (((struct hnat_desc *)(skb->head))->alg)
-#define skb_hnat_iface(skb) (((struct hnat_desc *)(skb->head))->iface)
-#define skb_hnat_magic_tag(skb) (((struct hnat_desc *)((skb)->head))->magic_tag_protect)
-#define skb_hnat_wdma_id(skb) (((struct hnat_desc *)((skb)->head))->wdmaid)
-#define skb_hnat_rx_id(skb) (((struct hnat_desc *)((skb)->head))->rxid)
-#define skb_hnat_wc_id(skb) (((struct hnat_desc *)((skb)->head))->wcid)
-#define skb_hnat_bss_id(skb) (((struct hnat_desc *)((skb)->head))->bssid)
-#define do_ext2ge_fast_try(dev, skb) (IS_EXT(dev) && !is_from_extge(skb))
-#define set_from_extge(skb) (HNAT_SKB_CB2(skb)->magic = 0x78786688)
-#define clr_from_extge(skb) (HNAT_SKB_CB2(skb)->magic = 0x0)
-#define set_to_ppe(skb) (HNAT_SKB_CB2(skb)->magic = 0x78681415)
-#define is_from_extge(skb) (HNAT_SKB_CB2(skb)->magic == 0x78786688)
-#define is_magic_tag_valid(skb) (skb_hnat_magic_tag(skb) == HNAT_MAGIC_TAG)
-#define set_from_mape(skb) (HNAT_SKB_CB2(skb)->magic = 0x78787788)
-#define is_from_mape(skb) (HNAT_SKB_CB2(skb)->magic == 0x78787788)
-#define is_unreserved_port(hdr)						       \
-	((ntohs(hdr->source) > 1023) && (ntohs(hdr->dest) > 1023))
-
-#define TTL_0 0x02
-#define HAS_OPTION_HEADER 0x03
-#define NO_FLOW_IS_ASSIGNED 0x07
-#define IPV4_WITH_FRAGMENT 0x08
-#define IPV4_HNAPT_DSLITE_WITH_FRAGMENT 0x09
-#define IPV4_HNAPT_DSLITE_WITHOUT_TCP_UDP 0x0A
-#define IPV6_5T_6RD_WITHOUT_TCP_UDP 0x0B
-#define TCP_FIN_SYN_RST                                                        \
-	0x0C /* Ingress packet is TCP fin/syn/rst (for IPv4 NAPT/DS-Lite or IPv6 5T-route/6RD) */
-#define UN_HIT 0x0D /* FOE Un-hit */
-#define HIT_UNBIND 0x0E /* FOE Hit unbind */
-#define HIT_UNBIND_RATE_REACH 0x0F
-#define HIT_BIND_TCP_FIN 0x10
-#define HIT_BIND_TTL_1 0x11
-#define HIT_BIND_WITH_VLAN_VIOLATION 0x12
-#define HIT_BIND_KEEPALIVE_UC_OLD_HDR 0x13
-#define HIT_BIND_KEEPALIVE_MC_NEW_HDR 0x14
-#define HIT_BIND_KEEPALIVE_DUP_OLD_HDR 0x15
-#define HIT_BIND_FORCE_TO_CPU 0x16
-#define HIT_BIND_WITH_OPTION_HEADER 0x17
-#define HIT_BIND_MULTICAST_TO_CPU 0x18
-#define HIT_BIND_MULTICAST_TO_GMAC_CPU 0x19
-#define HIT_PRE_BIND 0x1A
-#define HIT_BIND_PACKET_SAMPLING 0x1B
-#define HIT_BIND_EXCEED_MTU 0x1C
-
-u32 hnat_tx(struct sk_buff *skb);
-u32 hnat_set_skb_info(struct sk_buff *skb, u32 *rxd);
-u32 hnat_reg(struct net_device *, void __iomem *);
-u32 hnat_unreg(void);
-
-#endif
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.c
index d61acd72a..4e48245d3 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/ra_switch.c
@@ -2791,7 +2791,6 @@ void trgmii_set_7530(void)
 	pr_info("trgmii_set_7530 Completed!!\n");
 }
 
-#if !defined (CONFIG_RAETH_ESW_CONTROL)
 static void is_switch_vlan_table_busy(void)
 {
 	int j = 0;
@@ -2874,7 +2873,6 @@ static void lan_wan_partition(void)
 		is_switch_vlan_table_busy();
 	}
 }
-#endif
 
 static void mt7530_phy_setting(void)
 {
@@ -3095,9 +3093,7 @@ static void setup_internal_gsw(void)
 		sys_reg_write(ETHDMASYS_ETH_SW_BASE + 0x0378, 0x855);
 	}
 
-#if !defined (CONFIG_RAETH_ESW_CONTROL)
 	lan_wan_partition();
-#endif
 	mt7530_phy_setting();
 	for (i = 0; i <= 4; i++) {
 		/*turn on PHY */
@@ -3943,17 +3939,16 @@ void fe_sw_deinit(struct END_DEVICE *ei_local)
 	}
 }
 
-void (*esw_link_status_hook)(u32 port_id, int port_link) = NULL;
-EXPORT_SYMBOL(esw_link_status_hook);
-
 static void esw_link_status_changed(int port_no, void *dev_id)
 {
 	unsigned int reg_val;
 
 	mii_mgr_read(31, (0x3008 + (port_no * 0x100)), &reg_val);
-
-	if (esw_link_status_hook)
-		esw_link_status_hook(port_no, reg_val & 0x1);
+	if (reg_val & 0x1)
+		pr_info("ESW: Link Status Changed - Port%d Link UP\n", port_no);
+	else
+		pr_info("ESW: Link Status Changed - Port%d Link Down\n",
+			port_no);
 }
 
 irqreturn_t gsw_interrupt(int irq, void *resv)
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_config.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_config.h
index 5f1ca921e..d9eed660b 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_config.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_config.h
@@ -31,7 +31,7 @@
 
 #if defined(CONFIG_SOC_MT7621)
 #define CONFIG_GE1_RGMII_FORCE_1000
-//#define CONFIG_GE1_RGMII_FORCE_1200
+#define CONFIG_GE1_RGMII_FORCE_1200
 #define CONFIG_RA_NETWORK_TASKLET_BH
 #endif
 /*CONFIG_RA_NETWORK_TASKLET_BH*/
@@ -44,12 +44,12 @@
 /* #define CONFIG_RAETH_HW_LRO_FORCE */
 /* #define CONFIG_RAETH_HW_LRO_DVT */
 #define CONFIG_RAETH_HW_VLAN_TX
-#define CONFIG_RAETH_HW_VLAN_RX
+/*CONFIG_RAETH_HW_VLAN_RX*/
 #define CONFIG_RAETH_TSO
 /*#define CONFIG_RAETH_ETHTOOL*/
 #define CONFIG_RAETH_QDMA
-/*#define CONFIG_RAETH_QDMATX_QDMARX*/
-/*#define CONFIG_HW_SFQ*/
+/*CONFIG_RAETH_QDMATX_QDMARX*/
+/*CONFIG_HW_SFQ*/
 #define CONFIG_RAETH_HW_IOCOHERENT
 #define	CONFIG_RAETH_GMAC2
 /*#define CONFIG_RAETH_RSS_4RING*/
@@ -209,7 +209,7 @@
 #ifdef	CONFIG_QDMA_SUPPORT_QOS
 #define FE_QDMA_FQOS	BIT(29)
 #else
-#define FE_QDMA_FQOS	BIT(29)
+#define FE_QDMA_FQOS	(0)
 #endif
 
 #ifdef	CONFIG_QDMA_QOS_WEB
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_reg.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_reg.h
index 2ccae3a89..8078ccfda 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_reg.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raeth_reg.h
@@ -121,9 +121,6 @@ extern void __iomem *ethdma_frame_engine_base;
 #define RSTCTL_ETH_RST			BIT(23)
 #define RALINK_ETH_RST			RSTCTL_ETH_RST
 
-#define RSTCTL_PPE_RST			BIT(31)
-#define RALINK_PPE_RST			RSTCTL_PPE_RST
-
 /* FE_INT_STATUS */
 #define RX_COHERENT      BIT(31)
 #define RX_DLY_INT       BIT(30)
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.c
index 85fa1209f..78d180045 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.c
@@ -19,8 +19,6 @@
 #include "raether_hwlro.h"
 #include "ra_ethtool.h"
 
-#include "mtk_hnat/nf_hnat_mtk.h"
-
 void __iomem *ethdma_sysctl_base;
 #if defined(CONFIG_RA_HW_NAT)  || defined(CONFIG_RA_HW_NAT_MODULE)
 EXPORT_SYMBOL(ethdma_sysctl_base);
@@ -72,30 +70,27 @@ static const char *const mtk_clks_source_name[] = {
 /* reset frame engine */
 static void fe_reset(void)
 {
-	u32 val = 0;
+	u32 val;
 
 	val = sys_reg_read(RSTCTRL);
-	val = val | RALINK_FE_RST | RALINK_PPE_RST;
+	val = val | RALINK_FE_RST;
 	sys_reg_write(RSTCTRL, val);
-	udelay(10);
 
-	val = val & ~(RALINK_FE_RST | RALINK_PPE_RST);
+	val = val & ~(RALINK_FE_RST);
 	sys_reg_write(RSTCTRL, val);
-	udelay(1000);
 }
 
 static void fe_gmac_reset(void)
 {
-	u32 val = 0;
-
-	val = sys_reg_read(RSTCTRL);
-	val |= RALINK_ETH_RST;
-	sys_reg_write(RSTCTRL, val);
-	udelay(10);
-
-	val &= ~(RALINK_ETH_RST);
-	sys_reg_write(RSTCTRL, val);
-	udelay(1000);
+	u32 val;
+	/*Reset GMAC */
+	/* sys_reg_write(RALINK_SYSCTL_BASE + 0x34, 0x00800000); */
+	/* sys_reg_write(RALINK_SYSCTL_BASE + 0x34, 0x00000000); */
+	val = sys_reg_read(RALINK_SYSCTL_BASE + 0x34);
+	val |= (1 << 23);
+	sys_reg_write(RALINK_SYSCTL_BASE + 0x34, val);
+	val &= ~(1 << 23);
+	sys_reg_write(RALINK_SYSCTL_BASE + 0x34, val);
 }
 
 /* Set the hardware MAC address. */
@@ -325,22 +320,12 @@ static int rt2880_eth_recv(struct net_device *dev,
 		}
 #endif
 
-
 	if (ei_local->features & FE_HW_VLAN_RX) {
 		if (rx_ring->rxd_info2.TAG)
 			__vlan_hwaccel_put_tag(rx_skb,
 					       htons(ETH_P_8021Q),
 					       rx_ring->rxd_info3.VID);
 	}
-	
-
-		*(uint32_t *)(rx_skb->head) =*(uint32_t *)(&rx_ring->rxd_info4);
-		skb_hnat_alg(rx_skb) = 0;
-		skb_hnat_magic_tag(rx_skb) = HNAT_MAGIC_TAG;
-		if (skb_hnat_reason(rx_skb) == HIT_BIND_FORCE_TO_CPU) {
-			rx_skb->pkt_type = PACKET_HOST;
-		}
-
 
 /* ra_sw_nat_hook_rx return 1 --> continue
  * ra_sw_nat_hook_rx return 0 --> FWD & without netif_rx
@@ -1896,12 +1881,6 @@ static int fe_int_enable(struct net_device *dev)
 
 		/* enable switch link change intr */
 		mii_mgr_write(31, 0x7008, 0x1f);
-	} else if (ei_local->chip_name == MT7621_FE) {
-		if (request_threaded_irq(ei_local->esw_irq, gsw_interrupt, NULL, 0,
-					 "gsw", NULL))
-			pr_err("fail to request irq\n");
-
-		mii_mgr_write(31, 0x7008, 0x1f);
 	}
 
 	if (ei_local->architecture & RAETH_ESW) {
@@ -2055,7 +2034,7 @@ static int fe_int_disable(struct net_device *dev)
 		free_irq(ei_local->irq2, dev);
 	}
 
-	if (ei_local->architecture & RAETH_ESW || ei_local->chip_name == MT7621_FE)
+	if (ei_local->architecture & RAETH_ESW)
 		free_irq(ei_local->esw_irq, dev);
 
 	if (ei_local->features & (FE_RSS_4RING | FE_RSS_2RING))
@@ -2566,15 +2545,12 @@ int ei_open(struct net_device *dev)
 	}
 
 	/* initialize fe and switch register */
-	if (ei_local->chip_name == MT7622_FE)
+	if (ei_local->chip_name != LEOPARD_FE)
 		fe_sw_preinit(ei_local);
 
 	if (ei_local->features & FE_SW_LRO)
 		fe_set_sw_lro_my_ip(ei_local->lan_ip4_addr);
 
-#if defined (CONFIG_RAETH_ESW_CONTROL)
-	esw_ioctl_init_post();
-#endif
 	forward_config(dev);
 
 	if ((ei_local->chip_name == MT7623_FE) &&
@@ -2640,7 +2616,7 @@ int ei_close(struct net_device *dev)
 
 	ei_deinit_dma(dev);
 
-	if (ei_local->chip_name == MT7622_FE)
+	if (ei_local->chip_name != LEOPARD_FE)
 		fe_sw_deinit(ei_local);
 
 	module_put(THIS_MODULE);
@@ -3299,8 +3275,6 @@ static int rather_probe(struct platform_device *pdev)
 		else if (ei_local->architecture & LEOPARD_EPHY)
 			ei_local->esw_irq = platform_get_irq(pdev, 4);
 		pr_info("ei_local->esw_irq = %d\n", ei_local->esw_irq);
-	} else if (ei_local->chip_name == MT7621_FE) {
-		ei_local->esw_irq = platform_get_irq(pdev, 1);
 	}
 
 	ei_clock_enable(ei_local);
@@ -3352,9 +3326,7 @@ static int rather_probe(struct platform_device *pdev)
 		else
 			virtualif_open(ei_local->pseudo_dev);
 	}
-#if defined (CONFIG_RAETH_ESW_CONTROL)
-	esw_ioctl_init();
-#endif
+
 	return 0;
 
 err_free_dev:
@@ -3365,9 +3337,7 @@ err_free_dev:
 static int raether_remove(struct platform_device *pdev)
 {
 	struct END_DEVICE *ei_local = netdev_priv(dev_raether);
-#if defined (CONFIG_RAETH_ESW_CONTROL)
-	esw_ioctl_uninit();
-#endif
+
 	if (ei_local->features & FE_QDMA_FQOS)
 		if (ei_local->qdma_pdev)
 			ei_local->qdma_pdev->dev.release
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.h b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.h
index bd152f220..81e27b723 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.h
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether.h
@@ -127,8 +127,13 @@
 
 #define	MAX_RX_LENGTH	1536
 
+#if defined(CONFIG_SUPPORT_OPENWRT)
+#define DEV_NAME        "eth0"
+#define DEV2_NAME       "eth1"
+#else
 #define DEV_NAME        "eth2"
 #define DEV2_NAME       "eth3"
+#endif
 
 #if defined(CONFIG_MACH_MT7623)
 #define GMAC0_OFFSET    0xE000
@@ -352,12 +357,6 @@ static inline void ei_lro_flush_all(struct net_lro_mgr *lro_mgr)
 
 struct net_device_stats *ra_get_stats(struct net_device *dev);
 
-#if defined (CONFIG_RAETH_ESW_CONTROL)
-void esw_ioctl_uninit(void);
-int esw_ioctl_init(void);
-int esw_ioctl_init_post(void);
-#endif
-
 int ei_open(struct net_device *dev);
 int ei_close(struct net_device *dev);
 
@@ -373,7 +372,10 @@ u32 mii_mgr_write_cl45(u32 port_num, u32 dev_addr, u32 reg_addr,
 		       u32 write_data);
 
 /* HNAT functions */
-#if !defined(CONFIG_RA_NAT_NONE)
+#if defined(CONFIG_RA_NAT_NONE)
+static int (*ra_sw_nat_hook_rx)(struct sk_buff *skb);
+static int (*ra_sw_nat_hook_tx)(struct sk_buff *skb, int gmac_no);
+#else
 extern int (*ra_sw_nat_hook_rx)(struct sk_buff *skb);
 extern int (*ra_sw_nat_hook_tx)(struct sk_buff *skb, int gmac_no);
 #endif
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_pdma.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_pdma.c
index 443fe572f..12514e2d7 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_pdma.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_pdma.c
@@ -12,8 +12,6 @@
  */
 #include "raether.h"
 
-#include "mtk_hnat/nf_hnat_mtk.h"
-
 int fe_pdma_wait_dma_idle(void)
 {
 	unsigned int reg_val;
@@ -256,10 +254,7 @@ int fe_fill_tx_desc(struct net_device *dev,
 		}
 	}
 #endif
-	
-	if (HNAT_SKB_CB2(skb)->magic == 0x78681415)
-	{txd_info4_tmp.FPORT = 4;}
-	
+
 	txd_info2_tmp.LS0_bit = 1;
 	txd_info2_tmp.DDONE_bit = 0;
 
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_qdma.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_qdma.c
index c802b4c16..a956441f5 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_qdma.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/raether_qdma.c
@@ -15,8 +15,6 @@
 #include "ra_ioctl.h"
 #include "raether_qdma.h"
 
-#include "mtk_hnat/nf_hnat_mtk.h"
-
 /* skb->mark to queue mapping table */
 struct QDMA_txdesc *free_head;
 
@@ -647,7 +645,7 @@ int rt2880_qdma_eth_send(struct END_DEVICE *ei_local, struct net_device *dev,
 
 	if ((ei_local->features & QDMA_QOS_MARK) && (skb->mark != 0)) {
 		if (skb->mark < 64) {
-			qidx = skb->mark;
+			qidx = M2Q_table[skb->mark];
 			cpu_ptr->txd_info4.QID = ((qidx & 0x30) >> 4);
 			cpu_ptr->txd_info3.QID = (qidx & 0x0f);
 		} else {
@@ -684,10 +682,7 @@ int rt2880_qdma_eth_send(struct END_DEVICE *ei_local, struct net_device *dev,
 		}
 	}
 #endif
-	
-	if (HNAT_SKB_CB2(skb)->magic == 0x78681415)
-	cpu_ptr->txd_info4.FPORT = 4;	
-	
+
 	/* dma_sync_single_for_device(NULL, virt_to_phys(skb->data), */
 	/* skb->len, DMA_TO_DEVICE); */
 	cpu_ptr->txd_info3.SWC_bit = 1;
@@ -808,7 +803,7 @@ int rt2880_qdma_eth_send_tso(struct END_DEVICE *ei_local,
 	/* cpu_ptr->txd_info3.QID = ring_no; */
 	if ((ei_local->features & QDMA_QOS_MARK) && (skb->mark != 0)) {
 		if (skb->mark < 64) {
-			qidx = skb->mark;
+			qidx = M2Q_table[skb->mark];
 			cpu_ptr->txd_info4.QID = ((qidx & 0x30) >> 4);
 			cpu_ptr->txd_info3.QID = (qidx & 0x0f);
 		} else {
diff --git a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/rtl8367c/rtk_hal.c b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/rtl8367c/rtk_hal.c
index 6bbeaca29..b9373492c 100644
--- a/trunk/linux-4.4.x/drivers/net/ethernet/raeth/rtl8367c/rtk_hal.c
+++ b/trunk/linux-4.4.x/drivers/net/ethernet/raeth/rtl8367c/rtk_hal.c
@@ -501,11 +501,10 @@ void rtk_hal_qos_get_table2type(struct ra_switch_ioctl_data *data)
 	rtk_api_ret_t ret;
 	rtk_priority_select_t PriDec;
 
-	if (data->qos_table_idx == 0) {
+	if (data->qos_table_idx == 0)
         ret = rtk_qos_priSel_get(PRIDECTBL_IDX0, &PriDec);
-	} else {
+    else
         ret = rtk_qos_priSel_get(PRIDECTBL_IDX1, &PriDec);
-	}
 
 	if (ret != 0)
         printk("rtk_qos_priSel_set failed\n");
diff --git a/trunk/linux-4.4.x/drivers/net/imq.c b/trunk/linux-4.4.x/drivers/net/imq.c
new file mode 100644
index 000000000..2e27eeea0
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/imq.c
@@ -0,0 +1,903 @@
+/*
+ *             Pseudo-driver for the intermediate queue device.
+ *
+ *             This program is free software; you can redistribute it and/or
+ *             modify it under the terms of the GNU General Public License
+ *             as published by the Free Software Foundation; either version
+ *             2 of the License, or (at your option) any later version.
+ *
+ * Authors:    Patrick McHardy, <kaber@trash.net>
+ *
+ *            The first version was written by Martin Devera, <devik@cdi.cz>
+ *
+ *			   See Creditis.txt
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/moduleparam.h>
+#include <linux/list.h>
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/if_arp.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+	#include <linux/netfilter_ipv6.h>
+#endif
+#include <linux/imq.h>
+#include <net/pkt_sched.h>
+#include <net/netfilter/nf_queue.h>
+#include <net/sock.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/if_vlan.h>
+#include <linux/if_pppox.h>
+#include <net/ip.h>
+#include <net/ipv6.h>
+
+static int imq_nf_queue(struct nf_queue_entry *entry, unsigned queue_num);
+
+static nf_hookfn imq_nf_hook;
+
+static struct nf_hook_ops imq_ops[] = {
+	{
+	/* imq_ingress_ipv4 */
+		.hook		= imq_nf_hook,
+		.pf		= PF_INET,
+		.hooknum	= NF_INET_PRE_ROUTING,
+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
+		.priority	= NF_IP_PRI_MANGLE + 1,
+#else
+		.priority	= NF_IP_PRI_NAT_DST + 1,
+#endif
+	},
+	{
+	/* imq_egress_ipv4 */
+		.hook		= imq_nf_hook,
+		.pf		= PF_INET,
+		.hooknum	= NF_INET_POST_ROUTING,
+#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
+		.priority	= NF_IP_PRI_LAST,
+#else
+		.priority	= NF_IP_PRI_NAT_SRC - 1,
+#endif
+	},
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+	{
+	/* imq_ingress_ipv6 */
+		.hook		= imq_nf_hook,
+		.pf		= PF_INET6,
+		.hooknum	= NF_INET_PRE_ROUTING,
+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
+		.priority	= NF_IP6_PRI_MANGLE + 1,
+#else
+		.priority	= NF_IP6_PRI_NAT_DST + 1,
+#endif
+	},
+	{
+	/* imq_egress_ipv6 */
+		.hook		= imq_nf_hook,
+		.pf		= PF_INET6,
+		.hooknum	= NF_INET_POST_ROUTING,
+#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
+		.priority	= NF_IP6_PRI_LAST,
+#else
+		.priority	= NF_IP6_PRI_NAT_SRC - 1,
+#endif
+	},
+#endif
+};
+
+#if defined(CONFIG_IMQ_NUM_DEVS)
+static int numdevs = CONFIG_IMQ_NUM_DEVS;
+#else
+static int numdevs = IMQ_MAX_DEVS;
+#endif
+
+static struct net_device *imq_devs_cache[IMQ_MAX_DEVS];
+
+#define IMQ_MAX_QUEUES 32
+static int numqueues = 1;
+static u32 imq_hashrnd;
+static int imq_dev_accurate_stats = 1;
+
+static inline __be16 pppoe_proto(const struct sk_buff *skb)
+{
+	return *((__be16 *)(skb_mac_header(skb) + ETH_HLEN +
+			sizeof(struct pppoe_hdr)));
+}
+
+static u16 imq_hash(struct net_device *dev, struct sk_buff *skb)
+{
+	unsigned int pull_len;
+	u16 protocol = skb->protocol;
+	u32 addr1, addr2;
+	u32 hash, ihl = 0;
+	union {
+		u16 in16[2];
+		u32 in32;
+	} ports;
+	u8 ip_proto;
+
+	pull_len = 0;
+
+recheck:
+	switch (protocol) {
+	case htons(ETH_P_8021Q): {
+		if (unlikely(skb_pull(skb, VLAN_HLEN) == NULL))
+			goto other;
+
+		pull_len += VLAN_HLEN;
+		skb->network_header += VLAN_HLEN;
+
+		protocol = vlan_eth_hdr(skb)->h_vlan_encapsulated_proto;
+		goto recheck;
+	}
+
+	case htons(ETH_P_PPP_SES): {
+		if (unlikely(skb_pull(skb, PPPOE_SES_HLEN) == NULL))
+			goto other;
+
+		pull_len += PPPOE_SES_HLEN;
+		skb->network_header += PPPOE_SES_HLEN;
+
+		protocol = pppoe_proto(skb);
+		goto recheck;
+	}
+
+	case htons(ETH_P_IP): {
+		const struct iphdr *iph = ip_hdr(skb);
+
+		if (unlikely(!pskb_may_pull(skb, sizeof(struct iphdr))))
+			goto other;
+
+		addr1 = iph->daddr;
+		addr2 = iph->saddr;
+
+		ip_proto = !(ip_hdr(skb)->frag_off & htons(IP_MF | IP_OFFSET)) ?
+				 iph->protocol : 0;
+		ihl = ip_hdrlen(skb);
+
+		break;
+	}
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+	case htons(ETH_P_IPV6): {
+		const struct ipv6hdr *iph = ipv6_hdr(skb);
+		__be16 fo = 0;
+
+		if (unlikely(!pskb_may_pull(skb, sizeof(struct ipv6hdr))))
+			goto other;
+
+		addr1 = iph->daddr.s6_addr32[3];
+		addr2 = iph->saddr.s6_addr32[3];
+		ihl = ipv6_skip_exthdr(skb, sizeof(struct ipv6hdr), &ip_proto,
+				       &fo);
+		if (unlikely(ihl < 0))
+			goto other;
+
+		break;
+	}
+#endif
+	default:
+other:
+		if (pull_len != 0) {
+			skb_push(skb, pull_len);
+			skb->network_header -= pull_len;
+		}
+
+		return (u16)(ntohs(protocol) % dev->real_num_tx_queues);
+	}
+
+	if (addr1 > addr2)
+		swap(addr1, addr2);
+
+	switch (ip_proto) {
+	case IPPROTO_TCP:
+	case IPPROTO_UDP:
+	case IPPROTO_DCCP:
+	case IPPROTO_ESP:
+	case IPPROTO_AH:
+	case IPPROTO_SCTP:
+	case IPPROTO_UDPLITE: {
+		if (likely(skb_copy_bits(skb, ihl, &ports.in32, 4) >= 0)) {
+			if (ports.in16[0] > ports.in16[1])
+				swap(ports.in16[0], ports.in16[1]);
+			break;
+		}
+		/* fall-through */
+	}
+	default:
+		ports.in32 = 0;
+		break;
+	}
+
+	if (pull_len != 0) {
+		skb_push(skb, pull_len);
+		skb->network_header -= pull_len;
+	}
+
+	hash = jhash_3words(addr1, addr2, ports.in32, imq_hashrnd ^ ip_proto);
+
+	return (u16)(((u64)hash * dev->real_num_tx_queues) >> 32);
+}
+
+static inline bool sk_tx_queue_recorded(struct sock *sk)
+{
+	return (sk_tx_queue_get(sk) >= 0);
+}
+
+static struct netdev_queue *imq_select_queue(struct net_device *dev,
+						struct sk_buff *skb)
+{
+	u16 queue_index = 0;
+	u32 hash;
+
+	if (likely(dev->real_num_tx_queues == 1))
+		goto out;
+
+	/* IMQ can be receiving ingress or engress packets. */
+
+	/* Check first for if rx_queue is set */
+	if (skb_rx_queue_recorded(skb)) {
+		queue_index = skb_get_rx_queue(skb);
+		goto out;
+	}
+
+	/* Check if socket has tx_queue set */
+	if (sk_tx_queue_recorded(skb->sk)) {
+		queue_index = sk_tx_queue_get(skb->sk);
+		goto out;
+	}
+
+	/* Try use socket hash */
+	if (skb->sk && skb->sk->sk_hash) {
+		hash = skb->sk->sk_hash;
+		queue_index =
+			(u16)(((u64)hash * dev->real_num_tx_queues) >> 32);
+		goto out;
+	}
+
+	/* Generate hash from packet data */
+	queue_index = imq_hash(dev, skb);
+
+out:
+	if (unlikely(queue_index >= dev->real_num_tx_queues))
+		queue_index = (u16)((u32)queue_index % dev->real_num_tx_queues);
+
+	skb_set_queue_mapping(skb, queue_index);
+	return netdev_get_tx_queue(dev, queue_index);
+}
+
+static struct net_device_stats *imq_get_stats(struct net_device *dev)
+{
+	return &dev->stats;
+}
+
+/* called for packets kfree'd in qdiscs at places other than enqueue */
+static void imq_skb_destructor(struct sk_buff *skb)
+{
+	struct nf_queue_entry *entry = skb->nf_queue_entry;
+
+	skb->nf_queue_entry = NULL;
+
+	if (entry) {
+		nf_queue_entry_release_refs(entry);
+		kfree(entry);
+	}
+
+	skb_restore_cb(skb); /* kfree backup */
+}
+
+static void imq_done_check_queue_mapping(struct sk_buff *skb,
+					 struct net_device *dev)
+{
+	unsigned int queue_index;
+
+	/* Don't let queue_mapping be left too large after exiting IMQ */
+	if (likely(skb->dev != dev && skb->dev != NULL)) {
+		queue_index = skb_get_queue_mapping(skb);
+		if (unlikely(queue_index >= skb->dev->real_num_tx_queues)) {
+			queue_index = (u16)((u32)queue_index %
+						skb->dev->real_num_tx_queues);
+			skb_set_queue_mapping(skb, queue_index);
+		}
+	} else {
+		/* skb->dev was IMQ device itself or NULL, be on safe side and
+		 * just clear queue mapping.
+		 */
+		skb_set_queue_mapping(skb, 0);
+	}
+}
+
+static netdev_tx_t imq_dev_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct nf_queue_entry *entry = skb->nf_queue_entry;
+
+	skb->nf_queue_entry = NULL;
+	dev->trans_start = jiffies;
+
+	dev->stats.tx_bytes += skb->len;
+	dev->stats.tx_packets++;
+
+	if (unlikely(entry == NULL)) {
+		/* We don't know what is going on here.. packet is queued for
+		 * imq device, but (probably) not by us.
+		 *
+		 * If this packet was not send here by imq_nf_queue(), then
+		 * skb_save_cb() was not used and skb_free() should not show:
+		 *   WARNING: IMQ: kfree_skb: skb->cb_next:..
+		 * and/or
+		 *   WARNING: IMQ: kfree_skb: skb->nf_queue_entry...
+		 *
+		 * However if this message is shown, then IMQ is somehow broken
+		 * and you should report this to linuximq.net.
+		 */
+
+		/* imq_dev_xmit is black hole that eats all packets, report that
+		 * we eat this packet happily and increase dropped counters.
+		 */
+
+		dev->stats.tx_dropped++;
+		dev_kfree_skb(skb);
+
+		return NETDEV_TX_OK;
+	}
+
+	skb_restore_cb(skb); /* restore skb->cb */
+
+	skb->imq_flags = 0;
+	skb->destructor = NULL;
+
+	imq_done_check_queue_mapping(skb, dev);
+
+	nf_reinject(entry, NF_ACCEPT);
+
+	return NETDEV_TX_OK;
+}
+
+static struct net_device *get_imq_device_by_index(int index)
+{
+	struct net_device *dev = NULL;
+	struct net *net;
+	char buf[8];
+
+	/* get device by name and cache result */
+	snprintf(buf, sizeof(buf), "imq%d", index);
+
+	/* Search device from all namespaces. */
+	for_each_net(net) {
+		dev = dev_get_by_name(net, buf);
+		if (dev)
+			break;
+	}
+
+	if (WARN_ON_ONCE(dev == NULL)) {
+		/* IMQ device not found. Exotic config? */
+		return ERR_PTR(-ENODEV);
+	}
+
+	imq_devs_cache[index] = dev;
+	dev_put(dev);
+
+	return dev;
+}
+
+static struct nf_queue_entry *nf_queue_entry_dup(struct nf_queue_entry *e)
+{
+	struct nf_queue_entry *entry = kmemdup(e, e->size, GFP_ATOMIC);
+	if (entry) {
+		nf_queue_entry_get_refs(entry);
+			return entry;
+	}
+	return NULL;
+}
+
+#ifdef CONFIG_BRIDGE_NETFILTER
+/* When called from bridge netfilter, skb->data must point to MAC header
+ * before calling skb_gso_segment(). Else, original MAC header is lost
+ * and segmented skbs will be sent to wrong destination.
+ */
+static void nf_bridge_adjust_skb_data(struct sk_buff *skb)
+{
+	if (skb->nf_bridge)
+		__skb_push(skb, skb->network_header - skb->mac_header);
+}
+
+static void nf_bridge_adjust_segmented_data(struct sk_buff *skb)
+{
+	if (skb->nf_bridge)
+		__skb_pull(skb, skb->network_header - skb->mac_header);
+}
+#else
+#define nf_bridge_adjust_skb_data(s) do {} while (0)
+#define nf_bridge_adjust_segmented_data(s) do {} while (0)
+#endif
+
+static void free_entry(struct nf_queue_entry *entry)
+{
+	nf_queue_entry_release_refs(entry);
+	kfree(entry);
+}
+
+static int __imq_nf_queue(struct nf_queue_entry *entry, struct net_device *dev);
+
+static int __imq_nf_queue_gso(struct nf_queue_entry *entry,
+			      struct net_device *dev, struct sk_buff *skb)
+{
+	int ret = -ENOMEM;
+	struct nf_queue_entry *entry_seg;
+
+	nf_bridge_adjust_segmented_data(skb);
+
+	if (skb->next == NULL) { /* last packet, no need to copy entry */
+		struct sk_buff *gso_skb = entry->skb;
+		entry->skb = skb;
+		ret = __imq_nf_queue(entry, dev);
+		if (ret)
+			entry->skb = gso_skb;
+		return ret;
+	}
+
+	skb->next = NULL;
+
+	entry_seg = nf_queue_entry_dup(entry);
+	if (entry_seg) {
+		entry_seg->skb = skb;
+		ret = __imq_nf_queue(entry_seg, dev);
+		if (ret)
+			free_entry(entry_seg);
+	}
+	return ret;
+}
+
+static int imq_nf_queue(struct nf_queue_entry *entry, unsigned queue_num)
+{
+	struct sk_buff *skb, *segs;
+	struct net_device *dev;
+	unsigned int queued;
+	int index, retval, err;
+
+	index = entry->skb->imq_flags & IMQ_F_IFMASK;
+	if (unlikely(index > numdevs - 1)) {
+		if (net_ratelimit())
+			pr_warn("IMQ: invalid device specified, highest is %u\n",
+				numdevs - 1);
+		retval = -EINVAL;
+		goto out_no_dev;
+	}
+
+	/* check for imq device by index from cache */
+	dev = imq_devs_cache[index];
+	if (unlikely(!dev)) {
+		dev = get_imq_device_by_index(index);
+		if (IS_ERR(dev)) {
+			retval = PTR_ERR(dev);
+			goto out_no_dev;
+		}
+	}
+
+	if (unlikely(!(dev->flags & IFF_UP))) {
+		entry->skb->imq_flags = 0;
+		retval = -ECANCELED;
+		goto out_no_dev;
+	}
+
+	/* Since 3.10.x, GSO handling moved here as result of upstream commit
+	 * a5fedd43d5f6c94c71053a66e4c3d2e35f1731a2 (netfilter: move
+	 * skb_gso_segment into nfnetlink_queue module).
+	 *
+	 * Following code replicates the gso handling from
+	 * 'net/netfilter/nfnetlink_queue_core.c':nfqnl_enqueue_packet().
+	 */
+
+	skb = entry->skb;
+
+	switch (entry->state.pf) {
+	case NFPROTO_IPV4:
+		skb->protocol = htons(ETH_P_IP);
+		break;
+	case NFPROTO_IPV6:
+		skb->protocol = htons(ETH_P_IPV6);
+		break;
+	}
+
+	if (!skb_is_gso(entry->skb))
+		return __imq_nf_queue(entry, dev);
+
+	nf_bridge_adjust_skb_data(skb);
+	segs = skb_gso_segment(skb, 0);
+	/* Does not use PTR_ERR to limit the number of error codes that can be
+	 * returned by nf_queue.  For instance, callers rely on -ECANCELED to
+	 * mean 'ignore this hook'.
+	 */
+	err = -ENOBUFS;
+	if (IS_ERR(segs))
+		goto out_err;
+	queued = 0;
+	err = 0;
+	do {
+		struct sk_buff *nskb = segs->next;
+		if (nskb && nskb->next)
+			nskb->cb_next = NULL;
+		if (err == 0)
+			err = __imq_nf_queue_gso(entry, dev, segs);
+		if (err == 0)
+			queued++;
+		else
+			kfree_skb(segs);
+		segs = nskb;
+	} while (segs);
+
+	if (queued) {
+		if (err) /* some segments are already queued */
+			free_entry(entry);
+		kfree_skb(skb);
+		return 0;
+	}
+
+out_err:
+	nf_bridge_adjust_segmented_data(skb);
+	retval = err;
+out_no_dev:
+	return retval;
+}
+
+static int __imq_nf_queue(struct nf_queue_entry *entry, struct net_device *dev)
+{
+	struct sk_buff *skb_orig, *skb, *skb_shared, *skb_popd;
+	struct Qdisc *q;
+	struct netdev_queue *txq;
+	spinlock_t *root_lock;
+	int users;
+	int retval = -EINVAL;
+	unsigned int orig_queue_index;
+
+	dev->last_rx = jiffies;
+
+	skb = entry->skb;
+	skb_orig = NULL;
+
+	/* skb has owner? => make clone */
+	if (unlikely(skb->destructor)) {
+		skb_orig = skb;
+		skb = skb_clone(skb, GFP_ATOMIC);
+		if (unlikely(!skb)) {
+			retval = -ENOMEM;
+			goto out;
+		}
+		skb->cb_next = NULL;
+		entry->skb = skb;
+	}
+
+	dev->stats.rx_bytes += skb->len;
+	dev->stats.rx_packets++;
+
+	if (!skb->dev) {
+		/* skb->dev == NULL causes problems, try the find cause. */
+		if (net_ratelimit()) {
+			dev_warn(&dev->dev,
+				 "received packet with skb->dev == NULL\n");
+			dump_stack();
+		}
+
+		skb->dev = dev;
+	}
+
+	/* Disables softirqs for lock below */
+	rcu_read_lock_bh();
+
+	/* Multi-queue selection */
+	orig_queue_index = skb_get_queue_mapping(skb);
+	txq = imq_select_queue(dev, skb);
+
+	q = rcu_dereference(txq->qdisc);
+	if (unlikely(!q->enqueue))
+		goto packet_not_eaten_by_imq_dev;
+
+	skb->nf_queue_entry = entry;
+	root_lock = qdisc_lock(q);
+	spin_lock(root_lock);
+
+	users = atomic_read(&skb->users);
+
+	skb_shared = skb_get(skb); /* increase reference count by one */
+
+	/* backup skb->cb, as qdisc layer will overwrite it */
+	skb_save_cb(skb_shared);
+	qdisc_enqueue_root(skb_shared, q); /* might kfree_skb */
+	if (likely(atomic_read(&skb_shared->users) == users + 1)) {
+		bool validate;
+
+		kfree_skb(skb_shared); /* decrease reference count by one */
+
+		skb->destructor = &imq_skb_destructor;
+
+		skb_popd = qdisc_dequeue_skb(q, &validate);
+
+		/* cloned? */
+		if (unlikely(skb_orig))
+			kfree_skb(skb_orig); /* free original */
+
+		spin_unlock(root_lock);
+
+#if 0
+		/* schedule qdisc dequeue */
+		__netif_schedule(q);
+#else
+		if (likely(skb_popd)) {
+			/* Note that we validate skb (GSO, checksum, ...) outside of locks */
+			if (validate)
+        		skb_popd = validate_xmit_skb_list(skb_popd, dev);
+			
+			if (skb_popd) {
+				int dummy_ret;
+				int cpu = smp_processor_id(); /* ok because BHs are off */
+
+				txq = skb_get_tx_queue(dev, skb_popd);
+				/* 
+				IMQ device will not be frozen or stoped, and it always be successful.
+				So we need not check its status and return value to accelerate.
+				*/
+				if (imq_dev_accurate_stats && txq->xmit_lock_owner != cpu) {
+					HARD_TX_LOCK(dev, txq, cpu);
+					if (!netif_xmit_frozen_or_stopped(txq)) {
+						dev_hard_start_xmit(skb_popd, dev, txq, &dummy_ret);
+					}
+					HARD_TX_UNLOCK(dev, txq);
+				} else {
+					if (!netif_xmit_frozen_or_stopped(txq)) {
+						dev_hard_start_xmit(skb_popd, dev, txq, &dummy_ret);
+					}
+				}
+			}
+		} else {
+			/* No ready skb, then schedule it */
+			__netif_schedule(q);
+		}
+#endif
+		rcu_read_unlock_bh();
+		retval = 0;
+		goto out;
+	} else {
+		skb_restore_cb(skb_shared); /* restore skb->cb */
+		skb->nf_queue_entry = NULL;
+		/*
+		 * qdisc dropped packet and decreased skb reference count of
+		 * skb, so we don't really want to and try refree as that would
+		 * actually destroy the skb.
+		 */
+		spin_unlock(root_lock);
+		goto packet_not_eaten_by_imq_dev;
+	}
+
+packet_not_eaten_by_imq_dev:
+	skb_set_queue_mapping(skb, orig_queue_index);
+	rcu_read_unlock_bh();
+
+	/* cloned? restore original */
+	if (unlikely(skb_orig)) {
+		kfree_skb(skb);
+		entry->skb = skb_orig;
+	}
+	retval = -1;
+out:
+	return retval;
+}
+static unsigned int imq_nf_hook(void *priv,
+				struct sk_buff *skb,
+				const struct nf_hook_state *state)
+{
+	return (skb->imq_flags & IMQ_F_ENQUEUE) ? NF_IMQ_QUEUE : NF_ACCEPT;
+}
+
+static int imq_close(struct net_device *dev)
+{
+	netif_stop_queue(dev);
+	return 0;
+}
+
+static int imq_open(struct net_device *dev)
+{
+	netif_start_queue(dev);
+	return 0;
+}
+
+static const struct net_device_ops imq_netdev_ops = {
+	.ndo_open		= imq_open,
+	.ndo_stop		= imq_close,
+	.ndo_start_xmit		= imq_dev_xmit,
+	.ndo_get_stats		= imq_get_stats,
+};
+
+static void imq_setup(struct net_device *dev)
+{
+	dev->netdev_ops		= &imq_netdev_ops;
+	dev->type		= ARPHRD_VOID;
+	dev->mtu		= 16000; /* too small? */
+	dev->tx_queue_len	= 11000; /* too big? */
+	dev->flags		= IFF_NOARP;
+	dev->features		= NETIF_F_SG | NETIF_F_FRAGLIST |
+				  NETIF_F_GSO | NETIF_F_HW_CSUM |
+				  NETIF_F_HIGHDMA;
+	dev->priv_flags		&= ~(IFF_XMIT_DST_RELEASE |
+				     IFF_TX_SKB_SHARING);
+}
+
+static int imq_validate(struct nlattr *tb[], struct nlattr *data[])
+{
+	int ret = 0;
+
+	if (tb[IFLA_ADDRESS]) {
+		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN) {
+			ret = -EINVAL;
+			goto end;
+		}
+		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS]))) {
+			ret = -EADDRNOTAVAIL;
+			goto end;
+		}
+	}
+	return 0;
+end:
+	pr_warn("IMQ: imq_validate failed (%d)\n", ret);
+	return ret;
+}
+
+static struct rtnl_link_ops imq_link_ops __read_mostly = {
+	.kind		= "imq",
+	.priv_size	= 0,
+	.setup		= imq_setup,
+	.validate	= imq_validate,
+};
+
+static const struct nf_queue_handler imq_nfqh = {
+	.outfn = imq_nf_queue,
+};
+
+static int __init imq_init_hooks(void)
+{
+	int ret;
+
+	nf_register_queue_imq_handler(&imq_nfqh);
+
+	ret = nf_register_hooks(imq_ops, ARRAY_SIZE(imq_ops));
+	if (ret < 0)
+		nf_unregister_queue_imq_handler();
+
+	return ret;
+}
+
+static int __init imq_init_one(int index)
+{
+	struct net_device *dev;
+	int ret;
+
+	dev = alloc_netdev_mq(0, "imq%d", NET_NAME_UNKNOWN, imq_setup, numqueues);
+	if (!dev)
+		return -ENOMEM;
+
+	ret = dev_alloc_name(dev, dev->name);
+	if (ret < 0)
+		goto fail;
+
+	dev->rtnl_link_ops = &imq_link_ops;
+	ret = register_netdevice(dev);
+	if (ret < 0)
+		goto fail;
+
+	return 0;
+fail:
+	free_netdev(dev);
+	return ret;
+}
+
+static int __init imq_init_devs(void)
+{
+	int err, i;
+
+	if (numdevs < 1 || numdevs > IMQ_MAX_DEVS) {
+		pr_err("IMQ: numdevs has to be betweed 1 and %u\n",
+		       IMQ_MAX_DEVS);
+		return -EINVAL;
+	}
+
+	if (numqueues < 1 || numqueues > IMQ_MAX_QUEUES) {
+		pr_err("IMQ: numqueues has to be betweed 1 and %u\n",
+		       IMQ_MAX_QUEUES);
+		return -EINVAL;
+	}
+
+	get_random_bytes(&imq_hashrnd, sizeof(imq_hashrnd));
+
+	rtnl_lock();
+	err = __rtnl_link_register(&imq_link_ops);
+
+	for (i = 0; i < numdevs && !err; i++)
+		err = imq_init_one(i);
+
+	if (err) {
+		__rtnl_link_unregister(&imq_link_ops);
+		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
+	}
+	rtnl_unlock();
+
+	return err;
+}
+
+static int __init imq_init_module(void)
+{
+	int err;
+
+#if defined(CONFIG_IMQ_NUM_DEVS)
+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS > 16);
+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS < 2);
+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS - 1 > IMQ_F_IFMASK);
+#endif
+
+	err = imq_init_devs();
+	if (err) {
+		pr_err("IMQ: Error trying imq_init_devs(net)\n");
+		return err;
+	}
+
+	err = imq_init_hooks();
+	if (err) {
+		pr_err(KERN_ERR "IMQ: Error trying imq_init_hooks()\n");
+		rtnl_link_unregister(&imq_link_ops);
+		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
+		return err;
+	}
+
+	pr_info("IMQ driver loaded successfully. (numdevs = %d, numqueues = %d, imq_dev_accurate_stats = %d)\n",
+		numdevs, numqueues, imq_dev_accurate_stats);
+
+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
+	pr_info("\tHooking IMQ before NAT on PREROUTING.\n");
+#else
+	pr_info("\tHooking IMQ after NAT on PREROUTING.\n");
+#endif
+#if defined(CONFIG_IMQ_BEHAVIOR_AB) || defined(CONFIG_IMQ_BEHAVIOR_BB)
+	pr_info("\tHooking IMQ before NAT on POSTROUTING.\n");
+#else
+	pr_info("\tHooking IMQ after NAT on POSTROUTING.\n");
+#endif
+
+	return 0;
+}
+
+static void __exit imq_unhook(void)
+{
+	nf_unregister_hooks(imq_ops, ARRAY_SIZE(imq_ops));
+	nf_unregister_queue_imq_handler();
+}
+
+static void __exit imq_cleanup_devs(void)
+{
+	rtnl_link_unregister(&imq_link_ops);
+	memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
+}
+
+static void __exit imq_exit_module(void)
+{
+	imq_unhook();
+	imq_cleanup_devs();
+	pr_info("IMQ driver unloaded successfully.\n");
+}
+
+module_init(imq_init_module);
+module_exit(imq_exit_module);
+
+module_param(numdevs, int, 0);
+module_param(numqueues, int, 0);
+module_param(imq_dev_accurate_stats, int, 0);
+MODULE_PARM_DESC(numdevs, "number of IMQ devices (how many imq* devices will be created)");
+MODULE_PARM_DESC(numqueues, "number of queues per IMQ device");
+MODULE_PARM_DESC(imq_dev_accurate_stats, "Notify if need the accurate imq device stats");
+
+MODULE_AUTHOR("https://github.com/imq/linuximq");
+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See https://github.com/imq/linuximq/wiki for more information.");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS_RTNL_LINK("imq");
diff --git a/trunk/linux-4.4.x/drivers/net/phy/Kconfig b/trunk/linux-4.4.x/drivers/net/phy/Kconfig
index 5be37299e..7e1e6fc1d 100644
--- a/trunk/linux-4.4.x/drivers/net/phy/Kconfig
+++ b/trunk/linux-4.4.x/drivers/net/phy/Kconfig
@@ -125,6 +125,11 @@ config ICPLUS_PHY
 	tristate "Drivers for ICPlus PHYs"
 	---help---
 	  Currently supports the IP175C and IP1001 PHYs.
+	  
+config AIROHA_PHY
+	tristate "Drivers for Airoha PHYs"
+	---help---
+	  Currently supports the EN8801S PHY.	  
 
 config REALTEK_PHY
 	tristate "Drivers for Realtek PHYs"
@@ -251,6 +256,26 @@ config MDIO_BUS_MUX_MMIOREG
 
 source "drivers/net/phy/mtk/mt753x/Kconfig"
 
+config RTL8367S_GSW
+	tristate "rtl8367 Gigabit Switch support for mt7622"
+	depends on NET_VENDOR_MEDIATEK
+	help
+	  This driver supports rtl8367s in mt7622
+
+config MTK_GPHY
+    tristate "Drivers for Mediatek internal Gigabit PHY"
+    default y
+    ---help---
+      Driver for Mediatek internal Gigabit PHY with 1000M/100M/10M and
+      paue asym_pause capability.
+      Currently supports the mt7621, mt7530, mt7531, mt7629.
+
+config MTK_FE_GPHY
+	tristate "Driver for mediatek internal FE GPHY"
+	depends on NET_VENDOR_MEDIATEK
+	help
+	  Driver for Mediatek internal FE GPHY
+
 config MDIO_BCM_UNIMAC
 	tristate "Broadcom UniMAC MDIO bus controller"
 	depends on HAS_IOMEM
diff --git a/trunk/linux-4.4.x/drivers/net/phy/Makefile b/trunk/linux-4.4.x/drivers/net/phy/Makefile
index 8f9564b02..dc14d0393 100644
--- a/trunk/linux-4.4.x/drivers/net/phy/Makefile
+++ b/trunk/linux-4.4.x/drivers/net/phy/Makefile
@@ -20,6 +20,7 @@ obj-$(CONFIG_BCM7XXX_PHY)	+= bcm7xxx.o
 obj-$(CONFIG_BCM87XX_PHY)	+= bcm87xx.o
 obj-$(CONFIG_BCM_CYGNUS_PHY)	+= bcm-cygnus.o
 obj-$(CONFIG_ICPLUS_PHY)	+= icplus.o
+obj-$(CONFIG_AIROHA_PHY)	+= airoha.o
 obj-$(CONFIG_REALTEK_PHY)	+= realtek.o
 obj-$(CONFIG_RTL8366_SMI)  += rtl8366_smi.o
 obj-$(CONFIG_RTL8366S_PHY) += rtl8366s.o
@@ -49,3 +50,6 @@ obj-$(CONFIG_MDIO_BCM_UNIMAC)	+= mdio-bcm-unimac.o
 obj-$(CONFIG_MICROCHIP_PHY)	+= microchip.o
 obj-$(CONFIG_MDIO_BCM_IPROC)	+= mdio-bcm-iproc.o
 obj-$(CONFIG_MT753X_GSW)	+= mtk/mt753x/
+obj-$(CONFIG_RTL8367S_GSW)	+= rtk/
+obj-$(CONFIG_MTK_GPHY)      += mtk_gphy.o
+obj-$(CONFIG_MTK_FE_GPHY)	+= mtk/gphy/
diff --git a/trunk/linux-4.4.x/drivers/net/phy/airoha.c b/trunk/linux-4.4.x/drivers/net/phy/airoha.c
new file mode 100644
index 000000000..097ebf1bf
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/airoha.c
@@ -0,0 +1,396 @@
+/*******************************************************************************
+*  Copyright Statement:
+*  --------------------
+*  This software is protected by Copyright and the information contained
+*  herein is confidential. The software may not be copied and the information
+*  contained herein may not be used or disclosed except with the written
+*  permission of Airoha Technology Corp. (C) 2021
+*
+*  BY OPENING THIS FILE, BUYER HEREBY UNEQUIVOCALLY ACKNOWLEDGES AND AGREES
+*  THAT THE SOFTWARE/FIRMWARE AND ITS DOCUMENTATIONS ("AIROHA SOFTWARE")
+*  RECEIVED FROM AIROHA AND/OR ITS REPRESENTATIVES ARE PROVIDED TO BUYER ON
+*  AN "AS-IS" BASIS ONLY. AIROHA EXPRESSLY DISCLAIMS ANY AND ALL WARRANTIES,
+*  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE IMPLIED WARRANTIES OF
+*  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE OR NONINFRINGEMENT.
+*  NEITHER DOES AIROHA PROVIDE ANY WARRANTY WHATSOEVER WITH RESPECT TO THE
+*  SOFTWARE OF ANY THIRD PARTY WHICH MAY BE USED BY, INCORPORATED IN, OR
+*  SUPPLIED WITH THE AIROHA SOFTWARE, AND BUYER AGREES TO LOOK ONLY TO SUCH
+*  THIRD PARTY FOR ANY WARRANTY CLAIM RELATING THERETO. AIROHA SHALL ALSO
+*  NOT BE RESPONSIBLE FOR ANY AIROHA SOFTWARE RELEASES MADE TO BUYER'S
+*  SPECIFICATION OR TO CONFORM TO A PARTICULAR STANDARD OR OPEN FORUM.
+*
+*  BUYER'S SOLE AND EXCLUSIVE REMEDY AND AIROHA'S ENTIRE AND CUMULATIVE
+*  LIABILITY WITH RESPECT TO THE AIROHA SOFTWARE RELEASED HEREUNDER WILL BE,
+*  AT AIROHA'S OPTION, TO REVISE OR REPLACE THE AIROHA SOFTWARE AT ISSUE,
+*  OR REFUND ANY SOFTWARE LICENSE FEES OR SERVICE CHARGE PAID BY BUYER TO
+*  AIROHA FOR SUCH AIROHA SOFTWARE AT ISSUE.
+*
+*  THE TRANSACTION CONTEMPLATED HEREUNDER SHALL BE CONSTRUED IN ACCORDANCE
+*  WITH THE LAWS OF THE STATE OF CALIFORNIA, USA, EXCLUDING ITS CONFLICT OF
+*  LAWS PRINCIPLES.  ANY DISPUTES, CONTROVERSIES OR CLAIMS ARISING THEREOF AND
+*  RELATED THERETO SHALL BE SETTLED BY ARBITRATION IN SAN FRANCISCO, CA, UNDER
+*  THE RULES OF THE INTERNATIONAL CHAMBER OF COMMERCE (ICC).
+*
+*******************************************************************************/
+
+/* FILE NAME:  airoha.c
+ * PURPOSE:
+ *      EN8801S phy driver for Linux
+ * NOTES:
+ *
+ */
+
+/* INCLUDE FILE DECLARATIONS
+ */
+
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/errno.h>
+#include <linux/unistd.h>
+#include <linux/interrupt.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/mii.h>
+#include <linux/ethtool.h>
+#include <linux/phy.h>
+#include <linux/delay.h>
+
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <linux/uaccess.h>
+
+#include "airoha.h"
+
+MODULE_DESCRIPTION("Airoha EN8801S PHY drivers");
+MODULE_AUTHOR("Airoha");
+MODULE_LICENSE("GPL");
+
+static int preSpeed=0;
+/************************************************************************
+*                  F U N C T I O N S
+************************************************************************/
+unsigned int mdiobus_write45(struct mii_bus *bus, u32 port, u32 devad, u32 reg, u16 val)
+{
+    mdiobus_write(bus, port, MII_MMD_ACC_CTL_REG, devad);
+    mdiobus_write(bus, port, MII_MMD_ADDR_DATA_REG, reg);
+    mdiobus_write(bus, port, MII_MMD_ACC_CTL_REG, MMD_OP_MODE_DATA | devad);
+    mdiobus_write(bus, port, MII_MMD_ADDR_DATA_REG, val);
+    return 0;
+}
+
+unsigned int mdiobus_read45(struct mii_bus *bus, u32 port, u32 devad, u32 reg, u32 *read_data)
+{
+    mdiobus_write(bus, port, MII_MMD_ACC_CTL_REG, devad);
+    mdiobus_write(bus, port, MII_MMD_ADDR_DATA_REG, reg);
+    mdiobus_write(bus, port, MII_MMD_ACC_CTL_REG, MMD_OP_MODE_DATA | devad);
+    *read_data = mdiobus_read(bus, port, MII_MMD_ADDR_DATA_REG);
+    return 0;
+}
+
+/* Airoha MII read function */
+unsigned int ecnt_mii_cl22_read(struct mii_bus *ebus, unsigned int phy_addr,unsigned int phy_register,unsigned int *read_data)
+{
+    *read_data = mdiobus_read(ebus, phy_addr, phy_register);
+    return 0;
+}
+
+/* Airoha MII write function */
+unsigned int ecnt_mii_cl22_write(struct mii_bus *ebus, unsigned int phy_addr, unsigned int phy_register,unsigned int write_data)
+{
+    mdiobus_write(ebus, phy_addr, phy_register, write_data);
+    return 0;
+}
+
+/* EN8801 PBUS write function */
+void En8801_PbusRegWr(struct mii_bus *ebus, unsigned long pbus_address, unsigned long pbus_data)
+{
+    ecnt_mii_cl22_write(ebus, EN8801S_PBUS_PHY_ID, 0x1F, (unsigned int)(pbus_address >> 6));
+    ecnt_mii_cl22_write(ebus, EN8801S_PBUS_PHY_ID, (unsigned int)((pbus_address >> 2) & 0xf), (unsigned int)(pbus_data & 0xFFFF));
+    ecnt_mii_cl22_write(ebus, EN8801S_PBUS_PHY_ID, 0x10, (unsigned int)(pbus_data >> 16));
+    return;
+}
+
+/* EN8801 PBUS read function */
+unsigned long En8801_PbusRegRd(struct mii_bus *ebus, unsigned long pbus_address)
+{
+    unsigned long pbus_data;
+    unsigned int pbus_data_low, pbus_data_high;
+
+    ecnt_mii_cl22_write(ebus, EN8801S_PBUS_PHY_ID, 0x1F, (unsigned int)(pbus_address >> 6));
+    ecnt_mii_cl22_read(ebus, EN8801S_PBUS_PHY_ID, (unsigned int)((pbus_address >> 2) & 0xf), &pbus_data_low);
+    ecnt_mii_cl22_read(ebus, EN8801S_PBUS_PHY_ID, 0x10, &pbus_data_high);
+    pbus_data = (pbus_data_high << 16) + pbus_data_low;
+    return pbus_data;
+}
+
+/* Use default PBUS_PHY_ID */
+/* EN8801 PBUS write function */
+void En8801_varPbusRegWr(struct mii_bus *ebus, unsigned long pbus_id,unsigned long pbus_address, unsigned long pbus_data)
+{
+    ecnt_mii_cl22_write(ebus, pbus_id, 0x1F, (unsigned int)(pbus_address >> 6));
+    ecnt_mii_cl22_write(ebus, pbus_id, (unsigned int)((pbus_address >> 2) & 0xf), (unsigned int)(pbus_data & 0xFFFF));
+    ecnt_mii_cl22_write(ebus, pbus_id, 0x10, (unsigned int)(pbus_data >> 16));
+    return;
+}
+
+/* EN8801 PBUS read function */
+unsigned long En8801_varPbusRegRd(struct mii_bus *ebus, unsigned long pbus_id, unsigned long pbus_address)
+{
+    unsigned long pbus_data;
+    unsigned int pbus_data_low, pbus_data_high;
+
+    ecnt_mii_cl22_write(ebus, pbus_id, 0x1F, (unsigned int)(pbus_address >> 6));
+    ecnt_mii_cl22_read(ebus,  pbus_id, (unsigned int)((pbus_address >> 2) & 0xf), &pbus_data_low);
+    ecnt_mii_cl22_read(ebus,  pbus_id, 0x10, &pbus_data_high);
+    pbus_data = (pbus_data_high << 16) + pbus_data_low;
+    return pbus_data;
+}
+
+/* EN8801 Token Ring Write function */
+void En8801_TR_RegWr(struct mii_bus *ebus, unsigned long tr_address, unsigned long tr_data)
+{
+    ecnt_mii_cl22_write(ebus, EN8801S_MDIO_PHY_ID, 0x1F, 0x52b5);       /* page select */
+    ecnt_mii_cl22_write(ebus, EN8801S_MDIO_PHY_ID, 0x11, (unsigned int)(tr_data & 0xffff));
+    ecnt_mii_cl22_write(ebus, EN8801S_MDIO_PHY_ID, 0x12, (unsigned int)(tr_data >> 16));
+    ecnt_mii_cl22_write(ebus, EN8801S_MDIO_PHY_ID, 0x10, (unsigned int)(tr_address | TrReg_WR));
+    ecnt_mii_cl22_write(ebus, EN8801S_MDIO_PHY_ID, 0x1F, 0x0);          /* page resetore */
+    return;
+}
+
+/* EN8801 Token Ring Read function */
+unsigned long En8801_TR_RegRd(struct mii_bus *ebus, unsigned long tr_address)
+{
+    unsigned long tr_data;
+    unsigned int tr_data_low, tr_data_high;
+
+    ecnt_mii_cl22_write(ebus, EN8801S_MDIO_PHY_ID, 0x1F, 0x52b5);       /* page select */
+    ecnt_mii_cl22_write(ebus, EN8801S_MDIO_PHY_ID, 0x10, (unsigned int)(tr_address | TrReg_RD));
+    ecnt_mii_cl22_read(ebus, EN8801S_MDIO_PHY_ID, 0x11, &tr_data_low);
+    ecnt_mii_cl22_read(ebus, EN8801S_MDIO_PHY_ID, 0x12, &tr_data_high);
+    ecnt_mii_cl22_write(ebus, EN8801S_MDIO_PHY_ID, 0x1F, 0x0);          /* page resetore */
+    tr_data = (tr_data_high << 16) + tr_data_low;
+    return tr_data;
+}
+
+static int en8801s_config_init(struct phy_device *phydev)
+{
+    gephy_all_REG_LpiReg1Ch      GPHY_RG_LPI_1C;
+    gephy_all_REG_dev1Eh_reg324h GPHY_RG_1E_324;
+    gephy_all_REG_dev1Eh_reg012h GPHY_RG_1E_012;
+    gephy_all_REG_dev1Eh_reg017h GPHY_RG_1E_017;
+    u32 reg_value;
+    u32 retry;
+
+    reg_value = (En8801_PbusRegRd(phydev->bus, 0xcf8) & 0xfffffffc) | 0x02;
+    En8801_PbusRegWr(phydev->bus, 0xcf8, reg_value);
+    /* SGMII AN */
+    writel(0x10      ,ioremap(0x1b1280e8,4));
+    #if defined (MT7622_BOARD)
+    writel(0x14813   ,ioremap(0x1b12a028,4));        /*  MT7622 */
+    #else
+    writel(0x14813   ,ioremap(0x1b128128,4));        /*  MT7629 */
+    #endif
+    writel(0x31120103,ioremap(0x1b128020,4));
+    writel(0x01      ,ioremap(0x1b128008,4));
+    writel(0x1340    ,ioremap(0x1b128000,4));
+    writel(0x0       ,ioremap(0x1b1280e8,4));
+    mdelay(10);
+
+    En8801_PbusRegWr(phydev->bus, 0x10,0xD801);     /* control word */
+    En8801_PbusRegWr(phydev->bus, 0x0, 0x0140);
+    En8801_PbusRegWr(phydev->bus, 0x0, 0x9140);
+
+    retry = MAX_RETRY;
+    while(retry != 0)
+    {
+        mdelay(10);
+        reg_value = phy_read(phydev, MII_PHYSID1);
+        if(reg_value == EN8801S_PHY_ID1)
+        {
+            break;    /* wait GPHY ready */
+        }
+        retry--;
+        if(retry == 0)
+        {
+            printk(KERN_INFO "[Airoha] EN8801S initialize fail !\n");
+            return 0;
+        }
+    }
+    /* Software Reset PHY */
+    reg_value = phy_read(phydev, MII_BMCR);
+    reg_value |= BMCR_RESET;
+    phy_write(phydev, MII_BMCR, reg_value);
+    retry = MAX_RETRY;
+    do {
+        mdelay(10);
+        reg_value = phy_read(phydev, MII_BMCR);
+        retry--;
+        if(retry == 0)
+        {
+            printk(KERN_INFO "[Airoha] EN8801S initialize fail !\n");
+            return 0;
+        }
+    } while (reg_value & BMCR_RESET);
+
+    En8801_PbusRegWr(phydev->bus, 0x0600, 0x0c000c00);
+    En8801_PbusRegWr(phydev->bus, 0x10, 0xD801);
+    En8801_PbusRegWr(phydev->bus, 0x0,  0x9140);
+    En8801_PbusRegWr(phydev->bus, 0x0A14, 0x0003);
+    En8801_PbusRegWr(phydev->bus, 0x0600, 0x0c000c00);
+    /* Set FCM control */
+    En8801_PbusRegWr(phydev->bus, 0x1404, 0x004b);
+    En8801_PbusRegWr(phydev->bus, 0x140c, 0x0007);
+    /* Set GPHY Perfomance*/
+    /* Token Ring */
+    En8801_TR_RegWr(phydev->bus, RgAddr_PMA_01h,     0x6FB90A);
+    En8801_TR_RegWr(phydev->bus, RgAddr_PMA_18h,     0x0E2F00);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_06h,    0x2EBAEF);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_11h,    0x040001);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_03h,    0x000004);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_1Ch,    0x003210);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_14h,    0x00024A);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_0Ch,    0x00704D);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_0Dh,    0x02314F);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_10h,    0x005010);
+    En8801_TR_RegWr(phydev->bus, RgAddr_DSPF_0Fh,    0x003028);
+    En8801_TR_RegWr(phydev->bus, RgAddr_TR_26h,      0x444444);
+    En8801_TR_RegWr(phydev->bus, RgAddr_R1000DEC_15h,0x0055A0);
+    /* CL22 & CL45 */
+    phy_write(phydev, 0x1f, 0x03);
+    GPHY_RG_LPI_1C.DATA = phy_read(phydev, RgAddr_LpiReg1Ch);
+    GPHY_RG_LPI_1C.DataBitField.smi_deton_th = 0x0C;
+    phy_write(phydev, RgAddr_LpiReg1Ch, GPHY_RG_LPI_1C.DATA);
+    phy_write(phydev, 0x1f, 0x0);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x122, 0xffff);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x234, 0x0180);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x238, 0x0120);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x120, 0x9014);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x239, 0x0117);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x14A, 0xEE20);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x19B, 0x0111);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1F, 0x268, 0x07F4);
+
+    mdiobus_read45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x324, &reg_value);
+    GPHY_RG_1E_324.DATA=(u16)reg_value;
+    GPHY_RG_1E_324.DataBitField.smi_det_deglitch_off = 0;
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x324, (u32)GPHY_RG_1E_324.DATA);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x19E, 0xC2);
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x013, 0x0);
+
+    /* EFUSE */
+    En8801_PbusRegWr(phydev->bus, 0x1C08, 0x40000040);
+    retry = MAX_RETRY;
+    while(retry != 0)
+    {
+        mdelay(1);
+        reg_value = En8801_PbusRegRd(phydev->bus, 0x1C08);
+        if((reg_value & (1 << 30)) == 0)
+        {
+            break;
+        }
+        retry--;
+    }
+    reg_value = En8801_PbusRegRd(phydev->bus, 0x1C38);          /* RAW#2 */
+    GPHY_RG_1E_012.DataBitField.da_tx_i2mpb_a_tbt = reg_value & 0x03f;
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x12, (u32)GPHY_RG_1E_012.DATA);
+    GPHY_RG_1E_017.DataBitField.da_tx_i2mpb_b_tbt=(reg_value >> 8) & 0x03f;
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x12, (u32)GPHY_RG_1E_017.DATA);
+
+    En8801_PbusRegWr(phydev->bus, 0x1C08, 0x40400040);
+    retry = MAX_RETRY;
+    while(retry != 0)
+    {
+        mdelay(1);
+        reg_value = En8801_PbusRegRd(phydev->bus, 0x1C08);
+        if((reg_value & (1 << 30)) == 0)
+        {
+            break;
+        }
+        retry--;
+    }
+    reg_value = En8801_PbusRegRd(phydev->bus, 0x1C30);          /* RAW#16 */
+    GPHY_RG_1E_324.DataBitField.smi_det_deglitch_off = (reg_value >> 12) & 0x01;
+    mdiobus_write45(phydev->bus, EN8801S_MDIO_PHY_ID, 0x1E, 0x324, (u32)GPHY_RG_1E_324.DATA);
+
+    printk(KERN_INFO "[Airoha] EN8801S initialize OK ! (0722.2)\n");
+    return 0;
+}
+
+static int en8801s_read_status(struct phy_device *phydev)
+{
+    int ret;
+    u32 reg_value;
+
+    ret = genphy_read_status(phydev);
+
+    if(phydev->link == 0) preSpeed =0;
+    if(preSpeed != phydev->speed && phydev->link == 1)
+    {
+
+        preSpeed = phydev->speed;
+        En8801_PbusRegWr(phydev->bus, 0x0600, 0x0c000c00);
+        if(preSpeed == SPEED_1000)
+        {
+            En8801_PbusRegWr(phydev->bus, 0x10, 0xD801);
+            En8801_PbusRegWr(phydev->bus, 0x0,  0x9140);
+
+            En8801_PbusRegWr(phydev->bus, 0x0A14, 0x0003);
+            En8801_PbusRegWr(phydev->bus, 0x0600, 0x0c000c00);
+            mdelay(2);      /* delay 2 ms */
+            En8801_PbusRegWr(phydev->bus, 0x1404, 0x004b);
+            En8801_PbusRegWr(phydev->bus, 0x140c, 0x0007);
+        }
+        else if(preSpeed == SPEED_100)
+        {
+            En8801_PbusRegWr(phydev->bus, 0x10, 0xD401);
+            En8801_PbusRegWr(phydev->bus, 0x0,  0x9140);
+
+            En8801_PbusRegWr(phydev->bus, 0x0A14, 0x0007);
+            En8801_PbusRegWr(phydev->bus, 0x0600, 0x0c11);
+            mdelay(2);      /* delay 2 ms */
+            En8801_PbusRegWr(phydev->bus, 0x1404, 0x0027);
+            En8801_PbusRegWr(phydev->bus, 0x140c, 0x0007);
+        }
+        else if(preSpeed == SPEED_10)
+        {
+            En8801_PbusRegWr(phydev->bus, 0x10, 0xD001);
+            En8801_PbusRegWr(phydev->bus, 0x0,  0x9140);
+
+            En8801_PbusRegWr(phydev->bus, 0x0A14, 0x000b);
+            En8801_PbusRegWr(phydev->bus, 0x0600, 0x0c11);
+            mdelay(2);      /* delay 2 ms */
+            En8801_PbusRegWr(phydev->bus, 0x1404, 0x0027);
+            En8801_PbusRegWr(phydev->bus, 0x140c, 0x0007);
+        }
+    }
+    return ret;
+}
+
+
+static struct phy_driver Airoha_driver[] = {
+{
+    .phy_id         = 0x03a29416,
+    .name           = "Airoha EN8801S",
+    .phy_id_mask    = 0x0ffffff0,
+    .features       = PHY_GBIT_FEATURES,
+    .config_init    = &en8801s_config_init,
+    .config_aneg    = &genphy_config_aneg,
+    .read_status    = &en8801s_read_status,
+    .suspend        = genphy_suspend,
+    .resume         = genphy_resume,
+} };
+
+module_phy_driver(Airoha_driver);
+
+static struct mdio_device_id __maybe_unused Airoha_tbl[] = {
+    { 0x03a29416, 0x0ffffff0 },
+    { }
+};
+
+MODULE_DEVICE_TABLE(mdio, Airoha_tbl);
diff --git a/trunk/linux-4.4.x/drivers/net/phy/airoha.h b/trunk/linux-4.4.x/drivers/net/phy/airoha.h
new file mode 100644
index 000000000..8e2a9da6b
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/airoha.h
@@ -0,0 +1,178 @@
+/*******************************************************************************
+*  Copyright Statement:
+*  --------------------
+*  This software is protected by Copyright and the information contained
+*  herein is confidential. The software may not be copied and the information
+*  contained herein may not be used or disclosed except with the written
+*  permission of Airoha Technology Corp. (C) 2021
+*
+*  BY OPENING THIS FILE, BUYER HEREBY UNEQUIVOCALLY ACKNOWLEDGES AND AGREES
+*  THAT THE SOFTWARE/FIRMWARE AND ITS DOCUMENTATIONS ("AIROHA SOFTWARE")
+*  RECEIVED FROM AIROHA AND/OR ITS REPRESENTATIVES ARE PROVIDED TO BUYER ON
+*  AN "AS-IS" BASIS ONLY. AIROHA EXPRESSLY DISCLAIMS ANY AND ALL WARRANTIES,
+*  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE IMPLIED WARRANTIES OF
+*  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE OR NONINFRINGEMENT.
+*  NEITHER DOES AIROHA PROVIDE ANY WARRANTY WHATSOEVER WITH RESPECT TO THE
+*  SOFTWARE OF ANY THIRD PARTY WHICH MAY BE USED BY, INCORPORATED IN, OR
+*  SUPPLIED WITH THE AIROHA SOFTWARE, AND BUYER AGREES TO LOOK ONLY TO SUCH
+*  THIRD PARTY FOR ANY WARRANTY CLAIM RELATING THERETO. AIROHA SHALL ALSO
+*  NOT BE RESPONSIBLE FOR ANY AIROHA SOFTWARE RELEASES MADE TO BUYER'S
+*  SPECIFICATION OR TO CONFORM TO A PARTICULAR STANDARD OR OPEN FORUM.
+*
+*  BUYER'S SOLE AND EXCLUSIVE REMEDY AND AIROHA'S ENTIRE AND CUMULATIVE
+*  LIABILITY WITH RESPECT TO THE AIROHA SOFTWARE RELEASED HEREUNDER WILL BE,
+*  AT AIROHA'S OPTION, TO REVISE OR REPLACE THE AIROHA SOFTWARE AT ISSUE,
+*  OR REFUND ANY SOFTWARE LICENSE FEES OR SERVICE CHARGE PAID BY BUYER TO
+*  AIROHA FOR SUCH AIROHA SOFTWARE AT ISSUE.
+*
+*  THE TRANSACTION CONTEMPLATED HEREUNDER SHALL BE CONSTRUED IN ACCORDANCE
+*  WITH THE LAWS OF THE STATE OF CALIFORNIA, USA, EXCLUDING ITS CONFLICT OF
+*  LAWS PRINCIPLES.  ANY DISPUTES, CONTROVERSIES OR CLAIMS ARISING THEREOF AND
+*  RELATED THERETO SHALL BE SETTLED BY ARBITRATION IN SAN FRANCISCO, CA, UNDER
+*  THE RULES OF THE INTERNATIONAL CHAMBER OF COMMERCE (ICC).
+*
+*******************************************************************************/
+
+/* FILE NAME:  airoha.h
+ * PURPOSE:
+ *      Define EN8801S driver function
+ *
+ * NOTES:
+ *
+ */
+
+#ifndef __AIROHA_H
+#define __AIROHA_H
+
+/* NAMING DECLARATIONS
+ */
+#define PHY_ADDRESS_RANGE       0x1
+#define EN8801S_MDIO_PHY_ID     0x1     /* Range PHY_ADDRESS_RANGE .. 0x1e */
+#define EN8801S_PBUS_PHY_ID     (EN8801S_MDIO_PHY_ID+1)
+
+#define EN8801S_RG_ETHER_PHY_OUI 0x19a4
+#define EN8801S_RG_SMI_ADDR      0x19a8
+#define EN8801S_PBUS_OUI         0x17a5
+#define EN8801S_PHY_ID1          0x03a2
+#define EN8801S_PHY_ID2          0x9416
+
+#define DEV1E_REG013_VALUE       0
+#define DEV1E_REG19E_VALUE       0xC2
+#define DEV1E_REG324_VALUE       0x200
+
+#define TRUE                     1
+#define FALSE                    0
+#define MAX_RETRY                10
+/* CL45 MDIO control */
+#define MII_MMD_ACC_CTL_REG      0x0d
+#define MII_MMD_ADDR_DATA_REG    0x0e
+#define MMD_OP_MODE_DATA BIT(14)
+
+#define MAX_TRG_COUNTER 5
+
+/* CL22 Reg Support Page Select */
+#define RgAddr_Reg1Fh        0x1f
+#define CL22_Page_Reg        0x0000
+#define CL22_Page_ExtReg     0x0001
+#define CL22_Page_MiscReg    0x0002
+#define CL22_Page_LpiReg     0x0003
+#define CL22_Page_tReg       0x02A3
+#define CL22_Page_TrReg      0x52B5
+
+/* CL45 Reg Support DEVID */
+#define DEVID_03             0x03
+#define DEVID_07             0x07
+#define DEVID_1E             0x1E
+#define DEVID_1F             0x1F
+
+/* TokenRing Reg Access */
+#define TrReg_PKT_XMT_STA    0x8000
+#define TrReg_WR             0x8000
+#define TrReg_RD             0xA000
+
+#define RgAddr_LpiReg1Ch                            0x1c
+#define RgAddr_PMA_01h                              0x0f82
+#define RgAddr_PMA_18h                              0x0fb0
+#define RgAddr_DSPF_03h                             0x1686
+#define RgAddr_DSPF_06h                             0x168c
+#define RgAddr_DSPF_0Ch                             0x1698
+#define RgAddr_DSPF_0Dh                             0x169a
+#define RgAddr_DSPF_0Fh                             0x169e
+#define RgAddr_DSPF_10h                             0x16a0
+#define RgAddr_DSPF_11h                             0x16a2
+#define RgAddr_DSPF_14h                             0x16a8
+#define RgAddr_DSPF_1Ch                             0x16b8
+#define RgAddr_TR_26h                               0x0ecc
+#define RgAddr_R1000DEC_15h                         0x03aa
+
+/* DATA TYPE DECLARATIONS
+ */
+typedef struct
+{
+    u16 DATA_Lo;
+    u16 DATA_Hi;
+}TR_DATA_T;
+
+typedef union
+{
+    struct
+    {
+        /* b[15:00] */
+        u16 smi_deton_wt                             : 3;
+        u16 smi_det_mdi_inv                          : 1;
+        u16 smi_detoff_wt                            : 3;
+        u16 smi_sigdet_debouncing_en                 : 1;
+        u16 smi_deton_th                             : 6;
+        u16 rsv_14                                   : 2;
+    } DataBitField;
+    u16 DATA;
+} gephy_all_REG_LpiReg1Ch, *Pgephy_all_REG_LpiReg1Ch;
+
+typedef union
+{
+    struct
+    {
+        /* b[15:00] */
+        u16 rg_smi_detcnt_max                        : 6;
+        u16 rsv_6                                    : 2;
+        u16 rg_smi_det_max_en                        : 1;
+        u16 smi_det_deglitch_off                     : 1;
+        u16 rsv_10                                   : 6;
+    } DataBitField;
+    u16 DATA;
+} gephy_all_REG_dev1Eh_reg324h, *Pgephy_all_REG_dev1Eh_reg324h;
+
+typedef union
+{
+    struct
+    {
+        /* b[15:00] */
+        u16 da_tx_i2mpb_a_tbt                        : 6;
+        u16 rsv_6                                    : 4;
+        u16 da_tx_i2mpb_a_gbe                        : 6;
+    } DataBitField;
+    u16 DATA;
+} gephy_all_REG_dev1Eh_reg012h, *Pgephy_all_REG_dev1Eh_reg012h;
+
+typedef union
+{
+    struct
+    {
+        /* b[15:00] */
+        u16 da_tx_i2mpb_b_tbt                        : 6;
+        u16 rsv_6                                    : 2;
+        u16 da_tx_i2mpb_b_gbe                        : 6;
+        u16 rsv_14                                   : 2;
+    } DataBitField;
+    u16 DATA;
+} gephy_all_REG_dev1Eh_reg017h, *Pgephy_all_REG_dev1Eh_reg017h;
+
+
+/* EXPORTED SUBPROGRAM SPECIFICATIONS
+ */
+
+void En8801_PbusRegWr(struct mii_bus *ebus, unsigned long pbus_address, unsigned long pbus_data);
+unsigned long En8801_PbusRegRd(struct mii_bus *ebus, unsigned long pbus_address);
+void En8801_varPbusRegWr(struct mii_bus *ebus, unsigned long pbus_id, unsigned long pbus_address, unsigned long pbus_data);
+unsigned long En8801_varPbusRegRd(struct mii_bus *ebus, unsigned long pbus_id, unsigned long pbus_address);
+#endif /* End of __AIROHA_H */
diff --git a/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/Makefile b/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/Makefile
new file mode 100644
index 000000000..4b1a1a555
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/Makefile
@@ -0,0 +1,2 @@
+obj-$(CONFIG_MTK_FE_GPHY) += mtk_fe_gphy.o
+mtk_fe_gphy-objs := mtk_gphy.o
diff --git a/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/mtk_gphy.c b/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/mtk_gphy.c
new file mode 100644
index 000000000..65e752559
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/mtk_gphy.c
@@ -0,0 +1,217 @@
+/*
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+ 
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/delay.h>
+#include <linux/of_mdio.h>
+#include <linux/of_platform.h>
+#include <linux/mfd/syscon.h>
+#include <linux/regmap.h> 
+#include <linux/reset.h>
+
+#define INFRA_PHY 0x710
+#define GE_FE_PHY_EN 0x10000820
+#define GE_FE_PHY_DIS(x) (((x) & 0x1f) << 5)
+#define MTK_SMI_ADDR_MASD 0x1f
+#define MTK_INTERNAL_GPHY_ADDR 0
+
+#define MTK_ESW_BASE 0x18000
+#define MTK_ESW_LED_CTRL 0x168
+#define  MTK_ESW_EPHY_MDIO_ADDR(x) (((x) & 0x1f) << 16)
+#define  MTK_ESW_EPHY_MDIO_MASK MTK_ESW_EPHY_MDIO_ADDR(~0)
+
+struct mtk_gphy {
+        struct device		*dev;
+        struct mii_bus		*bus;
+        struct regmap		*infra;
+        struct regmap		*eth;
+	struct reset_control	*reset;
+	unsigned int		smi_base;
+};
+
+static struct mtk_gphy *_gphy;
+
+static unsigned int mii_mgr_read(unsigned int phy_addr,unsigned int phy_register,unsigned int *read_data)
+{
+        struct mii_bus *bus = _gphy->bus;
+
+	/* default smi_base is 0, and ephy addresses are 1,2,3,4. */
+	if (phy_addr < PHY_MAX_ADDR && phy_addr >= 0) {
+		/* skip gphy address if set. */
+		if (phy_addr != MTK_INTERNAL_GPHY_ADDR)
+			phy_addr = (_gphy->smi_base + phy_addr) &
+				   MTK_SMI_ADDR_MASD;
+	} else {
+		return 0;
+	}
+
+        *read_data = mdiobus_read(bus, phy_addr, phy_register);
+
+        return 0;
+}
+
+static unsigned int mii_mgr_write(unsigned int phy_addr,unsigned int phy_register,unsigned int write_data)
+{
+        struct mii_bus *bus =  _gphy->bus;
+
+	/* default smi_base is 0, and ephy addresses are 1,2,3,4. */
+	if (phy_addr < PHY_MAX_ADDR && phy_addr >= 0) {
+		/* skip gphy address if set. */
+		if (phy_addr != MTK_INTERNAL_GPHY_ADDR)
+			phy_addr = (_gphy->smi_base + phy_addr) &
+				   MTK_SMI_ADDR_MASD;
+	} else {
+		return 0;
+	}
+
+        mdiobus_write(bus, phy_addr, phy_register, write_data);
+
+        return 0;
+}
+
+#include "mtk_gphy_cal.c"
+
+static int leopard_set_ephy_base(unsigned int base)
+{
+	unsigned int val;
+
+	/* HW default, skip setup flow */
+	if (base == 0)
+		return -1;
+
+	if (IS_ERR(_gphy->eth)) {
+		dev_info(_gphy->dev, "gphy no eth support\n");
+		return -1;
+	}
+
+	if (IS_ERR(_gphy->reset)) {
+		dev_info(_gphy->dev, "Couldn't get our reset line\n");
+		return -1;
+	}
+
+	reset_control_deassert(_gphy->reset);
+	regmap_read(_gphy->eth, MTK_ESW_BASE + MTK_ESW_LED_CTRL, &val);
+	val &= ~MTK_ESW_EPHY_MDIO_MASK;
+	val |= MTK_ESW_EPHY_MDIO_ADDR(base);
+	regmap_write(_gphy->eth, MTK_ESW_BASE + MTK_ESW_LED_CTRL, val);
+
+	reset_control_assert(_gphy->reset);
+	usleep_range(1000, 1100);
+	reset_control_deassert(_gphy->reset);
+
+	return 0;
+}
+
+static const struct of_device_id mtk_gphy_match[] = {
+        { .compatible = "mediatek,eth-fe-gphy" },
+        {},
+};
+
+MODULE_DEVICE_TABLE(of, mtk_gphy_match);
+
+static int gphy_probe(struct platform_device *pdev)
+{
+        struct device_node *np = pdev->dev.of_node;
+        struct device_node *mdio;
+        struct mii_bus *mdio_bus;
+        struct mtk_gphy *gphy;
+	const __be32 *_id;
+	bool fe_cal;
+	int ret;
+
+        mdio = of_parse_phandle(np, "mediatek,mdio", 0);
+
+        if (!mdio)
+                return -EINVAL;
+
+        mdio_bus = of_mdio_find_bus(mdio);
+
+
+        if (!mdio_bus)
+                return -EPROBE_DEFER;
+
+        gphy = devm_kzalloc(&pdev->dev, sizeof(struct mtk_gphy), GFP_KERNEL);
+
+        if (!gphy)
+                return -ENOMEM;
+
+
+        gphy->dev = &pdev->dev;
+
+        gphy->bus = mdio_bus;
+
+	gphy->infra = syscon_regmap_lookup_by_phandle(pdev->dev.of_node,
+                                                           "mediatek,infracfg");
+	gphy->eth = syscon_regmap_lookup_by_phandle(pdev->dev.of_node,
+                                                           "mediatek,eth");
+	gphy->reset = devm_reset_control_get(&pdev->dev, "mtk_gephy");
+
+	_id = of_get_property(np, "reg", NULL);
+	if (_id)
+		gphy->smi_base = be32_to_cpup(_id);
+
+	_gphy = gphy;
+
+	ret = leopard_set_ephy_base(gphy->smi_base);
+	if (ret)
+		gphy->smi_base = 0;
+
+	fe_cal = of_property_read_bool(pdev->dev.of_node, "mediatek,fe-cal");
+
+	if (IS_ERR(gphy->infra))
+		dev_info(&pdev->dev, "gphy no infra support\n");
+        else {
+		/* enable fe/gphy for calibration */
+		if (fe_cal)
+			regmap_write(gphy->infra, INFRA_PHY, GE_FE_PHY_EN);
+		else
+			regmap_write(gphy->infra, INFRA_PHY,
+				     GE_FE_PHY_EN | GE_FE_PHY_DIS(0x1d));
+        }
+
+	dev_info(&pdev->dev, "esw smi base is 0x%x, esw calibration %s\n",
+		 _gphy->smi_base, fe_cal ? "enabled" : "disabled");
+
+	leopard_ephy_cal(fe_cal);
+
+        platform_set_drvdata(pdev, gphy);
+
+        return 0;
+}
+
+static int gphy_remove(struct platform_device *pdev)
+{
+        platform_set_drvdata(pdev, NULL);      
+
+        return 0;
+}
+
+static struct platform_driver fe_gphy_driver = {
+        .probe = gphy_probe,
+        .remove = gphy_remove,
+        .driver = {
+                .name = "mtk-fe-gphy",
+                .owner = THIS_MODULE,
+                .of_match_table = mtk_gphy_match,
+        },
+};
+
+module_platform_driver(fe_gphy_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Mark Lee <marklee0201@gmail.com>");
+MODULE_DESCRIPTION("mtk internal gphy driver");
+
diff --git a/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/mtk_gphy_cal.c b/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/mtk_gphy_cal.c
new file mode 100644
index 000000000..38a46fb99
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/mtk/gphy/mtk_gphy_cal.c
@@ -0,0 +1,2187 @@
+
+#define u32 unsigned int
+#define u16 unsigned short
+#define u8 unsigned char
+
+
+#define ANACAL_INIT             0x01
+#define ANACAL_ERROR            0xFD
+#define ANACAL_SATURATION       0xFE
+#define ANACAL_FINISH           0xFF
+#define ANACAL_PAIR_A           0
+#define ANACAL_PAIR_B           1
+#define ANACAL_PAIR_C           2
+#define ANACAL_PAIR_D           3
+#define DAC_IN_0V               0x000
+#define DAC_IN_2V               0x0f0
+#define TX_AMP_OFFSET_0MV       0x20
+#define TX_AMP_OFFSET_VALID_BITS        6
+#define FE_CAL_P0                       0
+#define FE_CAL_P1                       1
+#if 1//defined(CONFIG_MACH_LEOPARD)
+#define FE_CAL_COMMON                   1
+#else
+#define FE_CAL_COMMON                   0
+#endif
+
+#define CALDLY 40
+
+static u8 fe_cal_flag;
+static u8 fe_cal_flag_mdix;
+static u8 fe_cal_tx_offset_flag;
+static u8 fe_cal_tx_offset_flag_mdix;
+static u8 fe_cal_r50_flag;
+static u8 fe_cal_vbg_flag;
+static u32 iext_cal_result;
+static u32 r50_p0_cal_result;
+static u8 ge_cal_r50_flag;
+static u8 ge_cal_tx_offset_flag;
+static u8 ge_cal_flag;
+static int show_time =0 ;
+static u8 ephy_addr_base;
+
+/* 50ohm_new*/
+const u8 ZCAL_TO_R50OHM_TBL_100[64] = {
+	127, 121, 116, 115, 111, 109, 108, 104,
+	102, 99, 97, 96, 77, 76, 73, 72,
+	70, 69, 67, 66, 47, 46, 45, 43,
+	42, 41, 40, 38, 37, 36, 35, 34,
+	32, 16, 15, 14, 13, 12, 11, 10,
+	9, 8, 7, 6, 6, 5, 4, 4,
+	3, 2, 2, 1, 1, 0, 0, 0,
+	0, 0, 0, 0, 0, 0, 0, 0
+};
+
+const u8 ZCAL_TO_R50ohm_GE_TBL_100[64] = {
+	63, 63, 63, 63, 63, 63, 63, 63,
+	63, 63, 63, 63, 63, 63, 63, 60,
+	57, 55, 53, 51, 48, 46, 44, 42,
+	40, 38, 37, 36, 34, 32, 30, 28,
+	27, 26, 25, 23, 22, 21, 19, 18,
+	16, 15, 14, 13, 12, 11, 10, 9,
+	8, 7, 6, 5, 4, 4, 3, 2,
+	1, 0, 0, 0, 0, 0, 0, 0
+};
+
+const u8 ZCAL_TO_R50ohm_GE_TBL[64] = {
+	63, 63, 63, 63, 63, 63, 63, 63,
+	63, 63, 63, 63, 63, 63, 63, 60,
+	57, 55, 53, 51, 48, 46, 44, 42,
+	40, 38, 37, 36, 34, 32, 30, 28,
+	27, 26, 25, 23, 22, 21, 19, 18,
+	16, 15, 14, 13, 12, 11, 10, 9,
+	8, 7, 6, 5, 4, 4, 3, 2,
+	1, 0, 0, 0, 0, 0, 0, 0
+};
+
+const u8 ZCAL_TO_REXT_TBL[64] = {
+	0, 0, 0, 0, 0, 0, 0, 0,
+	0, 0, 0, 1, 1, 1, 1, 1,
+	1, 2, 2, 2, 2, 2, 2, 3,
+	3, 3, 3, 3, 3, 4, 4, 4,
+	4, 4, 4, 4, 5, 5, 5, 5,
+	5, 5, 6, 6, 6, 6, 6, 6,
+	7, 7, 7, 7, 7, 7, 7, 7,
+	7, 7, 7, 7, 7, 7, 7, 7
+};
+
+const u8 ZCAL_TO_FILTER_TBL[64] = {
+	0, 0, 0, 0, 0, 0, 0, 0,
+	0, 0, 0, 0, 0, 0, 0, 0,
+	0, 0, 0, 0, 0, 0, 1, 1,
+	1, 2, 2, 2, 3, 3, 3, 4,
+	4, 4, 4, 5, 5, 5, 6, 6,
+	7, 7, 7, 8, 8, 8, 9, 9,
+	9, 10, 10, 10, 11, 11, 11, 11,
+	12, 12, 12, 12, 12, 12, 12, 12
+};
+
+static inline void tc_phy_write_g_reg(u8 port_num, u8 page_num,
+			u8 reg_num, u32 reg_data)
+{
+	u32 r31 = 0;
+
+	r31 |= 0 << 15;	/* global */
+	r31 |= ((page_num & 0x7) << 12);	/* page no */
+	mii_mgr_write(port_num, 31, r31);	/* change Global page */
+	mii_mgr_write(port_num, reg_num, reg_data);
+}
+
+static inline void tc_phy_write_l_reg(u8 port_no, u8 page_no,
+			u8 reg_num, u32 reg_data)
+{
+	u32 r31 = 0;
+
+	r31 |= 1 << 15;	/* local */
+	r31 |= ((page_no & 0x7) << 12);	/* page no */
+	mii_mgr_write(port_no, 31, r31); /* select local page x */
+	mii_mgr_write(port_no, reg_num, reg_data);
+}
+
+static inline u32 tc_phy_read_g_reg(u8 port_num, u8 page_num, u8 reg_num)
+{
+	u32 phy_val;
+
+	u32 r31 = 0;
+
+	r31 |= 0 << 15;	/* global */
+	r31 |= ((page_num & 0x7) << 12);	/* page no */
+	mii_mgr_write(port_num, 31, r31);	/* change Global page */
+	mii_mgr_read(port_num, reg_num, &phy_val);
+	return phy_val;
+}
+
+static inline u32 tc_phy_read_l_reg(u8 port_no, u8 page_no, u8 reg_num)
+{
+	u32 phy_val;
+	u32 r31 = 0;
+
+	r31 |= 1 << 15;	/* local */
+	r31 |= ((page_no & 0x7) << 12);	/* page no */
+	mii_mgr_write(port_no, 31, r31); /* select local page x */
+	mii_mgr_read(port_no, reg_num, &phy_val);
+	return phy_val;
+}
+
+static inline u32 tc_phy_read_dev_reg(u32 port_no, u32 dev_addr, u32 reg_addr)
+{
+	u32 phy_val;
+	//mii_mgr_read_cl45(port_num, dev_addr, reg_addr, &phy_val);
+	mii_mgr_write(port_no, 13, dev_addr );
+	mii_mgr_write(port_no, 14, reg_addr  );
+	mii_mgr_write(port_no, 13, 0x4000 | dev_addr);
+	mii_mgr_read(port_no, 14, &phy_val );
+	
+	return phy_val;
+}
+
+static inline void tc_phy_write_dev_reg(u32 port_no, u32 dev_addr, u32 reg_addr, u32 write_data)
+{
+	//mii_mgr_write_cl45(port_num, dev_addr, reg_addr, write_data);
+	mii_mgr_write(port_no, 13, dev_addr );
+	mii_mgr_write(port_no, 14,reg_addr  );
+	mii_mgr_write(port_no, 13, 0x4000 | dev_addr);
+	mii_mgr_write(port_no, 14, write_data );
+	
+}
+
+static inline u32 tc_mii_read(u32 phy_addr, u32 phy_register)
+{
+	u32 phy_val;
+
+	mii_mgr_read(phy_addr, phy_register, &phy_val);
+	return phy_val;
+}
+
+static inline void tc_mii_write(u32 phy_addr, u32 phy_register, u32 write_data)
+{
+	mii_mgr_write(phy_addr, phy_register, write_data);
+}
+
+static void clear_ckinv_ana_txvos(void)
+{
+	u16 g7r24_tmp;
+	/*clear RG_CAL_CKINV/RG_ANA_CALEN/RG_TXVOS_CALEN*/
+	/*g7r24[13]:0x0, RG_ANA_CALEN_P0*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp & (~0x2000)));
+
+	/*g7r24[14]:0x0, RG_CAL_CKINV_P0*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp & (~0x4000)));
+
+	/*g7r24[12]:0x0, DA_TXVOS_CALEN_P0*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp & (~0x1000)));
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0);
+}
+
+static u8 all_fe_ana_cal_wait_txamp(u32 delay, u8 port_num)
+{				/* for EN7512 FE // allen_20160616 */
+	u8 all_ana_cal_status;
+	u16 cnt, g7r24_temp;
+
+	tc_phy_write_l_reg(FE_CAL_COMMON, 4, 23, (0x0000));
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp & (~0x10));
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp | 0x10);
+
+	cnt = 1000;
+	do {
+		udelay(delay);
+		cnt--;
+		all_ana_cal_status =
+		    ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) >> 1) & 0x1);
+	} while ((all_ana_cal_status == 0) && (cnt != 0));
+
+	tc_phy_write_l_reg(FE_CAL_COMMON, 4, 23, (0x0000));
+	tc_phy_write_l_reg(port_num, 4, 23, (0x0000));
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp & (~0x10));
+	return all_ana_cal_status;
+}
+
+static u8 all_fe_ana_cal_wait(u32 delay, u8 port_num)
+{
+	u8 all_ana_cal_status;
+	u16 cnt, g7r24_temp;
+
+	tc_phy_write_l_reg(FE_CAL_COMMON, 4, 23, (0x0000));
+	tc_phy_write_l_reg(port_num, 4, 23, (0x0000));
+
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp & (~0x10));
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp | 0x10);
+	cnt = 1000;
+	do {
+		udelay(delay);
+		cnt--;
+		all_ana_cal_status =
+		    ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) >> 1) & 0x1);
+
+	} while ((all_ana_cal_status == 0) && (cnt != 0));
+
+	tc_phy_write_l_reg(FE_CAL_COMMON, 4, 23, (0x0000));
+	tc_phy_write_l_reg(port_num, 4, 23, (0x0000));
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp & (~0x10));
+
+	return all_ana_cal_status;
+}
+
+static void fe_cal_tx_amp(u8 port_num, u32 delay)
+{
+	u8 all_ana_cal_status;
+	int ad_cal_comp_out_init;
+	u16 l3r25_temp, l0r26_temp, l2r20_temp;
+	u16 l2r23_temp = 0;
+	int calibration_polarity;
+	u8 tx_amp_reg_shift = 0;
+	int tx_amp_temp = 0, cnt = 0, phyaddr, tx_amp_cnt = 0;
+	u16 tx_amp_final;
+	//struct END_DEVICE *ei_local = netdev_priv(dev_raether);
+
+	phyaddr = port_num + ephy_addr_base;
+	tx_amp_temp = 0x20;
+	/* *** Tx Amp Cal start ********************** */
+
+/*Set device in 100M mode*/
+	tc_phy_write_l_reg(port_num, 0, 0, 0x2100);
+/*TXG output DC differential 1V*/
+	tc_phy_write_g_reg(port_num, 2, 25, 0x10c0);
+
+	tc_phy_write_g_reg(port_num, 1, 26, (0x8000 | DAC_IN_2V));
+	tc_phy_write_g_reg(port_num, 4, 21, (0x0800));	/* set default */
+	tc_phy_write_l_reg(port_num, 0, 30, (0x02c0));
+	tc_phy_write_l_reg(port_num, 4, 21, (0x0000));
+
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, (0xc800));
+	tc_phy_write_l_reg(port_num, 3, 25, (0xc800));
+
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x7000);
+
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	tc_phy_write_l_reg(port_num, 3, 25, (l3r25_temp | 0x400));
+
+	/*decide which port calibration RG_ZCALEN by port_num*/
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	l3r25_temp = l3r25_temp | 0x1000;
+	l3r25_temp = l3r25_temp & ~(0x200);
+	tc_phy_write_l_reg(port_num, 3, 25, l3r25_temp);
+
+	/*DA_PGA_MDIX_STASTUS_P0=0(L0R26[15:14] = 0x01*/
+	l0r26_temp = tc_phy_read_l_reg(port_num, 0, 26);
+	l0r26_temp = l0r26_temp & (~0xc000);
+	tc_phy_write_l_reg(port_num, 0, 26, 0x5203);/* Kant */
+
+	/*RG_RX2TX_EN_P0=0(L2R20[10] =0),*/
+	l2r20_temp = tc_phy_read_l_reg(port_num, 2, 20);
+	l2r20_temp = l2r20_temp & (~0x400);
+	tc_phy_write_l_reg(port_num, 2, 20, l2r20_temp);
+	tc_phy_write_l_reg(port_num, 2, 23, (tx_amp_temp));
+
+	all_ana_cal_status = all_fe_ana_cal_wait_txamp(delay, port_num);
+
+	if (all_ana_cal_status == 0) {
+		all_ana_cal_status = ANACAL_ERROR;
+		pr_info(" FE Tx amp AnaCal ERROR! (init)  \r\n");
+	}
+
+	tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+
+	if (ad_cal_comp_out_init == 1)
+		calibration_polarity = -1;
+	else
+		calibration_polarity = 1;
+
+	tx_amp_temp += calibration_polarity;
+	cnt = 0;
+	tx_amp_cnt = 0;
+	while (all_ana_cal_status < ANACAL_ERROR) {
+		tc_phy_write_l_reg(port_num, 2, 23, (tx_amp_temp));
+		l2r23_temp = tc_phy_read_l_reg(port_num, 2, 23);
+		cnt++;
+		tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+		tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+		all_ana_cal_status = all_fe_ana_cal_wait_txamp(delay, port_num);
+
+		if (((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24)) & 0x1) !=
+		    ad_cal_comp_out_init) {
+			all_ana_cal_status = ANACAL_FINISH;
+			fe_cal_flag = 1;
+		}
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info(" FE Tx amp AnaCal ERROR! (%d)  \r\n", cnt);
+		} else if ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1) !=
+			   ad_cal_comp_out_init) {
+			tx_amp_cnt++;
+			all_ana_cal_status = ANACAL_FINISH;
+			tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+			tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+			ad_cal_comp_out_init =
+			    tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+		} else {
+			if ((l2r23_temp == 0x3f) || (l2r23_temp == 0x00)) {
+				all_ana_cal_status = ANACAL_SATURATION;
+				pr_info
+				    (" Tx amp Cal Saturation(%d)(%x)(%x)\r\n",
+				     cnt, tc_phy_read_l_reg(0, 3, 25),
+				     tc_phy_read_l_reg(1, 3, 25));
+				pr_info
+				    (" Tx amp Cal Saturation(%x)(%x)(%x)\r\n",
+				     tc_phy_read_l_reg(2, 3, 25),
+				     tc_phy_read_l_reg(3, 3, 25),
+				     tc_phy_read_l_reg(0, 2, 30));
+				/* tx_amp_temp += calibration_polarity; */
+			} else {
+				tx_amp_temp += calibration_polarity;
+			}
+		}
+	}
+
+	if ((all_ana_cal_status == ANACAL_ERROR) ||
+	    (all_ana_cal_status == ANACAL_SATURATION)) {
+		l2r23_temp = tc_phy_read_l_reg(port_num, 2, 23);
+		tc_phy_write_l_reg(port_num, 2, 23,
+				   ((tx_amp_temp << tx_amp_reg_shift)));
+		l2r23_temp = tc_phy_read_l_reg(port_num, 2, 23);
+		pr_info("[%d] %s, ANACAL_SATURATION\n", port_num, __func__);
+	} else {
+#if 0	
+		if (ei_local->chip_name == MT7622_FE) {
+			if (port_num == 0)
+				l2r23_temp = l2r23_temp + 10;
+			else if (port_num == 1)
+				l2r23_temp = l2r23_temp + 11;
+			else if (port_num == 2)
+				l2r23_temp = l2r23_temp + 10;
+			else if (port_num == 3)
+				l2r23_temp = l2r23_temp + 9;
+			else if (port_num == 4)
+				l2r23_temp = l2r23_temp + 10;
+		} else if (ei_local->chip_name == LEOPARD_FE) {
+#endif		
+			if (port_num == 1)
+				l2r23_temp = l2r23_temp + 3;
+			else if (port_num == 2)
+				l2r23_temp = l2r23_temp + 3;
+			else if (port_num == 3)
+				l2r23_temp = l2r23_temp + 3 - 2;
+			else if (port_num == 4)
+				l2r23_temp = l2r23_temp + 2 - 1 + 2;
+		//}
+
+		tc_phy_write_l_reg(port_num, 2, 23, ((l2r23_temp) << tx_amp_reg_shift));
+		fe_cal_flag = 1;
+	}
+
+	tx_amp_final = tc_phy_read_l_reg(port_num, 2, 23) & 0x3f;
+	tc_phy_write_l_reg(port_num, 2, 24, ((tx_amp_final + 15)  << 8) | 0x20);
+
+	//if (ei_local->chip_name == LEOPARD_FE) {
+		if (port_num == 1)
+			tc_phy_write_l_reg(port_num, 2, 24, ((tx_amp_final + 15 - 4)  << 8) | 0x20);
+		else if (port_num == 2)
+			tc_phy_write_l_reg(port_num, 2, 24, ((tx_amp_final + 15 + 2)  << 8) | 0x20);
+		else if (port_num == 3)
+			tc_phy_write_l_reg(port_num, 2, 24, ((tx_amp_final + 15 + 4)  << 8) | 0x20);
+		else if (port_num == 4)
+			tc_phy_write_l_reg(port_num, 2, 24, ((tx_amp_final + 15 + 4)  << 8) | 0x20);
+	//}
+
+	pr_info("[%d] - tx_amp_final = 0x%x\n", port_num, tx_amp_final);
+
+	/*clear RG_CAL_CKINV/RG_ANA_CALEN/RG_TXVOS_CALEN*/
+	clear_ckinv_ana_txvos();
+
+	tc_phy_write_l_reg(port_num, 3, 25, 0x0000);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, 0x0000);
+	tc_phy_write_g_reg(port_num, 1, 26, 0);
+	/* *** Tx Amp Cal end *** */
+}
+
+static void fe_cal_tx_amp_mdix(u8 port_num, u32 delay)
+{
+	u8 all_ana_cal_status;
+	int ad_cal_comp_out_init;
+	u16 l3r25_temp, l4r26_temp, l0r26_temp;
+	u16 l2r20_temp, l4r26_temp_amp;
+	int calibration_polarity;
+	int tx_amp_temp = 0, cnt = 0, phyaddr, tx_amp_cnt = 0;
+	u16 tx_amp_mdix_final;
+	//struct END_DEVICE *ei_local = netdev_priv(dev_raether);
+
+	phyaddr = port_num + ephy_addr_base;
+	tx_amp_temp = 0x20;
+/*Set device in 100M mode*/
+	tc_phy_write_l_reg(port_num, 0, 0, 0x2100);
+/*TXG output DC differential 0V*/
+	tc_phy_write_g_reg(port_num, 2, 25, 0x10c0);
+
+	tc_phy_write_g_reg(port_num, 1, 26, (0x8000 | DAC_IN_2V));
+	tc_phy_write_g_reg(port_num, 4, 21, (0x0800));	/* set default */
+	tc_phy_write_l_reg(port_num, 0, 30, (0x02c0));/*0x3f80  // l0r30[9], [7], [6], [1]*/
+	tc_phy_write_l_reg(port_num, 4, 21, (0x0000));
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, (0xc800));
+	tc_phy_write_l_reg(port_num, 3, 25, (0xc800));	/* 0xca00 */
+	/* *** Tx Amp Cal start ********************** */
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x7000);
+	/* pr_info(" g7r24[%d] = %x\n", port_num, tc_phy_read_g_reg(port_num, 7, 24)); */
+
+	/*RG_TXG_CALEN =1 l3r25[10]by port number*/
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	tc_phy_write_l_reg(port_num, 3, 25, (l3r25_temp | 0x400));
+	/*decide which port calibration RG_ZCALEN l3r25[12] by port_num*/
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	l3r25_temp = l3r25_temp | 0x1000;
+	l3r25_temp = l3r25_temp & ~(0x200);
+	tc_phy_write_l_reg(port_num, 3, 25, l3r25_temp);
+
+	/*DA_PGA_MDIX_STASTUS_P0=0(L0R26[15:14] = 0x10) & RG_RX2TX_EN_P0=0(L2R20[10] =1),*/
+	l0r26_temp = tc_phy_read_l_reg(port_num, 0, 26);
+	l0r26_temp = l0r26_temp & (~0xc000);
+	tc_phy_write_l_reg(port_num, 0, 26, 0x9203); /* Kant */
+	l2r20_temp = tc_phy_read_l_reg(port_num, 2, 20);
+	l2r20_temp = l2r20_temp | 0x400;
+	tc_phy_write_l_reg(port_num, 2, 20, l2r20_temp);
+
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	tc_phy_write_l_reg(port_num, 3, 25, (l3r25_temp | 0x0400));
+/*DA_TX_I2MPB_MDIX L4R26[5:0]*/
+	l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+	/* pr_info("111l4r26 =%x\n", tc_phy_read_l_reg(port_num, 4, 26)); */
+	l4r26_temp = l4r26_temp & (~0x3f);
+	tc_phy_write_l_reg(port_num, 4, 26, (l4r26_temp | tx_amp_temp));
+	/* pr_info("222l4r26 =%x\n", tc_phy_read_l_reg(port_num, 4, 26)); */
+	all_ana_cal_status = all_fe_ana_cal_wait_txamp(delay, port_num);
+
+	if (all_ana_cal_status == 0) {
+		all_ana_cal_status = ANACAL_ERROR;
+		pr_info(" FE Tx amp mdix AnaCal ERROR! (init)  \r\n");
+	}
+
+	tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	/*ad_cal_comp_out_init = (tc_phy_read_l_reg(FE_CAL_COMMON, 4, 23) >> 4) & 0x1;*/
+	ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+	/* pr_info("mdix ad_cal_comp_out_init = %d\n", ad_cal_comp_out_init); */
+	if (ad_cal_comp_out_init == 1) {
+		calibration_polarity = -1;
+		/* tx_amp_temp = 0x10; */
+	} else {
+		calibration_polarity = 1;
+	}
+	tx_amp_temp += calibration_polarity;
+	cnt = 0;
+	tx_amp_cnt = 0;
+	while (all_ana_cal_status < ANACAL_ERROR) {
+		l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+		l4r26_temp = l4r26_temp & (~0x3f);
+		tc_phy_write_l_reg(port_num, 4, 26, (l4r26_temp | tx_amp_temp));
+		l4r26_temp = (tc_phy_read_l_reg(port_num, 4, 26));
+		l4r26_temp_amp = (tc_phy_read_l_reg(port_num, 4, 26)) & 0x3f;
+		cnt++;
+
+		tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+		tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+		all_ana_cal_status = all_fe_ana_cal_wait_txamp(delay, port_num);
+
+		if (((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24)) & 0x1) !=
+		    ad_cal_comp_out_init) {
+			all_ana_cal_status = ANACAL_FINISH;
+			fe_cal_flag_mdix = 1;
+		}
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info(" FE Tx amp mdix AnaCal ERROR! (%d)  \r\n", cnt);
+		} else if (((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24)) & 0x1) !=
+			   ad_cal_comp_out_init) {
+			all_ana_cal_status = ANACAL_FINISH;
+			tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+			tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+			ad_cal_comp_out_init =
+			    (tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24)) & 0x1;
+		} else {
+			if ((l4r26_temp_amp == 0x3f) || (l4r26_temp_amp == 0x00)) {
+				all_ana_cal_status = ANACAL_SATURATION;
+				pr_info
+				    (" Tx amp Cal mdix Saturation(%d)(%x)(%x)\r\n",
+				     cnt, tc_phy_read_l_reg(0, 3, 25),
+				     tc_phy_read_l_reg(1, 3, 25));
+				pr_info
+				    (" Tx amp Cal mdix Saturation(%x)(%x)(%x)\r\n",
+				     tc_phy_read_l_reg(2, 3, 25),
+				     tc_phy_read_l_reg(3, 3, 25),
+				     tc_phy_read_l_reg(0, 2, 30));
+				/* tx_amp_temp += calibration_polarity; */
+			} else {
+				tx_amp_temp += calibration_polarity;
+			}
+		}
+	}
+
+	if ((all_ana_cal_status == ANACAL_ERROR) ||
+	    (all_ana_cal_status == ANACAL_SATURATION)) {
+		l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+		pr_info(" FE-%d Tx amp AnaCal mdix Saturation! (%d)(l4r26=0x%x)  \r\n",
+			phyaddr, cnt, l4r26_temp);
+		tc_phy_write_l_reg(port_num, 4, 26,
+				   ((l4r26_temp & (~0x3f)) | tx_amp_temp));
+		l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+		pr_info(" FE-%d Tx amp AnaCal mdix Saturation! (%d)(l4r26=0x%x)  \r\n",
+			phyaddr, cnt, l4r26_temp);
+		pr_info("[%d] %s, ANACAL_SATURATION\n", port_num, __func__);
+	} else {
+	#if 0
+		if (ei_local->chip_name == MT7622_FE) {
+			if (port_num == 0) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 10;
+			} else if (port_num == 1) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 11;
+			} else if (port_num == 2) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 9;
+			} else if (port_num == 3) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 9;
+			} else if (port_num == 4) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 9;
+			}
+		} else if (ei_local->chip_name == LEOPARD_FE) {
+	#endif	
+			if (port_num == 1) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 4 - 2;
+			} else if (port_num == 2) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 3 - 1;
+			} else if (port_num == 3) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 4 - 3;
+			} else if (port_num == 4) {
+				l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+				l4r26_temp = l4r26_temp + 4 - 2 + 1;
+			}
+		//}
+		tc_phy_write_l_reg(port_num, 4, 26, l4r26_temp);
+		fe_cal_flag_mdix = 1;
+	}
+
+	tx_amp_mdix_final = tc_phy_read_l_reg(port_num, 4, 26) & 0x3f;
+	tc_phy_write_l_reg(port_num, 4, 27, ((tx_amp_mdix_final + 15) << 8) | 0x20);
+	//if (ei_local->chip_name == LEOPARD_FE) {
+		if (port_num == 2)
+			tc_phy_write_l_reg(port_num, 4, 27,
+					   ((tx_amp_mdix_final + 15 + 1)  << 8) | 0x20);
+		else if (port_num == 3)
+			tc_phy_write_l_reg(port_num, 4, 27,
+					   ((tx_amp_mdix_final + 15 + 4)  << 8) | 0x20);
+		else if (port_num == 4)
+			tc_phy_write_l_reg(port_num, 4, 27,
+					   ((tx_amp_mdix_final + 15 + 4)  << 8) | 0x20);
+	//}
+	pr_info("[%d] - tx_amp_mdix_final = 0x%x\n", port_num, tx_amp_mdix_final);
+
+	clear_ckinv_ana_txvos();
+	tc_phy_write_l_reg(port_num, 3, 25, 0x0000);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, 0x0000);
+	tc_phy_write_g_reg(port_num, 1, 26, 0);
+	/* *** Tx Amp Cal end *** */
+}
+
+static void fe_cal_tx_offset(u8 port_num, u32 delay)
+{
+	u8 all_ana_cal_status;
+	int ad_cal_comp_out_init;
+	u16 l3r25_temp, l2r20_temp;
+	u16 g4r21_temp, l0r30_temp, l4r17_temp, l0r26_temp;
+	int calibration_polarity, tx_offset_temp;
+	int cal_temp = 0;
+	u8 tx_offset_reg_shift;
+	u8 cnt = 0, phyaddr, tx_amp_cnt = 0;
+	u16 tx_offset_final;
+
+	phyaddr = port_num + ephy_addr_base;
+/*Set device in 100M mode*/
+	tc_phy_write_l_reg(port_num, 0, 0, 0x2100);
+
+	/*// g4r21[11]:Hw bypass tx offset cal, Fw cal*/
+	g4r21_temp = tc_phy_read_g_reg(port_num, 4, 21);
+	tc_phy_write_g_reg(port_num, 4, 21, (g4r21_temp | 0x0800));
+
+	/*l0r30[9], [7], [6], [1]*/
+	l0r30_temp = tc_phy_read_l_reg(port_num, 0, 30);
+	tc_phy_write_l_reg(port_num, 0, 30, (l0r30_temp | 0x02c0));
+
+	/* tx_offset_temp = TX_AMP_OFFSET_0MV; */
+	tx_offset_temp = 0x20;
+	tx_offset_reg_shift = 8;
+	tc_phy_write_g_reg(port_num, 1, 26, (0x8000 | DAC_IN_0V));
+
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x3000);
+	/* pr_info(" g7r24[%d] = %x\n", port_num, tc_phy_read_g_reg(port_num, 7, 24)); */
+	/*RG_TXG_CALEN =1 by port number*/
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	tc_phy_write_l_reg(port_num, 3, 25, (l3r25_temp | 0x400));
+	/*decide which port calibration RG_ZCALEN by port_num*/
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	tc_phy_write_l_reg(port_num, 3, 25, (l3r25_temp | 0x1000));
+
+	/*DA_PGA_MDIX_STASTUS_P0=0(L0R26[15:14] = 0x01) & RG_RX2TX_EN_P0=0(L2R20[10] =0),*/
+	l0r26_temp = tc_phy_read_l_reg(port_num, 0, 26);
+	l0r26_temp = l0r26_temp & (~0xc000);
+	/* tc_phy_write_l_reg(port_num, 0, 26, (l0r26_temp | 0x4000)); */
+	tc_phy_write_l_reg(port_num, 0, 26, 0x5203);/* Kant */
+	/* pr_info("l0r26[%d] = %x\n", port_num, tc_phy_read_l_reg(port_num, 0, 26)); */
+	l2r20_temp = tc_phy_read_l_reg(port_num, 2, 20);
+	l2r20_temp = l2r20_temp & (~0x400);
+	tc_phy_write_l_reg(port_num, 2, 20, l2r20_temp);
+	/* pr_info("l2r20[%d] = %x\n", port_num, tc_phy_read_l_reg(port_num, 2, 20)); */
+
+	tc_phy_write_l_reg(port_num, 4, 17, (0x0000));
+	l4r17_temp = tc_phy_read_l_reg(port_num, 4, 17);
+	tc_phy_write_l_reg(port_num, 4, 17,
+			   l4r17_temp |
+			   (tx_offset_temp << tx_offset_reg_shift));
+/*wat AD_CAL_CLK = 1*/
+	all_ana_cal_status = all_fe_ana_cal_wait(delay, port_num);
+	if (all_ana_cal_status == 0) {
+		all_ana_cal_status = ANACAL_ERROR;
+		pr_info(" FE Tx offset AnaCal ERROR! (init)  \r\n");
+	}
+
+	tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+/*GET AD_CAL_COMP_OUT g724[0]*/
+	/*ad_cal_comp_out_init = (tc_phy_read_l_reg(FE_CAL_COMMON, 4, 23) >> 4) & 0x1;*/
+	ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+
+	if (ad_cal_comp_out_init == 1)
+		calibration_polarity = -1;
+	else
+		calibration_polarity = 1;
+	cnt = 0;
+	tx_amp_cnt = 0;
+	tx_offset_temp += calibration_polarity;
+
+	while ((all_ana_cal_status < ANACAL_ERROR) && (cnt < 254)) {
+		cnt++;
+		cal_temp = tx_offset_temp;
+		tc_phy_write_l_reg(port_num, 4, 17,
+				   (cal_temp << tx_offset_reg_shift));
+
+		tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+		tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+		all_ana_cal_status = all_fe_ana_cal_wait(delay, port_num);
+
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info(" FE Tx offset AnaCal ERROR! (%d)  \r\n", cnt);
+		} else if ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1) !=
+			   ad_cal_comp_out_init) {
+			all_ana_cal_status = ANACAL_FINISH;
+			tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+			tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+
+			ad_cal_comp_out_init =
+			    tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+		} else {
+			l4r17_temp = tc_phy_read_l_reg(port_num, 4, 17);
+
+			if ((tx_offset_temp == 0x3f) || (tx_offset_temp == 0x00)) {
+				all_ana_cal_status = ANACAL_SATURATION;
+				pr_info("tx offset ANACAL_SATURATION\n");
+			} else {
+				tx_offset_temp += calibration_polarity;
+			}
+		}
+	}
+
+	if ((all_ana_cal_status == ANACAL_ERROR) ||
+	    (all_ana_cal_status == ANACAL_SATURATION)) {
+		tx_offset_temp = TX_AMP_OFFSET_0MV;
+		l4r17_temp = tc_phy_read_l_reg(port_num, 4, 17);
+		tc_phy_write_l_reg(port_num, 4, 17,
+				   (l4r17_temp |
+				    (tx_offset_temp << tx_offset_reg_shift)));
+		pr_info("[%d] %s, ANACAL_SATURATION\n", port_num, __func__);
+	} else {
+		fe_cal_tx_offset_flag = 1;
+	}
+	tx_offset_final = (tc_phy_read_l_reg(port_num, 4, 17) & 0x3f00) >> 8;
+	pr_info("[%d] - tx_offset_final = 0x%x\n", port_num, tx_offset_final);
+
+	clear_ckinv_ana_txvos();
+	tc_phy_write_l_reg(port_num, 3, 25, 0x0000);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, 0x0000);
+	tc_phy_write_g_reg(port_num, 1, 26, 0);
+}
+
+static void fe_cal_tx_offset_mdix(u8 port_num, u32 delay)
+{				/* for MT7622 */
+	u8 all_ana_cal_status;
+	int ad_cal_comp_out_init;
+	u16 l3r25_temp, l2r20_temp, l4r26_temp;
+	u16 g4r21_temp, l0r30_temp, l0r26_temp;
+	int calibration_polarity, tx_offset_temp;
+	int cal_temp = 0;
+	u8 tx_offset_reg_shift;
+	u8 cnt = 0, phyaddr;
+	u16 tx_offset_final_mdix;
+
+	phyaddr = port_num + ephy_addr_base;
+/*Set device in 100M mode*/
+	tc_phy_write_l_reg(port_num, 0, 0, 0x2100);
+
+	/*// g4r21[11]:Hw bypass tx offset cal, Fw cal*/
+	g4r21_temp = tc_phy_read_g_reg(port_num, 4, 21);
+	tc_phy_write_g_reg(port_num, 4, 21, (g4r21_temp | 0x0800));
+
+	/*l0r30[9], [7], [6], [1]*/
+	l0r30_temp = tc_phy_read_l_reg(port_num, 0, 30);
+	tc_phy_write_l_reg(port_num, 0, 30, (l0r30_temp | 0x02c0));
+
+	tx_offset_temp = 0x20;
+	tx_offset_reg_shift = 8;
+	tc_phy_write_g_reg(port_num, 1, 26, (0x8000 | DAC_IN_0V));
+
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x3000);
+
+	/*RG_TXG_CALEN =1 by port number*/
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	tc_phy_write_l_reg(port_num, 3, 25, (l3r25_temp | 0x400));
+
+	/*decide which port calibration RG_ZCALEN by port_num*/
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	tc_phy_write_l_reg(port_num, 3, 25, (l3r25_temp | 0x1000));
+
+	/*DA_PGA_MDIX_STASTUS_P0=0(L0R26[15:14] = 0x10) & RG_RX2TX_EN_P0=1(L2R20[10] =1),*/
+	l0r26_temp = tc_phy_read_l_reg(port_num, 0, 26);
+	l0r26_temp = l0r26_temp & (~0xc000);
+	tc_phy_write_l_reg(port_num, 0, 26, 0x9203); /* Kant */
+	l2r20_temp = tc_phy_read_l_reg(port_num, 2, 20);
+	l2r20_temp = l2r20_temp | 0x400;
+	tc_phy_write_l_reg(port_num, 2, 20, l2r20_temp);
+
+	l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+	tc_phy_write_l_reg(port_num, 4, 26, l4r26_temp & (~0x3f00));
+	tc_phy_write_l_reg(port_num, 4, 26,
+			   (l4r26_temp & ~0x3f00) | (cal_temp << tx_offset_reg_shift));
+
+	all_ana_cal_status = all_fe_ana_cal_wait(delay, port_num);
+	if (all_ana_cal_status == 0) {
+		all_ana_cal_status = ANACAL_ERROR;
+		pr_info(" FE Tx offset mdix AnaCal ERROR! (init)  \r\n");
+	}
+
+	tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+
+	ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+
+	if (ad_cal_comp_out_init == 1)
+		calibration_polarity = -1;
+	else
+		calibration_polarity = 1;
+
+	cnt = 0;
+	tx_offset_temp += calibration_polarity;
+	while ((all_ana_cal_status < ANACAL_ERROR) && (cnt < 254)) {
+		cnt++;
+		cal_temp = tx_offset_temp;
+		l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+		tc_phy_write_l_reg(port_num, 4, 26,
+				   (l4r26_temp & ~0x3f00) | (cal_temp << tx_offset_reg_shift));
+
+		tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+		tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+		all_ana_cal_status = all_fe_ana_cal_wait(delay, port_num);
+
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info(" FE Tx offset mdix AnaCal ERROR! (%d)  \r\n", cnt);
+		} else if ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1) !=
+			   ad_cal_comp_out_init) {
+			all_ana_cal_status = ANACAL_FINISH;
+			tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+			tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+			ad_cal_comp_out_init =
+			    tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+		} else {
+			l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+
+			if ((tx_offset_temp == 0x3f) || (tx_offset_temp == 0x00)) {
+				all_ana_cal_status = ANACAL_SATURATION;
+				pr_info("tx offset ANACAL_SATURATION\n");
+			} else {
+				tx_offset_temp += calibration_polarity;
+			}
+		}
+	}
+
+	if ((all_ana_cal_status == ANACAL_ERROR) ||
+	    (all_ana_cal_status == ANACAL_SATURATION)) {
+		tx_offset_temp = TX_AMP_OFFSET_0MV;
+		l4r26_temp = tc_phy_read_l_reg(port_num, 4, 26);
+		tc_phy_write_l_reg(port_num, 4, 26,
+				   (l4r26_temp & (~0x3f00)) | (cal_temp << tx_offset_reg_shift));
+		pr_info("[%d] %s, ANACAL_SATURATION\n", port_num, __func__);
+	} else {
+		fe_cal_tx_offset_flag_mdix = 1;
+	}
+	tx_offset_final_mdix = (tc_phy_read_l_reg(port_num, 4, 26) & 0x3f00) >> 8;
+	pr_info("[%d] - tx_offset_final_mdix = 0x%x\n", port_num, tx_offset_final_mdix);
+
+	clear_ckinv_ana_txvos();
+	tc_phy_write_l_reg(port_num, 3, 25, 0x0000);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, 0x0000);
+	tc_phy_write_g_reg(port_num, 1, 26, 0);
+}
+
+static void set_r50_leopard(u8 port_num, u32 r50_cal_result)
+{
+	int rg_zcal_ctrl_tx, rg_zcal_ctrl_rx;
+	u16 l4r22_temp;
+
+	rg_zcal_ctrl_rx = 0;
+	rg_zcal_ctrl_tx = 0;
+	pr_info("r50_cal_result  = 0x%x\n", r50_cal_result);
+	if (port_num == 0) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)];
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)];
+	}
+	if (port_num == 1) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)] + 4;
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)] + 4;
+	}
+	if (port_num == 2) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)] + 4;
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)] + 6;
+	}
+	if (port_num == 3) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)] + 5;
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)] + 6;
+	}
+	if (port_num == 4) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)] + 4;
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result)] + 4;
+	}
+	if (rg_zcal_ctrl_tx > 0x7f)
+		rg_zcal_ctrl_tx = 0x7f;
+	if (rg_zcal_ctrl_rx > 0x7f)
+		rg_zcal_ctrl_rx = 0x7f;
+/*R50OHM_RSEL_TX= LP4R22[14:8]*/
+	tc_phy_write_l_reg(port_num, 4, 22, ((rg_zcal_ctrl_tx << 8)));
+	l4r22_temp = tc_phy_read_l_reg(port_num, 4, 22);
+/*R50OHM_RSEL_RX= LP4R22[6:0]*/
+	tc_phy_write_l_reg(port_num, 4, 22,
+			   (l4r22_temp | (rg_zcal_ctrl_rx << 0)));
+	fe_cal_r50_flag = 1;
+	pr_info("[%d] - r50 final result l4r22[%d] = %x\n", port_num,
+		port_num, tc_phy_read_l_reg(port_num, 4, 22));
+}
+#if 0
+static void set_r50_mt7622(u8 port_num, u32 r50_cal_result)
+{
+	int rg_zcal_ctrl_tx, rg_zcal_ctrl_rx;
+	u16 l4r22_temp;
+
+	rg_zcal_ctrl_rx = 0;
+	rg_zcal_ctrl_tx = 0;
+	pr_info("r50_cal_result  = 0x%x\n", r50_cal_result);
+
+	if (port_num == 0) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 5)];
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 5)];
+	}
+	if (port_num == 1) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 3)];
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 3)];
+	}
+	if (port_num == 2) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 4)];
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 5)];
+	}
+	if (port_num == 3) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 4)];
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 3)];
+	}
+	if (port_num == 4) {
+		rg_zcal_ctrl_tx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 4)];
+		rg_zcal_ctrl_rx = ZCAL_TO_R50OHM_TBL_100[(r50_cal_result - 5)];
+	}
+/*R50OHM_RSEL_TX= LP4R22[14:8]*/
+	tc_phy_write_l_reg(port_num, 4, 22, ((rg_zcal_ctrl_tx << 8)));
+	l4r22_temp = tc_phy_read_l_reg(port_num, 4, 22);
+/*R50OHM_RSEL_RX= LP4R22[6:0]*/
+	tc_phy_write_l_reg(port_num, 4, 22,
+			   (l4r22_temp | (rg_zcal_ctrl_rx << 0)));
+	fe_cal_r50_flag = 1;
+	pr_info("[%d] - r50 final result l4r22[%d] = %x\n", port_num,
+		port_num, tc_phy_read_l_reg(port_num, 4, 22));
+}
+#endif
+static void fe_ge_r50_common(u8 port_num)
+{
+	u16 l3r25_temp, g7r24_tmp, l4r23_temp;
+	u8 phyaddr;
+
+	phyaddr = port_num;
+	tc_phy_write_l_reg(port_num, 0, 0, 0x2100);
+	/*g2r25[7:5]:0x110, BG voltage output*/
+	tc_phy_write_g_reg(FE_CAL_COMMON, 2, 25, 0xf0c0);
+
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x0000);
+	/*g7r24[13]:0x01, RG_ANA_CALEN_P0=1*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp | 0x2000));
+	/*g7r24[14]:0x01, RG_CAL_CKINV_P0=1*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp | 0x4000));
+
+	/*g7r24[12]:0x01, DA_TXVOS_CALEN_P0=0*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp & (~0x1000)));
+
+	/*DA_R50OHM_CAL_EN l4r23[0] = 0*/
+	l4r23_temp = tc_phy_read_l_reg(port_num, 4, 23);
+	l4r23_temp = l4r23_temp & ~(0x01);
+	tc_phy_write_l_reg(port_num, 4, 23, l4r23_temp);
+
+	/*RG_REXT_CALEN l2r25[13] = 0*/
+	l3r25_temp = tc_phy_read_l_reg(FE_CAL_COMMON, 3, 25);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, (l3r25_temp & (~0x2000)));
+}
+
+static void fe_cal_r50(u8 port_num, u32 delay)
+{
+	int rg_zcal_ctrl, all_ana_cal_status, rg_zcal_ctrl_tx, rg_zcal_ctrl_rx;
+	int ad_cal_comp_out_init;
+	u16 l3r25_temp, l0r4, g7r24_tmp, l4r23_temp;
+	int calibration_polarity;
+	u8 cnt = 0, phyaddr;
+	//struct END_DEVICE *ei_local = netdev_priv(dev_raether);
+
+	phyaddr = port_num + ephy_addr_base;
+	tc_phy_write_l_reg(port_num, 0, 0, 0x2100);
+	/*g2r25[7:5]:0x110, BG voltage output*/
+	tc_phy_write_g_reg(FE_CAL_COMMON, 2, 25, 0xf0c0);
+
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x0000);
+	/*g7r24[13]:0x01, RG_ANA_CALEN_P0=1*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp | 0x2000));
+	/*g7r24[14]:0x01, RG_CAL_CKINV_P0=1*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp | 0x4000));
+
+	/*g7r24[12]:0x01, DA_TXVOS_CALEN_P0=0*/
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp & (~0x1000)));
+
+	/* pr_info("g7r24 = %x\n", g7r24_tmp); */
+
+	/*DA_R50OHM_CAL_EN l4r23[0] = 1*/
+	l4r23_temp = tc_phy_read_l_reg(port_num, 4, 23);
+	tc_phy_write_l_reg(port_num, 4, 23, (l4r23_temp | (0x01)));
+
+	/*RG_REXT_CALEN l2r25[13] = 0*/
+	l3r25_temp = tc_phy_read_l_reg(FE_CAL_COMMON, 3, 25);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, (l3r25_temp & (~0x2000)));
+
+	/*decide which port calibration RG_ZCALEN by port_num*/
+	l3r25_temp = tc_phy_read_l_reg(port_num, 3, 25);
+	tc_phy_write_l_reg(port_num, 3, 25, (l3r25_temp | 0x1000));
+
+	rg_zcal_ctrl = 0x20;	/* start with 0 dB */
+	g7r24_tmp = (tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & (~0xfc0));
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_tmp | ((rg_zcal_ctrl & 0x3f) << 6));
+
+	/*wait AD_CAL_COMP_OUT = 1*/
+	all_ana_cal_status = all_fe_ana_cal_wait(delay, port_num);
+	if (all_ana_cal_status == 0) {
+		all_ana_cal_status = ANACAL_ERROR;
+		pr_info(" FE R50 AnaCal ERROR! (init)   \r\n");
+	}
+
+	ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+
+	if (ad_cal_comp_out_init == 1)
+		calibration_polarity = -1;
+	else
+		calibration_polarity = 1;
+
+	cnt = 0;
+	while ((all_ana_cal_status < ANACAL_ERROR) && (cnt < 254)) {
+		cnt++;
+
+		rg_zcal_ctrl += calibration_polarity;
+		g7r24_tmp = (tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & (~0xfc0));
+		tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_tmp | ((rg_zcal_ctrl & 0x3f) << 6));
+		all_ana_cal_status = all_fe_ana_cal_wait(delay, port_num);
+
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info(" FE R50 AnaCal ERROR! (%d)  \r\n", cnt);
+		} else if ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1) !=
+			ad_cal_comp_out_init) {
+			all_ana_cal_status = ANACAL_FINISH;
+		} else {
+			if ((rg_zcal_ctrl == 0x3F) || (rg_zcal_ctrl == 0x00)) {
+				all_ana_cal_status = ANACAL_SATURATION;
+				pr_info(" FE R50 AnaCal Saturation! (%d)  \r\n",
+					cnt);
+			} else {
+				l0r4 = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+				l0r4 = l0r4 & 0x1;
+			}
+		}
+	}
+	if (port_num == 0)
+		r50_p0_cal_result = rg_zcal_ctrl;
+
+	if ((all_ana_cal_status == ANACAL_ERROR) ||
+	    (all_ana_cal_status == ANACAL_SATURATION)) {
+		rg_zcal_ctrl = 0x20;	/* 0 dB */
+		rg_zcal_ctrl_tx = 0x7f;
+		rg_zcal_ctrl_rx = 0x7f;
+		pr_info("[%d] %s, ANACAL_SATURATION\n", port_num, __func__);
+	} else {
+		fe_cal_r50_flag = 1;
+	}
+	//if (ei_local->chip_name == MT7622_FE)
+		//set_r50_mt7622(port_num, rg_zcal_ctrl);
+    //	else if (ei_local->chip_name == LEOPARD_FE)
+		set_r50_leopard(port_num, rg_zcal_ctrl);
+
+	clear_ckinv_ana_txvos();
+	tc_phy_write_l_reg(port_num, 3, 25, 0x0000);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, 0x0000);
+}
+
+static void fe_cal_vbg(u8 port_num, u32 delay)
+{
+	int rg_zcal_ctrl, all_ana_cal_status;
+	int ad_cal_comp_out_init, port_no;
+	u16 l3r25_temp, l0r4, g7r24_tmp, l3r26_temp;
+	int calibration_polarity;
+	//struct END_DEVICE *ei_local = netdev_priv(dev_raether);
+	u16 g2r22_temp, rg_bg_rasel;
+	u8 cnt = 0, phyaddr;
+
+	ephy_addr_base = 0;
+	phyaddr = port_num + ephy_addr_base;
+
+	tc_phy_write_g_reg(FE_CAL_COMMON, 2, 25, 0x30c0);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 0, 25, 0x0030);
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp | 0x2000));
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp | 0x4000));
+
+	g7r24_tmp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, (g7r24_tmp & (~0x1000)));
+
+	l3r25_temp = tc_phy_read_l_reg(FE_CAL_COMMON, 3, 25);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, (l3r25_temp | 0x2000));
+
+	for (port_no = port_num; port_no < 5; port_no++) {
+		l3r25_temp = tc_phy_read_l_reg(port_no, 3, 25);
+		tc_phy_write_l_reg(port_no, 3, 25, (l3r25_temp & (~0x1000)));
+	}
+	rg_zcal_ctrl = 0x0;	/* start with 0 dB */
+
+	g7r24_tmp = (tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & (~0xfc0));
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_tmp | ((rg_zcal_ctrl & 0x3f) << 6));
+
+	all_ana_cal_status = all_fe_ana_cal_wait(delay, port_num);
+	if (all_ana_cal_status == 0) {
+		all_ana_cal_status = ANACAL_ERROR;
+		pr_info(" fe_cal_vbg ERROR! (init)   \r\n");
+	}
+	ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+
+	if (ad_cal_comp_out_init == 1)
+		calibration_polarity = -1;
+	else
+		calibration_polarity = 1;
+
+	cnt = 0;
+	while ((all_ana_cal_status < ANACAL_ERROR) && (cnt < 254)) {
+		cnt++;
+		rg_zcal_ctrl += calibration_polarity;
+		g7r24_tmp = (tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & (~0xfc0));
+		tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_tmp | ((rg_zcal_ctrl & 0x3f) << 6));
+		all_ana_cal_status = all_fe_ana_cal_wait(delay, port_num);
+
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info("VBG ERROR(%d)status=%d\n", cnt, all_ana_cal_status);
+		} else if ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1) !=
+			ad_cal_comp_out_init) {
+			all_ana_cal_status = ANACAL_FINISH;
+		} else {
+			if ((rg_zcal_ctrl == 0x3F) || (rg_zcal_ctrl == 0x00)) {
+				all_ana_cal_status = ANACAL_SATURATION;
+				pr_info(" VBG0 AnaCal Saturation! (%d)  \r\n",
+					cnt);
+			} else {
+				l0r4 = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+				l0r4 = l0r4 & 0x1;
+			}
+		}
+	}
+	if ((all_ana_cal_status == ANACAL_ERROR) ||
+	    (all_ana_cal_status == ANACAL_SATURATION)) {
+		rg_zcal_ctrl = 0x20;	/* 0 dB */
+	} else {
+		fe_cal_vbg_flag = 1;
+	}
+
+	rg_zcal_ctrl = (tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & (0xfc0)) >> 6;
+	iext_cal_result = rg_zcal_ctrl;
+	pr_info("iext_cal_result = 0x%x\n", iext_cal_result);
+	//if (ei_local->chip_name == LEOPARD_FE)
+		rg_bg_rasel =  ZCAL_TO_REXT_TBL[rg_zcal_ctrl];
+
+	l3r26_temp = tc_phy_read_l_reg(FE_CAL_COMMON, 3, 26);
+	l3r26_temp = l3r26_temp & (~0xfc0);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 26, l3r26_temp | ((rg_zcal_ctrl & 0x3f) << 6));
+
+	g2r22_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 2, 22);
+	g2r22_temp = g2r22_temp & (~0xe00);/*[11:9]*/
+
+	//if (ei_local->chip_name == LEOPARD_FE) {
+		rg_bg_rasel = rg_bg_rasel & 0x7;
+		tc_phy_write_g_reg(FE_CAL_COMMON, 2, 22,
+				   g2r22_temp | (rg_bg_rasel << 9));
+#if 0		
+	} else if (ei_local->chip_name == MT7622_FE) {
+		rg_zcal_ctrl = rg_zcal_ctrl & 0x38;
+		tc_phy_write_g_reg(FE_CAL_COMMON, 2, 22,
+				   g2r22_temp | (((rg_zcal_ctrl & 0x38) >> 3) << 9));
+	}
+#endif
+	clear_ckinv_ana_txvos();
+
+	tc_phy_write_l_reg(port_num, 3, 25, 0x0000);
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, 0x0000);
+}
+
+
+
+static void do_fe_phy_all_analog_cal(u8 port_num, bool fe_cal)
+{
+	u16 l0r26_temp, l0r30_temp, l3r25_tmp;
+	u8 cnt = 0, phyaddr, i, iext_port;
+	u32 iext_s, iext_e, r50_s, r50_e, txo_s, txo_e, txa_s, txa_e;
+	int max_port = (fe_cal)? 4: 1;
+	//struct END_DEVICE *ei_local = netdev_priv(dev_raether);
+
+	ephy_addr_base = 0;
+	phyaddr = port_num + ephy_addr_base;
+	l0r26_temp = tc_phy_read_l_reg(port_num, 0, 26);
+	tc_phy_write_l_reg(port_num, 0, 26, 0x5600);
+	tc_phy_write_l_reg(port_num, 4, 21, 0x0000);
+	tc_phy_write_l_reg(port_num, 0, 0, 0x2100);
+
+	l0r30_temp = tc_phy_read_l_reg(port_num, 0, 30);
+
+/*eye pic.*/
+	tc_phy_write_g_reg(port_num, 5, 20, 0x0170);
+	tc_phy_write_g_reg(port_num, 5, 23, 0x0220);
+	tc_phy_write_g_reg(port_num, 5, 24, 0x0206);
+	tc_phy_write_g_reg(port_num, 5, 26, 0x0370);
+	tc_phy_write_g_reg(port_num, 5, 27, 0x02f2);
+	tc_phy_write_g_reg(port_num, 5, 29, 0x001b);
+	tc_phy_write_g_reg(port_num, 5, 30, 0x0002);
+/*Yiron default setting*/
+	for (i = port_num; i <= max_port; i++) {
+		tc_phy_write_g_reg(i, 3, 23, 0x0);
+		tc_phy_write_l_reg(i, 3, 23, 0x2004);
+		tc_phy_write_l_reg(i, 2, 21, 0x8551);
+		tc_phy_write_l_reg(i, 4, 17, 0x2000);
+		tc_phy_write_g_reg(i, 7, 20, 0x7c62);
+		tc_phy_write_l_reg(i, 4, 20, 0x4444);
+		tc_phy_write_l_reg(i, 2, 22, 0x1011);
+		tc_phy_write_l_reg(i, 4, 28, 0x1011);
+		tc_phy_write_l_reg(i, 4, 19, 0x2222);
+		tc_phy_write_l_reg(i, 4, 29, 0x2222);
+		tc_phy_write_l_reg(i, 2, 28, 0x3444);
+		tc_phy_write_l_reg(i, 2, 29, 0x04c6);
+		tc_phy_write_l_reg(i, 4, 30, 0x0006);
+		tc_phy_write_l_reg(i, 5, 16, 0x04c6);
+	}
+	//if (ei_local->chip_name == LEOPARD_FE) {
+		tc_phy_write_l_reg(port_num, 0, 20, 0x0c0c);
+		tc_phy_write_dev_reg(0, 0x1e, 0x017d, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x017e, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x017f, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x0180, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x0181, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x0182, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x0183, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x0184, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x00db, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x00dc, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x003e, 0x0000);
+		tc_phy_write_dev_reg(0, 0x1e, 0x00dd, 0x0000);
+
+		/*eye pic.*/
+		tc_phy_write_g_reg(1, 5, 19, 0x0100);
+		tc_phy_write_g_reg(1, 5, 20, 0x0161);
+		tc_phy_write_g_reg(1, 5, 21, 0x00f0);
+		tc_phy_write_g_reg(1, 5, 22, 0x0046);
+		tc_phy_write_g_reg(1, 5, 23, 0x0210);
+		tc_phy_write_g_reg(1, 5, 24, 0x0206);
+		tc_phy_write_g_reg(1, 5, 25, 0x0238);
+		tc_phy_write_g_reg(1, 5, 26, 0x0360);
+		tc_phy_write_g_reg(1, 5, 27, 0x02f2);
+		tc_phy_write_g_reg(1, 5, 28, 0x0240);
+		tc_phy_write_g_reg(1, 5, 29, 0x0010);
+		tc_phy_write_g_reg(1, 5, 30, 0x0002);
+	//}
+	//if (ei_local->chip_name == MT7622_FE)
+	//	iext_port = 0;
+	//else if (ei_local->chip_name == LEOPARD_FE)
+		iext_port = 1;
+
+	if (port_num == iext_port) {
+			/*****VBG & IEXT Calibration*****/
+		cnt = 0;
+		while ((fe_cal_vbg_flag == 0) && (cnt < 0x03)) {
+			iext_s = jiffies;
+			fe_cal_vbg(port_num, 1);	/* allen_20160608 */
+			iext_e = jiffies;
+			if (show_time)
+				pr_info("port[%d] fe_cal_vbg time = %u\n",
+					port_num, (iext_e - iext_s) * 4);
+			cnt++;
+			if (fe_cal_vbg_flag == 0)
+				pr_info(" FE-%d VBG wait! (%d)  \r\n", phyaddr, cnt);
+		}
+		fe_cal_vbg_flag = 0;
+		/**** VBG & IEXT Calibration end ****/
+	}
+
+	if (!fe_cal)
+		goto restore_default;
+
+	/* *** R50 Cal start *************************************** */
+	cnt = 0;
+	while ((fe_cal_r50_flag == 0) && (cnt < 0x03)) {
+		r50_s = jiffies;
+
+		fe_cal_r50(port_num, 1);
+
+		r50_e = jiffies;
+		if (show_time)
+			pr_info("port[%d] fe_r50 time = %u\n",
+				port_num, (r50_e - r50_s) * 4);
+		cnt++;
+		if (fe_cal_r50_flag == 0)
+			pr_info(" FE-%d R50 wait! (%d)  \r\n", phyaddr, cnt);
+	}
+	fe_cal_r50_flag = 0;
+	cnt = 0;
+	/* *** R50 Cal end *** */
+	/* *** Tx offset Cal start ********************************* */
+
+	cnt = 0;
+	while ((fe_cal_tx_offset_flag == 0) && (cnt < 0x03)) {
+		txo_s = jiffies;
+		fe_cal_tx_offset(port_num, CALDLY);
+		txo_e = jiffies;
+		if (show_time)
+			pr_info("port[%d] fe_cal_tx_offset time = %u\n",
+				port_num, (txo_e - txo_s) * 4);
+		cnt++;
+	}
+	fe_cal_tx_offset_flag = 0;
+	cnt = 0;
+
+	while ((fe_cal_tx_offset_flag_mdix == 0) && (cnt < 0x03)) {
+		txo_s = jiffies;
+		fe_cal_tx_offset_mdix(port_num, CALDLY);
+		txo_e = jiffies;
+		if (show_time)
+			pr_info("port[%d] fe_cal_tx_offset_mdix time = %u\n",
+				port_num, (txo_e - txo_s) * 4);
+		cnt++;
+	}
+	fe_cal_tx_offset_flag_mdix = 0;
+	cnt = 0;
+	/* *** Tx offset Cal end *** */
+
+	/* *** Tx Amp Cal start ************************************** */
+	cnt = 0;
+	while ((fe_cal_flag == 0) && (cnt < 0x3)) {
+		txa_s = jiffies;
+		fe_cal_tx_amp(port_num, CALDLY);	/* allen_20160608 */
+		txa_e = jiffies;
+		if (show_time)
+			pr_info("port[%d] fe_cal_tx_amp time = %u\n",
+				port_num, (txa_e - txa_s) * 4);
+		cnt++;
+	}
+	fe_cal_flag = 0;
+	cnt = 0;
+	while ((fe_cal_flag_mdix == 0) && (cnt < 0x3)) {
+		txa_s = jiffies;
+		fe_cal_tx_amp_mdix(port_num, CALDLY);
+		txa_e = jiffies;
+		if (show_time)
+			pr_info("port[%d] fe_cal_tx_amp_mdix time = %u\n",
+				port_num, (txa_e - txa_s) * 4);
+		cnt++;
+	}
+	fe_cal_flag_mdix = 0;
+	cnt = 0;
+
+restore_default:
+	l3r25_tmp = tc_phy_read_l_reg(port_num, 3, 25);
+	l3r25_tmp = l3r25_tmp & ~(0x1000);/*[12] RG_ZCALEN = 0*/
+	tc_phy_write_l_reg(port_num, 3, 25, l3r25_tmp);
+	tc_phy_write_g_reg(port_num, 1, 26, 0x0000);
+	tc_phy_write_l_reg(port_num, 0, 26, l0r26_temp);
+	tc_phy_write_l_reg(port_num, 0, 30, l0r30_temp);
+	tc_phy_write_g_reg(port_num, 1, 26, 0x0000);
+	tc_phy_write_l_reg(port_num, 0, 0, 0x3100);
+	/*enable flow control*/
+	tc_phy_write_g_reg(port_num, 0, 4, 0x5e1);
+}
+
+static u8 all_ge_ana_cal_wait(unsigned int delay, u8 port_num) /* for EN7512 */
+{
+	u8 all_ana_cal_status;
+	u16 cnt, g7r24_temp;
+
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp & (~0x10));
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp | 0x10);
+
+	cnt = 1000;
+	do {
+		udelay(delay);
+		cnt--;
+		all_ana_cal_status =
+		    ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) >> 1) & 0x1);
+
+	} while ((all_ana_cal_status == 0) && (cnt != 0));
+	g7r24_temp = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_temp & (~0x10));
+
+	return all_ana_cal_status;
+}
+
+static void ge_cal_rext(u8 phyaddr, unsigned int delay)
+{
+	u8	rg_zcal_ctrl, all_ana_cal_status;
+	u16	ad_cal_comp_out_init;
+	u16	dev1e_e0_ana_cal_r5;
+	int	calibration_polarity;
+	u8	cnt = 0;
+	u16	dev1e_17a_tmp, dev1e_e0_tmp;
+
+	/* *** Iext/Rext Cal start ************ */
+	all_ana_cal_status = ANACAL_INIT;
+	/* analog calibration enable, Rext calibration enable */
+	/* 1e_db[12]:rg_cal_ckinv, [8]:rg_ana_calen, [4]:rg_rext_calen, [0]:rg_zcalen_a */
+	/* 1e_dc[0]:rg_txvos_calen */
+	/* 1e_e1[4]:rg_cal_refsel(0:1.2V) */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00db, 0x1110);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dc, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00e1, 0x0000);
+
+	rg_zcal_ctrl = 0x20;/* start with 0 dB */
+	dev1e_e0_ana_cal_r5 = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x00e0);
+	/* 1e_e0[5:0]:rg_zcal_ctrl */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00e0, (rg_zcal_ctrl));
+	all_ana_cal_status = all_ge_ana_cal_wait(delay, phyaddr);/* delay 20 usec */
+	if (all_ana_cal_status == 0) {
+		all_ana_cal_status = ANACAL_ERROR;
+		pr_info(" GE Rext AnaCal ERROR!   \r\n");
+	}
+	/* 1e_17a[8]:ad_cal_comp_out */
+	ad_cal_comp_out_init = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x017a) >> 8) & 0x1;
+	if (ad_cal_comp_out_init == 1)
+		calibration_polarity = -1;
+	else /* ad_cal_comp_out_init == 0 */
+		calibration_polarity = 1;
+
+	cnt = 0;
+	while (all_ana_cal_status < ANACAL_ERROR) {
+		cnt++;
+		rg_zcal_ctrl += calibration_polarity;
+		tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00e0, (rg_zcal_ctrl));
+		all_ana_cal_status = all_ge_ana_cal_wait(delay, phyaddr); /* delay 20 usec */
+		dev1e_17a_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x017a);
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info("  GE Rext AnaCal ERROR!   \r\n");
+		} else if (((dev1e_17a_tmp >> 8) & 0x1) != ad_cal_comp_out_init) {
+			all_ana_cal_status = ANACAL_FINISH;
+			pr_info("  GE Rext AnaCal Done! (%d)(0x%x)  \r\n", cnt, rg_zcal_ctrl);
+		} else {
+			dev1e_17a_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x017a);
+			dev1e_e0_tmp =	tc_phy_read_dev_reg(phyaddr, 0x1e, 0xe0);
+			if ((rg_zcal_ctrl == 0x3F) || (rg_zcal_ctrl == 0x00)) {
+				all_ana_cal_status = ANACAL_SATURATION;  /* need to FT(IC fail?) */
+				pr_info(" GE Rext AnaCal Saturation!  \r\n");
+				rg_zcal_ctrl = 0x20;  /* 0 dB */
+			} else {
+				pr_info(" GE Rxet cal (%d)(%d)(%d)(0x%x)  \r\n",
+					cnt, ad_cal_comp_out_init,
+				((dev1e_17a_tmp >> 8) & 0x1), dev1e_e0_tmp);
+			}
+		}
+	}
+
+	if (all_ana_cal_status == ANACAL_ERROR) {
+		rg_zcal_ctrl = 0x20;  /* 0 dB */
+		tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00e0, (dev1e_e0_ana_cal_r5 | rg_zcal_ctrl));
+	} else {
+		tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00e0, (dev1e_e0_ana_cal_r5 | rg_zcal_ctrl));
+		tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00e0, ((rg_zcal_ctrl << 8) | rg_zcal_ctrl));
+		/* ****  1f_115[2:0] = rg_zcal_ctrl[5:3]  // Mog review */
+		tc_phy_write_dev_reg(phyaddr, 0x1f, 0x0115, ((rg_zcal_ctrl & 0x3f) >> 3));
+		pr_info("  GE Rext AnaCal Done! (%d)(0x%x)  \r\n", cnt, rg_zcal_ctrl);
+		ge_cal_flag = 1;
+	}
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00db, 0x0000);
+	/* *** Iext/Rext Cal end *** */
+}
+
+static void ge_cal_r50(u8 phyaddr, unsigned int delay)
+{
+	u8	rg_zcal_ctrl, all_ana_cal_status, i;
+	u16	ad_cal_comp_out_init;
+	u16	dev1e_e0_ana_cal_r5;
+	int	calibration_polarity;
+	u16	cal_pair, val_tmp, g7r24_tmp;
+	u16	dev1e_174_tmp, dev1e_175_tmp, l3r25_temp;
+	u8	rg_zcal_ctrl_filter, cnt = 0;
+
+	/* *** R50 Cal start***************** */
+	fe_ge_r50_common(phyaddr);
+	/* 1e_db[12]:rg_cal_ckinv, [8]:rg_ana_calen, [4]:rg_rext_calen, [0]:rg_zcalen_a */
+	/* 1e_dc[0]:rg_txvos_calen */
+	/*disable RG_ZCALEN*/
+	/*decide which port calibration RG_ZCALEN by port_num*/
+	for (i = 1; i <= 4; i++) {
+		l3r25_temp = tc_phy_read_l_reg(i, 3, 25);
+		l3r25_temp = l3r25_temp & ~(0x1000);
+		tc_phy_write_l_reg(i, 3, 25, l3r25_temp);
+	}
+	for (cal_pair = ANACAL_PAIR_A; cal_pair <= ANACAL_PAIR_D; cal_pair++) {
+		rg_zcal_ctrl = 0x20;/* start with 0 dB */
+		dev1e_e0_ana_cal_r5 = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x00e0) & (~0x003f));
+		/* 1e_e0[5:0]:rg_zcal_ctrl */
+		if (cal_pair == ANACAL_PAIR_A) {
+	/* 1e_db[12]:rg_cal_ckinv, [8]:rg_ana_calen, [4]:rg_rext_calen, [0]:rg_zcalen_a */
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x1000);
+		} else if (cal_pair == ANACAL_PAIR_B) {
+	/* 1e_db[12]:rg_cal_ckinv, [8]:rg_ana_calen, [4]:rg_rext_calen, [0]:rg_zcalen_a */
+	/* 1e_dc[12]:rg_zcalen_b */
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0100);
+		} else if (cal_pair == ANACAL_PAIR_C) {
+	/* 1e_db[12]:rg_cal_ckinv, [8]:rg_ana_calen, [4]:rg_rext_calen, [0]:rg_zcalen_a */
+	/* 1e_dc[8]:rg_zcalen_c */
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0010);
+
+		} else {/* if(cal_pair == ANACAL_PAIR_D) */
+
+	/* 1e_db[12]:rg_cal_ckinv, [8]:rg_ana_calen, [4]:rg_rext_calen, [0]:rg_zcalen_a */
+	/* 1e_dc[4]:rg_zcalen_d */
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0001);
+		}
+		rg_zcal_ctrl = 0x20;	/* start with 0 dB */
+		g7r24_tmp = (tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & (~0xfc0));
+		tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, g7r24_tmp | ((rg_zcal_ctrl & 0x3f) << 6));
+
+		/*wait AD_CAL_COMP_OUT = 1*/
+		all_ana_cal_status = all_ge_ana_cal_wait(delay, phyaddr);
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info(" GE R50 AnaCal ERROR! (init)   \r\n");
+		}
+		ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+		if (ad_cal_comp_out_init == 1)
+			calibration_polarity = -1;
+		else
+			calibration_polarity = 1;
+
+		cnt = 0;
+		while ((all_ana_cal_status < ANACAL_ERROR) && (cnt < 254)) {
+			cnt++;
+
+			rg_zcal_ctrl += calibration_polarity;
+			g7r24_tmp = (tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & (~0xfc0));
+			tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24,
+					   g7r24_tmp | ((rg_zcal_ctrl & 0x3f) << 6));
+			all_ana_cal_status = all_ge_ana_cal_wait(delay, phyaddr);
+
+			if (all_ana_cal_status == 0) {
+				all_ana_cal_status = ANACAL_ERROR;
+				pr_info(" GE R50 AnaCal ERROR! (%d)  \r\n", cnt);
+			} else if ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1) !=
+				ad_cal_comp_out_init) {
+				all_ana_cal_status = ANACAL_FINISH;
+			} else {
+				if ((rg_zcal_ctrl == 0x3F) || (rg_zcal_ctrl == 0x00)) {
+					all_ana_cal_status = ANACAL_SATURATION;
+					pr_info(" GE R50 Cal Sat! rg_zcal_ctrl = 0x%x(%d)\n",
+						cnt, rg_zcal_ctrl);
+				}
+			}
+		}
+
+		if ((all_ana_cal_status == ANACAL_ERROR) ||
+		    (all_ana_cal_status == ANACAL_SATURATION)) {
+			rg_zcal_ctrl = 0x20;  /* 0 dB */
+			rg_zcal_ctrl_filter = 8; /*default value*/
+		} else {
+			/*DA_TX_R50*/
+			rg_zcal_ctrl_filter = rg_zcal_ctrl;
+			rg_zcal_ctrl = ZCAL_TO_R50ohm_GE_TBL[rg_zcal_ctrl];
+			/*DA_TX_FILTER*/
+			rg_zcal_ctrl_filter = ZCAL_TO_FILTER_TBL[rg_zcal_ctrl_filter];
+			rg_zcal_ctrl_filter = rg_zcal_ctrl_filter & 0xf;
+			rg_zcal_ctrl_filter = rg_zcal_ctrl_filter << 8 | rg_zcal_ctrl_filter;
+		}
+		if (all_ana_cal_status == ANACAL_FINISH) {
+			if (cal_pair == ANACAL_PAIR_A) {
+				dev1e_174_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0174);
+				dev1e_174_tmp = dev1e_174_tmp & ~(0xff00);
+				if (rg_zcal_ctrl > 4) {
+					val_tmp = (((rg_zcal_ctrl - 4) << 8) & 0xff00) |
+						dev1e_174_tmp;
+				} else {
+					val_tmp = (((0) << 8) & 0xff00) | dev1e_174_tmp;
+				}
+
+				tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0174, val_tmp);
+				tc_phy_write_dev_reg(phyaddr, 0x1e, 0x03a0, rg_zcal_ctrl_filter);
+
+				pr_info("R50_PAIR_A : 1e_174 = 0x%x\n",
+					tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0174));
+				pr_info("R50_PAIR_A : 1e_3a0 = 0x%x\n",
+					tc_phy_read_dev_reg(phyaddr, 0x1e, 0x03a0));
+
+			} else if (cal_pair == ANACAL_PAIR_B) {
+				dev1e_174_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0174);
+				dev1e_174_tmp = dev1e_174_tmp & (~0x007f);
+				if (rg_zcal_ctrl > 2) {
+					val_tmp = (((rg_zcal_ctrl - 2) << 0) & 0xff) |
+						dev1e_174_tmp;
+				} else {
+					val_tmp = (((0) << 0) & 0xff) |
+						dev1e_174_tmp;
+				}
+				tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0174, val_tmp);
+				tc_phy_write_dev_reg(phyaddr, 0x1e, 0x03a1, rg_zcal_ctrl_filter);
+				pr_info("R50_PAIR_B : 1e_174 = 0x%x\n",
+					tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0174));
+				pr_info("R50_PAIR_B : 1e_3a1 = 0x%x\n",
+					tc_phy_read_dev_reg(phyaddr, 0x1e, 0x03a1));
+			} else if (cal_pair == ANACAL_PAIR_C) {
+				dev1e_175_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0175);
+				dev1e_175_tmp =  dev1e_175_tmp & (~0x7f00);
+				if (rg_zcal_ctrl > 4) {
+					val_tmp = dev1e_175_tmp |
+						(((rg_zcal_ctrl - 4) << 8) & 0xff00);
+				} else {
+					val_tmp = dev1e_175_tmp | (((0) << 8) & 0xff00);
+				}
+				tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0175, val_tmp);
+				tc_phy_write_dev_reg(phyaddr, 0x1e, 0x03a2, rg_zcal_ctrl_filter);
+				pr_info("R50_PAIR_C : 1e_175 = 0x%x\n",
+					tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0175));
+				pr_info("R50_PAIR_C : 1e_3a2 = 0x%x\n",
+					tc_phy_read_dev_reg(phyaddr, 0x1e, 0x03a2));
+
+			} else {/* if(cal_pair == ANACAL_PAIR_D) */
+				dev1e_175_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0175);
+				dev1e_175_tmp = dev1e_175_tmp & (~0x007f);
+				if (rg_zcal_ctrl > 6) {
+					val_tmp = dev1e_175_tmp |
+						(((rg_zcal_ctrl - 6)  << 0) & 0xff);
+				} else {
+					val_tmp = dev1e_175_tmp |
+						(((0)  << 0) & 0xff);
+				}
+
+				tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0175, val_tmp);
+				tc_phy_write_dev_reg(phyaddr, 0x1e, 0x03a3, rg_zcal_ctrl_filter);
+				pr_info("R50_PAIR_D : 1e_175 = 0x%x\n",
+					tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0175));
+				pr_info("R50_PAIR_D : 1e_3a3 = 0x%x\n",
+					tc_phy_read_dev_reg(phyaddr, 0x1e, 0x03a3));
+			}
+		}
+	}
+	clear_ckinv_ana_txvos();
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00db, 0x0000);
+	ge_cal_r50_flag = 1;
+	/* *** R50 Cal end *** */
+}
+
+static void ge_cal_tx_amp(u8 phyaddr, unsigned int delay)
+{
+	u8	all_ana_cal_status;
+	u16	ad_cal_comp_out_init;
+	int	calibration_polarity;
+	u16	cal_pair;
+	u8	tx_amp_reg_shift;
+	u16	reg_temp, val_tmp, l3r25_temp, val_tmp_100;
+	u8	tx_amp_temp, tx_amp_reg, cnt = 0, tx_amp_reg_100;
+
+	u16	tx_amp_temp_L, tx_amp_temp_M;
+	u16	tx_amp_L_100, tx_amp_M_100;
+	/* *** Tx Amp Cal start ***/
+	tc_phy_write_l_reg(0, 0, 0, 0x0140);
+
+	tc_phy_write_dev_reg(0, 0x1e, 0x3e, 0xf808);
+	tc_phy_write_dev_reg(0, 0x1e, 0x145, 0x5010);
+	tc_phy_write_dev_reg(0, 0x1e, 0x17d, 0x80f0);
+	tc_phy_write_dev_reg(0, 0x1e, 0x17e, 0x80f0);
+	tc_phy_write_dev_reg(0, 0x1e, 0x17f, 0x80f0);
+	tc_phy_write_dev_reg(0, 0x1e, 0x180, 0x80f0);
+	tc_phy_write_dev_reg(0, 0x1e, 0x181, 0x80f0);
+	tc_phy_write_dev_reg(0, 0x1e, 0x182, 0x80f0);
+	tc_phy_write_dev_reg(0, 0x1e, 0x183, 0x80f0);
+	tc_phy_write_dev_reg(0, 0x1e, 0x184, 0x80f0);
+	tc_phy_write_dev_reg(0, 0x1e, 0x00db, 0x1000);
+	tc_phy_write_dev_reg(0, 0x1e, 0x00dc, 0x0001);
+	tc_phy_write_dev_reg(0, 0x1f, 0x300, 0x4);
+	tc_phy_write_dev_reg(0, 0x1f, 0x27a, 0x33);
+	tc_phy_write_g_reg(1, 2, 25, 0xf020);
+	tc_phy_write_dev_reg(0, 0x1f, 0x300, 0x14);
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x7000);
+	l3r25_temp = tc_phy_read_l_reg(FE_CAL_COMMON, 3, 25);
+	l3r25_temp = l3r25_temp | 0x200;
+	tc_phy_write_l_reg(FE_CAL_COMMON, 3, 25, l3r25_temp);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x11, 0xff00);
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x273, 0);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0xc9, 0xffff);
+	tc_phy_write_g_reg(1, 2, 25, 0xb020);
+
+	for (cal_pair = ANACAL_PAIR_A; cal_pair <= ANACAL_PAIR_D; cal_pair++) {
+		tx_amp_temp = 0x20;	/* start with 0 dB */
+		tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x7000);
+		if (cal_pair == ANACAL_PAIR_A) {
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x1000);
+			reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x012) & (~0xfc00));
+			tx_amp_reg_shift = 10;
+			tx_amp_reg = 0x12;
+			tx_amp_reg_100 = 0x16;
+		} else if (cal_pair == ANACAL_PAIR_B) {
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0100);
+			reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x017) & (~0x3f00));
+			tx_amp_reg_shift = 8;
+			tx_amp_reg = 0x17;
+			tx_amp_reg_100 = 0x18;
+		} else if (cal_pair == ANACAL_PAIR_C) {
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0010);
+			reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x019) & (~0x3f00));
+			tx_amp_reg_shift = 8;
+			tx_amp_reg = 0x19;
+			tx_amp_reg_100 = 0x20;
+		} else {/* if(cal_pair == ANACAL_PAIR_D) */
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0001);
+			reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x021) & (~0x3f00));
+			tx_amp_reg_shift = 8;
+			tx_amp_reg = 0x21;
+			tx_amp_reg_100 = 0x22;
+		}
+		/* 1e_12, 1e_17, 1e_19, 1e_21 */
+		val_tmp = tx_amp_temp | (tx_amp_temp << tx_amp_reg_shift);
+		tc_phy_write_dev_reg(phyaddr, 0x1e, tx_amp_reg, val_tmp);
+		tc_phy_write_dev_reg(phyaddr, 0x1e, tx_amp_reg_100, val_tmp);
+		all_ana_cal_status = all_ge_ana_cal_wait(delay, phyaddr);
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info(" GE Tx amp AnaCal ERROR!   \r\n");
+		}
+/* 1e_17a[8]:ad_cal_comp_out */
+		ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+		if (ad_cal_comp_out_init == 1)
+			calibration_polarity = -1;
+		else
+			calibration_polarity = 1;
+
+		cnt = 0;
+		while (all_ana_cal_status < ANACAL_ERROR) {
+			cnt++;
+			tx_amp_temp += calibration_polarity;
+
+			val_tmp = (tx_amp_temp | (tx_amp_temp << tx_amp_reg_shift));
+			tc_phy_write_dev_reg(phyaddr, 0x1e, tx_amp_reg, val_tmp);
+			tc_phy_write_dev_reg(phyaddr, 0x1e, tx_amp_reg_100, val_tmp);
+			all_ana_cal_status = all_ge_ana_cal_wait(delay, phyaddr);
+			if (all_ana_cal_status == 0) {
+				all_ana_cal_status = ANACAL_ERROR;
+				pr_info(" GE Tx amp AnaCal ERROR!\n");
+			} else if ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1) !=
+				    ad_cal_comp_out_init) {
+				all_ana_cal_status = ANACAL_FINISH;
+			} else {
+				if ((tx_amp_temp == 0x3f) || (tx_amp_temp == 0x00)) {
+					all_ana_cal_status = ANACAL_SATURATION;
+					pr_info(" GE Tx amp AnaCal Saturation!  \r\n");
+				}
+			}
+		}
+		if (all_ana_cal_status == ANACAL_ERROR) {
+			pr_info("ANACAL_ERROR\n");
+			tx_amp_temp = 0x20;
+			val_tmp = (reg_temp | (tx_amp_temp << tx_amp_reg_shift));
+			tc_phy_write_dev_reg(phyaddr, 0x1e, tx_amp_reg, val_tmp);
+		}
+
+		if (all_ana_cal_status == ANACAL_FINISH) {
+			if (cal_pair == ANACAL_PAIR_A) {
+				tx_amp_temp_M = tx_amp_temp + 9;
+				tx_amp_temp_L = tx_amp_temp + 18;
+			} else if (cal_pair == ANACAL_PAIR_B) {
+				tx_amp_temp_M = tx_amp_temp + 8;
+				tx_amp_temp_L = tx_amp_temp + 22;
+			} else if (cal_pair == ANACAL_PAIR_C) {
+				tx_amp_temp_M = tx_amp_temp + 9;
+				tx_amp_temp_L = tx_amp_temp + 9;
+			} else if (cal_pair == ANACAL_PAIR_D) {
+				tx_amp_temp_M = tx_amp_temp + 9;
+				tx_amp_temp_L = tx_amp_temp + 9;
+			}
+			if (tx_amp_temp_L >= 0x3f)
+				tx_amp_temp_L = 0x3f;
+			if (tx_amp_temp_M >= 0x3f)
+				tx_amp_temp_M = 0x3f;
+			val_tmp = ((tx_amp_temp_L) |
+				((tx_amp_temp_M) << tx_amp_reg_shift));
+			if (cal_pair == ANACAL_PAIR_A) {
+				if (tx_amp_temp < 6)
+					tx_amp_M_100 = 0;
+				else
+					tx_amp_M_100 = tx_amp_temp - 6;
+
+				if ((tx_amp_temp + 9) >= 0x3f)
+					tx_amp_L_100 = 0x3f;
+				else
+					tx_amp_L_100 = tx_amp_temp + 9;
+				val_tmp_100 = ((tx_amp_L_100) |
+					((tx_amp_M_100) << tx_amp_reg_shift));
+			} else if (cal_pair == ANACAL_PAIR_B) {
+				if (tx_amp_temp < 7)
+					tx_amp_M_100 = 0;
+				else
+					tx_amp_M_100 = tx_amp_temp - 7;
+
+				if ((tx_amp_temp + 8) >= 0x3f)
+					tx_amp_L_100 = 0x3f;
+				else
+					tx_amp_L_100 = tx_amp_temp + 8;
+				val_tmp_100 = ((tx_amp_L_100) |
+					((tx_amp_M_100) << tx_amp_reg_shift));
+			} else if (cal_pair == ANACAL_PAIR_C) {
+				if ((tx_amp_temp + 9) >= 0x3f)
+					tx_amp_L_100 = 0x3f;
+				else
+					tx_amp_L_100 = tx_amp_temp + 9;
+				tx_amp_M_100 = tx_amp_L_100;
+				val_tmp_100 = ((tx_amp_L_100) |
+					((tx_amp_M_100) << tx_amp_reg_shift));
+			} else if (cal_pair == ANACAL_PAIR_D) {
+				if ((tx_amp_temp + 9) >= 0x3f)
+					tx_amp_L_100 = 0x3f;
+				else
+					tx_amp_L_100 = tx_amp_temp + 9;
+
+				tx_amp_M_100 = tx_amp_L_100;
+				val_tmp_100 = ((tx_amp_L_100) |
+					((tx_amp_M_100) << tx_amp_reg_shift));
+			}
+
+			tc_phy_write_dev_reg(phyaddr, 0x1e, tx_amp_reg, val_tmp);
+			tc_phy_write_dev_reg(phyaddr, 0x1e, tx_amp_reg_100, val_tmp_100);
+
+			if (cal_pair == ANACAL_PAIR_A) {
+				pr_info("TX_AMP_PAIR_A : 1e_%x = 0x%x\n",
+					tx_amp_reg,
+					tc_phy_read_dev_reg(phyaddr, 0x1e, tx_amp_reg));
+				pr_info("TX_AMP_PAIR_A : 1e_%x = 0x%x\n",
+					tx_amp_reg_100,
+					tc_phy_read_dev_reg(phyaddr, 0x1e, tx_amp_reg_100));
+			} else if (cal_pair == ANACAL_PAIR_B) {
+				pr_info("TX_AMP_PAIR_B : 1e_%x = 0x%x\n",
+					tx_amp_reg,
+					tc_phy_read_dev_reg(phyaddr, 0x1e, tx_amp_reg));
+				pr_info("TX_AMP_PAIR_B : 1e_%x = 0x%x\n",
+					tx_amp_reg_100,
+					tc_phy_read_dev_reg(phyaddr, 0x1e, tx_amp_reg_100));
+			} else if (cal_pair == ANACAL_PAIR_C) {
+				pr_info("TX_AMP_PAIR_C : 1e_%x = 0x%x\n",
+					tx_amp_reg,
+					tc_phy_read_dev_reg(phyaddr, 0x1e, tx_amp_reg));
+				pr_info("TX_AMP_PAIR_C : 1e_%x = 0x%x\n",
+					tx_amp_reg_100,
+					tc_phy_read_dev_reg(phyaddr, 0x1e, tx_amp_reg_100));
+
+			} else {/* if(cal_pair == ANACAL_PAIR_D) */
+				pr_info("TX_AMP_PAIR_D : 1e_%x = 0x%x\n",
+					tx_amp_reg,
+					tc_phy_read_dev_reg(phyaddr, 0x1e, tx_amp_reg));
+				pr_info("TX_AMP_PAIR_D : 1e_%x = 0x%x\n",
+					tx_amp_reg_100,
+					tc_phy_read_dev_reg(phyaddr, 0x1e, tx_amp_reg_100));
+			}
+		}
+	}
+
+	ge_cal_flag = 1;
+	pr_info("GE_TX_AMP END\n");
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017d, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017e, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017f, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0180, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0181, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0182, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0183, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0184, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x273, 0x2000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0xc9, 0x0fff);
+	tc_phy_write_g_reg(1, 2, 25, 0xb020);
+	tc_phy_write_dev_reg(0, 0x1e, 0x145, 0x1000);
+
+/* disable analog calibration circuit */
+/* disable Tx offset calibration circuit */
+/* disable Tx VLD force mode */
+/* disable Tx offset/amplitude calibration circuit */
+
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00db, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dc, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x003e, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0000);
+	/* *** Tx Amp Cal end *** */
+}
+
+static void ge_cal_tx_offset(u8 phyaddr, unsigned int delay)
+{
+	u8	all_ana_cal_status;
+	u16	ad_cal_comp_out_init;
+	int	calibration_polarity, tx_offset_temp;
+	u16	cal_pair, cal_temp;
+	u8	tx_offset_reg_shift;
+	u16	tx_offset_reg, reg_temp, val_tmp;
+	u8	cnt = 0;
+
+	tc_phy_write_l_reg(0, 0, 0, 0x2100);
+
+	/* 1e_db[12]:rg_cal_ckinv, [8]:rg_ana_calen, [4]:rg_rext_calen, [0]:rg_zcalen_a */
+	/* 1e_dc[0]:rg_txvos_calen */
+	/* 1e_96[15]:bypass_tx_offset_cal, Hw bypass, Fw cal */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00db, 0x0100);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dc, 0x0001);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0096, 0x8000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x003e, 0xf808);/* 1e_3e */
+	tc_phy_write_g_reg(FE_CAL_COMMON, 7, 24, 0x3000);
+
+	for (cal_pair = ANACAL_PAIR_A; cal_pair <= ANACAL_PAIR_D; cal_pair++) {
+		tx_offset_temp = 0x20;
+
+		if (cal_pair == ANACAL_PAIR_A) {
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x145, 0x5010);
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x1000);
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017d, (0x8000 | DAC_IN_0V));
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0181, (0x8000 | DAC_IN_0V));
+			reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0172) & (~0x3f00));
+			tx_offset_reg_shift = 8;/* 1e_172[13:8] */
+			tx_offset_reg = 0x0172;
+
+		} else if (cal_pair == ANACAL_PAIR_B) {
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x145, 0x5018);
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0100);
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017e, (0x8000 | DAC_IN_0V));
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0182, (0x8000 | DAC_IN_0V));
+			reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0172) & (~0x003f));
+			tx_offset_reg_shift = 0;
+			tx_offset_reg = 0x0172;/* 1e_172[5:0] */
+		} else if (cal_pair == ANACAL_PAIR_C) {
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0010);
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017f, (0x8000 | DAC_IN_0V));
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0183, (0x8000 | DAC_IN_0V));
+			reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0173) & (~0x3f00));
+			tx_offset_reg_shift = 8;
+			tx_offset_reg = 0x0173;/* 1e_173[13:8] */
+		} else {/* if(cal_pair == ANACAL_PAIR_D) */
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0001);
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0180, (0x8000 | DAC_IN_0V));
+			tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0184, (0x8000 | DAC_IN_0V));
+			reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0173) & (~0x003f));
+			tx_offset_reg_shift = 0;
+			tx_offset_reg = 0x0173;/* 1e_173[5:0] */
+		}
+		/* 1e_172, 1e_173 */
+		val_tmp =  (reg_temp | (tx_offset_temp << tx_offset_reg_shift));
+		tc_phy_write_dev_reg(phyaddr, 0x1e, tx_offset_reg, val_tmp);
+
+		all_ana_cal_status = all_ge_ana_cal_wait(delay, phyaddr); /* delay 20 usec */
+		if (all_ana_cal_status == 0) {
+			all_ana_cal_status = ANACAL_ERROR;
+			pr_info(" GE Tx offset AnaCal ERROR!   \r\n");
+		}
+		ad_cal_comp_out_init = tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1;
+		if (ad_cal_comp_out_init == 1)
+			calibration_polarity = -1;
+		else
+			calibration_polarity = 1;
+
+		cnt = 0;
+		tx_offset_temp += calibration_polarity;
+		while (all_ana_cal_status < ANACAL_ERROR) {
+			cnt++;
+			cal_temp = tx_offset_temp;
+			val_tmp = (reg_temp | (cal_temp << tx_offset_reg_shift));
+			tc_phy_write_dev_reg(phyaddr, 0x1e, tx_offset_reg, val_tmp);
+
+			all_ana_cal_status = all_ge_ana_cal_wait(delay, phyaddr);
+			if (all_ana_cal_status == 0) {
+				all_ana_cal_status = ANACAL_ERROR;
+				pr_info(" GE Tx offset AnaCal ERROR!   \r\n");
+			} else if ((tc_phy_read_g_reg(FE_CAL_COMMON, 7, 24) & 0x1) !=
+				    ad_cal_comp_out_init) {
+				all_ana_cal_status = ANACAL_FINISH;
+			} else {
+				if ((tx_offset_temp == 0x3f) || (tx_offset_temp == 0x00)) {
+					all_ana_cal_status = ANACAL_SATURATION;
+					pr_info("GE tx offset ANACAL_SATURATION\n");
+					/* tx_amp_temp += calibration_polarity; */
+				} else {
+					tx_offset_temp += calibration_polarity;
+				}
+			}
+		}
+		if (all_ana_cal_status == ANACAL_ERROR) {
+			tx_offset_temp = 0x20;
+			val_tmp = (reg_temp | (tx_offset_temp << tx_offset_reg_shift));
+			tc_phy_write_dev_reg(phyaddr, 0x1e, tx_offset_reg, val_tmp);
+		}
+
+		if (all_ana_cal_status == ANACAL_FINISH) {
+			if (cal_pair == ANACAL_PAIR_A) {
+				pr_info("TX_OFFSET_PAIR_A : 1e_%x = 0x%x\n",
+					tx_offset_reg,
+				tc_phy_read_dev_reg(phyaddr, 0x1e, tx_offset_reg));
+			} else if (cal_pair == ANACAL_PAIR_B) {
+				pr_info("TX_OFFSET_PAIR_B : 1e_%x = 0x%x\n",
+					tx_offset_reg,
+				tc_phy_read_dev_reg(phyaddr, 0x1e, tx_offset_reg));
+			} else if (cal_pair == ANACAL_PAIR_C) {
+				pr_info("TX_OFFSET_PAIR_C : 1e_%x = 0x%x\n",
+					tx_offset_reg,
+				tc_phy_read_dev_reg(phyaddr, 0x1e, tx_offset_reg));
+
+			} else {/* if(cal_pair == ANACAL_PAIR_D) */
+				pr_info("TX_OFFSET_PAIR_D : 1e_%x = 0x%x\n",
+					tx_offset_reg,
+				tc_phy_read_dev_reg(phyaddr, 0x1e, tx_offset_reg));
+			}
+		}
+	}
+	ge_cal_tx_offset_flag = 1;
+	clear_ckinv_ana_txvos();
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017d, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017e, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x017f, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0180, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0181, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0182, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0183, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0184, 0x0000);
+/* disable analog calibration circuit */
+/* disable Tx offset calibration circuit */
+/* disable Tx VLD force mode */
+/* disable Tx offset/amplitude calibration circuit */
+
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00db, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dc, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x003e, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x00dd, 0x0000);
+}
+
+static void do_ge_phy_all_analog_cal(u8 phyaddr)
+{
+	u16	reg0_temp, dev1e_145_temp, reg_temp;
+	u16	reg_tmp;
+
+	tc_mii_write(phyaddr, 0x1f, 0x0000);/* g0 */
+	reg0_temp = tc_mii_read(phyaddr, 0x0);/* keep the default value */
+/* set [12]AN disable, [8]full duplex, [13/6]1000Mbps */
+	tc_mii_write(phyaddr, 0x0,  0x0140);
+
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x0100, 0xc000);/* BG voltage output */
+	dev1e_145_temp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0145);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0145, 0x1010);/* fix mdi */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0185, 0x0000);/* disable tx slew control */
+
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x27c, 0x1f1f);
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x27c, 0x3300);
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x273, 0);
+
+	reg_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x11);
+	reg_tmp = reg_tmp | (0xf << 12);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x11, reg_tmp);
+
+	/* calibration start ============ */
+	ge_cal_flag = 1; /*GE calibration not calibration*/
+	while (ge_cal_flag == 0)
+		ge_cal_rext(phyaddr, 100);
+
+	/* *** R50 Cal start ***************************** */
+	/*phyaddress = 0*/
+	ge_cal_r50(phyaddr, CALDLY);
+	/* *** R50 Cal end *** */
+
+	/* *** Tx offset Cal start *********************** */
+	ge_cal_tx_offset(phyaddr, CALDLY);
+	/* *** Tx offset Cal end *** */
+
+	/* *** Tx Amp Cal start *** */
+	ge_cal_tx_amp(phyaddr, CALDLY);
+	/* *** Tx Amp Cal end *** */
+
+	/* *** Rx offset Cal start *************** */
+	/* 1e_96[15]:bypass_tx_offset_cal, Hw bypass, Fw cal */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0096, 0x8000);
+	/* tx/rx_cal_criteria_value */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0037, 0x0033);
+	/* [14]: bypass all calibration, [11]: bypass adc offset cal analog */
+	reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0039) & (~0x4800));
+	/* rx offset cal by Hw setup */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0039, reg_temp);
+	/* [12]: enable rtune calibration */
+	reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1f, 0x0107) & (~0x1000));
+	/* disable rtune calibration */
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x0107, reg_temp);
+	/* 1e_171[8:7]: bypass tx/rx dc offset cancellation process */
+	reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0171) & (~0x0180));
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0171, (reg_temp | 0x0180));
+	reg_temp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0039);
+	/* rx offset calibration start */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0039, (reg_temp | 0x2000));
+	/* rx offset calibration end */
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0039, (reg_temp & (~0x2000)));
+	mdelay(10);	/* mdelay for Hw calibration finish */
+	reg_temp = (tc_phy_read_dev_reg(phyaddr, 0x1e, 0x0171) & (~0x0180));
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0171, reg_temp);
+
+	tc_mii_write(phyaddr, 0x0,  reg0_temp);
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x0100, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0145, dev1e_145_temp);
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x273, 0x2000);
+	/* *** Rx offset Cal end *** */
+	/*eye pic*/
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x0, 0x018d);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x1, 0x01c7);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x2, 0x01c0);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3, 0x003a);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x4, 0x0206);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x5, 0x0000);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x6, 0x038a);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x7, 0x03c8);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x8, 0x03c0);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x9, 0x0235);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0xa, 0x0008);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0xb, 0x0000);
+
+	/*tmp maybe changed*/
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x27c, 0x1111);
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x27b, 0x47);
+	tc_phy_write_dev_reg(phyaddr, 0x1f, 0x273, 0x2200);
+
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3a8, 0x0810);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3aa, 0x0008);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3ab, 0x0810);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3ad, 0x0008);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3ae, 0x0106);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3b0, 0x0001);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3b1, 0x0106);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3b3, 0x0001);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x18c, 0x0001);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x18d, 0x0001);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x18e, 0x0001);
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x18f, 0x0001);
+
+	/*da_tx_bias1_b_tx_standby = 5'b10 (dev1eh_reg3aah[12:8])*/
+	reg_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x3aa);
+	reg_tmp = reg_tmp & ~(0x1f00);
+	reg_tmp = reg_tmp | 0x2 << 8;
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3aa, reg_tmp);
+
+	/*da_tx_bias1_a_tx_standby = 5'b10 (dev1eh_reg3a9h[4:0])*/
+	reg_tmp = tc_phy_read_dev_reg(phyaddr, 0x1e, 0x3a9);
+	reg_tmp = reg_tmp & ~(0x1f);
+	reg_tmp = reg_tmp | 0x2;
+	tc_phy_write_dev_reg(phyaddr, 0x1e, 0x3a9, reg_tmp);
+
+	/* SpaceX/Mtk: Enable Auto downshift from 1G to 100M */
+	mii_mgr_write(phyaddr, 31, 1);
+	mii_mgr_read(phyaddr, 20, &reg_tmp);
+	mii_mgr_write(phyaddr, 20, reg_tmp | BIT(4));
+	mii_mgr_write(phyaddr, 31, 0);
+
+       //restart AN
+	mii_mgr_write(phyaddr, 9, 0x200);
+	mii_mgr_write(phyaddr, 0, 0x1340);
+}
+
+void leopard_ephy_cal(bool fe_cal)
+{
+	int i, dbg;
+	int max_port = (fe_cal)? 4: 1;
+	unsigned long t_s, t_e;
+
+	dbg = 1;
+	if (dbg) {
+		t_s = jiffies;
+		/* IEXT result of fe port 1 is always required. */
+		for (i = 1; i <= max_port; i++)
+			do_fe_phy_all_analog_cal(i, fe_cal);
+
+		do_ge_phy_all_analog_cal(0);
+
+		t_e = jiffies;
+	}
+	if (show_time)
+		pr_info("cal time = %lu\n", (t_e - t_s) * 4);
+}
+
+
diff --git a/trunk/linux-4.4.x/drivers/net/phy/mtk_gphy.c b/trunk/linux-4.4.x/drivers/net/phy/mtk_gphy.c
new file mode 100644
index 000000000..e29981f53
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/mtk_gphy.c
@@ -0,0 +1,53 @@
+/* SPDX-License-Identifier: GPL-2.0
+ *
+ * Copyright (c) 2020 MediaTek Inc.
+ * Author: Landen Chao <landen.chao@mediatek.com>
+ */
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/mii.h>
+#include <linux/phy.h>
+
+#define PHY_ID_MTK_GPHY		0x03a29441
+
+MODULE_DESCRIPTION("MTK GePHY driver");
+MODULE_AUTHOR("Landen Chao <landen.chao@mediatek.com>");
+MODULE_LICENSE("GPL");
+
+static int mt753x_gphy_config_init(struct phy_device *phydev)
+{
+	int val;
+
+	/* Enable pause capability of internal phy to match mac capability */
+	val = phy_read(phydev, MII_ADVERTISE);
+	val |= (ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM);
+	phy_write(phydev, MII_ADVERTISE, val);
+
+	return 0;
+}
+
+static struct phy_driver mtk_gphy_driver[] = { {
+	.phy_id		= PHY_ID_MTK_GPHY,
+	.phy_id_mask	= 0x0fffff00,
+	.name		= "mtk_gphy",
+	.soft_reset	= genphy_no_soft_reset,
+	.config_init	= mt753x_gphy_config_init,
+	.features	= (PHY_GBIT_FEATURES | SUPPORTED_MII |
+			   SUPPORTED_Pause | SUPPORTED_Asym_Pause),
+	.config_aneg	= genphy_config_aneg,
+	.aneg_done	= genphy_aneg_done,
+	.read_status	= genphy_read_status,
+	.suspend	= genphy_suspend,
+	.resume		= genphy_resume,
+	.driver		= { .owner = THIS_MODULE,},
+} };
+
+module_phy_driver(mtk_gphy_driver);
+
+static struct mdio_device_id __maybe_unused mtk_gphy_tbl[] = {
+	{ PHY_ID_MTK_GPHY, 0x0fffff00 },
+	{ }
+};
+
+MODULE_DEVICE_TABLE(mdio, mtk_gphy_tbl);
diff --git a/trunk/linux-4.4.x/drivers/net/phy/phy_device.c b/trunk/linux-4.4.x/drivers/net/phy/phy_device.c
index c6a878347..b6767f6eb 100644
--- a/trunk/linux-4.4.x/drivers/net/phy/phy_device.c
+++ b/trunk/linux-4.4.x/drivers/net/phy/phy_device.c
@@ -37,6 +37,10 @@
 
 #include <asm/irq.h>
 
+#ifdef CONFIG_AIROHA_PHY
+#include "airoha.h"
+#endif
+
 MODULE_DESCRIPTION("PHY library");
 MODULE_AUTHOR("Andy Fleming");
 MODULE_LICENSE("GPL");
@@ -323,25 +327,49 @@ static int get_phy_c45_ids(struct mii_bus *bus, int addr, u32 *phy_id,
 static int get_phy_id(struct mii_bus *bus, int addr, u32 *phy_id,
 		      bool is_c45, struct phy_c45_device_ids *c45_ids)
 {
-	int phy_reg;
+	int phy_reg_upper, phy_reg_lower;
+	u32 id;
 
 	if (is_c45)
 		return get_phy_c45_ids(bus, addr, phy_id, c45_ids);
 
+	/* SpaceX SATSW-26717: If we are booting the MRVL phy, the ID will be 0x01410dd1,
+	 * on our Econet PHY, this will not return properly, because we need to setup the PBUS first.
+	 * but will be caught by the CONFIG_AIROHA_PHY section. */
 	/* Grab the bits from PHYIR1, and put them in the upper half */
-	phy_reg = mdiobus_read(bus, addr, MII_PHYSID1);
-	if (phy_reg < 0)
-		return -EIO;
-
-	*phy_id = (phy_reg & 0xffff) << 16;
+	phy_reg_upper = mdiobus_read(bus, addr, MII_PHYSID1);
+	phy_reg_lower = mdiobus_read(bus, addr, MII_PHYSID2);
+	id = (phy_reg_upper & 0xffff) << 16 | (phy_reg_lower & 0xffff);
+
+	// EN8801S detection
+	#ifdef CONFIG_AIROHA_PHY
+	/* SpaceX: If we are the MRVL phy, skip modifying pbus to support Econet phy. */
+	if(id != 0x01410dd1)
+	{
+		unsigned long pbus_data;
+		unsigned int pbusAddress;
+
+		for(pbusAddress=PHY_ADDRESS_RANGE;pbusAddress<PHY_MAX_ADDR;pbusAddress++)
+		{
+			pbus_data = En8801_varPbusRegRd(bus,pbusAddress,EN8801S_RG_ETHER_PHY_OUI);      //PHY OUI
+			if(pbus_data==EN8801S_PBUS_OUI)
+			{
+				pbus_data = En8801_varPbusRegRd(bus,pbusAddress,EN8801S_RG_SMI_ADDR);       //SMI ADDR
+				pbus_data = (pbus_data & 0xffff0000) | (unsigned long)(EN8801S_PBUS_PHY_ID<<8) | (unsigned long)(EN8801S_MDIO_PHY_ID );
+				printk(KERN_INFO "[Airoha] EN8801S SMI_ADDR=%x (renew)\n",pbus_data);
+				En8801_varPbusRegWr(bus,pbusAddress, EN8801S_RG_SMI_ADDR,pbus_data);
+				*phy_id=0x03a29416;
+				return 0;
+			}
+		}
+	}
+	#endif
 
 	/* Grab the bits from PHYIR2, and put them in the lower half */
-	phy_reg = mdiobus_read(bus, addr, MII_PHYSID2);
-	if (phy_reg < 0)
+	if (phy_reg_upper < 0 || phy_reg_lower < 0)
 		return -EIO;
 
-	*phy_id |= (phy_reg & 0xffff);
-
+	*phy_id = id;
 	return 0;
 }
 
diff --git a/trunk/linux-4.4.x/drivers/net/phy/rtk/Makefile b/trunk/linux-4.4.x/drivers/net/phy/rtk/Makefile
new file mode 100644
index 000000000..ef067b695
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/rtk/Makefile
@@ -0,0 +1,66 @@
+obj-$(CONFIG_RTL8367S_GSW) += rtl8367s_gsw.o
+rtl8367s_gsw-objs := rtl8367s_mdio.o rtl8367s_dbg.o
+ifeq ($(CONFIG_SWCONFIG),y)
+rtl8367s_gsw-objs += rtl8367s.o
+endif
+rtl8367s_gsw-objs += rtl8367c/acl.o
+rtl8367s_gsw-objs += rtl8367c/cpu.o
+rtl8367s_gsw-objs += rtl8367c/dot1x.o
+rtl8367s_gsw-objs += rtl8367c/eee.o
+rtl8367s_gsw-objs += rtl8367c/igmp.o
+rtl8367s_gsw-objs += rtl8367c/interrupt.o
+rtl8367s_gsw-objs += rtl8367c/l2.o
+rtl8367s_gsw-objs += rtl8367c/leaky.o
+rtl8367s_gsw-objs += rtl8367c/led.o
+rtl8367s_gsw-objs += rtl8367c/mirror.o
+rtl8367s_gsw-objs += rtl8367c/oam.o
+rtl8367s_gsw-objs += rtl8367c/port.o
+rtl8367s_gsw-objs += rtl8367c/ptp.o
+rtl8367s_gsw-objs += rtl8367c/qos.o
+rtl8367s_gsw-objs += rtl8367c/rate.o
+rtl8367s_gsw-objs += rtl8367c/rldp.o
+rtl8367s_gsw-objs += rtl8367c/rtk_switch.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_acl.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_cputag.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_dot1x.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_eav.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_eee.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_fc.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_green.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_hsb.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_igmp.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_inbwctrl.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_interrupt.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_led.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_lut.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_meter.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_mib.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_mirror.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_misc.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_oam.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_phy.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_port.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_portIsolation.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_qos.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_rldp.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_rma.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_scheduling.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_storm.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_svlan.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_trunking.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_unknownMulticast.o
+rtl8367s_gsw-objs += rtl8367c/rtl8367c_asicdrv_vlan.o
+rtl8367s_gsw-objs += rtl8367c/smi.o
+rtl8367s_gsw-objs += rtl8367c/stat.o
+rtl8367s_gsw-objs += rtl8367c/storm.o
+rtl8367s_gsw-objs += rtl8367c/svlan.o
+rtl8367s_gsw-objs += rtl8367c/trap.o
+rtl8367s_gsw-objs += rtl8367c/trunk.o
+rtl8367s_gsw-objs += rtl8367c/vlan.o
+
+ccflags-y += -Werror -D_LITTLE_ENDIAN -DMDC_MDIO_OPERATION
+
+ccflags-y += -Idrivers/net/ethernet/raeth/rtl8367c/include
+ccflags-y += -Iinclude/linux/
+
diff --git a/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s.c b/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s.c
new file mode 100644
index 000000000..6a55631d5
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s.c
@@ -0,0 +1,580 @@
+/*
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/delay.h>
+#include <linux/skbuff.h>
+#include <linux/switch.h>
+
+//include from rtl8367c dir
+#include  "./rtl8367c/include/rtk_switch.h"
+#include  "./rtl8367c/include/vlan.h"
+#include  "./rtl8367c/include/stat.h"
+#include  "./rtl8367c/include/port.h"
+
+#define RTL8367C_SW_CPU_PORT    6
+
+ //RTL8367C_PHY_PORT_NUM + ext0 + ext1
+#define RTL8367C_NUM_PORTS 7 
+#define RTL8367C_NUM_VIDS  4096   
+
+struct rtl8367_priv {
+	struct switch_dev	swdev;
+	bool			global_vlan_enable;
+};
+
+struct rtl8367_mib_counter {	
+	const char *name;
+};
+
+struct rtl8367_vlan_info {
+	unsigned short	vid;
+	unsigned int	untag;
+	unsigned int	member;
+	unsigned char		fid;
+};
+
+struct rtl8367_priv  rtl8367_priv_data;
+
+unsigned int rtl8367c_port_id[RTL8367C_NUM_PORTS]={0,1,2,3,4,EXT_PORT1,EXT_PORT0};
+
+void (*rtl8367_switch_reset_func)(void)=NULL;
+
+static  struct rtl8367_mib_counter  rtl8367c_mib_counters[] = {
+	{"ifInOctets"},
+	{"dot3StatsFCSErrors"},
+	{"dot3StatsSymbolErrors"},
+	{"dot3InPauseFrames"},
+	{"dot3ControlInUnknownOpcodes"},
+	{"etherStatsFragments"},
+	{"etherStatsJabbers"},
+	{"ifInUcastPkts"},
+	{"etherStatsDropEvents"},
+	{"etherStatsOctets"},
+	{"etherStatsUndersizePkts"},
+	{"etherStatsOversizePkts"},
+	{"etherStatsPkts64Octets"},
+	{"etherStatsPkts65to127Octets"},
+	{"etherStatsPkts128to255Octets"},
+	{"etherStatsPkts256to511Octets"},
+	{"etherStatsPkts512to1023Octets"},
+	{"etherStatsPkts1024toMaxOctets"},
+	{"etherStatsMcastPkts"}, 
+	{"etherStatsBcastPkts"},
+	{"ifOutOctets"},
+	{"dot3StatsSingleCollisionFrames"},
+	{"dot3StatsMultipleCollisionFrames"},
+	{"dot3StatsDeferredTransmissions"},
+	{"dot3StatsLateCollisions"}, 
+	{"etherStatsCollisions"},
+	{"dot3StatsExcessiveCollisions"},
+	{"dot3OutPauseFrames"},
+	{"dot1dBasePortDelayExceededDiscards"},
+	{"dot1dTpPortInDiscards"},
+	{"ifOutUcastPkts"},
+	{"ifOutMulticastPkts"},
+	{"ifOutBrocastPkts"},
+	{"outOampduPkts"},
+	{"inOampduPkts"},
+	{"pktgenPkts"},
+	{"inMldChecksumError"},
+	{"inIgmpChecksumError"},
+	{"inMldSpecificQuery"},
+	{"inMldGeneralQuery"},
+	{"inIgmpSpecificQuery"},
+	{"inIgmpGeneralQuery"},
+	{"inMldLeaves"},
+	{"inIgmpLeaves"},
+	{"inIgmpJoinsSuccess"},
+	{"inIgmpJoinsFail"},
+	{"inMldJoinsSuccess"},
+	{"inMldJoinsFail"},
+	{"inReportSuppressionDrop"},
+	{"inLeaveSuppressionDrop"},
+	{"outIgmpReports"},
+	{"outIgmpLeaves"},
+	{"outIgmpGeneralQuery"},
+	{"outIgmpSpecificQuery"},
+	{"outMldReports"},
+	{"outMldLeaves"},
+	{"outMldGeneralQuery"},
+	{"outMldSpecificQuery"},
+	{"inKnownMulticastPkts"},
+	{"ifInMulticastPkts"},
+	{"ifInBroadcastPkts"},
+	{"ifOutDiscards"}
+};
+
+/*rtl8367c  proprietary switch API wrapper */
+static inline unsigned int rtl8367c_sw_to_phy_port(int port)
+{
+	return rtl8367c_port_id[port];
+}
+
+static inline unsigned int rtl8367c_portmask_phy_to_sw(rtk_portmask_t phy_portmask)
+{
+	int i;
+	for (i = 0; i < RTL8367C_NUM_PORTS; i++) {
+		if(RTK_PORTMASK_IS_PORT_SET(phy_portmask,rtl8367c_sw_to_phy_port(i))) {
+			RTK_PORTMASK_PORT_CLEAR(phy_portmask,rtl8367c_sw_to_phy_port(i));
+			RTK_PORTMASK_PORT_SET(phy_portmask,i);
+		}		
+
+	}
+	return (unsigned int)phy_portmask.bits[0];
+}
+
+static int rtl8367c_reset_mibs(void)
+{
+	return rtk_stat_global_reset();
+}
+
+static int rtl8367c_reset_port_mibs(int port)
+{
+
+	return rtk_stat_port_reset(rtl8367c_sw_to_phy_port(port));
+}
+
+static int rtl8367c_get_mibs_num(void)
+{
+	return ARRAY_SIZE(rtl8367c_mib_counters);
+}
+
+static const char *rtl8367c_get_mib_name(int idx)
+{
+	
+	return rtl8367c_mib_counters[idx].name;
+}
+
+static int rtl8367c_get_port_mib_counter(int idx, int port, unsigned long long *counter)
+{
+	return rtk_stat_port_get(rtl8367c_sw_to_phy_port(port), idx, counter);
+}
+
+static int rtl8367c_is_vlan_valid(unsigned int vlan)
+{
+	unsigned max = RTL8367C_NUM_VIDS;	
+
+	if (vlan == 0 || vlan >= max)
+		return 0;
+
+	return 1;
+}
+
+static int rtl8367c_get_vlan( unsigned short vid, struct rtl8367_vlan_info *vlan)
+{	
+	rtk_vlan_cfg_t vlan_cfg;
+
+	memset(vlan, '\0', sizeof(struct rtl8367_vlan_info));
+
+	if (vid >= RTL8367C_NUM_VIDS)
+		return -EINVAL;	
+
+	if(rtk_vlan_get(vid,&vlan_cfg))
+       	return -EINVAL;		
+	
+	vlan->vid = vid;
+	vlan->member = rtl8367c_portmask_phy_to_sw(vlan_cfg.mbr);	
+	vlan->untag = rtl8367c_portmask_phy_to_sw(vlan_cfg.untag);	
+	vlan->fid = vlan_cfg.fid_msti;
+
+	return 0;
+}
+
+static int rtl8367c_set_vlan( unsigned short vid, u32 mbr, u32 untag, u8 fid)
+{	
+	rtk_vlan_cfg_t vlan_cfg;
+	int i;
+
+	memset(&vlan_cfg, 0x00, sizeof(rtk_vlan_cfg_t));	
+
+	for (i = 0; i < RTL8367C_NUM_PORTS; i++) {
+		if (mbr & (1 << i)) {
+			RTK_PORTMASK_PORT_SET(vlan_cfg.mbr, rtl8367c_sw_to_phy_port(i));
+			if(untag & (1 << i))
+				RTK_PORTMASK_PORT_SET(vlan_cfg.untag, rtl8367c_sw_to_phy_port(i));			
+		}
+	}
+	vlan_cfg.fid_msti=fid;
+	vlan_cfg.ivl_en = 1;
+	return rtk_vlan_set(vid, &vlan_cfg);
+}
+
+
+static int rtl8367c_get_pvid( int port, int *pvid)
+{
+	u32 prio=0;
+	
+	if (port >= RTL8367C_NUM_PORTS)
+		return -EINVAL;		
+
+	return rtk_vlan_portPvid_get(rtl8367c_sw_to_phy_port(port),pvid,&prio);
+}
+
+
+static int rtl8367c_set_pvid( int port, int pvid)
+{
+	u32 prio=0;
+	
+	if (port >= RTL8367C_NUM_PORTS)
+		return -EINVAL;		
+
+	return rtk_vlan_portPvid_set(rtl8367c_sw_to_phy_port(port),pvid,prio);
+}
+
+static int rtl8367c_get_port_link(int port, int *link, int *speed, int *duplex)
+{
+	
+	if(rtk_port_phyStatus_get(rtl8367c_sw_to_phy_port(port),(rtk_port_linkStatus_t *)link,
+					(rtk_port_speed_t *)speed,(rtk_port_duplex_t *)duplex))
+		return -EINVAL;
+
+	return 0;
+}
+
+/*common rtl8367 swconfig entry API*/
+
+static int
+rtl8367_sw_set_vlan_enable(struct switch_dev *dev,
+			   const struct switch_attr *attr,
+			   struct switch_val *val)
+{
+	struct rtl8367_priv *priv = container_of(dev, struct rtl8367_priv, swdev);	
+
+	priv->global_vlan_enable = val->value.i ;
+
+	return 0;
+}
+
+static int
+rtl8367_sw_get_vlan_enable(struct switch_dev *dev,
+			   const struct switch_attr *attr,
+			   struct switch_val *val)
+{
+	struct rtl8367_priv *priv = container_of(dev, struct rtl8367_priv, swdev);
+
+	val->value.i = priv->global_vlan_enable;
+
+	return 0;
+}
+
+static int rtl8367_sw_reset_mibs(struct switch_dev *dev,
+				  const struct switch_attr *attr,
+				  struct switch_val *val)
+{
+	return rtl8367c_reset_mibs();
+}
+
+
+static int rtl8367_sw_reset_port_mibs(struct switch_dev *dev,
+				       const struct switch_attr *attr,
+				       struct switch_val *val)
+{
+	int port;
+
+	port = val->port_vlan;
+	if (port >= RTL8367C_NUM_PORTS)
+		return -EINVAL;
+
+	return rtl8367c_reset_port_mibs(port);
+}
+
+static int rtl8367_sw_get_port_mib(struct switch_dev *dev,
+			    const struct switch_attr *attr,
+			    struct switch_val *val)
+{	
+	int i, len = 0;
+	unsigned long long counter = 0;
+	static char mib_buf[4096];
+
+	if (val->port_vlan >= RTL8367C_NUM_PORTS)
+		return -EINVAL;
+
+	len += snprintf(mib_buf + len, sizeof(mib_buf) - len,
+			"Port %d MIB counters\n",
+			val->port_vlan);	
+
+	for (i = 0; i <rtl8367c_get_mibs_num(); ++i) {
+		len += snprintf(mib_buf + len, sizeof(mib_buf) - len,
+				"%-36s: ",rtl8367c_get_mib_name(i));
+		if (!rtl8367c_get_port_mib_counter(i, val->port_vlan,
+					       &counter))
+			len += snprintf(mib_buf + len, sizeof(mib_buf) - len,
+					"%llu\n", counter);
+		else
+			len += snprintf(mib_buf + len, sizeof(mib_buf) - len,
+					"%s\n", "N/A");
+	}
+
+	val->value.s = mib_buf;
+	val->len = len;
+	return 0;
+}
+
+
+static int rtl8367_sw_get_vlan_info(struct switch_dev *dev,
+			     const struct switch_attr *attr,
+			     struct switch_val *val)
+{	
+	int i;
+	u32 len = 0;
+	struct rtl8367_vlan_info vlan;
+	static char vlan_buf[256];
+	int err;
+
+	if (!rtl8367c_is_vlan_valid(val->port_vlan))
+		return -EINVAL;
+
+	memset(vlan_buf, '\0', sizeof(vlan_buf));
+
+	err = rtl8367c_get_vlan(val->port_vlan, &vlan);
+	if (err)
+		return err;
+
+	len += snprintf(vlan_buf + len, sizeof(vlan_buf) - len,
+			"VLAN %d: Ports: '", vlan.vid);
+
+	for (i = 0; i <RTL8367C_NUM_PORTS; i++) {
+		if (!(vlan.member & (1 << i)))
+			continue;
+
+		len += snprintf(vlan_buf + len, sizeof(vlan_buf) - len, "%d%s", i,
+				(vlan.untag & (1 << i)) ? "" : "t");
+	}
+
+	len += snprintf(vlan_buf + len, sizeof(vlan_buf) - len,
+			"', members=%04x, untag=%04x, fid=%u",
+			vlan.member, vlan.untag, vlan.fid);
+
+	val->value.s = vlan_buf;
+	val->len = len;
+
+	return 0;
+}
+
+
+static int rtl8367_sw_get_vlan_ports(struct switch_dev *dev, struct switch_val *val)
+{
+	struct switch_port *port;
+	struct rtl8367_vlan_info vlan;
+	int i;	
+	
+	if (!rtl8367c_is_vlan_valid(val->port_vlan))
+		return -EINVAL;
+
+	if(rtl8367c_get_vlan(val->port_vlan, &vlan))
+		return -EINVAL;
+
+	port = &val->value.ports[0];
+	val->len = 0;
+	for (i = 0; i <RTL8367C_NUM_PORTS ; i++) {
+		if (!(vlan.member & BIT(i)))
+			continue;
+
+		port->id = i;
+		port->flags = (vlan.untag & BIT(i)) ?
+					0 : BIT(SWITCH_PORT_FLAG_TAGGED);
+		val->len++;
+		port++;
+	}
+	return 0;
+}
+
+
+static int rtl8367_sw_set_vlan_ports(struct switch_dev *dev, struct switch_val *val)
+{
+	struct switch_port *port;
+	u32 member = 0;
+	u32 untag = 0;
+	u8 fid=0;
+	int err;
+	int i;	
+	
+	if (!rtl8367c_is_vlan_valid(val->port_vlan))
+		return -EINVAL;
+
+	port = &val->value.ports[0];
+	for (i = 0; i < val->len; i++, port++) {
+		int pvid = 0;
+		member |= BIT(port->id);
+
+		if (!(port->flags & BIT(SWITCH_PORT_FLAG_TAGGED)))
+			untag |= BIT(port->id);
+
+		/*
+		 * To ensure that we have a valid MC entry for this VLAN,
+		 * initialize the port VLAN ID here.
+		 */
+		err = rtl8367c_get_pvid(port->id, &pvid);
+		if (err < 0)
+			return err;
+		if (pvid == 0) {
+			err = rtl8367c_set_pvid(port->id, val->port_vlan);
+			if (err < 0)
+				return err;
+		}
+	}
+
+	//pr_info("[%s] vid=%d , mem=%x,untag=%x,fid=%d \n",__func__,val->port_vlan,member,untag,fid);
+
+	return rtl8367c_set_vlan(val->port_vlan, member, untag, fid);	
+
+}
+
+
+static int rtl8367_sw_get_port_pvid(struct switch_dev *dev, int port, int *val)
+{
+	return rtl8367c_get_pvid(port, val);
+}
+
+
+static int rtl8367_sw_set_port_pvid(struct switch_dev *dev, int port, int val)
+{	
+	return rtl8367c_set_pvid(port, val);
+}
+
+
+static int rtl8367_sw_reset_switch(struct switch_dev *dev)
+{
+	if(rtl8367_switch_reset_func)
+		(*rtl8367_switch_reset_func)();
+	else
+		printk("rest switch is not supported\n");
+
+	return 0;
+}
+
+static int rtl8367_sw_get_port_link(struct switch_dev *dev, int port,
+				    struct switch_port_link *link)
+{	
+	int speed;
+
+	if (port >= RTL8367C_NUM_PORTS)
+		return -EINVAL;
+
+	if(rtl8367c_get_port_link(port,(int *)&link->link,(int *)&speed,(int *)&link->duplex))
+		return -EINVAL;		
+
+	if (!link->link)
+		return 0;	
+
+	switch (speed) {
+	case 0:
+		link->speed = SWITCH_PORT_SPEED_10;
+		break;
+	case 1:
+		link->speed = SWITCH_PORT_SPEED_100;
+		break;
+	case 2:
+		link->speed = SWITCH_PORT_SPEED_1000;
+		break;
+	default:
+		link->speed = SWITCH_PORT_SPEED_UNKNOWN;
+		break;
+	}
+
+	return 0;
+}
+
+
+static struct switch_attr rtl8367_globals[] = {
+	{
+		.type = SWITCH_TYPE_INT,
+		.name = "enable_vlan",
+		.description = "Enable VLAN mode",
+		.set = rtl8367_sw_set_vlan_enable,
+		.get = rtl8367_sw_get_vlan_enable,
+		.max = 1,		
+	}, {		
+		.type = SWITCH_TYPE_NOVAL,
+		.name = "reset_mibs",
+		.description = "Reset all MIB counters",
+		.set = rtl8367_sw_reset_mibs,
+	}
+};
+
+static struct switch_attr rtl8367_port[] = {
+	{
+		.type = SWITCH_TYPE_NOVAL,
+		.name = "reset_mib",
+		.description = "Reset single port MIB counters",
+		.set = rtl8367_sw_reset_port_mibs,
+	}, {
+		.type = SWITCH_TYPE_STRING,
+		.name = "mib",
+		.description = "Get MIB counters for port",
+		//.max = 33,
+		.set = NULL,
+		.get = rtl8367_sw_get_port_mib,
+	},
+};
+
+static struct switch_attr rtl8367_vlan[] = {
+	{
+		.type = SWITCH_TYPE_STRING,
+		.name = "info",
+		.description = "Get vlan information",
+		.max = 1,
+		.set = NULL,
+		.get = rtl8367_sw_get_vlan_info,
+	},
+};
+
+static const struct switch_dev_ops rtl8367_sw_ops = {
+	.attr_global = {
+		.attr = rtl8367_globals,
+		.n_attr = ARRAY_SIZE(rtl8367_globals),
+	},
+	.attr_port = {
+		.attr = rtl8367_port,
+		.n_attr = ARRAY_SIZE(rtl8367_port),
+	},
+	.attr_vlan = {
+		.attr = rtl8367_vlan,
+		.n_attr = ARRAY_SIZE(rtl8367_vlan),
+	},
+
+	.get_vlan_ports = rtl8367_sw_get_vlan_ports,
+	.set_vlan_ports = rtl8367_sw_set_vlan_ports,
+	.get_port_pvid = rtl8367_sw_get_port_pvid,
+	.set_port_pvid = rtl8367_sw_set_port_pvid,
+	.reset_switch = rtl8367_sw_reset_switch,
+	.get_port_link = rtl8367_sw_get_port_link,
+};
+
+int rtl8367s_swconfig_init(void (*reset_func)(void))
+{
+	struct rtl8367_priv  *priv = &rtl8367_priv_data;
+	struct switch_dev *dev=&priv->swdev;
+	int err=0;
+
+	rtl8367_switch_reset_func = reset_func ;
+	
+	memset(priv, 0, sizeof(struct rtl8367_priv));	
+	priv->global_vlan_enable =0;
+
+	dev->name = "RTL8367C";
+	dev->cpu_port = RTL8367C_SW_CPU_PORT;
+	dev->ports = RTL8367C_NUM_PORTS;
+	dev->vlans = RTL8367C_NUM_VIDS;
+	dev->ops = &rtl8367_sw_ops;
+	dev->alias = "RTL8367C";		
+	err = register_switch(dev, NULL);
+
+	pr_info("[%s]\n",__func__);
+
+	return err;
+}
diff --git a/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s_dbg.c b/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s_dbg.c
new file mode 100644
index 000000000..ec8667971
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s_dbg.c
@@ -0,0 +1,655 @@
+#include <linux/uaccess.h>
+#include <linux/trace_seq.h>
+#include <linux/seq_file.h>
+#include <linux/proc_fs.h>
+#include <linux/u64_stats_sync.h>
+
+#include  "./rtl8367c/include/rtk_switch.h"
+#include  "./rtl8367c/include/port.h"
+#include  "./rtl8367c/include/vlan.h"
+#include  "./rtl8367c/include/rtl8367c_asicdrv_port.h"
+#include  "./rtl8367c/include/stat.h"
+#include  "./rtl8367c/include/l2.h"
+#include  "./rtl8367c/include/smi.h"
+#include  "./rtl8367c/include/mirror.h"
+#include  "./rtl8367c/include/igmp.h"
+#include  "./rtl8367c/include/leaky.h"
+
+static struct proc_dir_entry *proc_reg_dir;
+static struct proc_dir_entry *proc_esw_cnt;
+static struct proc_dir_entry *proc_vlan_cnt;
+static struct proc_dir_entry *proc_mac_tbl;
+static struct proc_dir_entry *proc_reg;
+static struct proc_dir_entry *proc_phyreg;
+static struct proc_dir_entry *proc_mirror;
+static struct proc_dir_entry *proc_igmp;
+
+#define PROCREG_ESW_CNT         "esw_cnt"
+#define PROCREG_VLAN            "vlan"
+#define PROCREG_MAC_TBL            "mac_tbl"
+#define PROCREG_REG            "reg"
+#define PROCREG_PHYREG            "phyreg"
+#define PROCREG_MIRROR            "mirror"
+#define PROCREG_IGMP            "igmp"
+#define PROCREG_DIR             "rtk_gsw"
+
+#define RTK_SW_VID_RANGE        16
+
+static void rtk_dump_mib_type(rtk_stat_port_type_t cntr_idx)
+{
+	rtk_port_t port;
+	rtk_stat_counter_t Cntr;
+
+	for (port = UTP_PORT0; port < (UTP_PORT0 + 5); port++) {
+		rtk_stat_port_get(port, cntr_idx, &Cntr);
+		printk("%8llu", Cntr);
+	}
+
+	for (port = EXT_PORT0; port < (EXT_PORT0 + 2); port++) {
+		rtk_stat_port_get(port, cntr_idx, &Cntr);
+		printk("%8llu", Cntr);
+	}
+	
+	printk("\n");
+}
+static void rtk_hal_dump_mib(void)
+{
+
+	printk("==================%8s%8s%8s%8s%8s%8s%8s\n", "Port0", "Port1",
+	       "Port2", "Port3", "Port4", "Port16", "Port17");
+	/* Get TX Unicast Pkts */
+	printk("TX Unicast Pkts  :");
+	rtk_dump_mib_type(STAT_IfOutUcastPkts);
+	/* Get TX Multicast Pkts */
+	printk("TX Multicast Pkts:");
+	rtk_dump_mib_type(STAT_IfOutMulticastPkts);
+	/* Get TX BroadCast Pkts */
+	printk("TX BroadCast Pkts:");
+	rtk_dump_mib_type(STAT_IfOutBroadcastPkts);
+	/* Get TX Collisions */
+	/* Get TX Puase Frames */
+	printk("TX Pause Frames  :");
+	rtk_dump_mib_type(STAT_Dot3OutPauseFrames);
+	/* Get TX Drop Events */
+	/* Get RX Unicast Pkts */
+	printk("RX Unicast Pkts  :");
+	rtk_dump_mib_type(STAT_IfInUcastPkts);
+	/* Get RX Multicast Pkts */
+	printk("RX Multicast Pkts:");
+	rtk_dump_mib_type(STAT_IfInMulticastPkts);
+	/* Get RX Broadcast Pkts */
+	printk("RX Broadcast Pkts:");
+	rtk_dump_mib_type(STAT_IfInBroadcastPkts);
+	/* Get RX FCS Erros */
+	printk("RX FCS Errors    :");
+	rtk_dump_mib_type(STAT_Dot3StatsFCSErrors);
+	/* Get RX Undersize Pkts */
+	printk("RX Undersize Pkts:");
+	rtk_dump_mib_type(STAT_EtherStatsUnderSizePkts);
+	/* Get RX Discard Pkts */
+	printk("RX Discard Pkts  :");
+	rtk_dump_mib_type(STAT_Dot1dTpPortInDiscards);
+	/* Get RX Fragments */
+	printk("RX Fragments     :");
+	rtk_dump_mib_type(STAT_EtherStatsFragments);
+	/* Get RX Oversize Pkts */
+	printk("RX Oversize Pkts :");
+	rtk_dump_mib_type(STAT_EtherOversizeStats);
+	/* Get RX Jabbers */
+	printk("RX Jabbers       :");
+	rtk_dump_mib_type(STAT_EtherStatsJabbers);
+	/* Get RX Pause Frames */
+	printk("RX Pause Frames  :");
+	rtk_dump_mib_type(STAT_Dot3InPauseFrames);
+	/* clear MIB */
+	rtk_stat_global_reset();
+	
+}
+
+static int rtk_hal_dump_vlan(void)
+{
+	rtk_vlan_cfg_t vlan;
+	int i;
+
+	printk("vid    portmap\n");
+	for (i = 0; i < RTK_SW_VID_RANGE; i++) {
+		rtk_vlan_get(i, &vlan);
+		printk("%3d    ", i);
+		printk("%c",
+		       RTK_PORTMASK_IS_PORT_SET(vlan.mbr,
+	                                UTP_PORT0) ? '1' : '-');
+		printk("%c",
+	       	RTK_PORTMASK_IS_PORT_SET(vlan.mbr,
+	                                UTP_PORT1) ? '1' : '-');
+		printk("%c",
+		       RTK_PORTMASK_IS_PORT_SET(vlan.mbr,
+	                                UTP_PORT2) ? '1' : '-');
+		printk("%c",
+		       RTK_PORTMASK_IS_PORT_SET(vlan.mbr,
+	                                UTP_PORT3) ? '1' : '-');
+		printk("%c",
+	       	RTK_PORTMASK_IS_PORT_SET(vlan.mbr,
+	                                UTP_PORT4) ? '1' : '-');
+		printk("%c",
+		       RTK_PORTMASK_IS_PORT_SET(vlan.mbr,
+	                                EXT_PORT0) ? '1' : '-');
+		printk("%c",
+		       RTK_PORTMASK_IS_PORT_SET(vlan.mbr,
+	                                EXT_PORT1) ? '1' : '-');
+		printk("\n");
+	}
+	
+	return 0;
+}
+
+static void rtk_hal_dump_table(void)
+{
+	rtk_uint32 i;
+	rtk_uint32 address = 0;
+	rtk_l2_ucastAddr_t l2_data;
+	rtk_l2_ipMcastAddr_t ipMcastAddr;
+	rtk_l2_age_time_t age_timout;
+
+	rtk_l2_aging_get(&age_timout);
+	printk("Mac table age timeout =%d\n",(unsigned int)age_timout);
+
+	printk("hash  port(0:17)   fid   vid  mac-address\n");
+	while (1) {
+		if (rtk_l2_addr_next_get(READMETHOD_NEXT_L2UC, UTP_PORT0, &address, &l2_data) != RT_ERR_OK) {
+			break;
+		} else {
+			printk("%03x   ", l2_data.address);
+			for (i = 0; i < 5; i++)
+				if ( l2_data.port == i)
+					printk("1");
+				else
+					printk("-");
+			for (i = 16; i < 18; i++)
+				if ( l2_data.port == i)
+					printk("1");
+				else
+					printk("-");
+
+			printk("      %2d", l2_data.fid);
+			printk("  %4d", l2_data.cvid);
+			printk("  %02x%02x%02x%02x%02x%02x\n", l2_data.mac.octet[0],
+			l2_data.mac.octet[1], l2_data.mac.octet[2], l2_data.mac.octet[3],
+			l2_data.mac.octet[4], l2_data.mac.octet[5]);
+			address ++;
+			}
+	}
+
+	address = 0;
+	while (1) {
+        if (rtk_l2_ipMcastAddr_next_get(&address, &ipMcastAddr) != RT_ERR_OK) {
+            break;
+        } else {
+            printk("%03x   ", ipMcastAddr.address);
+            for (i = 0; i < 5; i++)
+                printk("%c", RTK_PORTMASK_IS_PORT_SET(ipMcastAddr.portmask, i) ? '1' : '-');
+            for (i = 16; i < 18; i++)
+                printk("%c", RTK_PORTMASK_IS_PORT_SET(ipMcastAddr.portmask, i) ? '1' : '-');
+			printk("                ");
+			printk("01005E%06x\n", (ipMcastAddr.dip & 0xefffff));
+            address ++;
+            }
+    }
+}
+
+static void rtk_hal_clear_table(void)
+{
+        rtk_api_ret_t ret;
+
+        ret = rtk_l2_table_clear();
+        if (ret != RT_ERR_OK)
+                printk("rtk_l2_table_clear failed\n");
+}
+
+static void rtk_hal_read_reg(unsigned int reg_addr)
+{
+        ret_t retVal;
+	 unsigned int reg_val;
+
+        retVal = smi_read(reg_addr, &reg_val);
+
+        if(retVal != RT_ERR_OK)
+                printk("switch reg read failed\n");
+        else
+                printk("reg0x%x = 0x%x\n", reg_addr, reg_val);
+}
+
+static void rtk_hal_write_reg(unsigned int reg_addr , unsigned int reg_val)
+{
+        ret_t retVal;
+
+    retVal = smi_write(reg_addr, reg_val);
+
+    if(retVal != RT_ERR_OK)
+        printk("switch reg write failed\n");
+    else
+        printk("write switch reg0x%x 0x%x success\n", reg_addr, reg_val);
+}
+
+static void rtk_hal_get_phy_reg(unsigned int port ,unsigned int reg_addr )
+{
+        ret_t retVal;
+        rtk_port_phy_data_t Data;
+
+        retVal = rtk_port_phyReg_get(port, reg_addr, &Data);
+        if (retVal == RT_ERR_OK)
+                printk("Get: phy[%d].reg[%d] = 0x%04x\n", port, reg_addr, Data);
+        else
+                printk("read phy reg failed\n");
+}
+
+static void rtk_hal_set_phy_reg(unsigned int port ,unsigned int reg_addr,unsigned int reg_val)
+{
+        ret_t retVal;
+
+        retVal = rtk_port_phyReg_set(port, reg_addr, reg_val);
+        if (retVal == RT_ERR_OK)
+                printk("Set: phy[%d].reg[%d] = 0x%04x\n", port, reg_addr, reg_val);
+        else
+                printk("write phy reg failed\n");
+}
+
+static void rtk_hal_set_port_mirror(unsigned int port ,unsigned int rx_port_map,unsigned int tx_port_map)
+{
+        rtk_portmask_t rx_portmask;
+        rtk_portmask_t tx_portmask;
+        rtk_api_ret_t ret;
+        int i;
+
+        rtk_mirror_portIso_set(ENABLED);
+        RTK_PORTMASK_CLEAR(rx_portmask);
+        RTK_PORTMASK_CLEAR(tx_portmask);
+
+	for (i = 0; i < 5; i++)
+                if (rx_port_map & (1 << i))
+                        RTK_PORTMASK_PORT_SET(rx_portmask, i);
+
+        for (i = 0; i < 2; i++)
+                if (rx_port_map & (1 << (i + 5)))
+                        RTK_PORTMASK_PORT_SET(rx_portmask, (i + EXT_PORT0));
+
+        RTK_PORTMASK_CLEAR(tx_portmask);
+
+	for (i = 0; i < 5; i++)
+		if (tx_port_map & (1 << i))
+		           RTK_PORTMASK_PORT_SET(tx_portmask, i);
+
+	for (i = 0; i < 2; i++)
+		if (tx_port_map & (1 << (i + 5)))
+			RTK_PORTMASK_PORT_SET(tx_portmask, (i + EXT_PORT0));
+
+	ret = rtk_mirror_portBased_set(port, &rx_portmask, &tx_portmask);
+
+        if (!ret)
+                printk("rtk_mirror_portBased_set success\n");
+
+}
+
+static void rtk_hal_enable_igmpsnoop(int hw_on)
+{
+        rtk_api_ret_t ret;
+        rtk_portmask_t pmask;
+
+        ret = rtk_igmp_init();
+        if (hw_on == 1) {
+                RTK_PORTMASK_CLEAR(pmask);
+                RTK_PORTMASK_PORT_SET(pmask, EXT_PORT0);
+                ret |= rtk_igmp_static_router_port_set(&pmask);
+                ret |= rtk_igmp_protocol_set(UTP_PORT4, PROTOCOL_IGMPv1, IGMP_ACTION_FORWARD);
+                ret |= rtk_igmp_protocol_set(UTP_PORT4, PROTOCOL_IGMPv2, IGMP_ACTION_FORWARD);
+                ret |= rtk_igmp_protocol_set(UTP_PORT4, PROTOCOL_MLDv1, IGMP_ACTION_FORWARD);
+                ret |= rtk_igmp_protocol_set(EXT_PORT1, PROTOCOL_IGMPv1, IGMP_ACTION_FORWARD);
+                ret |= rtk_igmp_protocol_set(EXT_PORT1, PROTOCOL_IGMPv2, IGMP_ACTION_FORWARD);
+                ret |= rtk_igmp_protocol_set(EXT_PORT1, PROTOCOL_MLDv1, IGMP_ACTION_FORWARD);
+                ret |= rtk_igmp_protocol_set(UTP_PORT0, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+                ret |= rtk_igmp_protocol_set(UTP_PORT1, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+                ret |= rtk_igmp_protocol_set(UTP_PORT2, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+                ret |= rtk_igmp_protocol_set(UTP_PORT3, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+                ret |= rtk_igmp_protocol_set(EXT_PORT0, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+
+                ret |= rtk_leaky_vlan_set(LEAKY_IPMULTICAST, ENABLED);
+                ret |= rtk_l2_ipMcastForwardRouterPort_set(DISABLED);
+                /* drop unknown multicast packets*/
+                /* ret |= rtk_trap_unknownMcastPktAction_set(UTP_PORT4, MCAST_IPV4, MCAST_ACTION_DROP);*/
+        } else {
+		RTK_PORTMASK_CLEAR(pmask);
+		RTK_PORTMASK_PORT_SET(pmask, EXT_PORT0);
+		RTK_PORTMASK_PORT_SET(pmask, EXT_PORT1);
+                ret |= rtk_igmp_protocol_set(UTP_PORT0, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+                ret |= rtk_igmp_protocol_set(UTP_PORT1, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+                ret |= rtk_igmp_protocol_set(UTP_PORT2, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+                ret |= rtk_igmp_protocol_set(UTP_PORT3, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+                ret |= rtk_igmp_protocol_set(EXT_PORT0, PROTOCOL_IGMPv3, IGMP_ACTION_ASIC);
+
+                ret |= rtk_igmp_static_router_port_set(&pmask);
+        }
+
+        if(ret != RT_ERR_OK)
+                printk("enable switch igmpsnoop failed\n");
+
+}
+
+static void rtk_hal_disable_igmpsnoop(void)
+{
+        if (rtk_igmp_state_set(DISABLED) != RT_ERR_OK)
+                printk("Disable IGMP SNOOPING failed\n");
+}
+
+static ssize_t mac_tbl_write(struct file *file,
+                            const char __user *buffer, size_t count,
+                            loff_t *data)
+{
+	rtk_hal_clear_table();
+
+        return count;
+}
+
+
+static ssize_t phyreg_ops(struct file *file,
+                            const char __user *buffer, size_t count,
+                            loff_t *data)
+{
+        char buf[64];
+	 unsigned int port;
+        unsigned int offset;
+        unsigned int val;
+
+        memset(buf, 0, 64);
+
+        if (copy_from_user(buf, buffer, count))
+                return -EFAULT;
+
+
+        if(buf[0] == 'w') {
+
+                if(sscanf(buf, "w %d %x %x", &port,&offset,&val) == -1)
+                        return -EFAULT;
+                else
+                        rtk_hal_set_phy_reg(port,offset,val);
+
+        } else {
+
+		if(sscanf(buf, "r %d %x",&port, &offset) == -1)
+                        return -EFAULT;
+                else
+                        rtk_hal_get_phy_reg(port,offset);
+        }
+
+        return count;
+}
+
+static ssize_t reg_ops(struct file *file,
+                            const char __user *buffer, size_t count,
+                            loff_t *data)
+{
+        char buf[64];
+        unsigned int offset;
+        unsigned int val;
+
+        memset(buf, 0, 64);
+
+        if (copy_from_user(buf, buffer, count))
+                return -EFAULT;
+
+
+        if(buf[0] == 'w') {
+
+                if(sscanf(buf, "w %x %x", &offset,&val) == -1)
+                        return -EFAULT;
+                else
+                        rtk_hal_write_reg(offset,val);
+
+        } else {
+
+                if(sscanf(buf, "r %x", &offset) == -1)
+                        return -EFAULT;
+                else
+                        rtk_hal_read_reg(offset);
+        }
+
+        return count;
+}
+
+static ssize_t mirror_ops(struct file *file,
+                            const char __user *buffer, size_t count,
+                            loff_t *data)
+{
+        char buf[64];
+	 unsigned int port;
+        unsigned int tx_map,rx_map;
+
+        memset(buf, 0, 64);
+
+        if (copy_from_user(buf, buffer, count))
+                return -EFAULT;
+
+	if(sscanf(buf, "%d %x %x", &port,&rx_map,&tx_map) == -1)
+		return -EFAULT;
+	else
+		rtk_hal_set_port_mirror(port,rx_map,tx_map);
+
+        return count;
+}
+
+
+static ssize_t igmp_ops(struct file *file,
+                            const char __user *buffer, size_t count,
+                            loff_t *data)
+{
+        char buf[8];
+        unsigned int ops;
+
+        if (copy_from_user(buf, buffer, count))
+                return -EFAULT;
+
+	if(sscanf(buf, "%d", &ops) == -1)
+		return -EFAULT;
+
+        if(ops == 0)
+                rtk_hal_disable_igmpsnoop();
+	else if (ops == 1)
+		rtk_hal_enable_igmpsnoop(0);
+	else //hw igmp
+		rtk_hal_enable_igmpsnoop(1);
+
+        return count;
+}
+
+
+static int esw_cnt_read(struct seq_file *seq, void *v)
+{
+	rtk_hal_dump_mib();
+	return 0;
+}
+
+static int vlan_read(struct seq_file *seq, void *v)
+{
+	rtk_hal_dump_vlan();
+	return 0;
+}
+
+static int mac_tbl_read(struct seq_file *seq, void *v)
+{
+	rtk_hal_dump_table();
+	return 0;
+}
+
+static int reg_show(struct seq_file *seq, void *v)
+{
+	return 0;
+}
+
+static int phyreg_show(struct seq_file *seq, void *v)
+{
+	return 0;
+}
+
+static int mirror_show(struct seq_file *seq, void *v)
+{
+	return 0;
+}
+
+static int igmp_show(struct seq_file *seq, void *v)
+{
+	return 0;
+}
+
+static int switch_count_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, esw_cnt_read, 0);
+}
+
+static int switch_vlan_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, vlan_read, 0);
+}
+
+static int mac_tbl_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, mac_tbl_read, 0);
+}
+
+static int reg_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, reg_show, 0);
+}
+
+static int phyreg_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, phyreg_show, 0);
+}
+
+static int mirror_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, mirror_show, 0);
+}
+
+static int igmp_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, igmp_show, 0);
+}
+
+
+static const struct file_operations switch_count_fops = {
+	.owner = THIS_MODULE,
+	.open = switch_count_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release
+};
+
+static const struct file_operations switch_vlan_fops = {
+	.owner = THIS_MODULE,
+	.open = switch_vlan_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release
+};
+
+static const struct file_operations mac_tbl_fops = {
+        .owner = THIS_MODULE,
+        .open = mac_tbl_open,
+        .read = seq_read,
+        .llseek = seq_lseek,
+        .write = mac_tbl_write,
+        .release = single_release
+};
+
+static const struct file_operations reg_fops = {
+        .owner = THIS_MODULE,
+        .open = reg_open,
+        .read = seq_read,
+        .llseek = seq_lseek,
+        .write = reg_ops,
+        .release = single_release
+};
+
+static const struct file_operations phyreg_fops = {
+        .owner = THIS_MODULE,
+        .open = phyreg_open,
+        .read = seq_read,
+        .llseek = seq_lseek,
+        .write = phyreg_ops,
+        .release = single_release
+};
+
+static const struct file_operations mirror_fops = {
+        .owner = THIS_MODULE,
+        .open = mirror_open,
+        .read = seq_read,
+        .llseek = seq_lseek,
+        .write = mirror_ops,
+        .release = single_release
+};
+
+static const struct file_operations igmp_fops = {
+        .owner = THIS_MODULE,
+        .open = igmp_open,
+        .read = seq_read,
+        .llseek = seq_lseek,
+        .write = igmp_ops,
+        .release = single_release
+};
+
+int gsw_debug_proc_init(void)
+{
+
+	if (!proc_reg_dir)
+		proc_reg_dir = proc_mkdir(PROCREG_DIR, NULL);
+
+	proc_esw_cnt =
+	proc_create(PROCREG_ESW_CNT, 0, proc_reg_dir, &switch_count_fops);
+
+	if (!proc_esw_cnt)
+		pr_err("!! FAIL to create %s PROC !!\n", PROCREG_ESW_CNT);
+
+	proc_vlan_cnt =
+	proc_create(PROCREG_VLAN, 0, proc_reg_dir, &switch_vlan_fops);
+
+	if (!proc_vlan_cnt)
+		pr_err("!! FAIL to create %s PROC !!\n", PROCREG_VLAN);
+
+	proc_mac_tbl =
+	proc_create(PROCREG_MAC_TBL, 0, proc_reg_dir, &mac_tbl_fops);
+
+	if (!proc_mac_tbl)
+		pr_err("!! FAIL to create %s PROC !!\n", PROCREG_MAC_TBL);
+
+	proc_reg =
+	proc_create(PROCREG_REG, 0, proc_reg_dir, &reg_fops);
+
+	if (!proc_reg)
+		pr_err("!! FAIL to create %s PROC !!\n", PROCREG_REG);
+
+	proc_phyreg =
+	proc_create(PROCREG_PHYREG, 0, proc_reg_dir, &phyreg_fops);
+
+	if (!proc_phyreg)
+		pr_err("!! FAIL to create %s PROC !!\n", PROCREG_PHYREG);
+
+	proc_mirror =
+	proc_create(PROCREG_MIRROR, 0, proc_reg_dir, &mirror_fops);
+
+	if (!proc_mirror)
+		pr_err("!! FAIL to create %s PROC !!\n", PROCREG_MIRROR);
+
+	proc_igmp =
+	proc_create(PROCREG_IGMP, 0, proc_reg_dir, &igmp_fops);
+
+	if (!proc_igmp)
+		pr_err("!! FAIL to create %s PROC !!\n", PROCREG_IGMP);
+
+	return 0;
+}
+
+void gsw_debug_proc_exit(void)
+{
+	if (proc_esw_cnt)
+		remove_proc_entry(PROCREG_ESW_CNT, proc_reg_dir);
+}
+
+
diff --git a/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s_mdio.c b/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s_mdio.c
new file mode 100644
index 000000000..ae958e896
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/net/phy/rtk/rtl8367s_mdio.c
@@ -0,0 +1,312 @@
+/*
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+ 
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/delay.h>
+#include <linux/of_mdio.h>
+#include <linux/of_platform.h>
+#include <linux/of_gpio.h>
+
+
+#include  "./rtl8367c/include/rtk_switch.h"
+#include  "./rtl8367c/include/port.h"
+#include  "./rtl8367c/include/vlan.h"
+#include  "./rtl8367c/include/rtl8367c_asicdrv_port.h"
+
+struct rtk_gsw {
+ 	struct device           *dev;
+ 	struct mii_bus          *bus;
+	int reset_pin;
+};
+
+static struct rtk_gsw *_gsw;
+
+extern int gsw_debug_proc_init(void);
+extern void gsw_debug_proc_exit(void);
+
+#ifdef CONFIG_SWCONFIG
+extern int rtl8367s_swconfig_init( void (*reset_func)(void) );
+#endif
+
+/*mii_mgr_read/mii_mgr_write is the callback API for rtl8367 driver*/
+unsigned int mii_mgr_read(unsigned int phy_addr,unsigned int phy_register,unsigned int *read_data)
+{
+	struct mii_bus *bus = _gsw->bus;
+
+	mutex_lock_nested(&bus->mdio_lock, MDIO_MUTEX_NESTED);
+
+	*read_data = bus->read(bus, phy_addr, phy_register);
+
+	mutex_unlock(&bus->mdio_lock);
+
+	return 0;
+}
+
+unsigned int mii_mgr_write(unsigned int phy_addr,unsigned int phy_register,unsigned int write_data)
+{
+	struct mii_bus *bus =  _gsw->bus;
+
+	mutex_lock_nested(&bus->mdio_lock, MDIO_MUTEX_NESTED);
+
+	bus->write(bus, phy_addr, phy_register, write_data);
+
+	mutex_unlock(&bus->mdio_lock);
+	
+	return 0;
+}
+
+static int rtl8367s_hw_reset(void)
+{
+	struct rtk_gsw *gsw = _gsw;
+	int ret;
+
+	if (gsw->reset_pin < 0)
+		return 0;
+
+	ret = devm_gpio_request(gsw->dev, gsw->reset_pin, "mediatek,reset-pin");
+
+	if (ret)
+                printk("fail to devm_gpio_request\n");
+
+	gpio_direction_output(gsw->reset_pin, 0);
+
+	usleep_range(1000, 1100);
+
+	gpio_set_value(gsw->reset_pin, 1);
+
+	mdelay(500);
+
+	devm_gpio_free(gsw->dev, gsw->reset_pin);
+
+	return 0;
+	
+}
+
+static int rtl8367s_vlan_config(int want_at_p0)
+{
+	rtk_vlan_cfg_t vlan1, vlan2;
+	
+	/* Set LAN/WAN VLAN partition */
+	memset(&vlan1, 0x00, sizeof(rtk_vlan_cfg_t));
+
+	RTK_PORTMASK_PORT_SET(vlan1.mbr, EXT_PORT0);
+	RTK_PORTMASK_PORT_SET(vlan1.mbr, UTP_PORT1);
+	RTK_PORTMASK_PORT_SET(vlan1.mbr, UTP_PORT2);
+	RTK_PORTMASK_PORT_SET(vlan1.mbr, UTP_PORT3);
+	RTK_PORTMASK_PORT_SET(vlan1.untag, EXT_PORT0);
+	RTK_PORTMASK_PORT_SET(vlan1.untag, UTP_PORT1);
+	RTK_PORTMASK_PORT_SET(vlan1.untag, UTP_PORT2);
+	RTK_PORTMASK_PORT_SET(vlan1.untag, UTP_PORT3);
+  
+	 if (want_at_p0) {
+		RTK_PORTMASK_PORT_SET(vlan1.mbr, UTP_PORT4);
+		RTK_PORTMASK_PORT_SET(vlan1.untag, UTP_PORT4);
+        } else {
+		RTK_PORTMASK_PORT_SET(vlan1.mbr, UTP_PORT0);
+		RTK_PORTMASK_PORT_SET(vlan1.untag, UTP_PORT0);
+        }
+
+	vlan1.ivl_en = 1;
+	
+	rtk_vlan_set(1, &vlan1);
+	
+	memset(&vlan2, 0x00, sizeof(rtk_vlan_cfg_t));
+	
+	RTK_PORTMASK_PORT_SET(vlan2.mbr, EXT_PORT1);
+	RTK_PORTMASK_PORT_SET(vlan2.untag, EXT_PORT1);
+
+	if (want_at_p0) {
+		RTK_PORTMASK_PORT_SET(vlan2.mbr, UTP_PORT0);
+		RTK_PORTMASK_PORT_SET(vlan2.untag, UTP_PORT0);
+	} else {
+		RTK_PORTMASK_PORT_SET(vlan2.mbr, UTP_PORT4);
+		RTK_PORTMASK_PORT_SET(vlan2.untag, UTP_PORT4);
+	}
+
+	vlan2.ivl_en = 1;
+	rtk_vlan_set(2, &vlan2);
+
+	rtk_vlan_portPvid_set(EXT_PORT0, 1, 0);
+	rtk_vlan_portPvid_set(UTP_PORT1, 1, 0);
+	rtk_vlan_portPvid_set(UTP_PORT2, 1, 0);
+	rtk_vlan_portPvid_set(UTP_PORT3, 1, 0);
+	rtk_vlan_portPvid_set(EXT_PORT1, 2, 0);
+
+	if (want_at_p0) {
+		rtk_vlan_portPvid_set(UTP_PORT0, 2, 0);
+		rtk_vlan_portPvid_set(UTP_PORT4, 1, 0);
+	} else {
+		rtk_vlan_portPvid_set(UTP_PORT0, 1, 0);
+		rtk_vlan_portPvid_set(UTP_PORT4, 2, 0);
+	}
+
+	return 0;	
+}
+
+static int rtl8367s_hw_init(void)
+{
+
+	rtl8367s_hw_reset();
+
+	if(rtk_switch_init())
+	        return -1;
+
+	mdelay(500);
+
+	if (rtk_vlan_reset())
+	        return -1;
+
+	if (rtk_vlan_init())
+	        return -1;
+
+	return 0;
+}
+
+static void set_rtl8367s_sgmii(void)
+{
+	rtk_port_mac_ability_t mac_cfg;
+	rtk_mode_ext_t mode;
+
+	mode = MODE_EXT_HSGMII;
+	mac_cfg.forcemode = MAC_FORCE;
+	mac_cfg.speed = PORT_SPEED_2500M;
+	mac_cfg.duplex = PORT_FULL_DUPLEX;
+	mac_cfg.link = PORT_LINKUP;
+	mac_cfg.nway = DISABLED;
+	mac_cfg.txpause = ENABLED;
+	mac_cfg.rxpause = ENABLED;
+	rtk_port_macForceLinkExt_set(EXT_PORT0, mode, &mac_cfg);
+	rtk_port_sgmiiNway_set(EXT_PORT0, DISABLED);
+	rtk_port_phyEnableAll_set(ENABLED);
+
+}
+
+static void set_rtl8367s_rgmii(void)
+{
+	rtk_port_mac_ability_t mac_cfg;
+	rtk_mode_ext_t mode;
+
+	mode = MODE_EXT_RGMII;
+	mac_cfg.forcemode = MAC_FORCE;
+	mac_cfg.speed = PORT_SPEED_1000M;
+	mac_cfg.duplex = PORT_FULL_DUPLEX;
+	mac_cfg.link = PORT_LINKUP;
+	mac_cfg.nway = DISABLED;
+	mac_cfg.txpause = ENABLED;
+	mac_cfg.rxpause = ENABLED;
+	rtk_port_macForceLinkExt_set(EXT_PORT1, mode, &mac_cfg);
+	rtk_port_rgmiiDelayExt_set(EXT_PORT1, 1, 3);
+	rtk_port_phyEnableAll_set(ENABLED);
+	
+}
+
+void init_gsw(void)
+{
+	rtl8367s_hw_init();
+	set_rtl8367s_sgmii();
+	set_rtl8367s_rgmii();
+}
+
+// bleow are platform driver
+static const struct of_device_id rtk_gsw_match[] = {
+	{ .compatible = "mediatek,rtk-gsw" },
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, rtk_gsw_match);
+
+static int rtk_gsw_probe(struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	struct device_node *mdio;
+	struct mii_bus *mdio_bus;
+	struct rtk_gsw *gsw;
+	const char *pm;
+
+	mdio = of_parse_phandle(np, "mediatek,mdio", 0);
+
+	if (!mdio)
+		return -EINVAL;
+
+	mdio_bus = of_mdio_find_bus(mdio);
+
+	if (!mdio_bus)
+		return -EPROBE_DEFER;
+
+	gsw = devm_kzalloc(&pdev->dev, sizeof(struct rtk_gsw), GFP_KERNEL);
+	
+	if (!gsw)
+		return -ENOMEM;	
+
+	gsw->dev = &pdev->dev;
+
+	gsw->bus = mdio_bus;
+
+	gsw->reset_pin = of_get_named_gpio(np, "mediatek,reset-pin", 0);
+
+	_gsw = gsw;
+
+	init_gsw();
+
+	//init default vlan or init swocnfig
+	if(!of_property_read_string(pdev->dev.of_node,
+						"mediatek,port_map", &pm)) {
+
+		if (!strcasecmp(pm, "wllll"))
+			rtl8367s_vlan_config(1); 
+		else
+			rtl8367s_vlan_config(0);
+		
+		} else {
+#ifdef CONFIG_SWCONFIG		
+		rtl8367s_swconfig_init(&init_gsw);
+#else
+		rtl8367s_vlan_config(0);
+#endif
+	}
+
+	gsw_debug_proc_init();
+
+	platform_set_drvdata(pdev, gsw);
+
+	return 0;
+	
+}
+
+static int rtk_gsw_remove(struct platform_device *pdev)
+{
+	platform_set_drvdata(pdev, NULL);
+	gsw_debug_proc_exit();
+
+	return 0;
+}
+
+static struct platform_driver gsw_driver = {
+	.probe = rtk_gsw_probe,
+	.remove = rtk_gsw_remove,
+	.driver = {
+		.name = "rtk-gsw",
+		.owner = THIS_MODULE,
+		.of_match_table = rtk_gsw_match,
+	},
+};
+
+module_platform_driver(gsw_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Mark Lee <marklee0201@gmail.com>");
+MODULE_DESCRIPTION("rtl8367c switch driver for MT7622");
+
diff --git a/trunk/linux-4.4.x/drivers/net/ppp/ppp_generic.c b/trunk/linux-4.4.x/drivers/net/ppp/ppp_generic.c
index db53b437c..83e1bf01e 100644
--- a/trunk/linux-4.4.x/drivers/net/ppp/ppp_generic.c
+++ b/trunk/linux-4.4.x/drivers/net/ppp/ppp_generic.c
@@ -1157,7 +1157,7 @@ static void ppp_dev_priv_destructor(struct net_device *dev)
 
 static int ppp_hnat_check(struct hnat_hw_path *path)
 {
-        struct ppp *ppp = netdev_priv(path->dev);
+        struct ppp *ppp = netdev_priv(path->real_dev);
         struct ppp_channel *chan;
         struct channel *pch;
 
diff --git a/trunk/linux-4.4.x/drivers/net/ppp/pppoe.c b/trunk/linux-4.4.x/drivers/net/ppp/pppoe.c
index 6701f1df9..50625f8f2 100644
--- a/trunk/linux-4.4.x/drivers/net/ppp/pppoe.c
+++ b/trunk/linux-4.4.x/drivers/net/ppp/pppoe.c
@@ -496,8 +496,8 @@ static int pppoe_disc_rcv(struct sk_buff *skb, struct net_device *dev,
 	if (!skb)
 		goto out;
 
-	if (skb->pkt_type != PACKET_HOST)
-		goto abort;
+	if (skb->pkt_type != PACKET_HOST)
+		goto abort;
 
 	if (!pskb_may_pull(skb, sizeof(struct pppoe_hdr)))
 		goto abort;
@@ -1009,14 +1009,14 @@ static int pppoe_hnat_check(struct ppp_channel *chan,
             !(sk->sk_state & PPPOX_CONNECTED) || !dev)
                 return -ENODEV;
 
-        path->dev = po->pppoe_dev;
+        path->real_dev = po->pppoe_dev;
         path->flags |= HNAT_PATH_PPPOE;
         memcpy(path->eth_src, po->pppoe_dev->dev_addr, ETH_ALEN);
         memcpy(path->eth_dest, po->pppoe_pa.remote, ETH_ALEN);
         path->pppoe_sid = be16_to_cpu(po->num);
 
-        if (path->dev->netdev_ops->ndo_hnat_check)
-                return path->dev->netdev_ops->ndo_hnat_check(path);
+        if (path->real_dev->netdev_ops->ndo_hnat_check)
+                return path->real_dev->netdev_ops->ndo_hnat_check(path);
 
         return 0;
 }
diff --git a/trunk/linux-4.4.x/drivers/net/usb/ipheth.c b/trunk/linux-4.4.x/drivers/net/usb/ipheth.c
index 2b16a5fed..fce06ec80 100644
--- a/trunk/linux-4.4.x/drivers/net/usb/ipheth.c
+++ b/trunk/linux-4.4.x/drivers/net/usb/ipheth.c
@@ -70,7 +70,7 @@
 #define IPHETH_USBINTF_SUBCLASS 253
 #define IPHETH_USBINTF_PROTO    1
 
-#define IPHETH_BUF_SIZE         1516
+#define IPHETH_BUF_SIZE         1514
 #define IPHETH_IP_ALIGN		2	/* padding at front of URB */
 #define IPHETH_TX_TIMEOUT       (5 * HZ)
 
@@ -87,7 +87,7 @@
 #define IPHETH_CARRIER_CHECK_TIMEOUT round_jiffies_relative(1 * HZ)
 #define IPHETH_CARRIER_ON       0x04
 
-static struct usb_device_id ipheth_table[] = {
+static const struct usb_device_id ipheth_table[] = {
 	{ USB_DEVICE_AND_INTERFACE_INFO(
 		USB_VENDOR_APPLE, USB_PRODUCT_IPHONE,
 		IPHETH_USBINTF_CLASS, IPHETH_USBINTF_SUBCLASS,
@@ -173,7 +173,7 @@ static int ipheth_alloc_urbs(struct ipheth_device *iphone)
 	if (tx_buf == NULL)
 		goto free_rx_urb;
 
-	rx_buf = usb_alloc_coherent(iphone->udev, IPHETH_BUF_SIZE,
+	rx_buf = usb_alloc_coherent(iphone->udev, IPHETH_BUF_SIZE + IPHETH_IP_ALIGN,
 				    GFP_KERNEL, &rx_urb->transfer_dma);
 	if (rx_buf == NULL)
 		goto free_tx_buf;
@@ -198,7 +198,7 @@ error_nomem:
 
 static void ipheth_free_urbs(struct ipheth_device *iphone)
 {
-	usb_free_coherent(iphone->udev, IPHETH_BUF_SIZE, iphone->rx_buf,
+	usb_free_coherent(iphone->udev, IPHETH_BUF_SIZE + IPHETH_IP_ALIGN, iphone->rx_buf,
 			  iphone->rx_urb->transfer_dma);
 	usb_free_coherent(iphone->udev, IPHETH_BUF_SIZE, iphone->tx_buf,
 			  iphone->tx_urb->transfer_dma);
@@ -371,7 +371,7 @@ static int ipheth_rx_submit(struct ipheth_device *dev, gfp_t mem_flags)
 
 	usb_fill_bulk_urb(dev->rx_urb, udev,
 			  usb_rcvbulkpipe(udev, dev->bulk_in),
-			  dev->rx_buf, IPHETH_BUF_SIZE,
+			  dev->rx_buf, IPHETH_BUF_SIZE + IPHETH_IP_ALIGN,
 			  ipheth_rcvbulk_callback,
 			  dev);
 	dev->rx_urb->transfer_flags |= URB_NO_TRANSFER_DMA_MAP;
diff --git a/trunk/linux-4.4.x/drivers/net/usb/qmi_wwan.c b/trunk/linux-4.4.x/drivers/net/usb/qmi_wwan.c
index 4391430e2..cee72e2f4 100644
--- a/trunk/linux-4.4.x/drivers/net/usb/qmi_wwan.c
+++ b/trunk/linux-4.4.x/drivers/net/usb/qmi_wwan.c
@@ -262,7 +262,7 @@ static int qmi_wwan_bind(struct usbnet *dev, struct usb_interface *intf)
 	}
 
 	/* errors aren't fatal - we can live with the dynamic address */
-	if (cdc_ether && cdc_ether->wMaxSegmentSize) {
+	if (cdc_ether) {
 		dev->hard_mtu = le16_to_cpu(cdc_ether->wMaxSegmentSize);
 		usbnet_get_ethernet_addr(dev, cdc_ether->iMACAddress);
 	}
@@ -631,7 +631,7 @@ static const struct usb_device_id products[] = {
 	{QMI_FIXED_INTF(0x05c6, 0x9080, 8)},
 	{QMI_FIXED_INTF(0x05c6, 0x9083, 3)},
 	{QMI_FIXED_INTF(0x05c6, 0x9084, 4)},
-	{QMI_FIXED_INTF(0x05c6, 0x90b2, 3)},    /* ublox R410M */
+	//{QMI_FIXED_INTF(0x05c6, 0x90b2, 3)},    /* ublox R410M */
 	{QMI_FIXED_INTF(0x05c6, 0x920d, 0)},
 	{QMI_FIXED_INTF(0x05c6, 0x920d, 5)},
 	{QMI_FIXED_INTF(0x0846, 0x68a2, 8)},
@@ -690,7 +690,7 @@ static const struct usb_device_id products[] = {
 	{QMI_FIXED_INTF(0x19d2, 0x0191, 4)},	/* ZTE EuFi890 */
 	{QMI_FIXED_INTF(0x19d2, 0x0199, 1)},	/* ZTE MF820S */
 	{QMI_FIXED_INTF(0x19d2, 0x0200, 1)},
-	{QMI_FIXED_INTF(0x19d2, 0x0257, 3)},	/* ZTE MF821 */
+	//{QMI_FIXED_INTF(0x19d2, 0x0257, 3)},	/* ZTE MF821 */
 	{QMI_FIXED_INTF(0x19d2, 0x0265, 4)},	/* ONDA MT8205 4G LTE */
 	{QMI_FIXED_INTF(0x19d2, 0x0284, 4)},	/* ZTE MF880 */
 	{QMI_FIXED_INTF(0x19d2, 0x0326, 4)},	/* ZTE MF821D */
@@ -715,8 +715,8 @@ static const struct usb_device_id products[] = {
 	{QMI_FIXED_INTF(0x19d2, 0x1426, 2)},	/* ZTE MF91 */
 	{QMI_FIXED_INTF(0x19d2, 0x1428, 2)},	/* Telewell TW-LTE 4G v2 */
 	{QMI_FIXED_INTF(0x19d2, 0x2002, 4)},	/* ZTE (Vodafone) K3765-Z */
-	{QMI_FIXED_INTF(0x2001, 0x7e19, 4)},	/* D-Link DWM-221 B1 */
-	{QMI_FIXED_INTF(0x2001, 0x7e35, 4)},	/* D-Link DWM-222 */
+	//{QMI_FIXED_INTF(0x2001, 0x7e19, 4)},	/* D-Link DWM-221 B1 */
+	//{QMI_FIXED_INTF(0x2001, 0x7e35, 4)},	/* D-Link DWM-222 */
 	{QMI_FIXED_INTF(0x2020, 0x2031, 4)},	/* Olicard 600 */
 	{QMI_FIXED_INTF(0x2020, 0x2033, 4)},	/* BroadMobi BM806U */
 	{QMI_FIXED_INTF(0x2020, 0x2060, 4)},	/* BroadMobi BM818 */
@@ -739,12 +739,12 @@ static const struct usb_device_id products[] = {
 	{QMI_FIXED_INTF(0x1199, 0x9061, 8)},	/* Sierra Wireless Modem */
 	{QMI_FIXED_INTF(0x1199, 0x9070, 8)},	/* Sierra Wireless MC74xx/EM74xx */
 	{QMI_FIXED_INTF(0x1199, 0x9070, 10)},	/* Sierra Wireless MC74xx/EM74xx */
-	{QMI_FIXED_INTF(0x1199, 0x9071, 8)},	/* Sierra Wireless MC74xx */
-	{QMI_FIXED_INTF(0x1199, 0x9071, 10)},	/* Sierra Wireless MC74xx */
-	{QMI_FIXED_INTF(0x1199, 0x9079, 8)},	/* Sierra Wireless EM74xx */
-	{QMI_FIXED_INTF(0x1199, 0x9079, 10)},	/* Sierra Wireless EM74xx */
-	{QMI_FIXED_INTF(0x1199, 0x907b, 8)},	/* Sierra Wireless EM74xx */
-	{QMI_FIXED_INTF(0x1199, 0x907b, 10)},	/* Sierra Wireless EM74xx */
+	{QMI_FIXED_INTF(0x1199, 0x9071, 8)},	/* Sierra Wireless MC74xx/EM74xx */
+	{QMI_FIXED_INTF(0x1199, 0x9071, 10)},/* Sierra Wireless MC74xx/EM74xx */
+	//{QMI_FIXED_INTF(0x1199, 0x9079, 8)},	/* Sierra Wireless EM74xx */
+	//{QMI_FIXED_INTF(0x1199, 0x9079, 10)},	/* Sierra Wireless EM74xx */
+	//{QMI_FIXED_INTF(0x1199, 0x907b, 8)},	/* Sierra Wireless EM74xx */
+	//{QMI_FIXED_INTF(0x1199, 0x907b, 10)},	/* Sierra Wireless EM74xx */
 	{QMI_FIXED_INTF(0x1199, 0x9091, 8)},	/* Sierra Wireless EM7565 */
 	{QMI_FIXED_INTF(0x1bbb, 0x011e, 4)},	/* Telekom Speedstick LTE II (Alcatel One Touch L100V LTE) */
 	{QMI_FIXED_INTF(0x1bbb, 0x0203, 2)},	/* Alcatel L800MA */
diff --git a/trunk/linux-4.4.x/drivers/pci/host/pcie-mediatek.c b/trunk/linux-4.4.x/drivers/pci/host/pcie-mediatek.c
index 1e5d891a5..83c0d4c72 100644
--- a/trunk/linux-4.4.x/drivers/pci/host/pcie-mediatek.c
+++ b/trunk/linux-4.4.x/drivers/pci/host/pcie-mediatek.c
@@ -1011,7 +1011,7 @@ err_axi_clk:
 err_aux_clk:
 	clk_disable_unprepare(port->ahb_ck);
 err_ahb_clk:
-	clk_disable_unprepare(port->sys_ck);
+//	clk_disable_unprepare(port->sys_ck);
 err_sys_clk:
 	mtk_pcie_port_free(port);
 }
diff --git a/trunk/linux-4.4.x/drivers/pinctrl/pinctrl-sx150x.c b/trunk/linux-4.4.x/drivers/pinctrl/pinctrl-sx150x.c
new file mode 100644
index 000000000..45df89c88
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/pinctrl/pinctrl-sx150x.c
@@ -0,0 +1,1261 @@
+/*
+ * Copyright (c) 2016, BayLibre, SAS. All rights reserved.
+ * Author: Neil Armstrong <narmstrong@baylibre.com>
+ *
+ * Copyright (c) 2010, Code Aurora Forum. All rights reserved.
+ *
+ * Driver for Semtech SX150X I2C GPIO Expanders
+ * The handling of the 4-bit chips (SX1501/SX1504/SX1507) is untested.
+ *
+ * Author: Gregory Bean <gbean@codeaurora.org>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/regmap.h>
+#include <linux/i2c.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/mutex.h>
+#include <linux/slab.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/gpio/driver.h>
+#include <linux/pinctrl/pinconf.h>
+#include <linux/pinctrl/pinctrl.h>
+#include <linux/pinctrl/pinmux.h>
+#include <linux/pinctrl/pinconf-generic.h>
+
+#include "core.h"
+#include "pinconf.h"
+#include "pinctrl-utils.h"
+
+/* The chip models of sx150x */
+enum {
+	SX150X_123 = 0,
+	SX150X_456,
+	SX150X_789,
+};
+enum {
+	SX150X_789_REG_MISC_AUTOCLEAR_OFF = 1 << 0,
+	SX150X_MAX_REGISTER = 0xad,
+	SX150X_IRQ_TYPE_EDGE_RISING = 0x1,
+	SX150X_IRQ_TYPE_EDGE_FALLING = 0x2,
+	SX150X_789_RESET_KEY1 = 0x12,
+	SX150X_789_RESET_KEY2 = 0x34,
+};
+
+struct sx150x_123_pri {
+	u8 reg_pld_mode;
+	u8 reg_pld_table0;
+	u8 reg_pld_table1;
+	u8 reg_pld_table2;
+	u8 reg_pld_table3;
+	u8 reg_pld_table4;
+	u8 reg_advanced;
+};
+
+struct sx150x_456_pri {
+	u8 reg_pld_mode;
+	u8 reg_pld_table0;
+	u8 reg_pld_table1;
+	u8 reg_pld_table2;
+	u8 reg_pld_table3;
+	u8 reg_pld_table4;
+	u8 reg_advanced;
+};
+
+struct sx150x_789_pri {
+	u8 reg_drain;
+	u8 reg_polarity;
+	u8 reg_clock;
+	u8 reg_misc;
+	u8 reg_reset;
+	u8 ngpios;
+};
+
+struct sx150x_device_data {
+	u8 model;
+	u8 reg_pullup;
+	u8 reg_pulldn;
+	u8 reg_dir;
+	u8 reg_data;
+	u8 reg_irq_mask;
+	u8 reg_irq_src;
+	u8 reg_sense;
+	u8 ngpios;
+	union {
+		struct sx150x_123_pri x123;
+		struct sx150x_456_pri x456;
+		struct sx150x_789_pri x789;
+	} pri;
+	const struct pinctrl_pin_desc *pins;
+	unsigned int npins;
+};
+
+struct sx150x_pinctrl {
+	struct device *dev;
+	struct i2c_client *client;
+	struct pinctrl_dev *pctldev;
+	struct pinctrl_desc pinctrl_desc;
+	struct gpio_chip gpio;
+	struct irq_chip irq_chip;
+	struct regmap *regmap;
+	struct {
+		u32 sense;
+		u32 masked;
+	} irq;
+	struct mutex lock;
+	const struct sx150x_device_data *data;
+};
+
+static const struct pinctrl_pin_desc sx150x_4_pins[] = {
+	PINCTRL_PIN(0, "gpio0"),
+	PINCTRL_PIN(1, "gpio1"),
+	PINCTRL_PIN(2, "gpio2"),
+	PINCTRL_PIN(3, "gpio3"),
+	PINCTRL_PIN(4, "oscio"),
+};
+
+static const struct pinctrl_pin_desc sx150x_8_pins[] = {
+	PINCTRL_PIN(0, "gpio0"),
+	PINCTRL_PIN(1, "gpio1"),
+	PINCTRL_PIN(2, "gpio2"),
+	PINCTRL_PIN(3, "gpio3"),
+	PINCTRL_PIN(4, "gpio4"),
+	PINCTRL_PIN(5, "gpio5"),
+	PINCTRL_PIN(6, "gpio6"),
+	PINCTRL_PIN(7, "gpio7"),
+	PINCTRL_PIN(8, "oscio"),
+};
+
+static const struct pinctrl_pin_desc sx150x_16_pins[] = {
+	PINCTRL_PIN(0, "gpio0"),
+	PINCTRL_PIN(1, "gpio1"),
+	PINCTRL_PIN(2, "gpio2"),
+	PINCTRL_PIN(3, "gpio3"),
+	PINCTRL_PIN(4, "gpio4"),
+	PINCTRL_PIN(5, "gpio5"),
+	PINCTRL_PIN(6, "gpio6"),
+	PINCTRL_PIN(7, "gpio7"),
+	PINCTRL_PIN(8, "gpio8"),
+	PINCTRL_PIN(9, "gpio9"),
+	PINCTRL_PIN(10, "gpio10"),
+	PINCTRL_PIN(11, "gpio11"),
+	PINCTRL_PIN(12, "gpio12"),
+	PINCTRL_PIN(13, "gpio13"),
+	PINCTRL_PIN(14, "gpio14"),
+	PINCTRL_PIN(15, "gpio15"),
+	PINCTRL_PIN(16, "oscio"),
+};
+
+static const struct sx150x_device_data sx1501q_device_data = {
+	.model = SX150X_123,
+	.reg_pullup	= 0x02,
+	.reg_pulldn	= 0x03,
+	.reg_dir	= 0x01,
+	.reg_data	= 0x00,
+	.reg_irq_mask	= 0x05,
+	.reg_irq_src	= 0x08,
+	.reg_sense	= 0x07,
+	.pri.x123 = {
+		.reg_pld_mode	= 0x10,
+		.reg_pld_table0	= 0x11,
+		.reg_pld_table2	= 0x13,
+		.reg_advanced	= 0xad,
+	},
+	.ngpios	= 4,
+	.pins = sx150x_4_pins,
+	.npins = 4, /* oscio not available */
+};
+
+static const struct sx150x_device_data sx1502q_device_data = {
+	.model = SX150X_123,
+	.reg_pullup	= 0x02,
+	.reg_pulldn	= 0x03,
+	.reg_dir	= 0x01,
+	.reg_data	= 0x00,
+	.reg_irq_mask	= 0x05,
+	.reg_irq_src	= 0x08,
+	.reg_sense	= 0x06,
+	.pri.x123 = {
+		.reg_pld_mode	= 0x10,
+		.reg_pld_table0	= 0x11,
+		.reg_pld_table1	= 0x12,
+		.reg_pld_table2	= 0x13,
+		.reg_pld_table3	= 0x14,
+		.reg_pld_table4	= 0x15,
+		.reg_advanced	= 0xad,
+	},
+	.ngpios	= 8,
+	.pins = sx150x_8_pins,
+	.npins = 8, /* oscio not available */
+};
+
+static const struct sx150x_device_data sx1503q_device_data = {
+	.model = SX150X_123,
+	.reg_pullup	= 0x04,
+	.reg_pulldn	= 0x06,
+	.reg_dir	= 0x02,
+	.reg_data	= 0x00,
+	.reg_irq_mask	= 0x08,
+	.reg_irq_src	= 0x0e,
+	.reg_sense	= 0x0a,
+	.pri.x123 = {
+		.reg_pld_mode	= 0x20,
+		.reg_pld_table0	= 0x22,
+		.reg_pld_table1	= 0x24,
+		.reg_pld_table2	= 0x26,
+		.reg_pld_table3	= 0x28,
+		.reg_pld_table4	= 0x2a,
+		.reg_advanced	= 0xad,
+	},
+	.ngpios	= 16,
+	.pins = sx150x_16_pins,
+	.npins  = 16, /* oscio not available */
+};
+
+static const struct sx150x_device_data sx1504q_device_data = {
+	.model = SX150X_456,
+	.reg_pullup	= 0x02,
+	.reg_pulldn	= 0x03,
+	.reg_dir	= 0x01,
+	.reg_data	= 0x00,
+	.reg_irq_mask	= 0x05,
+	.reg_irq_src	= 0x08,
+	.reg_sense	= 0x07,
+	.pri.x456 = {
+		.reg_pld_mode	= 0x10,
+		.reg_pld_table0	= 0x11,
+		.reg_pld_table2	= 0x13,
+	},
+	.ngpios	= 4,
+	.pins = sx150x_4_pins,
+	.npins = 4, /* oscio not available */
+};
+
+static const struct sx150x_device_data sx1505q_device_data = {
+	.model = SX150X_456,
+	.reg_pullup	= 0x02,
+	.reg_pulldn	= 0x03,
+	.reg_dir	= 0x01,
+	.reg_data	= 0x00,
+	.reg_irq_mask	= 0x05,
+	.reg_irq_src	= 0x08,
+	.reg_sense	= 0x06,
+	.pri.x456 = {
+		.reg_pld_mode	= 0x10,
+		.reg_pld_table0	= 0x11,
+		.reg_pld_table1	= 0x12,
+		.reg_pld_table2	= 0x13,
+		.reg_pld_table3	= 0x14,
+		.reg_pld_table4	= 0x15,
+	},
+	.ngpios	= 8,
+	.pins = sx150x_8_pins,
+	.npins = 8, /* oscio not available */
+};
+
+static const struct sx150x_device_data sx1506q_device_data = {
+	.model = SX150X_456,
+	.reg_pullup	= 0x04,
+	.reg_pulldn	= 0x06,
+	.reg_dir	= 0x02,
+	.reg_data	= 0x00,
+	.reg_irq_mask	= 0x08,
+	.reg_irq_src	= 0x0e,
+	.reg_sense	= 0x0a,
+	.pri.x456 = {
+		.reg_pld_mode	= 0x20,
+		.reg_pld_table0	= 0x22,
+		.reg_pld_table1	= 0x24,
+		.reg_pld_table2	= 0x26,
+		.reg_pld_table3	= 0x28,
+		.reg_pld_table4	= 0x2a,
+		.reg_advanced	= 0xad,
+	},
+	.ngpios	= 16,
+	.pins = sx150x_16_pins,
+	.npins = 16, /* oscio not available */
+};
+
+static const struct sx150x_device_data sx1507q_device_data = {
+	.model = SX150X_789,
+	.reg_pullup	= 0x03,
+	.reg_pulldn	= 0x04,
+	.reg_dir	= 0x07,
+	.reg_data	= 0x08,
+	.reg_irq_mask	= 0x09,
+	.reg_irq_src	= 0x0b,
+	.reg_sense	= 0x0a,
+	.pri.x789 = {
+		.reg_drain	= 0x05,
+		.reg_polarity	= 0x06,
+		.reg_clock	= 0x0d,
+		.reg_misc	= 0x0e,
+		.reg_reset	= 0x7d,
+	},
+	.ngpios = 4,
+	.pins = sx150x_4_pins,
+	.npins = ARRAY_SIZE(sx150x_4_pins),
+};
+
+static const struct sx150x_device_data sx1508q_device_data = {
+	.model = SX150X_789,
+	.reg_pullup	= 0x03,
+	.reg_pulldn	= 0x04,
+	.reg_dir	= 0x07,
+	.reg_data	= 0x08,
+	.reg_irq_mask	= 0x09,
+	.reg_irq_src	= 0x0c,
+	.reg_sense	= 0x0a,
+	.pri.x789 = {
+		.reg_drain	= 0x05,
+		.reg_polarity	= 0x06,
+		.reg_clock	= 0x0f,
+		.reg_misc	= 0x10,
+		.reg_reset	= 0x7d,
+	},
+	.ngpios = 8,
+	.pins = sx150x_8_pins,
+	.npins = ARRAY_SIZE(sx150x_8_pins),
+};
+
+static const struct sx150x_device_data sx1509q_device_data = {
+	.model = SX150X_789,
+	.reg_pullup	= 0x06,
+	.reg_pulldn	= 0x08,
+	.reg_dir	= 0x0e,
+	.reg_data	= 0x10,
+	.reg_irq_mask	= 0x12,
+	.reg_irq_src	= 0x18,
+	.reg_sense	= 0x14,
+	.pri.x789 = {
+		.reg_drain	= 0x0a,
+		.reg_polarity	= 0x0c,
+		.reg_clock	= 0x1e,
+		.reg_misc	= 0x1f,
+		.reg_reset	= 0x7d,
+	},
+	.ngpios	= 16,
+	.pins = sx150x_16_pins,
+	.npins = ARRAY_SIZE(sx150x_16_pins),
+};
+
+static int sx150x_pinctrl_get_groups_count(struct pinctrl_dev *pctldev)
+{
+	return 0;
+}
+
+static const char *sx150x_pinctrl_get_group_name(struct pinctrl_dev *pctldev,
+						unsigned int group)
+{
+	return NULL;
+}
+
+static int sx150x_pinctrl_get_group_pins(struct pinctrl_dev *pctldev,
+					unsigned int group,
+					const unsigned int **pins,
+					unsigned int *num_pins)
+{
+	return -ENOTSUPP;
+}
+
+static const struct pinctrl_ops sx150x_pinctrl_ops = {
+	.get_groups_count = sx150x_pinctrl_get_groups_count,
+	.get_group_name = sx150x_pinctrl_get_group_name,
+	.get_group_pins = sx150x_pinctrl_get_group_pins,
+};
+
+static bool sx150x_pin_is_oscio(struct sx150x_pinctrl *pctl, unsigned int pin)
+{
+	if (pin >= pctl->data->npins)
+		return false;
+
+	/* OSCIO pin is only present in 789 devices */
+	if (pctl->data->model != SX150X_789)
+		return false;
+
+	return !strcmp(pctl->data->pins[pin].name, "oscio");
+}
+
+static int sx150x_gpio_get_direction(struct gpio_chip *chip,
+				      unsigned int offset)
+{
+	struct sx150x_pinctrl *pctl = gpiochip_get_data(chip);
+	unsigned int value;
+	int ret;
+
+	if (sx150x_pin_is_oscio(pctl, offset))
+		return false;
+
+	ret = regmap_read(pctl->regmap, pctl->data->reg_dir, &value);
+	if (ret < 0)
+		return ret;
+
+	return !!(value & BIT(offset));
+}
+
+static int sx150x_gpio_get(struct gpio_chip *chip, unsigned int offset)
+{
+	struct sx150x_pinctrl *pctl = gpiochip_get_data(chip);
+	unsigned int value;
+	int ret;
+
+	if (sx150x_pin_is_oscio(pctl, offset))
+		return -EINVAL;
+
+	ret = regmap_read(pctl->regmap, pctl->data->reg_data, &value);
+	if (ret < 0)
+		return ret;
+
+	return !!(value & BIT(offset));
+}
+
+static int __sx150x_gpio_set(struct sx150x_pinctrl *pctl, unsigned int offset,
+			     int value)
+{
+	return regmap_write_bits(pctl->regmap, pctl->data->reg_data,
+				 BIT(offset), value ? BIT(offset) : 0);
+}
+
+static int sx150x_gpio_oscio_set(struct sx150x_pinctrl *pctl,
+				 int value)
+{
+	return regmap_write(pctl->regmap,
+			    pctl->data->pri.x789.reg_clock,
+			    (value ? 0x1f : 0x10));
+}
+
+static void sx150x_gpio_set(struct gpio_chip *chip, unsigned int offset,
+			    int value)
+{
+	struct sx150x_pinctrl *pctl = gpiochip_get_data(chip);
+
+	if (sx150x_pin_is_oscio(pctl, offset))
+		sx150x_gpio_oscio_set(pctl, value);
+	else
+		__sx150x_gpio_set(pctl, offset, value);
+
+}
+
+static void sx150x_gpio_set_multiple(struct gpio_chip *chip,
+				     unsigned long *mask,
+				     unsigned long *bits)
+{
+	struct sx150x_pinctrl *pctl = gpiochip_get_data(chip);
+
+	regmap_write_bits(pctl->regmap, pctl->data->reg_data, *mask, *bits);
+}
+
+static int sx150x_gpio_direction_input(struct gpio_chip *chip,
+				       unsigned int offset)
+{
+	struct sx150x_pinctrl *pctl = gpiochip_get_data(chip);
+
+	if (sx150x_pin_is_oscio(pctl, offset))
+		return -EINVAL;
+
+	return regmap_write_bits(pctl->regmap,
+				 pctl->data->reg_dir,
+				 BIT(offset), BIT(offset));
+}
+
+static int sx150x_gpio_direction_output(struct gpio_chip *chip,
+					unsigned int offset, int value)
+{
+	struct sx150x_pinctrl *pctl = gpiochip_get_data(chip);
+	int ret;
+
+	if (sx150x_pin_is_oscio(pctl, offset))
+		return sx150x_gpio_oscio_set(pctl, value);
+
+	ret = __sx150x_gpio_set(pctl, offset, value);
+	if (ret < 0)
+		return ret;
+
+	return regmap_write_bits(pctl->regmap,
+				 pctl->data->reg_dir,
+				 BIT(offset), 0);
+}
+
+static void sx150x_irq_mask(struct irq_data *d)
+{
+	struct sx150x_pinctrl *pctl =
+			gpiochip_get_data(irq_data_get_irq_chip_data(d));
+	unsigned int n = d->hwirq;
+
+	pctl->irq.masked |= BIT(n);
+}
+
+static void sx150x_irq_unmask(struct irq_data *d)
+{
+	struct sx150x_pinctrl *pctl =
+			gpiochip_get_data(irq_data_get_irq_chip_data(d));
+	unsigned int n = d->hwirq;
+
+	pctl->irq.masked &= ~BIT(n);
+}
+
+static void sx150x_irq_set_sense(struct sx150x_pinctrl *pctl,
+				 unsigned int line, unsigned int sense)
+{
+	/*
+	 * Every interrupt line is represented by two bits shifted
+	 * proportionally to the line number
+	 */
+	const unsigned int n = line * 2;
+	const unsigned int mask = ~((SX150X_IRQ_TYPE_EDGE_RISING |
+				     SX150X_IRQ_TYPE_EDGE_FALLING) << n);
+
+	pctl->irq.sense &= mask;
+	pctl->irq.sense |= sense << n;
+}
+
+static int sx150x_irq_set_type(struct irq_data *d, unsigned int flow_type)
+{
+	struct sx150x_pinctrl *pctl =
+			gpiochip_get_data(irq_data_get_irq_chip_data(d));
+	unsigned int n, val = 0;
+
+	if (flow_type & (IRQ_TYPE_LEVEL_HIGH | IRQ_TYPE_LEVEL_LOW))
+		return -EINVAL;
+
+	n = d->hwirq;
+
+	if (flow_type & IRQ_TYPE_EDGE_RISING)
+		val |= SX150X_IRQ_TYPE_EDGE_RISING;
+	if (flow_type & IRQ_TYPE_EDGE_FALLING)
+		val |= SX150X_IRQ_TYPE_EDGE_FALLING;
+
+	sx150x_irq_set_sense(pctl, n, val);
+	return 0;
+}
+
+static irqreturn_t sx150x_irq_thread_fn(int irq, void *dev_id)
+{
+	struct sx150x_pinctrl *pctl = (struct sx150x_pinctrl *)dev_id;
+	unsigned long n, status;
+	unsigned int val;
+	int err;
+
+	err = regmap_read(pctl->regmap, pctl->data->reg_irq_src, &val);
+	if (err < 0)
+		return IRQ_NONE;
+
+	err = regmap_write(pctl->regmap, pctl->data->reg_irq_src, val);
+	if (err < 0)
+		return IRQ_NONE;
+
+	status = val;
+	for_each_set_bit(n, &status, pctl->data->ngpios)
+		handle_nested_irq(irq_find_mapping(pctl->gpio.irqdomain, n));
+
+	return IRQ_HANDLED;
+}
+
+static void sx150x_irq_bus_lock(struct irq_data *d)
+{
+	struct sx150x_pinctrl *pctl =
+			gpiochip_get_data(irq_data_get_irq_chip_data(d));
+
+	mutex_lock(&pctl->lock);
+}
+
+static void sx150x_irq_bus_sync_unlock(struct irq_data *d)
+{
+	struct sx150x_pinctrl *pctl =
+			gpiochip_get_data(irq_data_get_irq_chip_data(d));
+
+	regmap_write(pctl->regmap, pctl->data->reg_irq_mask, pctl->irq.masked);
+	regmap_write(pctl->regmap, pctl->data->reg_sense, pctl->irq.sense);
+	mutex_unlock(&pctl->lock);
+}
+
+static int sx150x_pinconf_get(struct pinctrl_dev *pctldev, unsigned int pin,
+			      unsigned long *config)
+{
+	struct sx150x_pinctrl *pctl = pinctrl_dev_get_drvdata(pctldev);
+	unsigned int param = pinconf_to_config_param(*config);
+	int ret;
+	u32 arg;
+	unsigned int data;
+
+	if (sx150x_pin_is_oscio(pctl, pin)) {
+		switch (param) {
+		case PIN_CONFIG_DRIVE_PUSH_PULL:
+		case PIN_CONFIG_OUTPUT:
+			ret = regmap_read(pctl->regmap,
+					  pctl->data->pri.x789.reg_clock,
+					  &data);
+			if (ret < 0)
+				return ret;
+
+			if (param == PIN_CONFIG_DRIVE_PUSH_PULL)
+				arg = (data & 0x1f) ? 1 : 0;
+			else {
+				if ((data & 0x1f) == 0x1f)
+					arg = 1;
+				else if ((data & 0x1f) == 0x10)
+					arg = 0;
+				else
+					return -EINVAL;
+			}
+
+			break;
+		default:
+			return -ENOTSUPP;
+		}
+
+		goto out;
+	}
+
+	switch (param) {
+	case PIN_CONFIG_BIAS_PULL_DOWN:
+		ret = regmap_read(pctl->regmap,
+				  pctl->data->reg_pulldn,
+				  &data);
+		data &= BIT(pin);
+
+		if (ret < 0)
+			return ret;
+
+		if (!ret)
+			return -EINVAL;
+
+		arg = 1;
+		break;
+
+	case PIN_CONFIG_BIAS_PULL_UP:
+		ret = regmap_read(pctl->regmap,
+				  pctl->data->reg_pullup,
+				  &data);
+		data &= BIT(pin);
+
+		if (ret < 0)
+			return ret;
+
+		if (!ret)
+			return -EINVAL;
+
+		arg = 1;
+		break;
+
+	case PIN_CONFIG_DRIVE_OPEN_DRAIN:
+		if (pctl->data->model != SX150X_789)
+			return -ENOTSUPP;
+
+		ret = regmap_read(pctl->regmap,
+				  pctl->data->pri.x789.reg_drain,
+				  &data);
+		data &= BIT(pin);
+
+		if (ret < 0)
+			return ret;
+
+		if (!data)
+			return -EINVAL;
+
+		arg = 1;
+		break;
+
+	case PIN_CONFIG_DRIVE_PUSH_PULL:
+		if (pctl->data->model != SX150X_789)
+			arg = true;
+		else {
+			ret = regmap_read(pctl->regmap,
+					  pctl->data->pri.x789.reg_drain,
+					  &data);
+			data &= BIT(pin);
+
+			if (ret < 0)
+				return ret;
+
+			if (data)
+				return -EINVAL;
+
+			arg = 1;
+		}
+		break;
+
+	case PIN_CONFIG_OUTPUT:
+		ret = sx150x_gpio_get_direction(&pctl->gpio, pin);
+		if (ret < 0)
+			return ret;
+
+		if (ret)
+			return -EINVAL;
+
+		ret = sx150x_gpio_get(&pctl->gpio, pin);
+		if (ret < 0)
+			return ret;
+
+		arg = ret;
+		break;
+
+	default:
+		return -ENOTSUPP;
+	}
+
+out:
+	*config = pinconf_to_config_packed(param, arg);
+
+	return 0;
+}
+
+static int sx150x_pinconf_set(struct pinctrl_dev *pctldev, unsigned int pin,
+			      unsigned long *configs, unsigned int num_configs)
+{
+	struct sx150x_pinctrl *pctl = pinctrl_dev_get_drvdata(pctldev);
+	enum pin_config_param param;
+	u32 arg;
+	int i;
+	int ret;
+
+	for (i = 0; i < num_configs; i++) {
+		param = pinconf_to_config_param(configs[i]);
+		arg = pinconf_to_config_argument(configs[i]);
+
+		if (sx150x_pin_is_oscio(pctl, pin)) {
+			if (param == PIN_CONFIG_OUTPUT) {
+				ret = sx150x_gpio_direction_output(&pctl->gpio,
+								   pin, arg);
+				if (ret < 0)
+					return ret;
+
+				continue;
+			} else
+				return -ENOTSUPP;
+		}
+
+		switch (param) {
+		case PIN_CONFIG_BIAS_PULL_PIN_DEFAULT:
+		case PIN_CONFIG_BIAS_DISABLE:
+			ret = regmap_write_bits(pctl->regmap,
+						pctl->data->reg_pulldn,
+						BIT(pin), 0);
+			if (ret < 0)
+				return ret;
+
+			ret = regmap_write_bits(pctl->regmap,
+						pctl->data->reg_pullup,
+						BIT(pin), 0);
+			if (ret < 0)
+				return ret;
+
+			break;
+
+		case PIN_CONFIG_BIAS_PULL_UP:
+			ret = regmap_write_bits(pctl->regmap,
+						pctl->data->reg_pullup,
+						BIT(pin), BIT(pin));
+			if (ret < 0)
+				return ret;
+
+			break;
+
+		case PIN_CONFIG_BIAS_PULL_DOWN:
+			ret = regmap_write_bits(pctl->regmap,
+						pctl->data->reg_pulldn,
+						BIT(pin), BIT(pin));
+			if (ret < 0)
+				return ret;
+
+			break;
+
+		case PIN_CONFIG_DRIVE_OPEN_DRAIN:
+			if (pctl->data->model != SX150X_789 ||
+			    sx150x_pin_is_oscio(pctl, pin))
+				return -ENOTSUPP;
+
+			ret = regmap_write_bits(pctl->regmap,
+						pctl->data->pri.x789.reg_drain,
+						BIT(pin), BIT(pin));
+			if (ret < 0)
+				return ret;
+
+			break;
+
+		case PIN_CONFIG_DRIVE_PUSH_PULL:
+			if (pctl->data->model != SX150X_789 ||
+			    sx150x_pin_is_oscio(pctl, pin))
+				return 0;
+
+			ret = regmap_write_bits(pctl->regmap,
+						pctl->data->pri.x789.reg_drain,
+						BIT(pin), 0);
+			if (ret < 0)
+				return ret;
+
+			break;
+
+		case PIN_CONFIG_OUTPUT:
+			ret = sx150x_gpio_direction_output(&pctl->gpio,
+							   pin, arg);
+			if (ret < 0)
+				return ret;
+
+			break;
+
+		default:
+			return -ENOTSUPP;
+		}
+	} /* for each config */
+
+	return 0;
+}
+
+static const struct pinconf_ops sx150x_pinconf_ops = {
+	.pin_config_get = sx150x_pinconf_get,
+	.pin_config_set = sx150x_pinconf_set,
+	.is_generic = true,
+};
+
+static const struct i2c_device_id sx150x_id[] = {
+	{"sx1501q", (kernel_ulong_t) &sx1501q_device_data },
+	{"sx1502q", (kernel_ulong_t) &sx1502q_device_data },
+	{"sx1503q", (kernel_ulong_t) &sx1503q_device_data },
+	{"sx1504q", (kernel_ulong_t) &sx1504q_device_data },
+	{"sx1505q", (kernel_ulong_t) &sx1505q_device_data },
+	{"sx1506q", (kernel_ulong_t) &sx1506q_device_data },
+	{"sx1507q", (kernel_ulong_t) &sx1507q_device_data },
+	{"sx1508q", (kernel_ulong_t) &sx1508q_device_data },
+	{"sx1509q", (kernel_ulong_t) &sx1509q_device_data },
+	{}
+};
+
+static const struct of_device_id sx150x_of_match[] = {
+	{ .compatible = "semtech,sx1501q", .data = &sx1501q_device_data },
+	{ .compatible = "semtech,sx1502q", .data = &sx1502q_device_data },
+	{ .compatible = "semtech,sx1503q", .data = &sx1503q_device_data },
+	{ .compatible = "semtech,sx1504q", .data = &sx1504q_device_data },
+	{ .compatible = "semtech,sx1505q", .data = &sx1505q_device_data },
+	{ .compatible = "semtech,sx1506q", .data = &sx1506q_device_data },
+	{ .compatible = "semtech,sx1507q", .data = &sx1507q_device_data },
+	{ .compatible = "semtech,sx1508q", .data = &sx1508q_device_data },
+	{ .compatible = "semtech,sx1509q", .data = &sx1509q_device_data },
+	{},
+};
+
+static int sx150x_reset(struct sx150x_pinctrl *pctl)
+{
+	int err;
+
+	err = i2c_smbus_write_byte_data(pctl->client,
+					pctl->data->pri.x789.reg_reset,
+					SX150X_789_RESET_KEY1);
+	if (err < 0)
+		return err;
+
+	err = i2c_smbus_write_byte_data(pctl->client,
+					pctl->data->pri.x789.reg_reset,
+					SX150X_789_RESET_KEY2);
+	return err;
+}
+
+static int sx150x_init_misc(struct sx150x_pinctrl *pctl)
+{
+	u8 reg, value;
+
+	switch (pctl->data->model) {
+	case SX150X_789:
+		reg   = pctl->data->pri.x789.reg_misc;
+		value = SX150X_789_REG_MISC_AUTOCLEAR_OFF;
+		break;
+	case SX150X_456:
+		reg   = pctl->data->pri.x456.reg_advanced;
+		value = 0x00;
+
+		/*
+		 * Only SX1506 has RegAdvanced, SX1504/5 are expected
+		 * to initialize this offset to zero
+		 */
+		if (!reg)
+			return 0;
+		break;
+	case SX150X_123:
+		reg   = pctl->data->pri.x123.reg_advanced;
+		value = 0x00;
+		break;
+	default:
+		WARN(1, "Unknown chip model %d\n", pctl->data->model);
+		return -EINVAL;
+	}
+
+	return regmap_write(pctl->regmap, reg, value);
+}
+
+static int sx150x_init_hw(struct sx150x_pinctrl *pctl)
+{
+	const u8 reg[] = {
+		[SX150X_789] = pctl->data->pri.x789.reg_polarity,
+		[SX150X_456] = pctl->data->pri.x456.reg_pld_mode,
+		[SX150X_123] = pctl->data->pri.x123.reg_pld_mode,
+	};
+	int err;
+
+	if (pctl->data->model == SX150X_789 &&
+	    of_property_read_bool(pctl->dev->of_node, "semtech,probe-reset")) {
+		err = sx150x_reset(pctl);
+		if (err < 0)
+			return err;
+	}
+
+	err = sx150x_init_misc(pctl);
+	if (err < 0)
+		return err;
+
+	/* Set all pins to work in normal mode */
+	return regmap_write(pctl->regmap, reg[pctl->data->model], 0);
+}
+
+static int sx150x_regmap_reg_width(struct sx150x_pinctrl *pctl,
+				   unsigned int reg)
+{
+	const struct sx150x_device_data *data = pctl->data;
+
+	if (reg == data->reg_sense) {
+		/*
+		 * RegSense packs two bits of configuration per GPIO,
+		 * so we'd need to read twice as many bits as there
+		 * are GPIO in our chip
+		 */
+		return 2 * data->ngpios;
+	} else if ((data->model == SX150X_789 &&
+		    (reg == data->pri.x789.reg_misc ||
+		     reg == data->pri.x789.reg_clock ||
+		     reg == data->pri.x789.reg_reset))
+		   ||
+		   (data->model == SX150X_123 &&
+		    reg == data->pri.x123.reg_advanced)
+		   ||
+		   (data->model == SX150X_456 &&
+		    data->pri.x456.reg_advanced &&
+		    reg == data->pri.x456.reg_advanced)) {
+		return 8;
+	} else {
+		return data->ngpios;
+	}
+}
+
+static unsigned int sx150x_maybe_swizzle(struct sx150x_pinctrl *pctl,
+					 unsigned int reg, unsigned int val)
+{
+	unsigned int a, b;
+	const struct sx150x_device_data *data = pctl->data;
+
+	/*
+	 * Whereas SX1509 presents RegSense in a simple layout as such:
+	 *	reg     [ f f e e d d c c ]
+	 *	reg + 1 [ b b a a 9 9 8 8 ]
+	 *	reg + 2 [ 7 7 6 6 5 5 4 4 ]
+	 *	reg + 3 [ 3 3 2 2 1 1 0 0 ]
+	 *
+	 * SX1503 and SX1506 deviate from that data layout, instead storing
+	 * their contents as follows:
+	 *
+	 *	reg     [ f f e e d d c c ]
+	 *	reg + 1 [ 7 7 6 6 5 5 4 4 ]
+	 *	reg + 2 [ b b a a 9 9 8 8 ]
+	 *	reg + 3 [ 3 3 2 2 1 1 0 0 ]
+	 *
+	 * so, taking that into account, we swap two
+	 * inner bytes of a 4-byte result
+	 */
+
+	if (reg == data->reg_sense &&
+	    data->ngpios == 16 &&
+	    (data->model == SX150X_123 ||
+	     data->model == SX150X_456)) {
+		a = val & 0x00ff0000;
+		b = val & 0x0000ff00;
+
+		val &= 0xff0000ff;
+		val |= b << 8;
+		val |= a >> 8;
+	}
+
+	return val;
+}
+
+/*
+ * In order to mask the differences between 16 and 8 bit expander
+ * devices we set up a sligthly ficticious regmap that pretends to be
+ * a set of 32-bit (to accomodate RegSenseLow/RegSenseHigh
+ * pair/quartet) registers and transparently reconstructs those
+ * registers via multiple I2C/SMBus reads
+ *
+ * This way the rest of the driver code, interfacing with the chip via
+ * regmap API, can work assuming that each GPIO pin is represented by
+ * a group of bits at an offset proportional to GPIO number within a
+ * given register.
+ */
+static int sx150x_regmap_reg_read(void *context, unsigned int reg,
+				  unsigned int *result)
+{
+	int ret, n;
+	struct sx150x_pinctrl *pctl = context;
+	struct i2c_client *i2c = pctl->client;
+	const int width = sx150x_regmap_reg_width(pctl, reg);
+	unsigned int idx, val;
+
+	/*
+	 * There are four potential cases covered by this function:
+	 *
+	 * 1) 8-pin chip, single configuration bit register
+	 *
+	 *	This is trivial the code below just needs to read:
+	 *		reg  [ 7 6 5 4 3 2 1 0 ]
+	 *
+	 * 2) 8-pin chip, double configuration bit register (RegSense)
+	 *
+	 *	The read will be done as follows:
+	 *		reg      [ 7 7 6 6 5 5 4 4 ]
+	 *		reg + 1  [ 3 3 2 2 1 1 0 0 ]
+	 *
+	 * 3) 16-pin chip, single configuration bit register
+	 *
+	 *	The read will be done as follows:
+	 *		reg     [ f e d c b a 9 8 ]
+	 *		reg + 1 [ 7 6 5 4 3 2 1 0 ]
+	 *
+	 * 4) 16-pin chip, double configuration bit register (RegSense)
+	 *
+	 *	The read will be done as follows:
+	 *		reg     [ f f e e d d c c ]
+	 *		reg + 1 [ b b a a 9 9 8 8 ]
+	 *		reg + 2 [ 7 7 6 6 5 5 4 4 ]
+	 *		reg + 3 [ 3 3 2 2 1 1 0 0 ]
+	 */
+
+	for (n = width, val = 0, idx = reg; n > 0; n -= 8, idx++) {
+		val <<= 8;
+
+		ret = i2c_smbus_read_byte_data(i2c, idx);
+		if (ret < 0)
+			return ret;
+
+		val |= ret;
+	}
+
+	*result = sx150x_maybe_swizzle(pctl, reg, val);
+
+	return 0;
+}
+
+static int sx150x_regmap_reg_write(void *context, unsigned int reg,
+				   unsigned int val)
+{
+	int ret, n;
+	struct sx150x_pinctrl *pctl = context;
+	struct i2c_client *i2c = pctl->client;
+	const int width = sx150x_regmap_reg_width(pctl, reg);
+
+	val = sx150x_maybe_swizzle(pctl, reg, val);
+
+	n = (width - 1) & ~7;
+	do {
+		const u8 byte = (val >> n) & 0xff;
+
+		ret = i2c_smbus_write_byte_data(i2c, reg, byte);
+		if (ret < 0)
+			return ret;
+
+		reg++;
+		n -= 8;
+	} while (n >= 0);
+
+	return 0;
+}
+
+static bool sx150x_reg_volatile(struct device *dev, unsigned int reg)
+{
+	struct sx150x_pinctrl *pctl = i2c_get_clientdata(to_i2c_client(dev));
+
+	return reg == pctl->data->reg_irq_src || reg == pctl->data->reg_data;
+}
+
+const struct regmap_config sx150x_regmap_config = {
+	.reg_bits = 8,
+	.val_bits = 32,
+
+	.cache_type = REGCACHE_RBTREE,
+
+	.reg_read = sx150x_regmap_reg_read,
+	.reg_write = sx150x_regmap_reg_write,
+
+	.max_register = SX150X_MAX_REGISTER,
+	.volatile_reg = sx150x_reg_volatile,
+};
+
+static int sx150x_probe(struct i2c_client *client,
+			const struct i2c_device_id *id)
+{
+	static const u32 i2c_funcs = I2C_FUNC_SMBUS_BYTE_DATA |
+				     I2C_FUNC_SMBUS_WRITE_WORD_DATA;
+	struct device *dev = &client->dev;
+	struct sx150x_pinctrl *pctl;
+	int ret;
+
+	if (!i2c_check_functionality(client->adapter, i2c_funcs))
+		return -ENOSYS;
+
+	pctl = devm_kzalloc(dev, sizeof(*pctl), GFP_KERNEL);
+	if (!pctl)
+		return -ENOMEM;
+
+	i2c_set_clientdata(client, pctl);
+
+	pctl->dev = dev;
+	pctl->client = client;
+
+	if (dev->of_node)
+		pctl->data = of_device_get_match_data(dev);
+	else
+		pctl->data = (struct sx150x_device_data *)id->driver_data;
+
+	if (!pctl->data)
+		return -EINVAL;
+
+	pctl->regmap = devm_regmap_init(dev, NULL, pctl,
+					&sx150x_regmap_config);
+	if (IS_ERR(pctl->regmap)) {
+		ret = PTR_ERR(pctl->regmap);
+		dev_err(dev, "Failed to allocate register map: %d\n",
+			ret);
+		return ret;
+	}
+
+	mutex_init(&pctl->lock);
+
+	ret = sx150x_init_hw(pctl);
+	if (ret)
+		return ret;
+
+	/* Pinctrl_desc */
+	pctl->pinctrl_desc.name = "sx150x-pinctrl";
+	pctl->pinctrl_desc.pctlops = &sx150x_pinctrl_ops;
+	pctl->pinctrl_desc.confops = &sx150x_pinconf_ops;
+	pctl->pinctrl_desc.pins = pctl->data->pins;
+	pctl->pinctrl_desc.npins = pctl->data->npins;
+	pctl->pinctrl_desc.owner = THIS_MODULE;
+
+	ret = devm_pinctrl_register_and_init(dev, &pctl->pinctrl_desc,
+					     pctl, &pctl->pctldev);
+	if (ret) {
+		dev_err(dev, "Failed to register pinctrl device\n");
+		return ret;
+	}
+
+	ret = pinctrl_enable(pctl->pctldev);
+	if (ret) {
+		dev_err(dev, "Failed to enable pinctrl device\n");
+		return ret;
+	}
+
+	/* Register GPIO controller */
+	pctl->gpio.base = -1;
+	pctl->gpio.ngpio = pctl->data->npins;
+	pctl->gpio.get_direction = sx150x_gpio_get_direction;
+	pctl->gpio.direction_input = sx150x_gpio_direction_input;
+	pctl->gpio.direction_output = sx150x_gpio_direction_output;
+	pctl->gpio.get = sx150x_gpio_get;
+	pctl->gpio.set = sx150x_gpio_set;
+	pctl->gpio.set_config = gpiochip_generic_config;
+	pctl->gpio.parent = dev;
+
+	pctl->gpio.can_sleep = true;
+	pctl->gpio.label = devm_kstrdup(dev, client->name, GFP_KERNEL);
+	if (!pctl->gpio.label)
+		return -ENOMEM;
+
+	/*
+	 * Setting multiple pins is not safe when all pins are not
+	 * handled by the same regmap register. The oscio pin (present
+	 * on the SX150X_789 chips) lives in its own register, so
+	 * would require locking that is not in place at this time.
+	 */
+	if (pctl->data->model != SX150X_789)
+		pctl->gpio.set_multiple = sx150x_gpio_set_multiple;
+
+	ret = devm_gpiochip_add_data(dev, &pctl->gpio, pctl);
+	if (ret)
+		return ret;
+
+	ret = gpiochip_add_pin_range(&pctl->gpio, dev_name(dev),
+				     0, 0, pctl->data->npins);
+	if (ret)
+		return ret;
+
+	/* Add Interrupt support if an irq is specified */
+	if (client->irq > 0) {
+		pctl->irq_chip.irq_mask = sx150x_irq_mask;
+		pctl->irq_chip.irq_unmask = sx150x_irq_unmask;
+		pctl->irq_chip.irq_set_type = sx150x_irq_set_type;
+		pctl->irq_chip.irq_bus_lock = sx150x_irq_bus_lock;
+		pctl->irq_chip.irq_bus_sync_unlock = sx150x_irq_bus_sync_unlock;
+		pctl->irq_chip.name = devm_kstrdup(dev, client->name,
+						   GFP_KERNEL);
+		if (!pctl->irq_chip.name)
+			return -ENOMEM;
+
+		pctl->irq.masked = ~0;
+		pctl->irq.sense = 0;
+
+		/*
+		 * Because sx150x_irq_threaded_fn invokes all of the
+		 * nested interrrupt handlers via handle_nested_irq,
+		 * any "handler" passed to gpiochip_irqchip_add()
+		 * below is going to be ignored, so the choice of the
+		 * function does not matter that much.
+		 *
+		 * We set it to handle_bad_irq to avoid confusion,
+		 * plus it will be instantly noticeable if it is ever
+		 * called (should not happen)
+		 */
+		ret = gpiochip_irqchip_add_nested(&pctl->gpio,
+					&pctl->irq_chip, 0,
+					handle_bad_irq, IRQ_TYPE_NONE);
+		if (ret) {
+			dev_err(dev, "could not connect irqchip to gpiochip\n");
+			return ret;
+		}
+
+		ret = devm_request_threaded_irq(dev, client->irq, NULL,
+						sx150x_irq_thread_fn,
+						IRQF_ONESHOT | IRQF_SHARED |
+						IRQF_TRIGGER_FALLING,
+						pctl->irq_chip.name, pctl);
+		if (ret < 0)
+			return ret;
+
+		gpiochip_set_nested_irqchip(&pctl->gpio,
+					    &pctl->irq_chip,
+					    client->irq);
+	}
+
+	return 0;
+}
+
+static struct i2c_driver sx150x_driver = {
+	.driver = {
+		.name = "sx150x-pinctrl",
+		.of_match_table = of_match_ptr(sx150x_of_match),
+	},
+	.probe    = sx150x_probe,
+	.id_table = sx150x_id,
+};
+
+static int __init sx150x_init(void)
+{
+	return i2c_add_driver(&sx150x_driver);
+}
+subsys_initcall(sx150x_init);
diff --git a/trunk/linux-4.4.x/drivers/spi/spi-mt7621.c b/trunk/linux-4.4.x/drivers/spi/spi-mt7621.c
index 97f087305..a15dc9567 100644
--- a/trunk/linux-4.4.x/drivers/spi/spi-mt7621.c
+++ b/trunk/linux-4.4.x/drivers/spi/spi-mt7621.c
@@ -277,8 +277,8 @@ static int mt7621_spi_setup(struct spi_device *spi)
 		return -EINVAL;
 	}
 
-	dev_info(&spi->dev, "setup: max speed is %d Hz\n",
-		spi->max_speed_hz);
+	//dev_info(&spi->dev, "setup: max speed is %d Hz\n",
+	//	spi->max_speed_hz);
 
 	return 0;
 }
diff --git a/trunk/linux-4.4.x/drivers/usb/class/usblp.c b/trunk/linux-4.4.x/drivers/usb/class/usblp.c
index 07c3c3449..7660b1ded 100644
--- a/trunk/linux-4.4.x/drivers/usb/class/usblp.c
+++ b/trunk/linux-4.4.x/drivers/usb/class/usblp.c
@@ -60,6 +60,40 @@
 #include <linux/usb/ch9.h>
 #include <linux/ratelimit.h>
 
+/* Added by PaN */
+#include <linux/proc_fs.h>
+#include <asm/uaccess.h>
+// End PaN
+
+/* Added by PaN */
+struct print_buffer
+{
+	int len;
+	char *buf;
+};
+#define MODULE_NAME "usblp"
+#define MAX_CLASS_NAME	16
+#define MAX_MFR		16
+#define MAX_MODEL	32
+#define MAX_DESCRIPT	64
+#define MAX_STATUS_TYPE	6
+
+static struct proc_dir_entry *usblp_dir, *usblpid_file;
+struct parport_splink_device_info {
+	char class_name[MAX_CLASS_NAME];
+	char mfr[MAX_MFR];
+	char model[MAX_MODEL];
+	char description[MAX_DESCRIPT];
+};
+static struct parport_splink_device_info usblpid_info;
+struct parport_splink_device_info prn_info_tmp, *prn_info; // Added by JYWeng 20031212:
+char *strunknown = "unknown"; // Added by JYWeng 20031212:
+void parseKeywords(char *str_dev_id, char *keyword1, char *keyword2, char *prn_info_data, char *usblpid_info_data); // Added by JYWeng 20031212:
+static ssize_t usblp_write(struct file *file, const char *buffer, size_t count, loff_t *ppos);
+static ssize_t usblp_read(struct file *file, char *buffer, size_t count, loff_t *ppos);
+static long usblp_ioctl(struct file *file, unsigned int cmd, unsigned long arg); // modified by Jiahao
+// END PaN
+
 /*
  * Version Information
  */
@@ -70,6 +104,15 @@
 #define USBLP_BUF_SIZE_IN	1024
 #define USBLP_DEVICE_ID_SIZE	1024
 
+/****************add by JY 20031118*************************************/
+#define LPGETID		0x0610  /* get printer's device ID */
+#define LPWRITEDATA	0x0613  /* write data to printer */
+#define LPWRITEADDR	0x0614  /* write address to printer */
+#define LPREADDATA	0x0615  /* read data from pinter */
+#define LPREADADDR	0x0616  /* read address from pinter */
+//#define DEVICE_ID_SIZE	1024
+/*******************************************************/
+
 /* ioctls: */
 #define IOCNR_GET_DEVICE_ID		1
 #define IOCNR_GET_PROTOCOLS		2
@@ -406,6 +449,8 @@ static int usblp_open(struct inode *inode, struct file *file)
 	struct usblp *usblp;
 	struct usb_interface *intf;
 	int retval;
+	unsigned long arg = 0; // Added by PaN. Modified by Jiahao
+	long ioctl_retval; // Added by Jiahao
 
 	if (minor < 0)
 		return -ENODEV;
@@ -446,6 +491,12 @@ static int usblp_open(struct inode *inode, struct file *file)
 		file->private_data = NULL;
 		retval = -EIO;
 	}
+
+	/* Added by PaN */
+	if ((ioctl_retval = usblp_ioctl(file, LPGETID, arg)) < 0)  // modified by Jiahao
+	{
+		// Update device id failed
+	}
 out:
 	mutex_unlock(&usblp_mutex);
 	return retval;
@@ -455,6 +506,11 @@ static void usblp_cleanup(struct usblp *usblp)
 {
 	printk(KERN_INFO "usblp%d: removed\n", usblp->minor);
 
+	/* Added by PaN */
+	remove_proc_entry("usblpid", usblp_dir);
+	remove_proc_entry(MODULE_NAME, NULL);
+	/* End PaN */
+
 	kfree(usblp->readbuf);
 	kfree(usblp->device_id_string);
 	kfree(usblp->statusbuf);
@@ -506,6 +562,8 @@ static unsigned int usblp_poll(struct file *file, struct poll_table_struct *wait
 static long usblp_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 {
 	struct usblp *usblp = file->private_data;
+	struct print_buffer *user_buf; // Added by PaN
+	char *str_dev_id; // Added by PaN: JYWeng 20031212: modified from the above
 	int length, err, i;
 	unsigned char newChannel;
 	int status;
@@ -672,8 +730,62 @@ static long usblp_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 		}
 	else	/* old-style ioctl value */
 		switch (cmd) {
+			/*=================================================================================== PaN */
+		case LPGETID: /* get the DEVICE_ID string */
+			err = usblp_get_id(usblp, 0, usblp->device_id_string, USBLP_DEVICE_ID_SIZE - 1);
+			if (err < 0) {
+				dev_dbg(&usblp->intf->dev, "usblp%d: error = %d reading IEEE-1284 Device ID string",
+					usblp->minor, err);
+				usblp->device_id_string[0] = usblp->device_id_string[1] = '\0';
+				retval = -EIO;
+				goto done;
+			}
+
+			length = (usblp->device_id_string[0] << 8) + usblp->device_id_string[1]; /* big-endian */
+			if (length < USBLP_DEVICE_ID_SIZE)
+				usblp->device_id_string[length] = '\0';
+			else
+				usblp->device_id_string[USBLP_DEVICE_ID_SIZE - 1] = '\0';
+
+			dev_dbg(&usblp->intf->dev, "usblp%d Device ID string [%d/max %d]='%s'",
+				usblp->minor, length, cmd, &usblp->device_id_string[2]);
+
+			str_dev_id = &usblp->device_id_string[2];
+#if 1//JYWeng 20031212: modified from below
+			parseKeywords(str_dev_id, "MFG:", "MANUFACTURE:", prn_info->mfr, usblpid_info.mfr);
+			parseKeywords(str_dev_id, "MDL:", "MODEL:", prn_info->model, usblpid_info.model);
+			parseKeywords(str_dev_id, "CLS:", "CLASS:", prn_info->class_name, usblpid_info.class_name);
+			parseKeywords(str_dev_id, "DES:", "DESCRIPTION:", prn_info->description, usblpid_info.description);
+#endif//JYWeng 20031212: end
+
+			dev_dbg(&usblp->intf->dev, "Parsing USBLPID...");
+			if (copy_to_user((unsigned char *) arg,
+					prn_info, (unsigned long) length)) {
+				retval = -EFAULT;
+				goto done;
+			}
+			break;
+
+		case LPREADDATA:
+			mutex_unlock (&usblp_mutex);
+			user_buf = (struct print_buffer *)arg;
+			retval = usblp_read(file, user_buf->buf, user_buf->len, NULL);
+			mutex_lock (&usblp_mutex);
+			break;
+
+		case LPWRITEDATA:
+			mutex_unlock (&usblp_mutex);
+			user_buf = (struct print_buffer *)arg;
+			retval = usblp_write(file, user_buf->buf, user_buf->len, NULL);
+			mutex_lock (&usblp_mutex);
+			break;
+
+		case LPRESET:
+			usblp_reset(usblp);
+			break;
 
 		case LPGETSTATUS:
+			/* OLD USB Code Removed by PaN for Printer Server
 			retval = usblp_read_status(usblp, usblp->statusbuf);
 			if (retval) {
 				printk_ratelimited(KERN_ERR "usblp%d:"
@@ -683,9 +795,12 @@ static long usblp_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 				goto done;
 			}
 			status = *usblp->statusbuf;
+			*/
+			status = 0;
 			if (copy_to_user((void __user *)arg, &status, sizeof(int)))
 				retval = -EFAULT;
 			break;
+/*=================================================================== PaN for Printer Server */
 
 		case LPABORT:
 			if (arg)
@@ -1096,8 +1211,107 @@ static ssize_t usblp_show_ieee1284_id(struct device *dev, struct device_attribut
 	return sprintf(buf, "%s", usblp->device_id_string+2);
 }
 
+/* Added by PaN */
+
+/*********************************************************
+** JYWeng 20031212: parsing the information of printers **
+*********************************************************/
+void parseKeywords(char *str_dev_id, char *keyword1, char *keyword2, char *prn_info_data, char *usblpid_info_data)
+{
+	char *strtmp;
+	int i, unk = 0;
+
+	if ((strtmp = strstr(str_dev_id, keyword1)) == NULL) {
+		if ((strtmp = strstr(str_dev_id, keyword2)) == NULL) {
+			for (i = 0; i < 7; i++) {
+				prn_info_data[i] = strunknown[i];
+				usblpid_info_data[i] = strunknown[i];
+			}
+			prn_info_data[i] = '\0';
+			usblpid_info_data[i] = '\0';
+			unk = 1;
+
+			return;
+		}
+		else
+			strtmp += strlen(keyword2);
+	}
+	else
+		strtmp += strlen(keyword1);
+
+	i = 0;
+	while (unk == 0 && strtmp[i] && strtmp[i] != ';') {
+		prn_info_data[i] = strtmp[i];
+		usblpid_info_data[i] = strtmp[i];
+		i++;
+	}
+	prn_info_data[i] = '\0';
+	usblpid_info_data[i] = '\0';
+
+	return;
+}
+
+static ssize_t proc_read_usblpid(struct file *file, char __user *buf, size_t count, loff_t *ppos)
+{
+	int len = 0;
+
+	len=sprintf(buf, "Manufacturer=%s\nModel=%s\nClass=%s\nDescription=%s\n\n",
+	usblpid_info.mfr, usblpid_info.model, usblpid_info.class_name, usblpid_info.description);
+
+	return len;
+}
+
+static int proc_get_usblpid(struct usblp *usblp)
+{
+//JYWeng 20031212: set this as global char *strtmp, *str_dev_id, *strunknown = "unknown"; // Added by PaN
+	char *str_dev_id; // Added by PaN: JYWeng 20031212: modified from the above
+	int length, err;
+	int retval = 0;
+
+	prn_info= &prn_info_tmp; // Added by JYWeng 20031212:
+
+	err = usblp_get_id(usblp, 0, usblp->device_id_string, USBLP_DEVICE_ID_SIZE - 1);
+
+	if (err < 0) {
+		dev_dbg(&usblp->intf->dev, "usblp%d: error = %d reading IEEE-1284 Device ID string",
+			usblp->minor, err);
+			usblp->device_id_string[0] = usblp->device_id_string[1] = '\0';
+		retval = -EIO;
+		goto done;
+	}
+
+	length = (usblp->device_id_string[0] << 8) + usblp->device_id_string[1]; /* big-endian */
+	if (length < USBLP_DEVICE_ID_SIZE)
+		usblp->device_id_string[length] = '\0';
+	else
+		usblp->device_id_string[USBLP_DEVICE_ID_SIZE - 1] = '\0';
+
+	dev_dbg(&usblp->intf->dev, "usblp%d Device ID string [%d]='%s'",
+		usblp->minor, length, &usblp->device_id_string[2]);
+
+	str_dev_id = &usblp->device_id_string[2];
+#if 1//JYWeng 20031212: modified from below
+				parseKeywords(str_dev_id, "MFG:", "MANUFACTURE:", prn_info->mfr, usblpid_info.mfr);
+				parseKeywords(str_dev_id, "MDL:", "MODEL:", prn_info->model, usblpid_info.model);
+				parseKeywords(str_dev_id, "CLS:", "CLASS:", prn_info->class_name, usblpid_info.class_name);
+				parseKeywords(str_dev_id, "DES:", "DESCRIPTION:", prn_info->description, usblpid_info.description);
+#endif//JYWeng 20031212: end
+
+done:
+	return retval;
+}
+
+int pan_count = 0;
+// End PaN
+
 static DEVICE_ATTR(ieee1284_id, S_IRUGO, usblp_show_ieee1284_id, NULL);
 
+static const struct file_operations usblpid_fops =
+{
+	.owner = THIS_MODULE,
+	.read = proc_read_usblpid,
+};
+
 static int usblp_probe(struct usb_interface *intf,
 		       const struct usb_device_id *id)
 {
@@ -1201,6 +1415,34 @@ static int usblp_probe(struct usb_interface *intf,
 		le16_to_cpu(usblp->dev->descriptor.idVendor),
 		le16_to_cpu(usblp->dev->descriptor.idProduct));
 
+	/* Added by PaN */
+	/* create directory */
+	if (pan_count < 0)
+		pan_count = 0;
+	++pan_count;
+	if (pan_count == 1)
+	{
+		usblp_dir = proc_mkdir(MODULE_NAME, NULL);
+		if (usblp_dir == NULL) {
+			goto outpan;
+		}
+		//usblp_dir->owner = THIS_MODULE;
+
+		usblpid_file = proc_create("usblpid", 0444, usblp_dir, &usblpid_fops);
+		if (usblpid_file == NULL) {
+			remove_proc_entry(MODULE_NAME, NULL);
+
+			goto outpan;
+		}
+		//usblpid_file->owner = THIS_MODULE;
+		/* get device id */
+		if (proc_get_usblpid(usblp) < 0)
+			dev_dbg(&usblp->intf->dev, "proc:get usblpid error!!");
+
+	}
+outpan:
+	// End PaN
+
 	return 0;
 
 abort_intfdata:
@@ -1391,6 +1633,8 @@ static void usblp_disconnect(struct usb_interface *intf)
 	mutex_lock(&usblp_mutex);
 	mutex_lock(&usblp->mut);
 	usblp->present = 0;
+	if (pan_count > 0)
+		--pan_count;
 	wake_up(&usblp->wwait);
 	wake_up(&usblp->rwait);
 	usb_set_intfdata(intf, NULL);
diff --git a/trunk/linux-4.4.x/drivers/usb/core/devio.c b/trunk/linux-4.4.x/drivers/usb/core/devio.c
index 7559d9669..d4d53f56f 100644
--- a/trunk/linux-4.4.x/drivers/usb/core/devio.c
+++ b/trunk/linux-4.4.x/drivers/usb/core/devio.c
@@ -631,6 +631,9 @@ static int claimintf(struct usb_dev_state *ps, unsigned int ifnum)
 	struct usb_interface *intf;
 	int err;
 
+	if (!strcmp(current->comm, "u2ec"))			// patch for U2EC
+		return 0;
+
 	if (ifnum >= 8*sizeof(ps->ifclaimed))
 		return -EINVAL;
 	/* already claimed */
@@ -676,9 +679,11 @@ static int checkintf(struct usb_dev_state *ps, unsigned int ifnum)
 	if (test_bit(ifnum, &ps->ifclaimed))
 		return 0;
 	/* if not yet claimed, claim it for the driver */
+#if 0								// patch for U2EC
 	dev_warn(&ps->dev->dev, "usbfs: process %d (%s) did not claim "
 		 "interface %u before use\n", task_pid_nr(current),
 		 current->comm, ifnum);
+#endif
 	return claimintf(ps, ifnum);
 }
 
diff --git a/trunk/linux-4.4.x/drivers/usb/core/message.c b/trunk/linux-4.4.x/drivers/usb/core/message.c
index adc696a76..dad2e18a7 100644
--- a/trunk/linux-4.4.x/drivers/usb/core/message.c
+++ b/trunk/linux-4.4.x/drivers/usb/core/message.c
@@ -922,6 +922,7 @@ int usb_get_device_descriptor(struct usb_device *dev, unsigned int size)
 	kfree(desc);
 	return ret;
 }
+EXPORT_SYMBOL_GPL(usb_get_device_descriptor);
 
 /**
  * usb_get_status - issues a GET_STATUS call
diff --git a/trunk/linux-4.4.x/drivers/usb/core/usb.c b/trunk/linux-4.4.x/drivers/usb/core/usb.c
index 36e5098e4..222b88d8f 100644
--- a/trunk/linux-4.4.x/drivers/usb/core/usb.c
+++ b/trunk/linux-4.4.x/drivers/usb/core/usb.c
@@ -706,6 +706,71 @@ int __usb_get_extra_descriptor(char *buffer, unsigned size,
 }
 EXPORT_SYMBOL_GPL(__usb_get_extra_descriptor);
 
+static struct usb_device *match_device_name(struct usb_device *dev,
+					    const char *name)
+{
+	struct usb_device *ret_dev = NULL;
+	struct usb_device *childdev = NULL;
+	int child;
+
+	dev_dbg(&dev->dev, "check for name %s ...\n", name);
+
+	/* see if this device matches */
+	if (strcmp(dev_name(&dev->dev), name) == 0 ) {
+		dev_dbg(&dev->dev, "matched this device!\n");
+		ret_dev = usb_get_dev(dev);
+		goto exit;
+	}
+	/* look through all of the children of this device */
+	usb_hub_for_each_child(dev, child, childdev) {
+		if (childdev) {
+			usb_lock_device(childdev);
+			ret_dev = match_device_name(childdev, name);
+			usb_unlock_device(childdev);
+			if (ret_dev)
+				goto exit;
+		}
+	}
+exit:
+	return ret_dev;
+}
+
+/**
+ * usb_find_device_by_name - find a specific usb device in the system
+ * @name: the name of the device to find
+ *
+ * Returns a pointer to a struct usb_device if such a specified usb
+ * device is present in the system currently.  The usage count of the
+ * device will be incremented if a device is found.  Make sure to call
+ * usb_put_dev() when the caller is finished with the device.
+ *
+ * If a device with the specified bus id is not found, NULL is returned.
+ */
+struct usb_device *usb_find_device_by_name(const char *name)
+{
+	struct list_head *buslist;
+	struct usb_bus *bus;
+	struct usb_device *dev = NULL;
+
+	mutex_lock(&usb_bus_list_lock);
+	for (buslist = usb_bus_list.next;
+	     buslist != &usb_bus_list;
+	     buslist = buslist->next) {
+		bus = container_of(buslist, struct usb_bus, bus_list);
+		if (!bus->root_hub)
+			continue;
+		usb_lock_device(bus->root_hub);
+		dev = match_device_name(bus->root_hub, name);
+		usb_unlock_device(bus->root_hub);
+		if (dev)
+			goto exit;
+	}
+exit:
+	mutex_unlock(&usb_bus_list_lock);
+	return dev;
+}
+EXPORT_SYMBOL_GPL(usb_find_device_by_name);
+
 /**
  * usb_alloc_coherent - allocate dma-consistent buffer for URB_NO_xxx_DMA_MAP
  * @dev: device the buffer will be used with
diff --git a/trunk/linux-4.4.x/drivers/usb/host/Makefile b/trunk/linux-4.4.x/drivers/usb/host/Makefile
index 65a06b438..ddeeaece8 100644
--- a/trunk/linux-4.4.x/drivers/usb/host/Makefile
+++ b/trunk/linux-4.4.x/drivers/usb/host/Makefile
@@ -10,11 +10,16 @@ fhci-y += fhci-mem.o fhci-tds.o fhci-sched.o
 
 fhci-$(CONFIG_FHCI_DEBUG) += fhci-dbg.o
 
+# ASUS_EXT
+ifeq ($(CONFIG_ASUS_EXT),y)
+EXTRA_CFLAGS += -DASUS_EXT
+endif
+
 xhci-hcd-y := xhci.o xhci-mem.o
 xhci-hcd-y += xhci-ring.o xhci-hub.o xhci-dbg.o
 xhci-hcd-y += xhci-trace.o
 ifneq ($(CONFIG_USB_XHCI_MTK), )
-	xhci-hcd-y += xhci-mtk-sch.o
+	xhci-hcd-y += xhci-mtk-sch.o xhci-mtk-test.o
 endif
 
 xhci-plat-hcd-y := xhci-plat.o
diff --git a/trunk/linux-4.4.x/drivers/usb/host/xhci-hub.c b/trunk/linux-4.4.x/drivers/usb/host/xhci-hub.c
index 2f8119fa9..8a9bbac76 100644
--- a/trunk/linux-4.4.x/drivers/usb/host/xhci-hub.c
+++ b/trunk/linux-4.4.x/drivers/usb/host/xhci-hub.c
@@ -27,8 +27,6 @@
 #include "xhci.h"
 #include "xhci-trace.h"
 
-extern int usb3_disable;
-
 #define	PORT_WAKE_BITS	(PORT_WKOC_E | PORT_WKDISC_E | PORT_WKCONN_E)
 #define	PORT_RWC_BITS	(PORT_CSC | PORT_PEC | PORT_WRC | PORT_OCC | \
 			 PORT_RC | PORT_PLC | PORT_PE)
@@ -1215,11 +1213,13 @@ int xhci_hub_control(struct usb_hcd *hcd, u16 typeReq, u16 wValue,
 			 * However, hub_wq will ignore the roothub events until
 			 * the roothub is registered.
 			 */
-			if (usb3_disable && hcd->speed == HCD_USB3)
-				writel(temp & ~PORT_POWER, port_array[wIndex]);
-			else
+#if defined(ASUS_EXT)
+			if (u3intf || hcd->speed != HCD_USB3) {
 				writel(temp | PORT_POWER, port_array[wIndex]);
-
+			}
+#else
+			writel(temp | PORT_POWER, port_array[wIndex]);
+#endif
 			temp = readl(port_array[wIndex]);
 			xhci_dbg(xhci, "set port power, actual port %d status  = 0x%x\n", wIndex, temp);
 
diff --git a/trunk/linux-4.4.x/drivers/usb/host/xhci-mem.c b/trunk/linux-4.4.x/drivers/usb/host/xhci-mem.c
index 0ec809a35..8f94bdf7f 100644
--- a/trunk/linux-4.4.x/drivers/usb/host/xhci-mem.c
+++ b/trunk/linux-4.4.x/drivers/usb/host/xhci-mem.c
@@ -2251,7 +2251,11 @@ static void xhci_add_in_port(struct xhci_hcd *xhci, unsigned int num_ports,
 static int xhci_setup_port_arrays(struct xhci_hcd *xhci, gfp_t flags)
 {
 	__le32 __iomem *addr, *tmp_addr;
+#if defined(ASUS_EXT)
+	u32 offset, tmp_offset, s1;
+#else
 	u32 offset, tmp_offset;
+#endif
 	unsigned int num_ports;
 	int i, j, port_index;
 	int cap_count = 0;
@@ -2388,10 +2392,25 @@ static int xhci_setup_port_arrays(struct xhci_hcd *xhci, gfp_t flags)
 				xhci->usb3_ports[port_index] =
 					&xhci->op_regs->port_status_base +
 					NUM_PORT_REGS*i;
+#if defined(ASUS_EXT)
+				if (u3intf) {
+					xhci_dbg_trace(xhci, trace_xhci_dbg_init,
+						"USB 3.0 port at index %u, "
+						"addr = %p", i,
+						xhci->usb3_ports[port_index]);
+				} else {
+					addr = xhci->usb3_ports[port_index];
+					s1 = readl(addr);
+					writel((s1 | PORT_PE) & ~(PORT_RESET | PORT_POWER), addr);
+					xhci_warn(xhci, "## USB3 port %d/%d addr(%p) s1(%08x) --> (%08x)\n",
+							port_index, i, addr, s1, readl(addr));
+				}
+#else
 				xhci_dbg_trace(xhci, trace_xhci_dbg_init,
 						"USB 3.0 port at index %u, "
 						"addr = %p", i,
 						xhci->usb3_ports[port_index]);
+#endif
 				port_index++;
 				if (port_index == xhci->num_usb3_ports)
 					break;
diff --git a/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk-test.c b/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk-test.c
new file mode 100644
index 000000000..0fcd6d724
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk-test.c
@@ -0,0 +1,739 @@
+
+#include <linux/platform_device.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/usb.h>
+#include <linux/kobject.h>
+
+#include "../core/usb.h"
+#include "xhci-mtk.h"
+
+static int t_test_j(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+static int t_test_k(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+static int t_test_se0(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+static int t_test_packet(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+static int t_test_suspend(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+static int t_test_resume(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+static int t_test_get_device_descriptor(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+static int t_test_enumerate_bus(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+
+#define PORT_PLS_VALUE(p) ((p >> 5) & 0xf)
+
+#define MAX_NAME_SIZE 32
+#define MAX_ARG_SIZE 4
+
+struct hqa_test_cmd {
+	char name[MAX_NAME_SIZE];
+	int (*cb_func)(struct xhci_hcd_mtk *mtk, int argc, char **argv);
+	char *discription;
+};
+
+
+struct hqa_test_cmd xhci_mtk_hqa_cmds[] = {
+	{"test.j", &t_test_j, "Test_J"},
+	{"test.k", &t_test_k, "Test_K"},
+	{"test.se0", &t_test_se0, "Test_SE0_NAK"},
+	{"test.packet", &t_test_packet, "Test_PACKET"},
+	{"test.suspend", &t_test_suspend, "Port Suspend"},
+	{"test.resume", &t_test_resume, "Port Resume"},
+	{"test.enumbus", &t_test_enumerate_bus, "Enumerate Bus"},
+	{"test.getdesc", &t_test_get_device_descriptor, "Single Step Get Device Discriptor"},
+	{"", NULL, ""},
+};
+
+
+int call_hqa_func(struct xhci_hcd_mtk *mtk, char *buf)
+{
+	struct hqa_test_cmd *hqa;
+	struct usb_hcd *hcd = mtk->hcd;
+	char *argv[MAX_ARG_SIZE];
+	int argc;
+	int i;
+
+	argc = 0;
+	do {
+		argv[argc] = strsep(&buf, " ");
+		xhci_err(hcd_to_xhci(hcd), "[%d] %s\r\n", argc, argv[argc]);
+		argc++;
+	} while (buf);
+
+	for (i = 0; i < ARRAY_SIZE(xhci_mtk_hqa_cmds); i++) {
+		hqa = &xhci_mtk_hqa_cmds[i];
+		if ((!strcmp(hqa->name, argv[0])) && (hqa->cb_func != NULL))
+			return hqa->cb_func(mtk, argc, argv);
+	}
+
+	return -1;
+}
+
+static int test_mode_enter(struct xhci_hcd_mtk *mtk, u32 port_id, u32 test_value)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	u32 __iomem *addr;
+	u32 temp;
+
+	if (mtk->test_mode == 0) {
+		xhci_stop(hcd);
+		xhci_halt(xhci);
+	}
+
+	addr = &xhci->op_regs->port_power_base + NUM_PORT_REGS * ((port_id - 1) & 0xff);
+	temp = readl(addr);
+	temp &= ~(0xf << 28);
+	temp |= (test_value << 28);
+	writel(temp, addr);
+
+	mtk->test_mode = 1;
+
+	return 0;
+}
+
+static int test_mode_exit(struct xhci_hcd_mtk *mtk)
+{
+	/*
+	*struct usb_hcd *hcd = mtk->hcd;
+	*struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	*/
+
+	if (mtk->test_mode == 1) {
+#if 0
+		xhci_reset(xhci);
+		/*reinitIP(&pdev->dev);*/
+
+		if (!usb_hcd_is_primary_hcd(test_hcd))
+			secondary_hcd = test_hcd;
+		else
+			secondary_hcd = xhci->shared_hcd;
+
+		retval = xhci_init(test_hcd->primary_hcd);
+		if (retval)
+			return retval;
+
+		retval = xhci_run(test_hcd->primary_hcd);
+		if (!retval)
+			retval = xhci_run(secondary_hcd);
+
+		/*enableXhciAllPortPower(xhci);*/
+#endif
+		mtk->test_mode = 0;
+	}
+	return 0;
+}
+
+static int t_test_j(struct xhci_hcd_mtk *mtk, int argc, char **argv)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	long port_id;
+	u32 test_value;
+
+	port_id = 2;
+	test_value = 1;
+
+	if (argc > 1 && kstrtol(argv[1], 10, &port_id))
+		xhci_err(xhci, "mu3h %s get port-id failed\n", __func__);
+
+	xhci_err(xhci, "mu3h %s test port%d\n", __func__, (int)port_id);
+	test_mode_enter(mtk, port_id, test_value);
+
+	return 0;
+}
+
+static int t_test_k(struct xhci_hcd_mtk *mtk, int argc, char **argv)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	long port_id;
+	u32 test_value;
+
+	port_id = 2;
+	test_value = 2;
+
+	if (argc > 1 && kstrtol(argv[1], 10, &port_id))
+		xhci_err(xhci, "mu3h %s get port-id failed\n", __func__);
+
+	xhci_err(xhci, "mu3h %s test port%d\n", __func__, (int)port_id);
+	test_mode_enter(mtk, port_id, test_value);
+
+	return 0;
+}
+
+static int t_test_se0(struct xhci_hcd_mtk *mtk, int argc, char **argv)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	long port_id;
+	u32 test_value;
+
+	port_id = 2;
+	test_value = 3;
+
+	if (argc > 1 && kstrtol(argv[1], 10, &port_id))
+		xhci_err(xhci, "mu3h %s get port-id failed\n", __func__);
+
+	xhci_err(xhci, "mu3h %s test port%ld\n", __func__, port_id);
+	test_mode_enter(mtk, port_id, test_value);
+
+	return 0;
+}
+
+static int t_test_packet(struct xhci_hcd_mtk *mtk, int argc, char **argv)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	long port_id;
+	u32 test_value;
+
+	port_id = 2;
+	test_value = 4;
+
+	if (argc > 1 && kstrtol(argv[1], 10, &port_id))
+		xhci_err(xhci, "mu3h %s get port-id failed\n", __func__);
+
+	xhci_err(xhci, "mu3h %s test port%ld\n", __func__, port_id);
+	test_mode_enter(mtk, port_id, test_value);
+
+	return 0;
+}
+
+static int t_test_suspend(struct xhci_hcd_mtk *mtk, int argc, char **argv)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	u32 __iomem *addr;
+	u32 temp;
+	long port_id;
+
+	port_id = 2;
+
+	if (argc > 1 && kstrtol(argv[1], 10, &port_id))
+		xhci_err(xhci, "mu3h %s get port-id failed\n", __func__);
+
+	xhci_err(xhci, "mu3h %s test port%d\n", __func__, (int)port_id);
+
+	xhci_err(xhci, "%s: stop port polling\n", __func__);
+	clear_bit(HCD_FLAG_POLL_RH, &hcd->flags);
+	del_timer_sync(&hcd->rh_timer);
+	clear_bit(HCD_FLAG_POLL_RH, &xhci->shared_hcd->flags);
+	del_timer_sync(&xhci->shared_hcd->rh_timer);
+	clear_bit(HCD_FLAG_HW_ACCESSIBLE, &hcd->flags);
+	clear_bit(HCD_FLAG_HW_ACCESSIBLE, &xhci->shared_hcd->flags);
+
+	temp = readl(&xhci->ir_set->irq_pending);
+	writel(ER_IRQ_DISABLE(temp), &xhci->ir_set->irq_pending);
+
+	if (mtk->test_mode == 1)
+		test_mode_exit(mtk);
+
+	/* set PLS = 3 */
+	addr = &xhci->op_regs->port_status_base + NUM_PORT_REGS*((port_id - 1) & 0xff);
+	temp = readl(addr);
+	temp = xhci_port_state_to_neutral(temp);
+	temp = (temp & ~(0xf << 5));
+	temp = (temp | (3 << 5) | PORT_LINK_STROBE);
+	writel(temp, addr);
+	xhci_handshake(addr, (0xf << 5), (3 << 5), 30*1000);
+
+	temp = readl(addr);
+	if (PORT_PLS_VALUE(temp) != 3)
+		xhci_err(xhci, "port not enter suspend state\n");
+	else
+		xhci_err(xhci, "port enter suspend state\n");
+
+	return 0;
+}
+
+static int t_test_resume(struct xhci_hcd_mtk *mtk, int argc, char **argv)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	u32 __iomem *addr;
+	u32 temp;
+	long port_id;
+	int retval = 0;
+
+	port_id = 2;
+
+	if (argc > 1 && kstrtol(argv[1], 10, &port_id))
+		xhci_err(xhci, "mu3h %s get port-id failed\n", __func__);
+
+	xhci_err(xhci, "mu3h %s test port%d\n", __func__, (int)port_id);
+
+	if (mtk->test_mode == 1) {
+		xhci_err(xhci, "please suspend port first\n");
+		return -1;
+	}
+	addr = &xhci->op_regs->port_status_base + NUM_PORT_REGS * ((port_id - 1) & 0xff);
+	temp = readl(addr);
+	if (PORT_PLS_VALUE(temp) != 3) {
+		xhci_err(xhci, "port not in suspend state, please suspend port first\n");
+		retval = -1;
+	} else {
+		temp = xhci_port_state_to_neutral(temp);
+		temp = (temp & ~(0xf << 5));
+		temp = (temp | (15 << 5) | PORT_LINK_STROBE);
+		writel(temp, addr);
+		mdelay(20);
+
+		temp = readl(addr);
+		temp = xhci_port_state_to_neutral(temp);
+		temp = (temp & ~(0xf << 5));
+		temp = (temp | PORT_LINK_STROBE);
+		writel(temp, addr);
+
+		xhci_handshake(addr, (0xf << 5), (0 << 5), 100*1000);
+		temp = readl(addr);
+		if (PORT_PLS_VALUE(temp) != 0) {
+			xhci_err(xhci, "port rusume fail, %x\n", PORT_PLS_VALUE(temp));
+			retval = -1;
+		} else {
+		  xhci_err(xhci, "port resume ok\n");
+		}
+	}
+
+	return retval;
+}
+
+static int t_test_enumerate_bus(struct xhci_hcd_mtk *mtk, int argc, char **argv)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	struct usb_device *usb2_rh;
+	struct usb_device *udev;
+	long port_id;
+	u32 retval;
+
+	port_id = 2;
+
+	if (argc > 1 && kstrtol(argv[1], 10, &port_id))
+		xhci_err(xhci, "mu3h %s get port-id failed\n", __func__);
+
+	xhci_err(xhci, "mu3h %s test port%d\n", __func__, (int)port_id);
+
+	if (mtk->test_mode == 1) {
+		test_mode_exit(mtk);
+		return 0;
+	}
+
+	usb2_rh = hcd->self.root_hub;
+
+#if 1
+	udev = usb_hub_find_child(usb2_rh, port_id - 1);
+#else
+	udev = usb2_rh->children[port_id-2];
+#endif
+
+	if (udev != NULL) {
+		retval = usb_reset_device(udev);
+		if (retval) {
+			xhci_err(xhci, "ERROR: enumerate bus fail!\n");
+			return -1;
+		}
+	} else {
+		xhci_err(xhci, "ERROR: Device does not exist!\n");
+		return -1;
+	}
+
+	return 0;
+}
+static int t_test_get_device_descriptor(struct xhci_hcd_mtk *mtk, int argc, char **argv)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	struct usb_device *usb2_rh;
+	struct usb_device *udev;
+	long port_id;
+	u32 retval = 0;
+
+	port_id = 2;
+
+	if (argc > 1 && kstrtol(argv[1], 10, &port_id))
+		xhci_err(xhci, "mu3h %s get port-id failed\n", __func__);
+
+	xhci_err(xhci, "mu3h %s test port%d\n", __func__, (int)port_id);
+
+	if (mtk->test_mode == 1) {
+		test_mode_exit(mtk);
+		msleep(2000);
+	}
+
+	usb2_rh = hcd->self.root_hub;
+
+	udev = usb_hub_find_child(usb2_rh, port_id - 1);
+
+	if (udev != NULL) {
+		retval = usb_get_device_descriptor(udev, USB_DT_DEVICE_SIZE);
+		if (retval != sizeof(udev->descriptor)) {
+			xhci_err(xhci, "ERROR: get device descriptor fail!\n");
+			return -1;
+		}
+	} else {
+		xhci_err(xhci, "ERROR: Device does not exist!\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+static ssize_t mu3h_hqa_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	int len = 0;
+	int bufLen = PAGE_SIZE;
+	struct hqa_test_cmd *hqa;
+	int i;
+
+	len += snprintf(buf+len, bufLen-len, "info:\n");
+	len += snprintf(buf+len, bufLen-len, "\techo -n item port-id > hqa\n");
+	len += snprintf(buf+len, bufLen-len, "\tport-id : based on number of usb3-port, e.g.\n");
+	len += snprintf(buf+len, bufLen-len, "\t\txHCI with 1 u3p, 2 u2p: 1st u2p-id is 2(1+1), 2nd is 3\n");
+	len += snprintf(buf+len, bufLen-len, "items:\n");
+
+	for (i = 0; i < ARRAY_SIZE(xhci_mtk_hqa_cmds); i++) {
+		hqa = &xhci_mtk_hqa_cmds[i];
+		len += snprintf(buf+len, bufLen-len, "\t%s: %s\n", hqa->name, hqa->discription);
+	}
+
+	return len;
+}
+
+static ssize_t mu3h_hqa_store(struct device *dev, struct device_attribute *attr, const char *buf, size_t count)
+{
+	struct xhci_hcd_mtk *mtk = dev_get_drvdata(dev);
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	int retval;
+
+	retval = call_hqa_func(mtk, (char *)buf);
+	if (retval < 0) {
+		xhci_err(xhci, "mu3h cli fail\n");
+		return -1;
+	}
+
+	return count;
+}
+
+static DEVICE_ATTR(hqa, 0664, mu3h_hqa_show, mu3h_hqa_store);
+
+#define REGS_LIMIT_XHCI 0x1000
+#define REGS_LIMIT_MU3D 0x3000
+#define REGS_LIMIT_IPPC 0x100
+#define REGS_LIMIT_PHYS 0x10000
+
+#define REGS_XHCI_OFFSET 0x0000
+#define REGS_MU3D_OFFSET 0x1000
+#define REGS_IPPC_OFFSET 0x4700
+#define REGS_PHY_OFFSET 0x4800
+
+static ssize_t ssusb_reg_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	int ret = -EINVAL;
+
+	ret = sprintf(buf, "SSUSB register operation interface help info.\n"
+		"  rx - read xhci reg: offset [len]\n"
+		"  rm - read mu3d reg: offset [len]\n"
+		"  ri - read ippc reg: offset [len]\n"
+		"  rp - read phy reg: offset [len]\n"
+		"  wx - write xhci reg: offset value\n"
+		"  wm - write mu3d reg: offset value\n"
+		"  wi - write ippc reg: offset value\n"
+		"  wp - write phy reg: offset value\n"
+		"  sx - set xhci mac reg bits: offset bit_start mask value\n"
+		"  sm - set mu3d mac reg bits: offset bit_start mask value\n"
+		"  si - set ippc reg bits: offset bit_start mask value\n"
+		"  sp - set phy reg bits: offset bit_start mask value\n"
+		"  px - print xhci mac reg bits: offset bit_start mask\n"
+		"  pm - print mu3d mac reg bits: offset bit_start mask\n"
+		"  pi - print ippc reg bits: offset bit_start mask\n"
+		"  pp - print phy reg bits: offset bit_start mask\n"
+		"  NOTE: numbers should be HEX, except bit_star(DEC)\n");
+
+	return ret;
+}
+
+/* base address: return value; limit is put into @limit */
+static void __iomem *get_reg_base_limit(struct xhci_hcd_mtk *mtk,  const char *buf, u32 *limit)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	void __iomem *base;
+	u32 len = 0;
+
+	switch (buf[1]) {
+	case 'x':
+		base = mtk->ip_base + REGS_XHCI_OFFSET;
+		len = REGS_LIMIT_XHCI;
+		xhci_info(xhci, "xhci's reg:\n");
+		break;
+	case 'm':
+		base = mtk->ip_base + REGS_MU3D_OFFSET;
+		len = REGS_LIMIT_MU3D;
+		xhci_info(xhci, "mu3d's reg:\n");
+		break;
+	case 'i':
+		base = mtk->ip_base + REGS_IPPC_OFFSET;
+		len = REGS_LIMIT_IPPC;
+		xhci_info(xhci, "ippc's reg:\n");
+		break;
+	case 'p':
+		base = mtk->ip_base + REGS_PHY_OFFSET;
+		len = REGS_LIMIT_PHYS;
+		xhci_info(xhci, "phy's reg:\n");
+		break;
+	default:
+		base = NULL;
+	}
+
+	*limit = len;
+
+	return base;
+}
+
+static void ssusb_write_reg(struct xhci_hcd_mtk *mtk, const char *buf)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	void __iomem *base;
+	u32 offset = 0;
+	u32 value = 0;
+	u32 old_val = 0;
+	u32 limit = 0;
+	u32 param;
+
+	param = sscanf(buf, "%*s 0x%x 0x%x", &offset, &value);
+	xhci_info(xhci, "params-%d (offset: %#x, value: %#x)\n", param, offset, value);
+
+	base = get_reg_base_limit(mtk, buf, &limit);
+	if (!base || (param != 2)) {
+		xhci_err(xhci, "params are invalid!\n");
+		return;
+	}
+
+	offset &= ~0x3;  /* 4-bytes align */
+	if (offset >= limit) {
+		xhci_err(xhci, "reg's offset overrun!\n");
+		return;
+	}
+	old_val = readl(base + offset);
+	writel(value, base + offset);
+	xhci_info(xhci, "0x%8.8x : 0x%8.8x --> 0x%8.8x\n", offset, old_val,
+		readl(base + offset));
+}
+
+static void read_single_reg(struct xhci_hcd_mtk *mtk, void __iomem *base, u32 offset, u32 limit)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	u32 value;
+
+	offset &= ~0x3;  /* 4-bytes align */
+	if (offset >= limit) {
+		xhci_err(xhci, "reg's offset overrun!\n");
+		return;
+	}
+	value = readl(base + offset);
+	xhci_err(xhci, "0x%8.8x : 0x%8.8x\n", offset, value);
+}
+
+static void read_multi_regs(struct xhci_hcd_mtk *mtk, void __iomem *base, u32 offset, u32 len, u32 limit)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	int i;
+
+	/* at least 4 ints */
+	offset &= ~0xF;
+	len = (len + 0x3) & ~0x3;
+
+	if (offset + len > limit) {
+		xhci_err(xhci, "reg's offset overrun!\n");
+		return;
+	}
+
+	len >>= 2;
+	xhci_info(xhci, "read regs [%#x, %#x)\n", offset, offset + (len << 4));
+	for (i = 0; i < len; i++) {
+		xhci_err(xhci, "0x%8.8x : 0x%8.8x 0x%8.8x 0x%8.8x 0x%8.8x\n",
+			offset, readl(base + offset), readl(base + offset + 0x4),
+			readl(base + offset + 0x8), readl(base + offset + 0xc));
+		offset += 0x10;
+	}
+}
+
+static void ssusb_read_regs(struct xhci_hcd_mtk *mtk, const char *buf)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	void __iomem *base;
+	u32 offset = 0;
+	u32 len = 0;
+	u32 limit = 0;
+	u32 param;
+
+	param = sscanf(buf, "%*s 0x%x 0x%x", &offset, &len);
+	xhci_info(xhci, "params-%d (offset: %#x, len: %#x)\n", param, offset, len);
+
+	base = get_reg_base_limit(mtk, buf, &limit);
+	if (!base || !param) {
+		xhci_err(xhci, "params are invalid!\n");
+		return;
+	}
+
+	if (param == 1)
+		read_single_reg(mtk, base, offset, limit);
+	else
+		read_multi_regs(mtk, base, offset, len, limit);
+}
+
+static void ssusb_set_reg_bits(struct xhci_hcd_mtk *mtk, const char *buf)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	void __iomem *base;
+	u32 offset = 0;
+	u32 bit_start = 0;
+	u32 mask = 0;
+	u32 value = 0;
+	u32 old_val = 0;
+	u32 new_val = 0;
+	u32 limit = 0;
+	u32 param;
+
+	param = sscanf(buf, "%*s 0x%x %d 0x%x 0x%x", &offset, &bit_start, &mask, &value);
+	xhci_info(xhci, "params-%d (offset: %#x, bit_start: %d, mask: %#x, value: %#x)\n",
+		param, offset, bit_start, mask, value);
+
+	base = get_reg_base_limit(mtk, buf, &limit);
+	if (!base || (param != 4) || (bit_start > 32)) {
+		xhci_err(xhci, "params are invalid!\n");
+		return;
+	}
+
+	offset &= ~0x3;  /* 4-bytes align */
+	if (offset >= limit) {
+		xhci_err(xhci, "reg's offset overrun!\n");
+		return;
+	}
+	old_val = readl(base + offset);
+	new_val = old_val;
+	new_val &= ~(mask << bit_start);
+	new_val |= (value << bit_start);
+	writel(new_val, base + offset);
+	xhci_info(xhci, "0x%8.8x : 0x%8.8x --> 0x%8.8x\n", offset, old_val,
+		readl(base + offset));
+}
+
+
+static void ssusb_print_reg_bits(struct xhci_hcd_mtk *mtk, const char *buf)
+{
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+	void __iomem *base;
+	u32 offset = 0;
+	u32 bit_start = 0;
+	u32 mask = 0;
+	u32 old_val = 0;
+	u32 new_val = 0;
+	u32 limit = 0;
+	u32 param;
+
+	param = sscanf(buf, "%*s 0x%x %d 0x%x", &offset, &bit_start, &mask);
+	xhci_info(xhci, "params-%d (offset: %#x, bit_start: %d, mask: %#x)\n",
+		param, offset, bit_start, mask);
+
+	base = get_reg_base_limit(mtk, buf, &limit);
+	if (!base || (param != 3) || (bit_start > 32)) {
+		xhci_err(xhci, "params are invalid!\n");
+		return;
+	}
+
+	offset &= ~0x3;  /* 4-bytes align */
+	if (offset >= limit) {
+		xhci_err(xhci, "reg's offset overrun!\n");
+		return;
+	}
+
+	old_val = readl(base + offset);
+	new_val = old_val;
+	new_val >>= bit_start;
+	new_val &= mask;
+	xhci_info(xhci, "0x%8.8x : 0x%8.8x (0x%x)\n", offset, old_val, new_val);
+}
+
+
+static ssize_t
+ssusb_reg_store(struct device *dev, struct device_attribute *attr, const char *buf, size_t n)
+{
+	struct xhci_hcd_mtk *mtk = dev_get_drvdata(dev);
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+
+	xhci_info(xhci, " cmd: %s\n", buf);
+
+	switch (buf[0]) {
+	case 'w':
+		ssusb_write_reg(mtk, buf);
+		break;
+	case 'r':
+		ssusb_read_regs(mtk, buf);
+		break;
+	case 's':
+		ssusb_set_reg_bits(mtk, buf);
+		break;
+	case 'p':
+		ssusb_print_reg_bits(mtk, buf);
+		break;
+	default:
+		xhci_err(xhci, "No such cmd\n");
+	}
+
+	return n;
+}
+
+static DEVICE_ATTR(reg, 0664, ssusb_reg_show, ssusb_reg_store);
+
+static struct device_attribute *mu3h_hqa_attr_list[] = {
+	&dev_attr_hqa,
+	&dev_attr_reg,
+};
+
+static void ssusb_remap_ip_regs(struct device *dev)
+{
+	struct xhci_hcd_mtk *mtk = dev_get_drvdata(dev);
+	struct usb_hcd *hcd = mtk->hcd;
+	struct xhci_hcd *xhci = hcd_to_xhci(hcd);
+
+	mtk->ip_base = ioremap(hcd->rsrc_start, 0x30000);
+	if (!mtk->ip_base)
+		xhci_err(xhci, "could not ioremap regs\n");
+}
+
+int mu3h_hqa_create_attr(struct device *dev)
+{
+	int idx, err = 0;
+	int num = ARRAY_SIZE(mu3h_hqa_attr_list);
+
+	if (!dev)
+		return -EINVAL;
+
+	ssusb_remap_ip_regs(dev);
+
+	for (idx = 0; idx < num; idx++) {
+		err = device_create_file(dev, mu3h_hqa_attr_list[idx]);
+		if (err)
+			break;
+	}
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(mu3h_hqa_create_attr);
+
+void mu3h_hqa_remove_attr(struct device *dev)
+{
+	int idx;
+	int num = ARRAY_SIZE(mu3h_hqa_attr_list);
+
+	for (idx = 0; idx < num; idx++)
+		device_remove_file(dev, mu3h_hqa_attr_list[idx]);
+}
+EXPORT_SYMBOL_GPL(mu3h_hqa_remove_attr);
diff --git a/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk-test.h b/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk-test.h
new file mode 100644
index 000000000..3259af884
--- /dev/null
+++ b/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk-test.h
@@ -0,0 +1,17 @@
+/*
+ * Copyright (C) 2014 Mediatek
+ *
+ * chunfeng yun <chunfeng.yun@mediatek.com>
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef __XHCI_MTK_TEST_H
+#define __XHCI_MTK_TEST_H
+
+int mu3h_hqa_create_attr(struct device *dev);
+void mu3h_hqa_remove_attr(struct device *dev);
+
+#endif /* __XHCI_MTK_TEST_H */
diff --git a/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.c b/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.c
index e903cb2b5..878788df5 100644
--- a/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.c
+++ b/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.c
@@ -31,6 +31,7 @@
 
 #include "xhci.h"
 #include "xhci-mtk.h"
+#include "xhci-mtk-test.h" /*Add for XHCI U2 HQA test*/
 
 /* ip_pw_ctrl0 register */
 #define CTRL0_IP_SW_RST	BIT(0)
@@ -726,6 +727,9 @@ static int xhci_mtk_probe(struct platform_device *pdev)
 	if (ret)
 		goto dealloc_usb2_hcd;
 
+	/*Add for XHCI U2 HQA test*/
+	mu3h_hqa_create_attr(dev);
+
 	return 0;
 
 dealloc_usb2_hcd:
@@ -763,6 +767,9 @@ static int xhci_mtk_remove(struct platform_device *dev)
 	struct usb_hcd	*hcd = mtk->hcd;
 	struct xhci_hcd	*xhci = hcd_to_xhci(hcd);
 
+	/*Add for XHCI U2 HQA test*/
+	mu3h_hqa_remove_attr(&dev->dev);
+
 	usb_remove_hcd(xhci->shared_hcd);
 	xhci_mtk_phy_power_off(mtk);
 	xhci_mtk_phy_exit(mtk);
diff --git a/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.h b/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.h
index aa2c16e77..0e489f92f 100644
--- a/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.h
+++ b/trunk/linux-4.4.x/drivers/usb/host/xhci-mtk.h
@@ -146,6 +146,8 @@ struct xhci_hcd_mtk {
 	int num_phys;
 	int wakeup_src;
 	bool lpm_support;
+	void __iomem *ip_base;	/*Add for XHCI U2 HQA test*/
+	int test_mode;			/*Add for XHCI U2 HQA test*/
 };
 
 static inline struct xhci_hcd_mtk *hcd_to_mtk(struct usb_hcd *hcd)
diff --git a/trunk/linux-4.4.x/drivers/usb/host/xhci.c b/trunk/linux-4.4.x/drivers/usb/host/xhci.c
index f64160d8d..0a6963208 100644
--- a/trunk/linux-4.4.x/drivers/usb/host/xhci.c
+++ b/trunk/linux-4.4.x/drivers/usb/host/xhci.c
@@ -43,15 +43,15 @@
 static int link_quirk;
 module_param(link_quirk, int, S_IRUGO | S_IWUSR);
 MODULE_PARM_DESC(link_quirk, "Don't clear the chain bit on a link TRB");
-
+#if defined(ASUS_EXT)
+int u3intf = 0;
+module_param(u3intf, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(u3intf, "USB3/2.4GHz interference");
+#endif
 static unsigned int quirks;
 module_param(quirks, uint, S_IRUGO);
 MODULE_PARM_DESC(quirks, "Bit flags for quirks to be enabled as default");
 
-int usb3_disable = 0;
-module_param(usb3_disable, int, S_IRUGO | S_IWUSR);
-MODULE_PARM_DESC(usb3_disable, "Disable USB3 interface");
-
 /*
  * xhci_handshake - spin reading hc until handshake completes or fails
  * @ptr: address of hc register to be read
diff --git a/trunk/linux-4.4.x/drivers/usb/host/xhci.h b/trunk/linux-4.4.x/drivers/usb/host/xhci.h
index ccfd3efe3..d84bae243 100644
--- a/trunk/linux-4.4.x/drivers/usb/host/xhci.h
+++ b/trunk/linux-4.4.x/drivers/usb/host/xhci.h
@@ -1670,7 +1670,9 @@ struct xhci_hcd {
 /* Compliance Mode Timer Triggered every 2 seconds */
 #define COMP_MODE_RCVRY_MSECS 2000
 };
-
+#if defined(ASUS_EXT)
+extern int u3intf;
+#endif
 /* Platform specific overrides to generic XHCI hc_driver ops */
 struct xhci_driver_overrides {
 	size_t extra_priv_size;
diff --git a/trunk/linux-4.4.x/drivers/usb/serial/option.c b/trunk/linux-4.4.x/drivers/usb/serial/option.c
index 00a6e62a6..11a669eb8 100644
--- a/trunk/linux-4.4.x/drivers/usb/serial/option.c
+++ b/trunk/linux-4.4.x/drivers/usb/serial/option.c
@@ -48,9 +48,17 @@ static int  option_probe(struct usb_serial *serial,
 			const struct usb_device_id *id);
 static int option_attach(struct usb_serial *serial);
 static void option_release(struct usb_serial *serial);
+#if defined(CONFIG_FIBOCOM_FG621)
+static int option_send_setup(struct usb_serial_port *port);
+#endif
 static void option_instat_callback(struct urb *urb);
 
 /* Vendor and product IDs */
+#if defined(CONFIG_FIBOCOM_FG621)
+#define VENDOR_UNISOC               0x1782
+#define NODECOM_VENDOR_ID			0x1508
+#define FIBOCOM_VENDOR_ID			0x2CB7
+#endif
 #define OPTION_VENDOR_ID			0x0AF0
 #define OPTION_PRODUCT_COLT			0x5000
 #define OPTION_PRODUCT_RICOLA			0x6000
@@ -159,6 +167,7 @@ static void option_instat_callback(struct urb *urb);
 #define NOVATELWIRELESS_PRODUCT_EVDO_EMBEDDED_HIGHSPEED	0x8001
 #define NOVATELWIRELESS_PRODUCT_HSPA_EMBEDDED_FULLSPEED	0x9000
 #define NOVATELWIRELESS_PRODUCT_HSPA_EMBEDDED_HIGHSPEED	0x9001
+#define NOVATELWIRELESS_PRODUCT_ENTERPRISE_U730L	0x9032
 #define NOVATELWIRELESS_PRODUCT_E362		0x9010
 #define NOVATELWIRELESS_PRODUCT_E371		0x9011
 #define NOVATELWIRELESS_PRODUCT_U620L		0x9022
@@ -565,8 +574,100 @@ static void option_instat_callback(struct urb *urb);
 /* Interface is reserved */
 #define RSVD(ifnum)	((BIT(ifnum) & 0xff) << 0)
 
+#if defined(CONFIG_FIBOCOM_FG621)
+/* some devices interfaces need special handling due to a number of reasons */
+enum option_blacklist_reason {
+		OPTION_BLACKLIST_NONE = 0,
+		OPTION_BLACKLIST_SENDSETUP = 1,
+		OPTION_BLACKLIST_RESERVED_IF = 2
+};
+
+#define MAX_BL_NUM  11
+struct option_blacklist_info {
+	/* bitfield of interface numbers for OPTION_BLACKLIST_SENDSETUP */
+	const unsigned long sendsetup;
+	/* bitfield of interface numbers for OPTION_BLACKLIST_RESERVED_IF */
+	const unsigned long reserved;
+};
+
+static const struct option_blacklist_info fg621_012 = {
+	.reserved = BIT(0) | BIT(1) | BIT(2),
+};
+
+static const struct option_blacklist_info fg621_014 = {
+	.reserved = BIT(0) | BIT(1) | BIT(4),
+};
+
+static const struct option_blacklist_info fg621_015 = {
+	.reserved = BIT(0) | BIT(1) | BIT(5),
+};
+
+static const struct option_blacklist_info fg621_016 = {
+	.reserved = BIT(0) | BIT(1) | BIT(6),
+};
+#endif
 
 static const struct usb_device_id option_ids[] = {
+#if defined(CONFIG_FIBOCOM_FG621)
+//Fibocom begin
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0104) },
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0105) },
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0106) },
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0107) },
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0108) },
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0109) },
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x010A) },
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x010B) },
+	{ USB_DEVICE(NODECOM_VENDOR_ID, 0x1000) },
+	{ USB_DEVICE(NODECOM_VENDOR_ID, 0x1001) },
+	{ USB_DEVICE(QUALCOMM_VENDOR_ID, 0x9025) },
+	{ USB_DEVICE(QUALCOMM_VENDOR_ID, 0x90DB) },
+	{ USB_DEVICE(0x2C7C, 0x0306) },
+		/*Added by Fibocom 2020-03-12 */
+	{ USB_DEVICE(VENDOR_UNISOC, 0x4028),
+	    .driver_info = (kernel_ulong_t)&fg621_012},
+	{ USB_DEVICE(VENDOR_UNISOC, 0x4030),
+	    .driver_info = (kernel_ulong_t)&fg621_012},
+	{ USB_DEVICE(VENDOR_UNISOC, 0x4032),
+	    .driver_info = (kernel_ulong_t)&fg621_012},
+	{ USB_DEVICE(VENDOR_UNISOC, 0x4033),
+	    .driver_info = (kernel_ulong_t)&fg621_014},
+	//for Fibocom FG621-EA
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0A04),
+	    .driver_info = (kernel_ulong_t)&fg621_015},
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0A05),
+	    .driver_info = (kernel_ulong_t)&fg621_016},
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0A06),
+	    .driver_info = (kernel_ulong_t)&fg621_016},
+	{ USB_DEVICE(FIBOCOM_VENDOR_ID, 0x0A07),
+	    .driver_info = (kernel_ulong_t)&fg621_016},
+	//End of changing by Fibocom 2020-03-12
+//Fibocom end
+#endif
+#if 1 //Added by Quectel
+	{ USB_DEVICE(0x05C6, 0x9090) }, /* Quectel UC15 */
+	{ USB_DEVICE(0x05C6, 0x9003) }, /* Quectel UC20 */
+	{ USB_DEVICE(0x05C6, 0x9215) }, /* Quectel EC20(MDM9215) */
+	{ USB_DEVICE(0x2C7C, 0x0125) }, /* Quectel EC20(MDM9x07)/EC25/EG25 */
+	{ USB_DEVICE(0x2C7C, 0x0121) }, /* Quectel EC21 */
+	{ USB_DEVICE(0x2C7C, 0x0191) }, /* Quectel EG91 */
+	{ USB_DEVICE(0x2C7C, 0x0195) }, /* Quectel EG95 */
+	{ USB_DEVICE(0x2C7C, 0x0306) }, /* Quectel EG06/EP06/EM06 */
+	{ USB_DEVICE(0x2C7C, 0x0512) }, /* Quectel EG12/EP12/EM12/EG16/EG18 */
+	{ USB_DEVICE(0x2C7C, 0x0296) }, /* Quectel BG96 */
+	{ USB_DEVICE(0x2C7C, 0x0700) }, /* Quectel BG95/BG77/BG600L-M3/BC69 */
+	{ USB_DEVICE(0x2C7C, 0x0435) }, /* Quectel AG35 */
+	{ USB_DEVICE(0x2C7C, 0x0415) }, /* Quectel AG15 */
+	{ USB_DEVICE(0x2C7C, 0x0452) }, /* Quectel AG520R */
+	{ USB_DEVICE(0x2C7C, 0x0455) }, /* Quectel AG550R */
+	{ USB_DEVICE(0x2C7C, 0x0520) }, /* Quectel AG520 */
+	{ USB_DEVICE(0x2C7C, 0x0550) }, /* Quectel AG550 */
+	{ USB_DEVICE(0x2C7C, 0x0620) }, /* Quectel EG20 */
+	{ USB_DEVICE(0x2C7C, 0x0800) }, /* Quectel RG500/RM500/RG510/RM510 */
+	{ USB_DEVICE(0x2C7C, 0x6026) }, /* Quectel EC200 */
+	{ USB_DEVICE(0x2C7C, 0x6120) }, /* Quectel UC200 */
+	{ USB_DEVICE(0x2C7C, 0x6000) }, /* Quectel EC200/UC200 */
+#endif
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_COLT) },
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_RICOLA) },
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_RICOLA_LIGHT) },
@@ -1010,6 +1111,7 @@ static const struct usb_device_id option_ids[] = {
 	{ USB_DEVICE(NOVATELWIRELESS_VENDOR_ID, NOVATELWIRELESS_PRODUCT_MC547) },
 	{ USB_DEVICE(NOVATELWIRELESS_VENDOR_ID, NOVATELWIRELESS_PRODUCT_EVDO_EMBEDDED_HIGHSPEED) },
 	{ USB_DEVICE(NOVATELWIRELESS_VENDOR_ID, NOVATELWIRELESS_PRODUCT_HSPA_EMBEDDED_HIGHSPEED) },
+	{ USB_DEVICE_AND_INTERFACE_INFO(NOVATELWIRELESS_VENDOR_ID, NOVATELWIRELESS_PRODUCT_ENTERPRISE_U730L, 0xff, 0x0, 0x0) },
 	{ USB_DEVICE(NOVATELWIRELESS_VENDOR_ID, NOVATELWIRELESS_PRODUCT_G2) },
 	/* Novatel Ovation MC551 a.k.a. Verizon USB551L */
 	{ USB_DEVICE_AND_INTERFACE_INFO(NOVATELWIRELESS_VENDOR_ID, NOVATELWIRELESS_PRODUCT_MC551, 0xff, 0xff, 0xff) },
@@ -2027,6 +2129,9 @@ static struct usb_serial_driver option_1port_device = {
 #ifdef CONFIG_PM
 	.suspend           = usb_wwan_suspend,
 	.resume            = usb_wwan_resume,
+#if 1 //Added by Quectel
+	.reset_resume = usb_wwan_resume,
+#endif
 #endif
 };
 
@@ -2034,6 +2139,35 @@ static struct usb_serial_driver * const serial_drivers[] = {
 	&option_1port_device, NULL
 };
 
+#if defined(CONFIG_FIBOCOM_FG621)
+struct option_private {
+	u8 bInterfaceNumber;
+};
+
+static bool is_blacklisted(const u8 ifnum, enum option_blacklist_reason reason,
+			   const struct option_blacklist_info *blacklist)
+{
+	unsigned long num;
+	const unsigned long *intf_list;
+
+	if (blacklist) {
+		if (reason == OPTION_BLACKLIST_SENDSETUP)
+			intf_list = &blacklist->sendsetup;
+		else if (reason == OPTION_BLACKLIST_RESERVED_IF)
+			intf_list = &blacklist->reserved;
+		else {
+			BUG_ON(reason);
+			return false;
+		}
+
+		for_each_set_bit(num, intf_list, MAX_BL_NUM + 1) {
+			if (num == ifnum)
+				return true;
+		}
+	}
+	return false;
+}
+#endif
 module_usb_serial_driver(serial_drivers, option_ids);
 
 static int option_probe(struct usb_serial *serial,
@@ -2042,7 +2176,9 @@ static int option_probe(struct usb_serial *serial,
 	struct usb_interface_descriptor *iface_desc =
 				&serial->interface->cur_altsetting->desc;
 	struct usb_device_descriptor *dev_desc = &serial->dev->descriptor;
+#if !defined(CONFIG_FIBOCOM_FG621)
 	unsigned long device_flags = id->driver_info;
+#endif
 
 	/* Never bind to the CD-Rom emulation interface	*/
 	if (iface_desc->bInterfaceClass == 0x08)
@@ -2053,8 +2189,16 @@ static int option_probe(struct usb_serial *serial,
 	 * the same class/subclass/protocol as the serial interfaces.  Look at
 	 * the Windows driver .INF files for reserved interface numbers.
 	 */
+#if defined(CONFIG_FIBOCOM_FG621)
+	if (is_blacklisted(
+		iface_desc->bInterfaceNumber,
+		OPTION_BLACKLIST_RESERVED_IF,
+		(const struct option_blacklist_info *) id->driver_info))
+		return -ENODEV;
+#else
 	if (device_flags & RSVD(iface_desc->bInterfaceNumber))
 		return -ENODEV;
+#endif
 	/*
 	 * Don't bind network interface on Samsung GT-B3730, it is handled by
 	 * a separate module.
@@ -2064,9 +2208,48 @@ static int option_probe(struct usb_serial *serial,
 	    iface_desc->bInterfaceClass != USB_CLASS_CDC_DATA)
 		return -ENODEV;
 
+#if defined(CONFIG_FIBOCOM_FG621)
+    if((dev_desc->idVendor == FIBOCOM_VENDOR_ID &&
+             (((dev_desc->idProduct == cpu_to_le16(0x0104)|| 
+             dev_desc->idProduct == cpu_to_le16(0x0105)||  
+             dev_desc->idProduct == cpu_to_le16(0x010b)) && 
+                 serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4) || 
+              (dev_desc->idProduct == cpu_to_le16(0x0109) &&
+                 serial->interface->cur_altsetting->desc.bInterfaceNumber >= 2))
+      )||(dev_desc->idVendor == NODECOM_VENDOR_ID &&
+             ((dev_desc->idProduct == cpu_to_le16(0x1001) && 
+                 serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4) || 
+              (dev_desc->idProduct == cpu_to_le16(0x1000) &&
+                 serial->interface->cur_altsetting->desc.bInterfaceNumber >= 2))
+      )||(dev_desc->idVendor == 0x2C7C && (dev_desc->idProduct == cpu_to_le16(0x0306) && 
+                 serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4)))
+    {
+            printk(KERN_INFO "Discovery the interface for Fibocom.");
+            return -ENODEV;
+    }
+#endif
+
+#if 1 //Added by Quectel
+	//Quectel moduless interface 4 can be used as USB network device
+	if (serial->dev->descriptor.idVendor == cpu_to_le16(0x2C7C)) {
+		//some interfaces can be used as USB Network device (ecm, rndis, mbim)
+		if (serial->interface->cur_altsetting->desc.bInterfaceClass != 0xFF) {
+			return -ENODEV;
+		}
+		//interface 4 can be used as USB Network device (qmi)
+		else if (serial->interface->cur_altsetting->desc.bInterfaceNumber >= 4) {
+			return -ENODEV;
+		}
+	}
+#endif
+
+#if defined(CONFIG_FIBOCOM_FG621)
+	/* Store device id so we can use it during attach. */
+	usb_set_serial_data(serial, (void *)id);
+#else
 	/* Store the device flags so we can use them during attach. */
 	usb_set_serial_data(serial, (void *)device_flags);
-
+#endif
 	return 0;
 }
 
@@ -2074,19 +2257,44 @@ static int option_attach(struct usb_serial *serial)
 {
 	struct usb_interface_descriptor *iface_desc;
 	struct usb_wwan_intf_private *data;
+#if defined(CONFIG_FIBOCOM_FG621)
+	const struct usb_device_id *id;
+	struct option_private *priv;
+#else
 	unsigned long device_flags;
+#endif
 
 	data = kzalloc(sizeof(struct usb_wwan_intf_private), GFP_KERNEL);
 	if (!data)
 		return -ENOMEM;
 
+#if defined(CONFIG_FIBOCOM_FG621)
+	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
+	if (!priv) {
+		kfree(data);
+		return -ENOMEM;
+	}
+
+	/* Retrieve device id stored at probe. */
+	id = usb_get_serial_data(serial);
+	iface_desc = &serial->interface->cur_altsetting->desc;
+
+	priv->bInterfaceNumber = iface_desc->bInterfaceNumber;
+	data->private = priv;
+
+	if (!is_blacklisted(iface_desc->bInterfaceNumber,
+			OPTION_BLACKLIST_SENDSETUP,
+			(struct option_blacklist_info *)id->driver_info)) {
+		data->send_setup = option_send_setup;
+	}
+#else
 	/* Retrieve device flags stored at probe. */
 	device_flags = (unsigned long)usb_get_serial_data(serial);
 
 	iface_desc = &serial->interface->cur_altsetting->desc;
-
 	if (!(device_flags & NCTRL(iface_desc->bInterfaceNumber)))
 		data->use_send_setup = 1;
+#endif
 
 	spin_lock_init(&data->susp_lock);
 
@@ -2098,7 +2306,11 @@ static int option_attach(struct usb_serial *serial)
 static void option_release(struct usb_serial *serial)
 {
 	struct usb_wwan_intf_private *intfdata = usb_get_serial_data(serial);
+#if defined(CONFIG_FIBOCOM_FG621)
+	struct option_private *priv = intfdata->private;
 
+	kfree(priv);
+#endif
 	kfree(intfdata);
 }
 
@@ -2157,6 +2369,33 @@ static void option_instat_callback(struct urb *urb)
 	}
 }
 
+#if defined(CONFIG_FIBOCOM_FG621)
+/** send RTS/DTR state to the port.
+ *
+ * This is exactly the same as SET_CONTROL_LINE_STATE from the PSTN
+ * CDC.
+*/
+static int option_send_setup(struct usb_serial_port *port)
+{
+	struct usb_serial *serial = port->serial;
+	struct usb_wwan_intf_private *intfdata = usb_get_serial_data(serial);
+	struct option_private *priv = intfdata->private;
+	struct usb_wwan_port_private *portdata;
+	int val = 0;
+
+	portdata = usb_get_serial_port_data(port);
+
+	if (portdata->dtr_state)
+		val |= 0x01;
+	if (portdata->rts_state)
+		val |= 0x02;
+
+	return usb_control_msg(serial->dev, usb_rcvctrlpipe(serial->dev, 0),
+				0x22, 0x21, val, priv->bInterfaceNumber, NULL,
+				0, USB_CTRL_SET_TIMEOUT);
+}
+#endif
+
 MODULE_AUTHOR(DRIVER_AUTHOR);
 MODULE_DESCRIPTION(DRIVER_DESC);
 MODULE_LICENSE("GPL");
diff --git a/trunk/linux-4.4.x/drivers/usb/serial/usb-serial.c b/trunk/linux-4.4.x/drivers/usb/serial/usb-serial.c
index 80ba818d3..a2ec53590 100644
--- a/trunk/linux-4.4.x/drivers/usb/serial/usb-serial.c
+++ b/trunk/linux-4.4.x/drivers/usb/serial/usb-serial.c
@@ -1223,6 +1223,9 @@ static struct usb_driver usb_serial_driver = {
 	.disconnect =	usb_serial_disconnect,
 	.suspend =	usb_serial_suspend,
 	.resume =	usb_serial_resume,
+#if 1 //Added by Quectel
+	.reset_resume = usb_serial_resume,
+#endif
 	.no_dynamic_id =	1,
 	.supports_autosuspend =	1,
 };
diff --git a/trunk/linux-4.4.x/drivers/usb/serial/usb-wwan.h b/trunk/linux-4.4.x/drivers/usb/serial/usb-wwan.h
index 44b25c08c..ccc3963ee 100644
--- a/trunk/linux-4.4.x/drivers/usb/serial/usb-wwan.h
+++ b/trunk/linux-4.4.x/drivers/usb/serial/usb-wwan.h
@@ -36,6 +36,9 @@ struct usb_wwan_intf_private {
 	unsigned int suspended:1;
 	unsigned int use_send_setup:1;
 	int in_flight;
+#if defined(CONFIG_FIBOCOM_FG621)
+	int (*send_setup) (struct usb_serial_port *port);
+#endif
 	unsigned int open_ports;
 	void *private;
 };
diff --git a/trunk/linux-4.4.x/drivers/usb/serial/usb_wwan.c b/trunk/linux-4.4.x/drivers/usb/serial/usb_wwan.c
index be9cb61b4..6222bf0ab 100644
--- a/trunk/linux-4.4.x/drivers/usb/serial/usb_wwan.c
+++ b/trunk/linux-4.4.x/drivers/usb/serial/usb_wwan.c
@@ -505,6 +505,19 @@ static struct urb *usb_wwan_setup_urb(struct usb_serial_port *port,
 			  usb_sndbulkpipe(serial->dev, endpoint) | dir,
 			  buf, len, callback, ctx);
 
+#if 1 //Added by Quectel for Zero Packet
+	if (dir == USB_DIR_OUT) {
+		if (serial->dev->descriptor.idVendor == cpu_to_le16(0x05C6) && serial->dev->descriptor.idProduct == cpu_to_le16(0x9090))
+			urb->transfer_flags |= URB_ZERO_PACKET;
+		if (serial->dev->descriptor.idVendor == cpu_to_le16(0x05C6) && serial->dev->descriptor.idProduct == cpu_to_le16(0x9003))
+			urb->transfer_flags |= URB_ZERO_PACKET;
+		if (serial->dev->descriptor.idVendor == cpu_to_le16(0x05C6) && serial->dev->descriptor.idProduct == cpu_to_le16(0x9215))
+			urb->transfer_flags |= URB_ZERO_PACKET;
+		if (serial->dev->descriptor.idVendor == cpu_to_le16(0x2C7C))
+			urb->transfer_flags |= URB_ZERO_PACKET;
+	}
+#endif
+
 	return urb;
 }
 
diff --git a/trunk/linux-4.4.x/drivers/usb/storage/uas-detect.h b/trunk/linux-4.4.x/drivers/usb/storage/uas-detect.h
index ecc83c405..c76b3c5ab 100644
--- a/trunk/linux-4.4.x/drivers/usb/storage/uas-detect.h
+++ b/trunk/linux-4.4.x/drivers/usb/storage/uas-detect.h
@@ -112,8 +112,10 @@ static int uas_use_uas_driver(struct usb_interface *intf,
 	}
 
 	/* All Seagate disk enclosures have broken ATA pass-through support */
-	if (le16_to_cpu(udev->descriptor.idVendor) == 0x0bc2)
+	if (le16_to_cpu(udev->descriptor.idVendor) == 0x0bc2) {
 		flags |= US_FL_NO_ATA_1X;
+		//flags |= US_FL_IGNORE_UAS;
+	}
 
 	usb_stor_adjust_quirks(udev, &flags);
 
diff --git a/trunk/linux-4.4.x/drivers/usb/storage/unusual_uas.h b/trunk/linux-4.4.x/drivers/usb/storage/unusual_uas.h
index 8ed80f284..22e6f26f7 100644
--- a/trunk/linux-4.4.x/drivers/usb/storage/unusual_uas.h
+++ b/trunk/linux-4.4.x/drivers/usb/storage/unusual_uas.h
@@ -148,6 +148,12 @@ UNUSUAL_DEV(0x152d, 0x0578, 0x0000, 0x9999,
 		USB_SC_DEVICE, USB_PR_DEVICE, NULL,
 		US_FL_BROKEN_FUA),
 
+UNUSUAL_DEV(0x174c, 0x1053, 0x0000, 0x9999,
+		"ASMedia",
+		"USB3.0 Device",
+		USB_SC_DEVICE, USB_PR_DEVICE, NULL,
+		US_FL_IGNORE_UAS),
+
 /* Reported-by: Hans de Goede <hdegoede@redhat.com> */
 UNUSUAL_DEV(0x2109, 0x0711, 0x0000, 0x9999,
 		"VIA",
@@ -182,3 +188,10 @@ UNUSUAL_DEV(0x4971, 0x8017, 0x0000, 0x9999,
 		"External HDD",
 		USB_SC_DEVICE, USB_PR_DEVICE, NULL,
 		US_FL_NO_REPORT_OPCODES),
+
+/* some ssd enclosures */
+UNUSUAL_DEV(0x0bda, 0x9210, 0x0000, 0x9999,
+		"SSD enclosure",
+		"External HDD",
+		USB_SC_DEVICE, USB_PR_DEVICE, NULL,
+		US_FL_IGNORE_UAS),
diff --git a/trunk/linux-4.4.x/drivers/watchdog/mtk_wdt.c b/trunk/linux-4.4.x/drivers/watchdog/mtk_wdt.c
index c471a1c5a..bc445efd0 100644
--- a/trunk/linux-4.4.x/drivers/watchdog/mtk_wdt.c
+++ b/trunk/linux-4.4.x/drivers/watchdog/mtk_wdt.c
@@ -245,7 +245,7 @@ static int mtk_wdt_ping(struct watchdog_device *wdt_dev)
 	void __iomem *wdt_base = mtk_wdt->wdt_base;
 
 	iowrite32(WDT_RST_RELOAD, wdt_base + WDT_RST);
-	printk_deferred("[WDK]: kick Ex WDT\n");
+//	printk_deferred("[WDK]: kick Ex WDT\n");
 
 	return 0;
 }
diff --git a/trunk/linux-4.4.x/fs/jffs2/summary.c b/trunk/linux-4.4.x/fs/jffs2/summary.c
index bc5385471..f6cb9071d 100644
--- a/trunk/linux-4.4.x/fs/jffs2/summary.c
+++ b/trunk/linux-4.4.x/fs/jffs2/summary.c
@@ -697,7 +697,7 @@ static int jffs2_sum_write_data(struct jffs2_sb_info *c, struct jffs2_eraseblock
 		/* don't try to write out summary for this jeb */
 		jffs2_sum_disable_collecting(c->summary);
 
-		JFFS2_WARNING("Not enough space for summary, padsize = %d\n",
+		JFFS2_DEBUG("Not enough space for summary, padsize = %d\n",
 			      padsize);
 		/* Non-fatal */
 		return 0;
diff --git a/trunk/linux-4.4.x/include/linux/gfp.h b/trunk/linux-4.4.x/include/linux/gfp.h
index 8942af081..99fcb625e 100644
--- a/trunk/linux-4.4.x/include/linux/gfp.h
+++ b/trunk/linux-4.4.x/include/linux/gfp.h
@@ -236,6 +236,7 @@ struct vm_area_struct;
  */
 #define GFP_ATOMIC	(__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM)
 #define GFP_KERNEL	(__GFP_RECLAIM | __GFP_IO | __GFP_FS)
+#define GFP_KERNEL_ACCOUNT (GFP_KERNEL)
 #define GFP_NOWAIT	(__GFP_KSWAPD_RECLAIM)
 #define GFP_NOIO	(__GFP_RECLAIM)
 #define GFP_NOFS	(__GFP_RECLAIM | __GFP_IO)
diff --git a/trunk/linux-4.4.x/include/linux/imq.h b/trunk/linux-4.4.x/include/linux/imq.h
new file mode 100644
index 000000000..1babb0978
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/imq.h
@@ -0,0 +1,13 @@
+#ifndef _IMQ_H
+#define _IMQ_H
+
+/* IFMASK (16 device indexes, 0 to 15) and flag(s) fit in 5 bits */
+#define IMQ_F_BITS	5
+
+#define IMQ_F_IFMASK	0x0f
+#define IMQ_F_ENQUEUE	0x10
+
+#define IMQ_MAX_DEVS	(IMQ_F_IFMASK + 1)
+
+#endif /* _IMQ_H */
+
diff --git a/trunk/linux-4.4.x/include/linux/mm.h b/trunk/linux-4.4.x/include/linux/mm.h
index e4f71bafb..eb134a9ea 100644
--- a/trunk/linux-4.4.x/include/linux/mm.h
+++ b/trunk/linux-4.4.x/include/linux/mm.h
@@ -412,6 +412,20 @@ static inline int is_vmalloc_or_module_addr(const void *x)
 }
 #endif
 
+extern void *kvmalloc_node(size_t size, gfp_t flags, int node);
+static inline void *kvmalloc(size_t size, gfp_t flags)
+{
+	return kvmalloc_node(size, flags, NUMA_NO_NODE);
+}
+static inline void *kvzalloc_node(size_t size, gfp_t flags, int node)
+{
+	return kvmalloc_node(size, flags | __GFP_ZERO, node);
+}
+static inline void *kvzalloc(size_t size, gfp_t flags)
+{
+	return kvmalloc(size, flags | __GFP_ZERO);
+}
+
 extern void kvfree(const void *addr);
 
 static inline void compound_lock(struct page *page)
diff --git a/trunk/linux-4.4.x/include/linux/mtd/mtd.h b/trunk/linux-4.4.x/include/linux/mtd/mtd.h
index d369a6316..ecde03ea2 100644
--- a/trunk/linux-4.4.x/include/linux/mtd/mtd.h
+++ b/trunk/linux-4.4.x/include/linux/mtd/mtd.h
@@ -471,6 +471,8 @@ extern struct mtd_info *get_mtd_device(struct mtd_info *mtd, int num);
 extern int __get_mtd_device(struct mtd_info *mtd);
 extern void __put_mtd_device(struct mtd_info *mtd);
 extern struct mtd_info *get_mtd_device_nm(const char *name);
+extern struct mtd_info *get_mtd_device_by_node(
+		const struct device_node *of_node);
 extern void put_mtd_device(struct mtd_info *mtd);
 
 
diff --git a/trunk/linux-4.4.x/include/linux/netdevice.h b/trunk/linux-4.4.x/include/linux/netdevice.h
index 751686246..156c130c8 100644
--- a/trunk/linux-4.4.x/include/linux/netdevice.h
+++ b/trunk/linux-4.4.x/include/linux/netdevice.h
@@ -1699,6 +1699,9 @@ struct net_device {
  * Cache lines mostly used on receive path (including eth_type_trans())
  */
 	unsigned long		last_rx;
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	//unsigned long           last_rx;
+#endif
 
 	/* Interface address info used in eth_type_trans() */
 	unsigned char		*dev_addr;
@@ -3440,6 +3443,18 @@ static inline void netif_tx_unlock_bh(struct net_device *dev)
 	}						\
 }
 
+#define HARD_TX_LOCK_BH(dev, txq) {           \
+	if ((dev->features & NETIF_F_LLTX) == 0) {  \
+		__netif_tx_lock_bh(txq);      \
+	}                       \
+}
+
+#define HARD_TX_UNLOCK_BH(dev, txq) {          \
+	if ((dev->features & NETIF_F_LLTX) == 0) {  \
+	__netif_tx_unlock_bh(txq);         \
+	}                       \
+}
+
 static inline void netif_tx_disable(struct net_device *dev)
 {
 	unsigned int i;
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/compat_skbuff.h b/trunk/linux-4.4.x/include/linux/netfilter/compat_skbuff.h
new file mode 100644
index 000000000..ba064c124
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/compat_skbuff.h
@@ -0,0 +1,16 @@
+#ifndef COMPAT_SKBUFF_H
+#define COMPAT_SKBUFF_H 1
+
+struct tcphdr;
+struct udphdr;
+
+#define skb_ifindex(skb) (skb)->skb_iif
+#define skb_nfmark(skb) (((struct sk_buff *)(skb))->mark)
+
+#ifdef CONFIG_NETWORK_SECMARK
+#	define skb_secmark(skb) ((skb)->secmark)
+#else
+#	define skb_secmark(skb) 0
+#endif
+
+#endif /* COMPAT_SKBUFF_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/compat_xtables.h b/trunk/linux-4.4.x/include/linux/netfilter/compat_xtables.h
new file mode 100644
index 000000000..1e8bd4771
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/compat_xtables.h
@@ -0,0 +1,92 @@
+#ifndef _XTABLES_COMPAT_H
+#define _XTABLES_COMPAT_H 1
+
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/netfilter/compat_skbuff.h>
+#include <linux/netfilter/compat_xtnu.h>
+
+#define DEBUGP Use__pr_debug__instead
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 7, 0)
+#	warning Kernels below 3.7 not supported.
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 8, 0)
+#	define prandom_u32() random32()
+#endif
+
+#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
+#	if !defined(CONFIG_NF_CONNTRACK_MARK)
+#		warning You have CONFIG_NF_CONNTRACK enabled, but CONFIG_NF_CONNTRACK_MARK is not (please enable).
+#	endif
+#	include <net/netfilter/nf_conntrack.h>
+#else
+#	warning You need CONFIG_NF_CONNTRACK.
+#endif
+
+#if !defined(NIP6) && !defined(NIP6_FMT)
+#	define NIP6(addr) \
+		ntohs((addr).s6_addr16[0]), \
+		ntohs((addr).s6_addr16[1]), \
+		ntohs((addr).s6_addr16[2]), \
+		ntohs((addr).s6_addr16[3]), \
+		ntohs((addr).s6_addr16[4]), \
+		ntohs((addr).s6_addr16[5]), \
+		ntohs((addr).s6_addr16[6]), \
+		ntohs((addr).s6_addr16[7])
+#	define NIP6_FMT "%04x:%04x:%04x:%04x:%04x:%04x:%04x:%04x"
+#endif
+#if !defined(NIPQUAD) && !defined(NIPQUAD_FMT)
+#	define NIPQUAD(addr) \
+		((const unsigned char *)&addr)[0], \
+		((const unsigned char *)&addr)[1], \
+		((const unsigned char *)&addr)[2], \
+		((const unsigned char *)&addr)[3]
+#	define NIPQUAD_FMT "%u.%u.%u.%u"
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 9, 0)
+static inline struct inode *file_inode(struct file *f)
+{
+	return f->f_path.dentry->d_inode;
+}
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 10, 0)
+static inline void proc_set_user(struct proc_dir_entry *de,
+    typeof(de->uid) uid, typeof(de->gid) gid)
+{
+	de->uid = uid;
+	de->gid = gid;
+}
+
+static inline void *PDE_DATA(struct inode *inode)
+{
+	return PDE(inode)->data;
+}
+
+static inline void proc_remove(struct proc_dir_entry *de)
+{
+	if (de != NULL)
+		remove_proc_entry(de->name, de->parent);
+}
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+#	define ip6_local_out(xnet, xsk, xskb) ip6_local_out(xskb)
+#	define ip6_route_me_harder(xnet, xskb) ip6_route_me_harder(xskb)
+#	define ip_local_out(xnet, xsk, xskb) ip_local_out(xskb)
+#	define ip_route_me_harder(xnet, xskb, xaddrtype) ip_route_me_harder((xskb), (xaddrtype))
+#endif
+
+static inline struct net *par_net(const struct xt_action_param *par)
+{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 4, 0)
+	return par->net;
+#else
+	return dev_net((par->in != NULL) ? par->in : par->out);
+#endif
+}
+
+#endif /* _XTABLES_COMPAT_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/compat_xtnu.h b/trunk/linux-4.4.x/include/linux/netfilter/compat_xtnu.h
new file mode 100644
index 000000000..150dc0eaf
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/compat_xtnu.h
@@ -0,0 +1,67 @@
+#ifndef _COMPAT_XTNU_H
+#define _COMPAT_XTNU_H 1
+
+#include <linux/netfilter/x_tables.h>
+
+struct module;
+struct sk_buff;
+
+struct xtnu_match {
+	/*
+	 * Making it smaller by sizeof(void *) on purpose to catch
+	 * lossy translation, if any.
+	 */
+	char name[sizeof(((struct xt_match *)NULL)->name) - 1 - sizeof(void *)];
+	uint8_t revision;
+	bool (*match)(const struct sk_buff *, struct xt_action_param *);
+	int (*checkentry)(const struct xt_mtchk_param *);
+	void (*destroy)(const struct xt_mtdtor_param *);
+	struct module *me;
+	const char *table;
+	unsigned int matchsize, hooks;
+	unsigned short proto, family;
+
+	void *__compat_match;
+};
+
+struct xtnu_target {
+	char name[sizeof(((struct xt_target *)NULL)->name) - 1 - sizeof(void *)];
+	uint8_t revision;
+	unsigned int (*target)(struct sk_buff **,
+		const struct xt_action_param *);
+	int (*checkentry)(const struct xt_tgchk_param *);
+	void (*destroy)(const struct xt_tgdtor_param *);
+	struct module *me;
+	const char *table;
+	unsigned int targetsize, hooks;
+	unsigned short proto, family;
+
+	void *__compat_target;
+};
+
+static inline struct xtnu_match *xtcompat_numatch(const struct xt_match *m)
+{
+	void *q;
+	memcpy(&q, m->name + sizeof(m->name) - sizeof(void *), sizeof(void *));
+	return q;
+}
+
+static inline struct xtnu_target *xtcompat_nutarget(const struct xt_target *t)
+{
+	void *q;
+	memcpy(&q, t->name + sizeof(t->name) - sizeof(void *), sizeof(void *));
+	return q;
+}
+
+extern int xtnu_register_match(struct xtnu_match *);
+extern void xtnu_unregister_match(struct xtnu_match *);
+extern int xtnu_register_matches(struct xtnu_match *, unsigned int);
+extern void xtnu_unregister_matches(struct xtnu_match *, unsigned int);
+extern int xtnu_register_target(struct xtnu_target *);
+extern void xtnu_unregister_target(struct xtnu_target *);
+extern int xtnu_register_targets(struct xtnu_target *, unsigned int);
+extern void xtnu_unregister_targets(struct xtnu_target *, unsigned int);
+
+extern void *HX_memmem(const void *, size_t, const void *, size_t);
+
+#endif /* _COMPAT_XTNU_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/nf_conntrack_quake3.h b/trunk/linux-4.4.x/include/linux/netfilter/nf_conntrack_quake3.h
new file mode 100644
index 000000000..302591dd3
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/nf_conntrack_quake3.h
@@ -0,0 +1,16 @@
+#ifndef _IP_CT_QUAKE3
+#define _IP_CT_QUAKE3
+
+/* Don't confuse with 27960, often used as the Server Port */
+#define QUAKE3_MASTER_PORT 27950
+
+struct quake3_search {
+	const char marker[4]; /* always 0xff 0xff 0xff 0xff ? */
+	const char *pattern;
+	size_t plen;
+};
+
+extern unsigned int (*nf_nat_quake3_hook)(struct sk_buff *skb,
+				   enum ip_conntrack_info ctinfo,
+				   struct nf_conntrack_expect *exp);
+#endif /* _IP_CT_QUAKE3 */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/nf_conntrack_rtsp.h b/trunk/linux-4.4.x/include/linux/netfilter/nf_conntrack_rtsp.h
new file mode 100644
index 000000000..7965755bf
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/nf_conntrack_rtsp.h
@@ -0,0 +1,72 @@
+/*
+ * RTSP extension for IP connection tracking.
+ * (C) 2003 by Tom Marshall <tmarshall at real.com>
+ * based on ip_conntrack_irc.h
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ *
+ * 2013-03-04: Il'inykh Sergey <sergeyi at inango-sw.com>. Inango Systems Ltd
+ *	- conditional compilation for kernel 3.7
+ *	- port mapping improvements
+*/
+#ifndef _IP_CONNTRACK_RTSP_H
+#define _IP_CONNTRACK_RTSP_H
+
+#include <linux/version.h>
+
+//#define IP_NF_RTSP_DEBUG 1
+#define IP_NF_RTSP_VERSION "0.7"
+
+#ifdef __KERNEL__
+/* port block types */
+typedef enum {
+    pb_single,  /* client_port=x */
+    pb_range,   /* client_port=x-y */
+    pb_discon   /* client_port=x/y (rtspbis) */
+} portblock_t;
+
+/* We record seq number and length of rtsp headers here, all in host order. */
+
+/*
+ * This structure is per expected connection.  It is a member of struct
+ * ip_conntrack_expect.  The TCP SEQ for the conntrack expect is stored
+ * there and we are expected to only store the length of the data which
+ * needs replaced.  If a packet contains multiple RTSP messages, we create
+ * one expected connection per message.
+ *
+ * We use these variables to mark the entire header block.  This may seem
+ * like overkill, but the nature of RTSP requires it.  A header may appear
+ * multiple times in a message.  We must treat two Transport headers the
+ * same as one Transport header with two entries.
+ */
+struct ip_ct_rtsp_expect
+{
+    u_int32_t   len;        /* length of header block */
+    portblock_t pbtype;     /* Type of port block that was requested */
+    u_int16_t   loport;     /* Port that was requested, low or first */
+    u_int16_t   hiport;     /* Port that was requested, high or second */
+#if 0
+    uint        method;     /* RTSP method */
+    uint        cseq;       /* CSeq from request */
+#endif
+};
+
+extern unsigned int (*nf_nat_rtsp_hook)(struct sk_buff *skb,
+					enum ip_conntrack_info ctinfo,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+					unsigned int protoff,
+#endif
+					unsigned int matchoff,
+					unsigned int matchlen,
+					struct ip_ct_rtsp_expect *prtspexp,
+					struct nf_conntrack_expect *rtp_exp,
+					struct nf_conntrack_expect *rtcp_exp);
+
+#define RTSP_PORT   554
+
+#endif /* __KERNEL__ */
+
+#endif /* _IP_CONNTRACK_RTSP_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/xt_IMQ.h b/trunk/linux-4.4.x/include/linux/netfilter/xt_IMQ.h
new file mode 100644
index 000000000..9b072300f
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/xt_IMQ.h
@@ -0,0 +1,9 @@
+#ifndef _XT_IMQ_H
+#define _XT_IMQ_H
+
+struct xt_imq_info {
+	unsigned int todev;     /* target imq device */
+};
+
+#endif /* _XT_IMQ_H */
+
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/xt_condition.h b/trunk/linux-4.4.x/include/linux/netfilter/xt_condition.h
new file mode 100644
index 000000000..db37a31c8
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/xt_condition.h
@@ -0,0 +1,16 @@
+#ifndef _XT_CONDITION_H
+#define _XT_CONDITION_H
+
+enum {
+	CONDITION_NAME_LEN = 31,
+};
+
+struct xt_condition_mtinfo {
+	char name[CONDITION_NAME_LEN];
+	__u8 invert;
+
+	/* Used internally by the kernel */
+	void *condvar __attribute__((aligned(8)));
+};
+
+#endif /* _XT_CONDITION_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/xt_ethport.h b/trunk/linux-4.4.x/include/linux/netfilter/xt_ethport.h
new file mode 100644
index 000000000..633b64b5c
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/xt_ethport.h
@@ -0,0 +1,20 @@
+/* x_tables module for matching the IPv4/IPv6 DSCP field
+ *
+ * (C) 2002 Harald Welte <laforge@gnumonks.org>
+ * This software is distributed under GNU GPL v2, 1991
+ *
+ * xt_ethport.h, 2009/06/09
+*/
+#ifndef _XT_ETHPORT_H
+#define _XT_ETHPORT_H
+
+#define XT_SKB_CB_OFFSET	0x24	/* store port number info in skb->cb[0x24] */
+#define XT_ETHPORT_MAX		0x8		/* port 0-5 && cpu port(port6)*/
+
+/* match info */
+struct xt_ethport_info {
+	u_int8_t portnum;
+	u_int8_t invert;
+};
+
+#endif /* _XT_ETHPORT_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/xt_geoip.h b/trunk/linux-4.4.x/include/linux/netfilter/xt_geoip.h
new file mode 100644
index 000000000..ee6e66280
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/xt_geoip.h
@@ -0,0 +1,58 @@
+/* ipt_geoip.h header file for libipt_geoip.c and ipt_geoip.c
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * Copyright (c) 2004, 2005, 2006, 2007, 2008
+ *
+ * Samuel Jean
+ * Nicolas Bouliane
+ */
+#ifndef _LINUX_NETFILTER_XT_GEOIP_H
+#define _LINUX_NETFILTER_XT_GEOIP_H 1
+
+enum {
+	XT_GEOIP_SRC = 1 << 0,	/* Perform check on Source IP */
+	XT_GEOIP_DST = 1 << 1,	/* Perform check on Destination IP */
+	XT_GEOIP_INV = 1 << 2,	/* Negate the condition */
+
+	XT_GEOIP_MAX = 15,	/* Maximum of countries */
+};
+
+/* Yup, an address range will be passed in with host-order */
+struct geoip_subnet4 {
+	__u32 begin;
+	__u32 end;
+};
+
+struct geoip_subnet6 {
+	struct in6_addr begin, end;
+};
+
+struct geoip_country_user {
+	aligned_u64 subnets;
+	__u32 count;
+	__u16 cc;
+};
+
+struct geoip_country_kernel;
+
+union geoip_country_group {
+	aligned_u64 user; /* struct geoip_country_user * */
+	struct geoip_country_kernel *kernel;
+};
+
+struct xt_geoip_match_info {
+	__u8 flags;
+	__u8 count;
+	__u16 cc[XT_GEOIP_MAX];
+
+	/* Used internally by the kernel */
+	union geoip_country_group mem[XT_GEOIP_MAX];
+};
+
+#define COUNTRY(cc) ((cc) >> 8), ((cc) & 0x00FF)
+
+#endif /* _LINUX_NETFILTER_XT_GEOIP_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter/xt_layer7.h b/trunk/linux-4.4.x/include/linux/netfilter/xt_layer7.h
new file mode 100644
index 000000000..162ab4603
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter/xt_layer7.h
@@ -0,0 +1,14 @@
+#ifndef _XT_LAYER7_H                
+#define _XT_LAYER7_H                
+                                    
+#define MAX_PATTERN_LEN 8192        
+#define MAX_PROTOCOL_LEN 256        
+                                    
+struct xt_layer7_info {             
+    char protocol[MAX_PROTOCOL_LEN];
+    char invert:1;                  
+	    char pattern[MAX_PATTERN_LEN];
+	    char pkt;                     
+	};                                
+	                                  
+#endif /* _XT_LAYER7_H */         
\ No newline at end of file
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_helpers.h b/trunk/linux-4.4.x/include/linux/netfilter_helpers.h
new file mode 100644
index 000000000..903f37455
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_helpers.h
@@ -0,0 +1,133 @@
+/*
+ * Helpers for netfiler modules.  This file provides implementations for basic
+ * functions such as strncasecmp(), etc.
+ *
+ * gcc will warn for defined but unused functions, so we only include the
+ * functions requested.  The following macros are used:
+ *   NF_NEED_STRNCASECMP        nf_strncasecmp()
+ *   NF_NEED_STRTOU16           nf_strtou16()
+ *   NF_NEED_STRTOU32           nf_strtou32()
+ */
+#ifndef _NETFILTER_HELPERS_H
+#define _NETFILTER_HELPERS_H
+
+/* Only include these functions for kernel code. */
+#ifdef __KERNEL__
+
+#include <linux/ctype.h>
+#define iseol(c) ( (c) == '\r' || (c) == '\n' )
+
+/*
+ * The standard strncasecmp()
+ */
+#ifdef NF_NEED_STRNCASECMP
+static int
+nf_strncasecmp(const char* s1, const char* s2, u_int32_t len)
+{
+    if (s1 == NULL || s2 == NULL)
+    {
+        if (s1 == NULL && s2 == NULL)
+        {
+            return 0;
+        }
+        return (s1 == NULL) ? -1 : 1;
+    }
+    while (len > 0 && tolower(*s1) == tolower(*s2))
+    {
+        len--;
+        s1++;
+        s2++;
+    }
+    return ( (len == 0) ? 0 : (tolower(*s1) - tolower(*s2)) );
+}
+#endif /* NF_NEED_STRNCASECMP */
+
+/*
+ * Parse a string containing a 16-bit unsigned integer.
+ * Returns the number of chars used, or zero if no number is found.
+ */
+#ifdef NF_NEED_STRTOU16
+static int
+nf_strtou16(const char* pbuf, u_int16_t* pval)
+{
+    int n = 0;
+
+    *pval = 0;
+    while (isdigit(pbuf[n]))
+    {
+        *pval = (*pval * 10) + (pbuf[n] - '0');
+        n++;
+    }
+
+    return n;
+}
+#endif /* NF_NEED_STRTOU16 */
+
+/*
+ * Parse a string containing a 32-bit unsigned integer.
+ * Returns the number of chars used, or zero if no number is found.
+ */
+#ifdef NF_NEED_STRTOU32
+static int
+nf_strtou32(const char* pbuf, u_int32_t* pval)
+{
+    int n = 0;
+
+    *pval = 0;
+    while (pbuf[n] >= '0' && pbuf[n] <= '9')
+    {
+        *pval = (*pval * 10) + (pbuf[n] - '0');
+        n++;
+    }
+
+    return n;
+}
+#endif /* NF_NEED_STRTOU32 */
+
+/*
+ * Given a buffer and length, advance to the next line and mark the current
+ * line.
+ */
+#ifdef NF_NEED_NEXTLINE
+static int
+nf_nextline(char* p, uint len, uint* poff, uint* plineoff, uint* plinelen)
+{
+    uint    off = *poff;
+    uint    physlen = 0;
+
+    if (off >= len)
+    {
+        return 0;
+    }
+
+    while (p[off] != '\n')
+    {
+        if (len-off <= 1)
+        {
+            return 0;
+        }
+
+        physlen++;
+        off++;
+    }
+
+    /* if we saw a crlf, physlen needs adjusted */
+    if (physlen > 0 && p[off] == '\n' && p[off-1] == '\r')
+    {
+        physlen--;
+    }
+
+    /* advance past the newline */
+    off++;
+
+    *plineoff = *poff;
+    *plinelen = physlen;
+    *poff = off;
+
+    return 1;
+}
+#endif /* NF_NEED_NEXTLINE */
+
+#endif /* __KERNEL__ */
+
+#endif /* _NETFILTER_HELPERS_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ip_autofw.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ip_autofw.h
new file mode 100644
index 000000000..c46c4e675
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ip_autofw.h
@@ -0,0 +1,35 @@
+/*
+ * Copyright (C) 2013, Broadcom Corporation. All Rights Reserved.
+ * 
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ * 
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ *
+ * $Id: ip_autofw.h,v 1.1 2008-10-02 03:42:40 $
+ */
+
+#ifndef _IP_AUTOFW_H
+#define _IP_AUTOFW_H
+
+#define AUTOFW_MASTER_TIMEOUT 600	/* 600 secs */
+
+struct ip_autofw_info {
+	u_int16_t proto;	/* Related protocol */
+	u_int16_t dport[2];	/* Related destination port range */
+	u_int16_t to[2];	/* Port range to map related destination port range to */
+};
+
+struct ip_autofw_expect {
+	u_int16_t dport[2];	/* Related destination port range */
+	u_int16_t to[2];	/* Port range to map related destination port range to */
+};
+
+#endif /* _IP_AUTOFW_H */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_IMQ.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_IMQ.h
new file mode 100644
index 000000000..7af320fc7
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_IMQ.h
@@ -0,0 +1,10 @@
+#ifndef _IPT_IMQ_H
+#define _IPT_IMQ_H
+
+/* Backwards compatibility for old userspace */
+#include <linux/netfilter/xt_IMQ.h>
+
+#define ipt_imq_info xt_imq_info
+
+#endif /* _IPT_IMQ_H */
+
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_ROUTE.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_ROUTE.h
new file mode 100644
index 000000000..41b1a9c86
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_ROUTE.h
@@ -0,0 +1,23 @@
+/* Header file for iptables ipt_ROUTE target
+ *
+ * (C) 2002 by Cdric de Launois <delaunois@info.ucl.ac.be>
+ *
+ * This software is distributed under GNU GPL v2, 1991
+ */
+#ifndef _IPT_ROUTE_H_target
+#define _IPT_ROUTE_H_target
+
+#define IPT_ROUTE_IFNAMSIZ 16
+
+struct ipt_route_target_info {
+	char      oif[IPT_ROUTE_IFNAMSIZ];      /* Output Interface Name */
+	char      iif[IPT_ROUTE_IFNAMSIZ];      /* Input Interface Name  */
+	u_int32_t gw;                           /* IP address of gateway */
+	u_int8_t  flags;
+};
+
+/* Values for "flags" field */
+#define IPT_ROUTE_CONTINUE        0x01
+#define IPT_ROUTE_TEE             0x02
+
+#endif /*_IPT_ROUTE_H_target*/
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_TOS.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_TOS.h
new file mode 100644
index 000000000..6bf9e1fdf
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_TOS.h
@@ -0,0 +1,12 @@
+#ifndef _IPT_TOS_H_target
+#define _IPT_TOS_H_target
+
+#ifndef IPTOS_NORMALSVC
+#define IPTOS_NORMALSVC 0
+#endif
+
+struct ipt_tos_target_info {
+	u_int8_t tos;
+};
+
+#endif /*_IPT_TOS_H_target*/
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_TRIGGER.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_TRIGGER.h
new file mode 100644
index 000000000..aa1bb8bd0
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_TRIGGER.h
@@ -0,0 +1,25 @@
+#ifndef _IPT_TRIGGER_H_target
+#define _IPT_TRIGGER_H_target
+
+#define TRIGGER_TIMEOUT 600	/* 600 secs */
+
+enum ipt_trigger_type
+{
+	IPT_TRIGGER_DNAT = 1,
+	IPT_TRIGGER_IN = 2,
+	IPT_TRIGGER_OUT = 3,
+	IPT_TRIGGER_REFRESH = 4
+};
+
+struct ipt_trigger_ports {
+	u_int16_t mport[2];	/* Related destination port range */
+	u_int16_t rport[2];	/* Port range to map related destination port range to */
+};
+
+struct ipt_trigger_info {
+	enum ipt_trigger_type type;
+	u_int16_t proto;	/* Related protocol */
+	struct ipt_trigger_ports ports;
+};
+
+#endif /*_IPT_TRIGGER_H_target*/
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_geoip.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_geoip.h
new file mode 100644
index 000000000..1feeedffa
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_geoip.h
@@ -0,0 +1,24 @@
+/* ipt_geoip.h header file for libipt_geoip.c and ipt_geoip.c
+ * 
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * Copyright (c) 2004 Cookinglinux
+ */
+#ifndef _IPT_GEOIP_H
+#define _IPT_GEOIP_H
+
+#include <linux/netfilter/xt_geoip.h>
+
+#define IPT_GEOIP_SRC	XT_GEOIP_SRC
+#define IPT_GEOIP_DST	XT_GEOIP_DST
+#define IPT_GEOIP_INV	XT_GEOIP_INV
+#define IPT_GEOIP_MAX	XT_GEOIP_MAX
+
+#define ipt_geoip_info	xt_geoip_match_info
+
+#endif
+
+/* End of ipt_geoip.h */
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_ipp2p.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_ipp2p.h
new file mode 100644
index 000000000..7033a495d
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_ipp2p.h
@@ -0,0 +1,31 @@
+#ifndef __IPT_IPP2P_H
+#define __IPT_IPP2P_H
+#define IPP2P_VERSION "0.8.2-pomng"
+
+struct ipt_p2p_info {
+    int cmd;
+    int debug;
+};
+
+#endif //__IPT_IPP2P_H
+
+#define SHORT_HAND_IPP2P	1 /* --ipp2p switch*/
+//#define SHORT_HAND_DATA		4 /* --ipp2p-data switch*/
+#define SHORT_HAND_NONE		5 /* no short hand*/
+
+#define IPP2P_EDK		(1 << 1)
+#define IPP2P_DATA_KAZAA	(1 << 2)
+#define IPP2P_DATA_EDK		(1 << 3)
+#define IPP2P_DATA_DC		(1 << 4)
+#define IPP2P_DC		(1 << 5)
+#define IPP2P_DATA_GNU		(1 << 6)
+#define IPP2P_GNU		(1 << 7)
+#define IPP2P_KAZAA		(1 << 8)
+#define IPP2P_BIT		(1 << 9)
+#define IPP2P_APPLE		(1 << 10)
+#define IPP2P_SOUL		(1 << 11)
+#define IPP2P_WINMX		(1 << 12)
+#define IPP2P_ARES		(1 << 13)
+#define IPP2P_MUTE		(1 << 14)
+#define IPP2P_WASTE		(1 << 15)
+#define IPP2P_XDCC		(1 << 16)
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_tos.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_tos.h
new file mode 100644
index 000000000..a21f5df23
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_tos.h
@@ -0,0 +1,13 @@
+#ifndef _IPT_TOS_H
+#define _IPT_TOS_H
+
+struct ipt_tos_info {
+    u_int8_t tos;
+    u_int8_t invert;
+};
+
+#ifndef IPTOS_NORMALSVC
+#define IPTOS_NORMALSVC 0
+#endif
+
+#endif /*_IPT_TOS_H*/
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_web.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_web.h
new file mode 100644
index 000000000..176208e21
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_web.h
@@ -0,0 +1,30 @@
+/*
+
+	web (experimental)
+	HTTP client match
+	Copyright (C) 2006 Jonathan Zarate
+
+	Licensed under GNU GPL v2 or later.
+
+*/
+#ifndef _IPT_WEB_H
+#define _IPT_WEB_H
+
+#define IPT_WEB_MAXTEXT	512
+
+typedef enum {
+	IPT_WEB_HTTP,
+	IPT_WEB_RURI,
+	IPT_WEB_PATH,
+	IPT_WEB_QUERY,
+	IPT_WEB_HOST,
+	IPT_WEB_HORE
+} ipt_web_mode_t;
+
+struct ipt_web_info {
+	ipt_web_mode_t mode;
+	int invert;
+	char text[IPT_WEB_MAXTEXT];
+};
+
+#endif
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_webmon.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_webmon.h
new file mode 100644
index 000000000..934dd0cd8
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv4/ipt_webmon.h
@@ -0,0 +1,63 @@
+/*  webmon --	A netfilter module to match URLs in HTTP requests
+ *  		This module can match using string match or regular expressions
+ *  		Originally designed for use with Gargoyle router firmware (gargoyle-router.com)
+ *
+ *
+ *  Copyright  2008-2010 by Eric Bishop <eric@gargoyle-router.com>
+ *
+ *  This file is free software: you may copy, redistribute and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation, either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *  This file is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+
+
+
+#ifndef _IPT_WEBMON_H
+#define _IPT_WEBMON_H
+
+
+#define WEBMON_MAX_IPS           256
+#define WEBMON_MAX_IP_RANGES      16
+
+#define WEBMON_EXCLUDE             1
+#define WEBMON_INCLUDE             2
+
+#define WEBMON_MAXDOMAIN           4
+#define WEBMON_MAXSEARCH           8
+
+#define WEBMON_DOMAIN             16
+#define WEBMON_SEARCH             32
+
+
+#define WEBMON_SET              3064
+
+struct ipt_webmon_ip_range
+{
+	uint32_t start;
+	uint32_t end;
+};
+
+struct ipt_webmon_info
+{
+	uint32_t max_domains;
+	uint32_t max_searches;
+	uint32_t exclude_ips[WEBMON_MAX_IPS];
+	struct ipt_webmon_ip_range exclude_ranges[WEBMON_MAX_IP_RANGES];
+	uint32_t num_exclude_ips;
+	uint32_t num_exclude_ranges;
+	unsigned char exclude_type;
+	uint32_t* ref_count;
+
+};
+
+#endif /*_IPT_WEBMON_H*/
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv6/ip6t_IMQ.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv6/ip6t_IMQ.h
new file mode 100644
index 000000000..198ac01f8
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv6/ip6t_IMQ.h
@@ -0,0 +1,10 @@
+#ifndef _IP6T_IMQ_H
+#define _IP6T_IMQ_H
+
+/* Backwards compatibility for old userspace */
+#include <linux/netfilter/xt_IMQ.h>
+
+#define ip6t_imq_info xt_imq_info
+
+#endif /* _IP6T_IMQ_H */
+
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_ipv6/ip6t_ROUTE.h b/trunk/linux-4.4.x/include/linux/netfilter_ipv6/ip6t_ROUTE.h
new file mode 100644
index 000000000..c5ec871b5
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_ipv6/ip6t_ROUTE.h
@@ -0,0 +1,23 @@
+/* Header file for iptables ip6t_ROUTE target
+ *
+ * (C) 2003 by Cdric de Launois <delaunois@info.ucl.ac.be>
+ *
+ * This software is distributed under GNU GPL v2, 1991
+ */
+#ifndef _IPT_ROUTE_H_target
+#define _IPT_ROUTE_H_target
+
+#define IP6T_ROUTE_IFNAMSIZ 16
+
+struct ip6t_route_target_info {
+	char      oif[IP6T_ROUTE_IFNAMSIZ];     /* Output Interface Name */
+	char      iif[IP6T_ROUTE_IFNAMSIZ];     /* Input Interface Name  */
+	u_int32_t gw[4];                        /* IPv6 address of gateway */
+	u_int8_t  flags;
+};
+
+/* Values for "flags" field */
+#define IP6T_ROUTE_CONTINUE        0x01
+#define IP6T_ROUTE_TEE             0x02
+
+#endif /*_IP6T_ROUTE_H_target*/
diff --git a/trunk/linux-4.4.x/include/linux/netfilter_mime.h b/trunk/linux-4.4.x/include/linux/netfilter_mime.h
new file mode 100644
index 000000000..7eeb18352
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/netfilter_mime.h
@@ -0,0 +1,89 @@
+/*
+ * MIME functions for netfilter modules.  This file provides implementations
+ * for basic MIME parsing.  MIME headers are used in many protocols, such as
+ * HTTP, RTSP, SIP, etc.
+ *
+ * gcc will warn for defined but unused functions, so we only include the
+ * functions requested.  The following macros are used:
+ *   NF_NEED_MIME_NEXTLINE      nf_mime_nextline()
+ */
+#ifndef _NETFILTER_MIME_H
+#define _NETFILTER_MIME_H
+
+/* Only include these functions for kernel code. */
+#ifdef __KERNEL__
+
+#include <linux/ctype.h>
+
+/*
+ * Given a buffer and length, advance to the next line and mark the current
+ * line.  If the current line is empty, *plinelen will be set to zero.  If
+ * not, it will be set to the actual line length (including CRLF).
+ *
+ * 'line' in this context means logical line (includes LWS continuations).
+ * Returns 1 on success, 0 on failure.
+ */
+#ifdef NF_NEED_MIME_NEXTLINE
+static int
+nf_mime_nextline(char* p, uint len, uint* poff, uint* plineoff, uint* plinelen)
+{
+    uint    off = *poff;
+    uint    physlen = 0;
+    int     is_first_line = 1;
+
+    if (off >= len)
+    {
+        return 0;
+    }
+
+    do
+    {
+        while (p[off] != '\n')
+        {
+            if (len-off <= 1)
+            {
+                return 0;
+            }
+
+            physlen++;
+            off++;
+        }
+
+        /* if we saw a crlf, physlen needs adjusted */
+        if (physlen > 0 && p[off] == '\n' && p[off-1] == '\r')
+        {
+            physlen--;
+        }
+
+        /* advance past the newline */
+        off++;
+
+        /* check for an empty line */
+        if (physlen == 0)
+        {
+            break;
+        }
+
+        /* check for colon on the first physical line */
+        if (is_first_line)
+        {
+            is_first_line = 0;
+            if (memchr(p+(*poff), ':', physlen) == NULL)
+            {
+                return 0;
+            }
+        }
+    }
+    while (p[off] == ' ' || p[off] == '\t');
+
+    *plineoff = *poff;
+    *plinelen = (physlen == 0) ? 0 : (off - *poff);
+    *poff = off;
+
+    return 1;
+}
+#endif /* NF_NEED_MIME_NEXTLINE */
+
+#endif /* __KERNEL__ */
+
+#endif /* _NETFILTER_MIME_H */
diff --git a/trunk/linux-4.4.x/include/linux/netlink.h b/trunk/linux-4.4.x/include/linux/netlink.h
index 0b41959aa..0db24f33c 100644
--- a/trunk/linux-4.4.x/include/linux/netlink.h
+++ b/trunk/linux-4.4.x/include/linux/netlink.h
@@ -153,6 +153,14 @@ struct netlink_notify {
 struct nlmsghdr *
 __nlmsg_put(struct sk_buff *skb, u32 portid, u32 seq, int type, int len, int flags);
 
+/*#define NLMSG_NEW(skb, pid, seq, type, len, flags) \
+({	if (unlikely(skb_tailroom(skb) < (int)NLMSG_SPACE(len))) \
+		goto nlmsg_failure; \
+	__nlmsg_put(skb, pid, seq, type, len, flags); })
+
+#define NLMSG_PUT(skb, pid, seq, type, len) \
+	NLMSG_NEW(skb, pid, seq, type, len, 0)
+*/
 struct netlink_dump_control {
 	int (*start)(struct netlink_callback *);
 	int (*dump)(struct sk_buff *skb, struct netlink_callback *);
diff --git a/trunk/linux-4.4.x/include/linux/skbuff.h b/trunk/linux-4.4.x/include/linux/skbuff.h
index 77ab7845c..6699b34d8 100644
--- a/trunk/linux-4.4.x/include/linux/skbuff.h
+++ b/trunk/linux-4.4.x/include/linux/skbuff.h
@@ -38,6 +38,9 @@
 #include <linux/splice.h>
 #include <linux/in6.h>
 #include <net/flow.h>
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+#include <linux/imq.h>
+#endif
 
 /* A. Checksumming of received packets by device.
  *
@@ -573,6 +576,9 @@ struct sk_buff {
 	 * first. This is owned by whoever has the skb queued ATM.
 	 */
 	char			cb[48] __aligned(8);
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	void			*cb_next;
+#endif
 
 	unsigned long		_skb_refdst;
 	void			(*destructor)(struct sk_buff *skb);
@@ -582,6 +588,9 @@ struct sk_buff {
 #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
 	struct nf_conntrack	*nfct;
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	struct nf_queue_entry   *nf_queue_entry;
+#endif
 #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)
 	struct nf_bridge_info	*nf_bridge;
 #endif
@@ -646,12 +655,15 @@ struct sk_buff {
 	__u8			ipvs_property:1;
 
 	__u8			inner_protocol_type:1;
-#ifdef CONFIG_SHORTCUT_FE
-	__u8			fast_forwarded:1;
-#endif
 	__u8			remcsum_offload:1;
 	__u8			gro_skip:1;
 	/* 2 or 4 bit hole */
+#ifdef CONFIG_SHORTCUT_FE
+	__u8			fast_forwarded:1;
+#endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	__u8			imq_flags:IMQ_F_BITS;
+#endif
 
 #ifdef CONFIG_NET_SCHED
 	__u16			tc_index;	/* traffic control index */
@@ -808,6 +820,12 @@ void kfree_skb_list(struct sk_buff *segs);
 void skb_tx_error(struct sk_buff *skb);
 void consume_skb(struct sk_buff *skb);
 void  __kfree_skb(struct sk_buff *skb);
+
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+int skb_save_cb(struct sk_buff *skb);
+int skb_restore_cb(struct sk_buff *skb);
+#endif
+
 extern struct kmem_cache *skbuff_head_cache;
 
 void kfree_skb_partial(struct sk_buff *skb, bool head_stolen);
@@ -2205,7 +2223,13 @@ static inline int pskb_network_may_pull(struct sk_buff *skb, unsigned int len)
  * NET_IP_ALIGN(2) + ethernet_header(14) + IP_header(20/40) + ports(8)
  */
 #ifndef NET_SKB_PAD
-#define NET_SKB_PAD	max(64, L1_CACHE_BYTES)
+#if defined (CONFIG_PPTP) || defined (CONFIG_PPPOL2TP)
+#define NET_SKB_PAD             128
+#define NET_SKB_PAD_ORIG        max(64, L1_CACHE_BYTES)
+#else
+#define NET_SKB_PAD             max(64, L1_CACHE_BYTES)
+#define NET_SKB_PAD_ORIG        NET_SKB_PAD
+#endif
 #endif
 
 int ___pskb_trim(struct sk_buff *skb, unsigned int len);
@@ -3454,8 +3478,12 @@ static inline void __nf_copy(struct sk_buff *dst, const struct sk_buff *src,
 	if (copy)
 		dst->nfctinfo = src->nfctinfo;
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	dst->imq_flags = src->imq_flags;
+	dst->nf_queue_entry = src->nf_queue_entry;
+#endif
 #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)
-	dst->nf_bridge  = src->nf_bridge;
+	dst->nf_bridge = src->nf_bridge;
 	nf_bridge_get(src->nf_bridge);
 #endif
 #if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE) || defined(CONFIG_NF_TABLES)
diff --git a/trunk/linux-4.4.x/include/linux/swrt_fastpath/fast_path.h b/trunk/linux-4.4.x/include/linux/swrt_fastpath/fast_path.h
new file mode 100644
index 000000000..951653f2d
--- /dev/null
+++ b/trunk/linux-4.4.x/include/linux/swrt_fastpath/fast_path.h
@@ -0,0 +1,6 @@
+#ifndef __FAST_PATH_H__
+#define __FAST_PATH_H__
+
+#define SWRT_FASTPATH(skb) fast_path_nf_filter_port(skb)
+int fast_path_nf_filter_port(struct sk_buff *skb);
+#endif
diff --git a/trunk/linux-4.4.x/include/linux/timer.h b/trunk/linux-4.4.x/include/linux/timer.h
index 566fc1f02..1e37f5861 100644
--- a/trunk/linux-4.4.x/include/linux/timer.h
+++ b/trunk/linux-4.4.x/include/linux/timer.h
@@ -19,10 +19,11 @@ struct timer_list {
 	void			(*function)(unsigned long);
 	unsigned long		data;
 	u32			flags;
+	int			slack;
+
 #ifdef CONFIG_SHORTCUT_FE
-	unsigned long		cust_data;
+	//unsigned long		cust_data;
 #endif
-	int			slack;
 
 #ifdef CONFIG_TIMER_STATS
 	int			start_pid;
diff --git a/trunk/linux-4.4.x/include/linux/usb.h b/trunk/linux-4.4.x/include/linux/usb.h
index 02bffcc61..5ba9e4b69 100644
--- a/trunk/linux-4.4.x/include/linux/usb.h
+++ b/trunk/linux-4.4.x/include/linux/usb.h
@@ -727,6 +727,7 @@ static inline bool usb_device_no_sg_constraint(struct usb_device *udev)
 	return udev && udev->bus && udev->bus->no_sg_constraint;
 }
 
+extern struct usb_device *usb_find_device_by_name(const char *name);
 
 /*-------------------------------------------------------------------------*/
 
diff --git a/trunk/linux-4.4.x/include/linux/vmalloc.h b/trunk/linux-4.4.x/include/linux/vmalloc.h
index 3bff87a25..2a2a56afb 100644
--- a/trunk/linux-4.4.x/include/linux/vmalloc.h
+++ b/trunk/linux-4.4.x/include/linux/vmalloc.h
@@ -79,6 +79,7 @@ extern void *__vmalloc_node_range(unsigned long size, unsigned long align,
 			unsigned long start, unsigned long end, gfp_t gfp_mask,
 			pgprot_t prot, unsigned long vm_flags, int node,
 			const void *caller);
+extern void *__vmalloc_node_flags(unsigned long size, int node, gfp_t flags);
 
 extern void vfree(const void *addr);
 
diff --git a/trunk/linux-4.4.x/include/net/mtk_esp.h b/trunk/linux-4.4.x/include/net/mtk_esp.h
new file mode 100644
index 000000000..85a687694
--- /dev/null
+++ b/trunk/linux-4.4.x/include/net/mtk_esp.h
@@ -0,0 +1,421 @@
+#ifndef MTK_ESP_H
+#define MTK_ESP_H
+
+#include <linux/skbuff.h>
+#include <linux/dma-mapping.h>
+#include <linux/kernel.h>
+
+#if defined (CONFIG_ARCH_MT7623)
+#define MTK_EIP97_DRIVER	1
+#define MTK_EIP97_IPI		1
+#endif
+
+#define CONFIG_HWCRYPTO_MEMPOOL 1
+
+#define HASH_DIGEST_OUT			0
+#define HASH_DIGEST_IN			1
+#define CRYPTO_ENCRYPTION		1
+#define CRYPTO_DECRYPTION		2
+#define CRYPTO_PREDIGEST		3
+
+#define TBL_EMPTY				0
+#define TBL_ACTIVE				0xAAAAAAAA
+#define TBL_DEL					0xDDDDDDDD
+
+#define IPESC_EIP93_ADAPTERS	16
+
+#ifdef MTK_EIP97_DRIVER
+#define LOCALPOOLSIZE					1024
+#define HASHKEYTANK_OFFSET				0
+#define PRECOMPUTE_IDIGEST_OFFSET		128	//64
+#define PRECOMPUTE_ODIGEST_OFFSET		256//128
+#define PRECOMPUTE_TCRDATA_OFFSET		512//256
+
+#define RECPOOLSIZE						2048
+#define IPAD_OFFSET						0
+#define OPAD_OFFSET						64
+#define SA_OFFSET							128
+#define TOKEN_OFFSET					512
+#define STATE_OFFSET					640
+
+#define SAPOOLSIZE						1024
+
+#define CMDLOCALPOOLSIZE				2048
+#define CMD_IDIGEST_OFFSET				0
+#define CMD_ODIGEST_OFFSET				512
+#define CMD_TCRDATA_OFFSET				1024
+#else
+#define LOCALPOOLSIZE					1024
+#define HASHKEYTANK_OFFSET				0
+#define PRECOMPUTE_IDIGEST_OFFSET		64
+#define PRECOMPUTE_ODIGEST_OFFSET		128
+#define PRECOMPUTE_TCRDATA_OFFSET		256
+
+#define RECPOOLSIZE						2048
+#define IPAD_OFFSET						0
+#define OPAD_OFFSET						64
+#define SA_OFFSET						128
+#define TOKEN_OFFSET					512
+#define STATE_OFFSET					640
+#define STATE2_OFFSET					768
+
+#define SAPOOLSIZE						1024
+#define SAPOOL_STATE_OFFSET             256
+#define SAPOOL_STATE2_OFFSET            512 
+#define SAPOOL_ARC4STATE_OFFSET         768 
+
+#endif
+
+#ifdef MTK_EIP97_DRIVER
+#define NUM_CMD_RING					4
+#define NUM_RESULT_RING				4
+#else
+#define NUM_CMD_RING    			1
+#define NUM_RESULT_RING 			1
+#endif
+/************************************************************************
+*      E X T E R N E L    S T R U C T U R E    D E F I N I T I O N
+*************************************************************************
+*/
+typedef union
+{
+	struct
+	{
+		unsigned int hostReady		: 1;
+		unsigned int peReady		: 1;
+		unsigned int reserved		: 1;
+		unsigned int initArc4		: 1;
+		unsigned int hashFinal		: 1;
+		unsigned int haltMode		: 1;
+		unsigned int prngMode		: 2;
+		unsigned int padValue		: 8;
+		unsigned int errStatus		: 8;
+		unsigned int padCrtlStat	: 8;
+	} bits;
+	unsigned int word;
+		
+} peCrtlStat_t;
+
+typedef union
+{
+	struct
+	{
+		unsigned int length			: 20;
+		unsigned int reserved		: 2;
+		unsigned int hostReady		: 1;
+		unsigned int peReady		: 1;
+		unsigned int byPass			: 8;	
+	} bits;	
+	unsigned int word;
+		
+} peLength_t;
+
+#if defined (MTK_EIP97_DRIVER)
+typedef union
+{
+    struct
+    {
+        unsigned int Particle_Fill_Level  : 17;
+        unsigned int Reserved      	: 3;
+        unsigned int Desc_Ovf  			: 1;
+        unsigned int Buf_Ovf 				: 1;
+        unsigned int LS       			: 1;
+        unsigned int FS      				: 1;
+        unsigned int Result_Size    : 8;
+    } bits;
+    unsigned int word;
+
+} ResultDescW0_t;
+
+typedef union
+{
+    struct
+    {
+        unsigned int Packet_Length  : 17;
+        unsigned int Error_Code     : 15;
+    } bits;
+    unsigned int word;
+
+} peRDataW0_t;
+
+typedef union
+{
+    struct
+    {
+        unsigned int Bypass_Length  	: 4;
+        unsigned int E15				: 1;
+				unsigned int reserved			: 16;
+				unsigned int H					: 1;
+				unsigned int Hash_Length		: 6;
+				unsigned int B					: 1;
+				unsigned int C					: 1;
+				unsigned int N					: 1;
+				unsigned int L					: 1;
+    } bits;
+    unsigned int word;
+
+} peRDataW1_t;
+
+typedef union
+{
+    struct
+    {
+        unsigned int Application_ID  : 24;
+        unsigned int reserved     	 : 8;
+    } bits;
+    unsigned int word;
+
+} peRDataW2_t;
+
+typedef union
+{
+    struct
+    {
+        unsigned int Next_Header  	: 8;
+        unsigned int Pad_Length     : 8;	
+        unsigned int reserved     	: 16;
+    } bits;
+    unsigned int word;
+
+} peRDataW3_t;
+
+typedef struct peRData_s
+{
+    peRDataW0_t			peRDataW0;
+    peRDataW1_t			peRDataW1;
+    peRDataW2_t			peRDataW2;
+    peRDataW3_t			peRDataW3;
+	unsigned int		Bypass_Token_Words[4];
+}peRData_t;
+#endif
+
+typedef struct addrHandler_s
+{
+	unsigned int addr;
+	dma_addr_t	 phyAddr;
+	int			 size;
+
+} addrHandler_t;
+
+typedef struct eip93DescpHandler_s
+{
+	peCrtlStat_t	peCrtlStat;
+	addrHandler_t	srcAddr;
+	addrHandler_t	dstAddr;
+	addrHandler_t	saAddr;
+	addrHandler_t	stateAddr;
+	addrHandler_t	arc4Addr;
+	unsigned int	userId;
+	peLength_t		peLength;
+} eip93DescpHandler_t;
+
+#if defined (MTK_EIP97_DRIVER)
+typedef struct eip97DescpHandler_s
+{
+    addrHandler_t   srcAddr;
+    addrHandler_t   dstAddr;
+    addrHandler_t	ACDataAddr;				/* Token */
+    void			*pTCRData;
+    uint32_t		TokenHeaderWord;
+    uint32_t		TokenWords;
+    addrHandler_t   saAddr;						/* Context Record */
+    unsigned int	KeySizeDW;
+    unsigned int	digestWord;
+    unsigned int	blkSize;							
+    addrHandler_t   arc4Addr;
+    unsigned int    userId;						/* filter_words */
+    unsigned int	seq_no;
+    ResultDescW0_t	RxDescW0;
+    peRData_t			peRData;
+    unsigned int		nexthdr;
+    unsigned int 		*pIDigest;
+    unsigned int 		*pODigest;
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+    unsigned char		*LocalPool;
+#endif
+} eip97DescpHandler_t;
+#endif
+
+typedef struct addrsDigestPreCompute_s
+{
+	unsigned int 		*hashKeyTank;
+	addrHandler_t 		ipadHandler;
+	addrHandler_t 		opadHandler;
+	unsigned int 		blkSize;
+	void* 				cmdHandler;
+	addrHandler_t 		saHandler;
+#if defined (MTK_EIP97_DRIVER) || defined (CONFIG_HWCRYPTO_MEMPOOL)
+addrHandler_t 		RecPoolHandler;
+#endif
+#if defined (MTK_EIP97_DRIVER)
+	addrHandler_t 		saHandler2;
+#endif
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+	unsigned char		*LocalPool;		
+#endif
+	addrHandler_t 		stateHandler;
+	addrHandler_t 		stateHandler2;
+	unsigned int 		digestWord;
+	unsigned int 		*pIDigest;
+	unsigned int 		*pODigest;
+#if defined (MTK_EIP97_DRIVER)
+	addrHandler_t		ACDataAddr;				/* Token for in digest */
+	addrHandler_t		ACDataAddr2;			/* Token for out digest */
+#endif
+} addrsDigestPreCompute_t;
+
+typedef struct ipsecEip93Adapter_s
+{
+	unsigned int 				spi; //every ipsec flow has a unique spi
+	struct xfrm_state 			*x; //the SA
+	struct dst_entry 			*dst;
+	unsigned int 				isHashPreCompute; //0:pre-compute init, 1:inner digest done, 2:inner digest done, 3:pre-compute done
+	unsigned int 				isEncryptOrDecrypt; //1:encrypt, 2:decrypt
+	struct sk_buff_head 		skbQueue;
+	addrsDigestPreCompute_t		*addrsPreCompute; //for hash pre-compute
+	void*						cmdHandler;
+	spinlock_t 					lock;
+	spinlock_t					seqlock;
+	unsigned int 				addedLen; //refer to ssh_hwaccel_alloc_combined() in safenet_la.c
+	unsigned int				tunnel;
+	unsigned int				status;
+	unsigned int				idx;
+	int							packet_count;
+	unsigned int                seqno_in;
+	unsigned int                seqno_out;
+	struct sk_buff_head 		skbIPIQueue;
+} ipsecEip93Adapter_t;
+
+/************************************************************************
+*      E X T E R N E L     F U N C T I O N    D E C L A R A T I O N
+*************************************************************************
+*/
+#if defined (MTK_EIP97_DRIVER)
+extern int 
+(*ipsec_packet_put)(
+	void *descpHandler, struct sk_buff *skb, unsigned int rdx
+);
+#else
+extern int 
+(*ipsec_packet_put)(
+	void *descpHandler, struct sk_buff *skb
+);
+#endif
+
+extern int 
+(*ipsec_packet_get)(
+	void *descpHandler,
+	unsigned int rdx
+);
+extern bool 
+(*ipsec_eip93CmdResCnt_check)(
+	unsigned int rdx
+);
+extern int 
+(*ipsec_preComputeIn_cmdDescp_set)(
+	ipsecEip93Adapter_t *currAdapterPtr,
+	//unsigned int hashAlg,
+	unsigned int direction
+);
+extern int 
+(*ipsec_preComputeOut_cmdDescp_set)(
+	ipsecEip93Adapter_t *currAdapterPtr,
+	//unsigned int hashAlg, 
+	unsigned int direction
+);
+extern int 
+(*ipsec_cmdHandler_cmdDescp_set)(
+	ipsecEip93Adapter_t *currAdapterPtr, 
+	unsigned int direction,
+	unsigned int cipherAlg, 
+	unsigned int hashAlg, 
+	unsigned int digestWord,
+	unsigned int cipherMode, 
+	unsigned int enHmac, 
+	unsigned int aesKeyLen, 
+	unsigned int *cipherKey, 
+	unsigned int keyLen, 
+	unsigned int spi, 
+	unsigned int padCrtlStat
+);
+extern void 
+(*ipsec_espNextHeader_set)(
+	void *cmdHandler, 
+	unsigned char protocol	
+);
+extern unsigned char 
+(*ipsec_espNextHeader_get)(
+	void *resHandler
+);
+extern unsigned int 
+(*ipsec_pktLength_get)(
+	void *resHandler
+);
+extern unsigned int 
+(*ipsec_eip93HashFinal_get)(
+	void *resHandler
+);
+extern unsigned int 
+(*ipsec_eip93UserId_get)(
+	void *resHandler
+);
+
+extern void 
+(*ipsec_addrsDigestPreCompute_free)(
+	ipsecEip93Adapter_t *currAdapterPtr
+);
+
+extern void 
+(*ipsec_cmdHandler_free)(
+	void *cmdHandler
+);
+
+extern void 
+(*ipsec_hashDigests_get)(
+	ipsecEip93Adapter_t *currAdapterPtr
+);
+extern void 
+(*ipsec_hashDigests_set)(
+	ipsecEip93Adapter_t *currAdapterPtr,
+	unsigned int isInOrOut
+);
+	
+extern unsigned int 
+(*ipsec_espSeqNum_get)(
+	void *resHandler
+);
+
+extern void 
+ipsec_eip93_adapters_init(
+	void
+);
+extern void 
+ipsec_cryptoLock_init(
+	void
+);
+extern void 
+ipsec_BH_handler_resultGet(
+unsigned long rdx
+);
+
+#define PROCNAME    "mcrypto"
+
+typedef struct mcrypto_proc_t {
+	int ipicpu[10];
+	int copy_expand_count;
+    int nolinear_count;
+    int oom_in_put;
+    unsigned int chstatus;
+    unsigned int	dbg_pt[16];
+    unsigned int qlen[32];
+}mcrypto_proc_type;
+
+extern mcrypto_proc_type mcrypto_proc;
+extern ipsecEip93Adapter_t 	*ipsecEip93AdapterListOut[IPESC_EIP93_ADAPTERS];
+extern ipsecEip93Adapter_t 	*ipsecEip93AdapterListIn[IPESC_EIP93_ADAPTERS];
+
+#define HWCRYPTO_OK			1
+#define HWCRYPTO_NOMEM		0x80
+#define HWCRYPTO_PREPROCESS_DROP		0x40
+#endif
+
diff --git a/trunk/linux-4.4.x/include/net/netfilter/nf_conntrack_ecache.h b/trunk/linux-4.4.x/include/net/netfilter/nf_conntrack_ecache.h
index 3b47ec993..fd711053d 100644
--- a/trunk/linux-4.4.x/include/net/netfilter/nf_conntrack_ecache.h
+++ b/trunk/linux-4.4.x/include/net/netfilter/nf_conntrack_ecache.h
@@ -99,7 +99,7 @@ nf_conntrack_event_cache(enum ip_conntrack_events event, struct nf_conn *ct)
 }
 
 #ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
-static int
+static inline int
 nf_conntrack_eventmask_report(unsigned int eventmask,
 			      struct nf_conn *ct,
 			      u32 portid,
@@ -112,9 +112,9 @@ nf_conntrack_eventmask_report(unsigned int eventmask,
 	if (e == NULL)
 		return 0;
 
-	if (nf_ct_is_confirmed(ct)) {
+	if (nf_ct_is_confirmed(ct) && !nf_ct_is_dying(ct)) {
 		struct nf_ct_event item = {
-			.ct = ct,
+			.ct 	= ct,
 			.portid	= e->portid ? e->portid : portid,
 			.report = report
 		};
@@ -201,10 +201,10 @@ nf_conntrack_event_report(enum ip_conntrack_events event, struct nf_conn *ct,
 			  u32 portid, int report)
 {
 #ifndef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
- 	const struct net *net = nf_ct_net(ct);
+ 	/*const struct net *net = nf_ct_net(ct);
  
  	if (!rcu_access_pointer(net->ct.nf_conntrack_event_cb))
- 		return 0;
+ 		return 0;*/
 #endif
 
 	return nf_conntrack_eventmask_report(1 << event, ct, portid, report);
@@ -214,10 +214,10 @@ static inline int
 nf_conntrack_event(enum ip_conntrack_events event, struct nf_conn *ct)
 {
 #ifndef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
- 	const struct net *net = nf_ct_net(ct);
+ 	/*const struct net *net = nf_ct_net(ct);
  
  	if (!rcu_access_pointer(net->ct.nf_conntrack_event_cb))
- 		return 0;
+ 		return 0;*/
 #endif
 
 	return nf_conntrack_eventmask_report(1 << event, ct, 0, 0);
diff --git a/trunk/linux-4.4.x/include/net/netfilter/nf_hnat.h b/trunk/linux-4.4.x/include/net/netfilter/nf_hnat.h
index 80a77aba8..51b74e5dc 100644
--- a/trunk/linux-4.4.x/include/net/netfilter/nf_hnat.h
+++ b/trunk/linux-4.4.x/include/net/netfilter/nf_hnat.h
@@ -4,9 +4,11 @@
 #define HNAT_PATH_VLAN          BIT(1)
 #define HNAT_PATH_PPPOE         BIT(2)
 #define HNAT_PATH_DSLITE        BIT(3)
+#define HNAT_PATH_6RD           BIT(4)
 
 struct hnat_hw_path {
-        const struct net_device *dev;
+        const struct net_device *virt_dev;
+        const struct net_device *real_dev;
         u32 flags;
 
         u8 eth_src[ETH_ALEN];
diff --git a/trunk/linux-4.4.x/include/net/netfilter/nf_nat.h b/trunk/linux-4.4.x/include/net/netfilter/nf_nat.h
index 344b1ab19..8c0bf25da 100644
--- a/trunk/linux-4.4.x/include/net/netfilter/nf_nat.h
+++ b/trunk/linux-4.4.x/include/net/netfilter/nf_nat.h
@@ -13,6 +13,12 @@ enum nf_nat_manip_type {
 #define HOOK2MANIP(hooknum) ((hooknum) != NF_INET_POST_ROUTING && \
 			     (hooknum) != NF_INET_LOCAL_IN)
 
+/*#define IP_NAT_RANGE_MAP_IPS 1
+#define IP_NAT_RANGE_PROTO_SPECIFIED 2
+#define IP_NAT_RANGE_PROTO_RANDOM 4
+#define IP_NAT_RANGE_PERSISTENT 8
+#define IP_NAT_RANGE_PROTO_PSID (1 << 7)
+*/
 #include <linux/list.h>
 #include <linux/netfilter/nf_conntrack_pptp.h>
 #include <net/netfilter/nf_conntrack_extend.h>
diff --git a/trunk/linux-4.4.x/include/net/netfilter/nf_nat_l4proto.h b/trunk/linux-4.4.x/include/net/netfilter/nf_nat_l4proto.h
index 12f4cc841..fd465f39b 100644
--- a/trunk/linux-4.4.x/include/net/netfilter/nf_nat_l4proto.h
+++ b/trunk/linux-4.4.x/include/net/netfilter/nf_nat_l4proto.h
@@ -23,8 +23,7 @@ struct nf_nat_l4proto {
 	/* Is the manipable part of the tuple between min and max incl? */
 	bool (*in_range)(const struct nf_conntrack_tuple *tuple,
 			 enum nf_nat_manip_type maniptype,
-			 const union nf_conntrack_man_proto *min,
-			 const union nf_conntrack_man_proto *max);
+			 const struct nf_nat_range *range);
 
 	/* Alter the per-proto part of the tuple (depending on
 	 * maniptype), to give a unique tuple in the given range if
@@ -57,8 +56,7 @@ extern const struct nf_nat_l4proto nf_nat_l4proto_unknown;
 
 bool nf_nat_l4proto_in_range(const struct nf_conntrack_tuple *tuple,
 			     enum nf_nat_manip_type maniptype,
-			     const union nf_conntrack_man_proto *min,
-			     const union nf_conntrack_man_proto *max);
+			     const struct nf_nat_range *range);
 
 void nf_nat_l4proto_unique_tuple(const struct nf_nat_l3proto *l3proto,
 				 struct nf_conntrack_tuple *tuple,
diff --git a/trunk/linux-4.4.x/include/net/netfilter/nf_nat_rule.h b/trunk/linux-4.4.x/include/net/netfilter/nf_nat_rule.h
new file mode 100644
index 000000000..2890bdc4c
--- /dev/null
+++ b/trunk/linux-4.4.x/include/net/netfilter/nf_nat_rule.h
@@ -0,0 +1,15 @@
+#ifndef _NF_NAT_RULE_H
+#define _NF_NAT_RULE_H
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_nat.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+
+extern int nf_nat_rule_init(void) __init;
+extern void nf_nat_rule_cleanup(void);
+extern int nf_nat_rule_find(struct sk_buff *skb,
+			    unsigned int hooknum,
+			    const struct net_device *in,
+			    const struct net_device *out,
+			    struct nf_conn *ct);
+
+#endif /* _NF_NAT_RULE_H */
diff --git a/trunk/linux-4.4.x/include/net/netfilter/nf_queue.h b/trunk/linux-4.4.x/include/net/netfilter/nf_queue.h
index 0dbce5543..4393c7fe3 100644
--- a/trunk/linux-4.4.x/include/net/netfilter/nf_queue.h
+++ b/trunk/linux-4.4.x/include/net/netfilter/nf_queue.h
@@ -14,6 +14,9 @@ struct nf_queue_entry {
 	struct nf_hook_ops	*elem;
 	struct nf_hook_state	state;
 	u16			size; /* sizeof(entry) + saved route keys */
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	//u_int8_t		pf;
+#endif
 
 	/* extra space to store route keys */
 };
@@ -32,6 +35,10 @@ void nf_register_queue_handler(struct net *net, const struct nf_queue_handler *q
 void nf_unregister_queue_handler(struct net *net);
 void nf_reinject(struct nf_queue_entry *entry, unsigned int verdict);
 
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+void nf_register_queue_imq_handler(const struct nf_queue_handler *qh);
+void nf_unregister_queue_imq_handler(void);
+#endif
 void nf_queue_entry_get_refs(struct nf_queue_entry *entry);
 void nf_queue_entry_release_refs(struct nf_queue_entry *entry);
 
diff --git a/trunk/linux-4.4.x/include/net/pkt_sched.h b/trunk/linux-4.4.x/include/net/pkt_sched.h
index 401038d2f..4668849c4 100644
--- a/trunk/linux-4.4.x/include/net/pkt_sched.h
+++ b/trunk/linux-4.4.x/include/net/pkt_sched.h
@@ -104,6 +104,8 @@ int sch_direct_xmit(struct sk_buff *skb, struct Qdisc *q,
 
 void __qdisc_run(struct Qdisc *q);
 
+struct sk_buff *qdisc_dequeue_skb(struct Qdisc *q, bool *validate);
+
 static inline void qdisc_run(struct Qdisc *q)
 {
 	if (qdisc_run_begin(q))
diff --git a/trunk/linux-4.4.x/include/net/ra_nat.h b/trunk/linux-4.4.x/include/net/ra_nat.h
index 687de201b..d9399d68b 100644
--- a/trunk/linux-4.4.x/include/net/ra_nat.h
+++ b/trunk/linux-4.4.x/include/net/ra_nat.h
@@ -141,91 +141,6 @@ enum foe_cpu_reason {
 	HIT_PRE_BIND = 0x1A	/*  Pre-bind */
 };
 
-enum dst_port_num {
-	DP_RA0 = 11,
-#if defined(CONFIG_RT2860V2_AP_MBSS) || \
-defined(CONFIG_RTPCI_AP_MBSS) || defined(CONFIG_MBSS_SUPPORT)
-	DP_RA1 = 12,
-	DP_RA2 = 13,
-	DP_RA3 = 14,
-	DP_RA4 = 15,
-	DP_RA5 = 16,
-	DP_RA6 = 17,
-	DP_RA7 = 18,
-	DP_RA8 = 19,
-	DP_RA9 = 20,
-	DP_RA10 = 21,
-	DP_RA11 = 22,
-	DP_RA12 = 23,
-	DP_RA13 = 24,
-	DP_RA14 = 25,
-	DP_RA15 = 26,
-#endif				/* CONFIG_RT2860V2_AP_MBSS // */
-#if defined(CONFIG_RT2860V2_AP_WDS) || \
-defined(CONFIG_RTPCI_AP_WDS) || defined(CONFIG_WDS_SUPPORT)
-	DP_WDS0 = 27,
-	DP_WDS1 = 28,
-	DP_WDS2 = 29,
-	DP_WDS3 = 30,
-#endif				/* CONFIG_RT2860V2_AP_WDS // */
-#if defined(CONFIG_RT2860V2_AP_APCLI) || \
-defined(CONFIG_RTPCI_AP_APCLI) || defined(CONFIG_APCLI_SUPPORT)
-	DP_APCLI0 = 31,
-#endif				/* CONFIG_RT2860V2_AP_APCLI // */
-#if defined(CONFIG_RT2860V2_AP_MESH)
-	DP_MESH0 = 32,
-#endif				/* CONFIG_RT2860V2_AP_MESH // */
-	DP_RAI0 = 33,
-#if defined(CONFIG_RT3090_AP_MBSS) || defined(CONFIG_RT5392_AP_MBSS) || \
-defined(CONFIG_RT3572_AP_MBSS) || defined(CONFIG_RT5572_AP_MBSS) || \
-defined(CONFIG_RT5592_AP_MBSS) || defined(CONFIG_RT3593_AP_MBSS) || \
-defined(CONFIG_MT7610_AP_MBSS) || defined(CONFIG_RTPCI_AP_MBSS)  || \
-defined(CONFIG_MBSS_SUPPORT)
-	DP_RAI1 = 34,
-	DP_RAI2 = 35,
-	DP_RAI3 = 36,
-	DP_RAI4 = 37,
-	DP_RAI5 = 38,
-	DP_RAI6 = 39,
-	DP_RAI7 = 40,
-	DP_RAI8 = 41,
-	DP_RAI9 = 42,
-	DP_RAI10 = 43,
-	DP_RAI11 = 44,
-	DP_RAI12 = 45,
-	DP_RAI13 = 46,
-	DP_RAI14 = 47,
-	DP_RAI15 = 48,
-#endif				/* CONFIG_RTDEV_AP_MBSS // */
-#if defined(CONFIG_RT3090_AP_WDS) || defined(CONFIG_RT5392_AP_WDS) || \
-defined(CONFIG_RT3572_AP_WDS) || defined(CONFIG_RT5572_AP_WDS) || \
-defined(CONFIG_RT5592_AP_WDS) || defined(CONFIG_RT3593_AP_WDS) || \
-defined(CONFIG_MT7610_AP_WDS) || defined(CONFIG_WDS_SUPPORT)
-	DP_WDSI0 = 49,
-	DP_WDSI1 = 50,
-	DP_WDSI2 = 51,
-	DP_WDSI3 = 52,
-#endif				/* CONFIG_RTDEV_AP_WDS // */
-#if defined(CONFIG_RT3090_AP_APCLI) || defined(CONFIG_RT5392_AP_APCLI) || \
-defined(CONFIG_RT3572_AP_APCLI) || defined(CONFIG_RT5572_AP_APCLI) || \
-defined(CONFIG_RT5592_AP_APCLI) || defined(CONFIG_RT3593_AP_APCLI) || \
-defined(CONFIG_MT7610_AP_APCLI) || defined(CONFIG_APCLI_SUPPORT)
-	DP_APCLII0 = 53,
-#endif				/* CONFIG_RTDEV_AP_APCLI // */
-#if defined(CONFIG_RT3090_AP_MESH) || defined(CONFIG_RT5392_AP_MESH) || \
-defined(CONFIG_RT3572_AP_MESH) || defined(CONFIG_RT5572_AP_MESH) || \
-defined(CONFIG_RT5592_AP_MESH) || defined(CONFIG_RT3593_AP_MESH) || \
-defined(CONFIG_MT7610_AP_MESH)
-	DP_MESHI0 = 54,
-#endif				/* CONFIG_RTDEV_AP_MESH // */
-	MAX_WIFI_IF_NUM = 59,
-	DP_GMAC = 60,
-	DP_GMAC2 = 61,
-	DP_PCI = 62,
-	DP_USB = 63,
-	MAX_IF_NUM
-};
-
 #define MAX_IF_NUM 64
 struct pdma_rx_desc_info4 {
 	u16 MAGIC_TAG_PROTECT;
diff --git a/trunk/linux-4.4.x/include/net/sch_generic.h b/trunk/linux-4.4.x/include/net/sch_generic.h
index d95ea025f..7fa018417 100644
--- a/trunk/linux-4.4.x/include/net/sch_generic.h
+++ b/trunk/linux-4.4.x/include/net/sch_generic.h
@@ -517,6 +517,12 @@ static inline int qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch)
 	return sch->enqueue(skb, sch);
 }
 
+static inline int qdisc_enqueue_root(struct sk_buff *skb, struct Qdisc *sch)
+{
+    qdisc_skb_cb(skb)->pkt_len = skb->len;
+    return qdisc_enqueue(skb, sch) & NET_XMIT_MASK;
+}
+
 static inline bool qdisc_is_percpu_stats(const struct Qdisc *q)
 {
 	return q->flags & TCQ_F_CPUSTATS;
diff --git a/trunk/linux-4.4.x/include/nmbm/nmbm-os.h b/trunk/linux-4.4.x/include/nmbm/nmbm-os.h
new file mode 100644
index 000000000..74d042ca7
--- /dev/null
+++ b/trunk/linux-4.4.x/include/nmbm/nmbm-os.h
@@ -0,0 +1,68 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ *
+ * OS-dependent definitions for NAND Mapped-block Management (NMBM)
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#ifndef _NMBM_OS_H_
+#define _NMBM_OS_H_
+
+#include <linux/kernel.h>
+#include <linux/limits.h>
+#include <linux/types.h>
+#include <linux/crc32.h>
+#include <linux/log2.h>
+#include <asm/div64.h>
+
+static inline uint32_t nmbm_crc32(uint32_t crcval, const void *buf, size_t size)
+{
+	uint chksz;
+	const unsigned char *p = buf;
+
+	while (size) {
+		if (size > UINT_MAX)
+			chksz = UINT_MAX;
+		else
+			chksz = (uint)size;
+
+		crcval = crc32_le(crcval, p, chksz);
+		size -= chksz;
+		p += chksz;
+	}
+
+	return crcval;
+}
+
+static inline uint32_t nmbm_lldiv(uint64_t dividend, uint32_t divisor)
+{
+#if BITS_PER_LONG == 64
+	return dividend / divisor;
+#else
+	do_div(dividend, divisor);
+	//__div64_32(&dividend, divisor);
+	return dividend;
+#endif
+}
+
+#define WATCHDOG_RESET()
+
+#ifdef CONFIG_NMBM_LOG_LEVEL_DEBUG
+#define NMBM_DEFAULT_LOG_LEVEL		0
+#elif defined(NMBM_LOG_LEVEL_INFO)
+#define NMBM_DEFAULT_LOG_LEVEL		1
+#elif defined(NMBM_LOG_LEVEL_WARN)
+#define NMBM_DEFAULT_LOG_LEVEL		2
+#elif defined(NMBM_LOG_LEVEL_ERR)
+#define NMBM_DEFAULT_LOG_LEVEL		3
+#elif defined(NMBM_LOG_LEVEL_EMERG)
+#define NMBM_DEFAULT_LOG_LEVEL		4
+#elif defined(NMBM_LOG_LEVEL_NONE)
+#define NMBM_DEFAULT_LOG_LEVEL		5
+#else
+#define NMBM_DEFAULT_LOG_LEVEL		1
+#endif
+
+#endif /* _NMBM_OS_H_ */
diff --git a/trunk/linux-4.4.x/include/nmbm/nmbm.h b/trunk/linux-4.4.x/include/nmbm/nmbm.h
new file mode 100644
index 000000000..8e4c7ffe3
--- /dev/null
+++ b/trunk/linux-4.4.x/include/nmbm/nmbm.h
@@ -0,0 +1,96 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2020 MediaTek Inc. All Rights Reserved.
+ * 
+ * Definitions for NAND Mapped-block Management (NMBM)
+ *
+ * Author: Weijie Gao <weijie.gao@mediatek.com>
+ */
+
+#ifndef _NMBM_H_
+#define _NMBM_H_
+
+#include <nmbm/nmbm-os.h>
+
+enum nmbm_log_category {
+	NMBM_LOG_DEBUG,
+	NMBM_LOG_INFO,
+	NMBM_LOG_WARN,
+	NMBM_LOG_ERR,
+	NMBM_LOG_EMERG,
+
+	__NMBM_LOG_MAX
+};
+
+enum nmbm_oob_mode {
+	NMBM_MODE_PLACE_OOB,
+	NMBM_MODE_AUTO_OOB,
+	NMBM_MODE_RAW,
+
+	__NMBM_MODE_MAX
+};
+
+struct nmbm_lower_device {
+	uint32_t max_ratio;
+	uint32_t max_reserved_blocks;
+	int flags;
+
+	uint64_t size;
+	uint32_t erasesize;
+	uint32_t writesize;
+	uint32_t oobsize;
+	uint32_t oobavail;
+
+	void *arg;
+	int (*reset_chip)(void *arg);
+
+	/*
+	 * read_page:
+	 *    return 0 if succeeds
+	 *    return positive number for ecc error
+	 *    return negative number for other errors
+	 */
+	int (*read_page)(void *arg, uint64_t addr, void *buf, void *oob, enum nmbm_oob_mode mode);
+	int (*write_page)(void *arg, uint64_t addr, const void *buf, const void *oob, enum nmbm_oob_mode mode);
+	int (*erase_block)(void *arg, uint64_t addr);
+
+	int (*is_bad_block)(void *arg, uint64_t addr);
+	int (*mark_bad_block)(void *arg, uint64_t addr);
+
+	/* OS-dependent logging function */
+	void (*logprint)(void *arg, enum nmbm_log_category level, const char *fmt, va_list ap);
+};
+
+struct nmbm_instance;
+
+/* Create NMBM if management area not found, or not complete */
+#define NMBM_F_CREATE			0x01
+
+size_t nmbm_calc_structure_size(struct nmbm_lower_device *nld);
+int nmbm_attach(struct nmbm_lower_device *nld, struct nmbm_instance *ni);
+int nmbm_detach(struct nmbm_instance *ni);
+
+enum nmbm_log_category nmbm_set_log_level(struct nmbm_instance *ni,
+					  enum nmbm_log_category level);
+
+int nmbm_erase_block_range(struct nmbm_instance *ni, uint64_t addr,
+			   uint64_t size, uint64_t *failed_addr);
+int nmbm_read_single_page(struct nmbm_instance *ni, uint64_t addr, void *data,
+			  void *oob, enum nmbm_oob_mode mode);
+int nmbm_read_range(struct nmbm_instance *ni, uint64_t addr, size_t size,
+		    void *data, enum nmbm_oob_mode mode, size_t *retlen);
+int nmbm_write_single_page(struct nmbm_instance *ni, uint64_t addr,
+			   const void *data, const void *oob,
+			   enum nmbm_oob_mode mode);
+int nmbm_write_range(struct nmbm_instance *ni, uint64_t addr, size_t size,
+		     const void *data, enum nmbm_oob_mode mode,
+		     size_t *retlen);
+
+int nmbm_check_bad_block(struct nmbm_instance *ni, uint64_t addr);
+int nmbm_mark_bad_block(struct nmbm_instance *ni, uint64_t addr);
+
+uint64_t nmbm_get_avail_size(struct nmbm_instance *ni);
+
+int nmbm_get_lower_device(struct nmbm_instance *ni, struct nmbm_lower_device *nld);
+
+#endif /* _NMBM_H_ */
diff --git a/trunk/linux-4.4.x/include/uapi/linux/ip6_tunnel.h b/trunk/linux-4.4.x/include/uapi/linux/ip6_tunnel.h
index 48af63c9a..439c23e2c 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/ip6_tunnel.h
+++ b/trunk/linux-4.4.x/include/uapi/linux/ip6_tunnel.h
@@ -18,6 +18,8 @@
 #define IP6_TNL_F_RCV_DSCP_COPY 0x10
 /* copy fwmark from inner packet */
 #define IP6_TNL_F_USE_ORIG_FWMARK 0x20
+/* Use FMR draft-03 mapping */
+#define IP6_TNL_F_USE_FMR_DRAFT 0x40
 
 struct ip6_tnl_parm {
 	char name[IFNAMSIZ];	/* name of tunnel device */
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter.h
index d93f949d1..5df46bd84 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netfilter.h
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter.h
@@ -14,7 +14,9 @@
 #define NF_QUEUE 3
 #define NF_REPEAT 4
 #define NF_STOP 5
-#define NF_MAX_VERDICT NF_STOP
+//#define NF_MAX_VERDICT NF_STOP
+#define NF_IMQ_QUEUE 6
+#define NF_MAX_VERDICT NF_IMQ_QUEUE
 
 /* we overload the higher bits for encoding auxiliary data such as the queue
  * number or errno values. Not nice, but better than additional function
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter/Kbuild b/trunk/linux-4.4.x/include/uapi/linux/netfilter/Kbuild
index a46f9ce1e..1640b968c 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netfilter/Kbuild
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter/Kbuild
@@ -57,6 +57,7 @@ header-y += xt_hashlimit.h
 header-y += xt_helper.h
 header-y += xt_ipcomp.h
 header-y += xt_iprange.h
+header-y += xt_layer7.h
 header-y += xt_ipvs.h
 header-y += xt_l2tp.h
 header-y += xt_length.h
@@ -85,4 +86,6 @@ header-y += xt_tcpmss.h
 header-y += xt_tcpudp.h
 header-y += xt_time.h
 header-y += xt_u32.h
-header-y += xt_webstr.h
+header-y += xt_ethport.h
+#header-y += xt_geoip.h
+#header-y += xt_webstr.h
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_conntrack_common.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_conntrack_common.h
index c439e0633..8d2a546d7 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_conntrack_common.h
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_conntrack_common.h
@@ -95,6 +95,9 @@ enum ip_conntrack_status {
 	IPS_OFFLOAD_BIT = 14,
 	IPS_OFFLOAD = (1 << IPS_OFFLOAD_BIT),
 
+        /* Trigger */
+        IPS_TRIGGER_BIT = 15,
+        IPS_TRIGGER = (1 << IPS_TRIGGER_BIT),
 };
 
 /* Connection tracking event types */
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
index 2f6bbc5b8..b2fd3bbf3 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
@@ -32,6 +32,13 @@ union nf_conntrack_man_proto {
 	struct {
 		__be16 key;	/* GRE key is 32bit, PPtP only uses 16bit */
 	} gre;
+	union {
+		struct {
+			__u8 offset;
+			__u8 length;
+		};
+		__be16 id;
+	} psid;
 };
 
 #define CTINFO2DIR(ctinfo) ((ctinfo) >= IP_CT_IS_REPLY ? IP_CT_DIR_REPLY : IP_CT_DIR_ORIGINAL)
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_nat.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_nat.h
index 0880781ad..10bbc308e 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_nat.h
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter/nf_nat.h
@@ -9,6 +9,7 @@
 #define NF_NAT_RANGE_PROTO_RANDOM		(1 << 2)
 #define NF_NAT_RANGE_PERSISTENT			(1 << 3)
 #define NF_NAT_RANGE_PROTO_RANDOM_FULLY		(1 << 4)
+#define NF_NAT_RANGE_PROTO_PSID			(1 << 7)
 
 #define NF_NAT_RANGE_PROTO_RANDOM_ALL		\
 	(NF_NAT_RANGE_PROTO_RANDOM | NF_NAT_RANGE_PROTO_RANDOM_FULLY)
@@ -16,7 +17,7 @@
 #define NF_NAT_RANGE_MASK					\
 	(NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED |	\
 	 NF_NAT_RANGE_PROTO_RANDOM | NF_NAT_RANGE_PERSISTENT |	\
-	 NF_NAT_RANGE_PROTO_RANDOM_FULLY)
+	 NF_NAT_RANGE_PROTO_RANDOM_FULLY | define NF_NAT_RANGE_PROTO_PSID)
 
 struct nf_nat_ipv4_range {
 	unsigned int			flags;
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_connmark.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_connmark.h
index efc17a830..a9e11be29 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_connmark.h
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_connmark.h
@@ -15,7 +15,8 @@
 enum {
 	XT_CONNMARK_SET = 0,
 	XT_CONNMARK_SAVE,
-	XT_CONNMARK_RESTORE
+	XT_CONNMARK_RESTORE,
+	XT_CONNMARK_SET_RETURN
 };
 
 struct xt_connmark_tginfo1 {
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_ethport.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_ethport.h
new file mode 100644
index 000000000..633b64b5c
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_ethport.h
@@ -0,0 +1,20 @@
+/* x_tables module for matching the IPv4/IPv6 DSCP field
+ *
+ * (C) 2002 Harald Welte <laforge@gnumonks.org>
+ * This software is distributed under GNU GPL v2, 1991
+ *
+ * xt_ethport.h, 2009/06/09
+*/
+#ifndef _XT_ETHPORT_H
+#define _XT_ETHPORT_H
+
+#define XT_SKB_CB_OFFSET	0x24	/* store port number info in skb->cb[0x24] */
+#define XT_ETHPORT_MAX		0x8		/* port 0-5 && cpu port(port6)*/
+
+/* match info */
+struct xt_ethport_info {
+	u_int8_t portnum;
+	u_int8_t invert;
+};
+
+#endif /* _XT_ETHPORT_H */
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_geoip.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_geoip.h
new file mode 100644
index 000000000..52adc8381
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_geoip.h
@@ -0,0 +1,53 @@
+/* ipt_geoip.h header file for libipt_geoip.c and ipt_geoip.c
+ * 
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * Copyright (c) 2004, 2005, 2006, 2007, 2008
+ *
+ * Samuel Jean
+ * Nicolas Bouliane
+ */
+#ifndef _XT_GEOIP_H
+#define _XT_GEOIP_H
+
+#define XT_GEOIP_SRC         0x01     /* Perform check on Source IP */
+#define XT_GEOIP_DST         0x02     /* Perform check on Destination IP */
+#define XT_GEOIP_INV         0x04     /* Negate the condition */
+
+#define XT_GEOIP_MAX         15       /* Maximum of countries */
+
+struct geoip_subnet {
+   u_int32_t begin;
+   u_int32_t end;
+};
+
+struct geoip_info {
+   struct geoip_subnet *subnets;
+   u_int32_t count;
+   u_int32_t ref;
+   u_int16_t cc;
+   struct geoip_info *next;
+   struct geoip_info *prev;
+};
+
+struct xt_geoip_match_info {
+   u_int8_t flags;
+   u_int8_t count;
+   u_int16_t cc[XT_GEOIP_MAX];
+
+   /* Used internally by the kernel */
+   struct geoip_info *mem[XT_GEOIP_MAX];
+   u_int8_t *refcount;
+
+   /* not implemented yet:
+   void *fini;
+   */
+};
+
+#define COUNTRY(cc) (cc >> 8), (cc & 0x00FF)
+
+#endif
+
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_layer7.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_layer7.h
new file mode 100644
index 000000000..162ab4603
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter/xt_layer7.h
@@ -0,0 +1,14 @@
+#ifndef _XT_LAYER7_H                
+#define _XT_LAYER7_H                
+                                    
+#define MAX_PATTERN_LEN 8192        
+#define MAX_PROTOCOL_LEN 256        
+                                    
+struct xt_layer7_info {             
+    char protocol[MAX_PROTOCOL_LEN];
+    char invert:1;                  
+	    char pattern[MAX_PATTERN_LEN];
+	    char pkt;                     
+	};                                
+	                                  
+#endif /* _XT_LAYER7_H */         
\ No newline at end of file
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/Kbuild b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/Kbuild
index ecb291df3..7815e7e5d 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/Kbuild
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/Kbuild
@@ -8,3 +8,10 @@ header-y += ipt_TTL.h
 header-y += ipt_ah.h
 header-y += ipt_ecn.h
 header-y += ipt_ttl.h
+#header-y += ipt_ROUTE.h
+#header-y += ipt_TOS.h
+#header-y += ipt_TRIGGER.h
+#header-y += ipt_geoip.h
+#header-y += ipt_ipp2p.h
+#header-y += ipt_tos.h
+#header-y += ipt_web.h
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_ROUTE.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_ROUTE.h
new file mode 100644
index 000000000..41b1a9c86
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_ROUTE.h
@@ -0,0 +1,23 @@
+/* Header file for iptables ipt_ROUTE target
+ *
+ * (C) 2002 by Cdric de Launois <delaunois@info.ucl.ac.be>
+ *
+ * This software is distributed under GNU GPL v2, 1991
+ */
+#ifndef _IPT_ROUTE_H_target
+#define _IPT_ROUTE_H_target
+
+#define IPT_ROUTE_IFNAMSIZ 16
+
+struct ipt_route_target_info {
+	char      oif[IPT_ROUTE_IFNAMSIZ];      /* Output Interface Name */
+	char      iif[IPT_ROUTE_IFNAMSIZ];      /* Input Interface Name  */
+	u_int32_t gw;                           /* IP address of gateway */
+	u_int8_t  flags;
+};
+
+/* Values for "flags" field */
+#define IPT_ROUTE_CONTINUE        0x01
+#define IPT_ROUTE_TEE             0x02
+
+#endif /*_IPT_ROUTE_H_target*/
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_TOS.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_TOS.h
new file mode 100644
index 000000000..6bf9e1fdf
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_TOS.h
@@ -0,0 +1,12 @@
+#ifndef _IPT_TOS_H_target
+#define _IPT_TOS_H_target
+
+#ifndef IPTOS_NORMALSVC
+#define IPTOS_NORMALSVC 0
+#endif
+
+struct ipt_tos_target_info {
+	u_int8_t tos;
+};
+
+#endif /*_IPT_TOS_H_target*/
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_TRIGGER.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_TRIGGER.h
new file mode 100644
index 000000000..aa1bb8bd0
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_TRIGGER.h
@@ -0,0 +1,25 @@
+#ifndef _IPT_TRIGGER_H_target
+#define _IPT_TRIGGER_H_target
+
+#define TRIGGER_TIMEOUT 600	/* 600 secs */
+
+enum ipt_trigger_type
+{
+	IPT_TRIGGER_DNAT = 1,
+	IPT_TRIGGER_IN = 2,
+	IPT_TRIGGER_OUT = 3,
+	IPT_TRIGGER_REFRESH = 4
+};
+
+struct ipt_trigger_ports {
+	u_int16_t mport[2];	/* Related destination port range */
+	u_int16_t rport[2];	/* Port range to map related destination port range to */
+};
+
+struct ipt_trigger_info {
+	enum ipt_trigger_type type;
+	u_int16_t proto;	/* Related protocol */
+	struct ipt_trigger_ports ports;
+};
+
+#endif /*_IPT_TRIGGER_H_target*/
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_geoip.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_geoip.h
new file mode 100644
index 000000000..1feeedffa
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_geoip.h
@@ -0,0 +1,24 @@
+/* ipt_geoip.h header file for libipt_geoip.c and ipt_geoip.c
+ * 
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * Copyright (c) 2004 Cookinglinux
+ */
+#ifndef _IPT_GEOIP_H
+#define _IPT_GEOIP_H
+
+#include <linux/netfilter/xt_geoip.h>
+
+#define IPT_GEOIP_SRC	XT_GEOIP_SRC
+#define IPT_GEOIP_DST	XT_GEOIP_DST
+#define IPT_GEOIP_INV	XT_GEOIP_INV
+#define IPT_GEOIP_MAX	XT_GEOIP_MAX
+
+#define ipt_geoip_info	xt_geoip_match_info
+
+#endif
+
+/* End of ipt_geoip.h */
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_ipp2p.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_ipp2p.h
new file mode 100644
index 000000000..7033a495d
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_ipp2p.h
@@ -0,0 +1,31 @@
+#ifndef __IPT_IPP2P_H
+#define __IPT_IPP2P_H
+#define IPP2P_VERSION "0.8.2-pomng"
+
+struct ipt_p2p_info {
+    int cmd;
+    int debug;
+};
+
+#endif //__IPT_IPP2P_H
+
+#define SHORT_HAND_IPP2P	1 /* --ipp2p switch*/
+//#define SHORT_HAND_DATA		4 /* --ipp2p-data switch*/
+#define SHORT_HAND_NONE		5 /* no short hand*/
+
+#define IPP2P_EDK		(1 << 1)
+#define IPP2P_DATA_KAZAA	(1 << 2)
+#define IPP2P_DATA_EDK		(1 << 3)
+#define IPP2P_DATA_DC		(1 << 4)
+#define IPP2P_DC		(1 << 5)
+#define IPP2P_DATA_GNU		(1 << 6)
+#define IPP2P_GNU		(1 << 7)
+#define IPP2P_KAZAA		(1 << 8)
+#define IPP2P_BIT		(1 << 9)
+#define IPP2P_APPLE		(1 << 10)
+#define IPP2P_SOUL		(1 << 11)
+#define IPP2P_WINMX		(1 << 12)
+#define IPP2P_ARES		(1 << 13)
+#define IPP2P_MUTE		(1 << 14)
+#define IPP2P_WASTE		(1 << 15)
+#define IPP2P_XDCC		(1 << 16)
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_tos.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_tos.h
new file mode 100644
index 000000000..a21f5df23
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_tos.h
@@ -0,0 +1,13 @@
+#ifndef _IPT_TOS_H
+#define _IPT_TOS_H
+
+struct ipt_tos_info {
+    u_int8_t tos;
+    u_int8_t invert;
+};
+
+#ifndef IPTOS_NORMALSVC
+#define IPTOS_NORMALSVC 0
+#endif
+
+#endif /*_IPT_TOS_H*/
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_web.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_web.h
new file mode 100644
index 000000000..176208e21
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv4/ipt_web.h
@@ -0,0 +1,30 @@
+/*
+
+	web (experimental)
+	HTTP client match
+	Copyright (C) 2006 Jonathan Zarate
+
+	Licensed under GNU GPL v2 or later.
+
+*/
+#ifndef _IPT_WEB_H
+#define _IPT_WEB_H
+
+#define IPT_WEB_MAXTEXT	512
+
+typedef enum {
+	IPT_WEB_HTTP,
+	IPT_WEB_RURI,
+	IPT_WEB_PATH,
+	IPT_WEB_QUERY,
+	IPT_WEB_HOST,
+	IPT_WEB_HORE
+} ipt_web_mode_t;
+
+struct ipt_web_info {
+	ipt_web_mode_t mode;
+	int invert;
+	char text[IPT_WEB_MAXTEXT];
+};
+
+#endif
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv6/Kbuild b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv6/Kbuild
index 75a668ca2..e4c45ac41 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv6/Kbuild
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv6/Kbuild
@@ -11,3 +11,4 @@ header-y += ip6t_ipv6header.h
 header-y += ip6t_mh.h
 header-y += ip6t_opts.h
 header-y += ip6t_rt.h
+#header-y += ip6t_ROUTE.h
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv6/ip6t_ROUTE.h b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv6/ip6t_ROUTE.h
new file mode 100644
index 000000000..c5ec871b5
--- /dev/null
+++ b/trunk/linux-4.4.x/include/uapi/linux/netfilter_ipv6/ip6t_ROUTE.h
@@ -0,0 +1,23 @@
+/* Header file for iptables ip6t_ROUTE target
+ *
+ * (C) 2003 by Cdric de Launois <delaunois@info.ucl.ac.be>
+ *
+ * This software is distributed under GNU GPL v2, 1991
+ */
+#ifndef _IPT_ROUTE_H_target
+#define _IPT_ROUTE_H_target
+
+#define IP6T_ROUTE_IFNAMSIZ 16
+
+struct ip6t_route_target_info {
+	char      oif[IP6T_ROUTE_IFNAMSIZ];     /* Output Interface Name */
+	char      iif[IP6T_ROUTE_IFNAMSIZ];     /* Input Interface Name  */
+	u_int32_t gw[4];                        /* IPv6 address of gateway */
+	u_int8_t  flags;
+};
+
+/* Values for "flags" field */
+#define IP6T_ROUTE_CONTINUE        0x01
+#define IP6T_ROUTE_TEE             0x02
+
+#endif /*_IP6T_ROUTE_H_target*/
diff --git a/trunk/linux-4.4.x/include/uapi/linux/netlink.h b/trunk/linux-4.4.x/include/uapi/linux/netlink.h
index 0dba4e4ed..f7aa5f091 100644
--- a/trunk/linux-4.4.x/include/uapi/linux/netlink.h
+++ b/trunk/linux-4.4.x/include/uapi/linux/netlink.h
@@ -27,6 +27,7 @@
 #define NETLINK_ECRYPTFS	19
 #define NETLINK_RDMA		20
 #define NETLINK_CRYPTO		21	/* Crypto layer */
+#define NETLINK_BROOP		22	/* Broop state */
 
 #define NETLINK_INET_DIAG	NETLINK_SOCK_DIAG
 
diff --git a/trunk/linux-4.4.x/include/uapi/linux/wapp/wapp_cmm_type.h b/trunk/linux-4.4.x/include/uapi/linux/wapp/wapp_cmm_type.h
index c5d405d6d..d27261b5a 100755
--- a/trunk/linux-4.4.x/include/uapi/linux/wapp/wapp_cmm_type.h
+++ b/trunk/linux-4.4.x/include/uapi/linux/wapp/wapp_cmm_type.h
@@ -58,6 +58,7 @@
 #define MAX_LEN_OF_SSID 32
 #define MAX_NUM_OF_CHANNELS		59 // 14 channels @2.4G +  12@UNII(lower/middle) + 16@HiperLAN2 + 11@UNII(upper) + 0@Japan + 1 as NULL termination
 #define ASSOC_REQ_LEN 154
+#define ASSOC_REQ_LEN_MAX 512
 #define PREQ_IE_LEN 128
 #define BCN_RPT_LEN 200
 #define IWSC_MAX_SUB_MASK_LIST_COUNT	3
@@ -71,6 +72,7 @@
 #define MAX_PROFILE_CNT 4
 #define PER_EVENT_LIST_MAX_NUM 		5
 #define	DAEMON_NEIGHBOR_REPORT_MAX_NUM 128
+#define VERSION_WAPP_CMM "v2.0.2"
 typedef enum {
 	WAPP_STA_INVALID,
 	WAPP_STA_DISCONNECTED,
@@ -180,6 +182,10 @@ typedef enum {
 #endif
 #endif
 	WAPP_CAC_PERIOD_EVENT,
+#ifdef WIFI_MD_COEX_SUPPORT
+	WAPP_UNSAFE_CHANNEL_EVENT,
+	WAPP_BAND_STATUS_CHANGE_EVENT,
+#endif
 } WAPP_EVENT_ID;
 
 typedef enum {
@@ -360,7 +366,6 @@ typedef struct GNU_PACKED _wapp_client_info {
 	u8 bssid[MAC_ADDR_LEN];
 	u8 sta_status; /* WAPP_STA_STATE */
 	u16 assoc_time;
-	u8 assoc_req[ASSOC_REQ_LEN];
 	u16 downlink;
 	u16 uplink;
 	signed char uplink_rssi;
@@ -373,7 +378,7 @@ typedef struct GNU_PACKED _wapp_client_info {
 	u32 rx_packets_errors;
 	u32 retransmission_count;
 	u16 link_availability;
-	u8 assoc_req_len;
+	u16 assoc_req_len;
 	u8 bLocalSteerDisallow;
 	u8 bBTMSteerDisallow;
 	u8 status;
@@ -387,7 +392,6 @@ typedef struct GNU_PACKED _wapp_client_info {
 #ifdef MAP_R2
 	wdev_extended_sta_metrics ext_metric_info;
 	u16 disassoc_reason;
-	u16 assoc_req_len_R2; 
 	u8 IsReassoc; 
 #endif
 	u8  is_APCLI;
@@ -396,6 +400,7 @@ typedef struct GNU_PACKED _wapp_client_info {
 struct GNU_PACKED chnList {
 	u8 channel;
 	u8 pref;
+	u16 cac_timer;
 };
 
 typedef struct GNU_PACKED _wdev_chn_info {
@@ -503,6 +508,7 @@ typedef struct GNU_PACKED _wapp_bcn_rpt_info {
 typedef struct GNU_PACKED wapp_bhsta_info {
 	u8 mac_addr[MAC_ADDR_LEN];
 	u8 connected_bssid[MAC_ADDR_LEN];
+	u8 peer_map_enable;
 } wapp_bhsta_info;
 
 typedef struct GNU_PACKED _wdev_steer_policy {
@@ -540,6 +546,7 @@ typedef struct GNU_PACKED _wapp_bss_state_info {
 typedef struct GNU_PACKED _wapp_ch_change_info {
 	u32 interface_index;
 	u8 new_ch;/*New channel IEEE number*/
+	u8 op_class;
 } wapp_ch_change_info;
 
 typedef struct GNU_PACKED _wapp_txpower_change_info {
@@ -551,6 +558,7 @@ typedef struct GNU_PACKED _wapp_apcli_association_info {
 	u32 interface_index;
 	WAPP_APCLI_ASSOC_STATE apcli_assoc_state;
 	signed char rssi;
+	signed char PeerMAPEnable;
 } wapp_apcli_association_info;
 
 typedef struct GNU_PACKED _wapp_bssload_crossing_info {
@@ -654,6 +662,17 @@ struct GNU_PACKED radar_notif_s
 	u32 status;
 };
 
+#ifdef WIFI_MD_COEX_SUPPORT
+struct GNU_PACKED unsafe_channel_notif_s
+{
+	u32 ch_bitmap[4];
+};
+
+struct GNU_PACKED band_status_change {
+	u8 status;	/*0-radio temporarily cannot be used, 1-radio can be used*/
+};
+#endif
+
 typedef struct GNU_PACKED _NDIS_802_11_SSID {
 	u32 SsidLength;	/* length of SSID field below, in bytes; */
 	/* this can be zero. */
@@ -804,6 +823,10 @@ typedef union GNU_PACKED _wapp_event_data {
 #endif
 #endif /*DPP_SUPPORT*/
 	unsigned char cac_enable;
+#ifdef WIFI_MD_COEX_SUPPORT
+	struct unsafe_channel_notif_s unsafe_ch_notif;
+	struct band_status_change band_status;
+#endif
 } wapp_event_data;
 typedef struct GNU_PACKED _wapp_req_data {
 	u32	ifindex;
diff --git a/trunk/linux-4.4.x/kernel/irq/irqdesc.c b/trunk/linux-4.4.x/kernel/irq/irqdesc.c
index 239e2ae2c..e2d37481f 100644
--- a/trunk/linux-4.4.x/kernel/irq/irqdesc.c
+++ b/trunk/linux-4.4.x/kernel/irq/irqdesc.c
@@ -605,6 +605,7 @@ unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 	return desc && desc->kstat_irqs ?
 			*per_cpu_ptr(desc->kstat_irqs, cpu) : 0;
 }
+EXPORT_SYMBOL(kstat_irqs_cpu);
 
 /**
  * kstat_irqs - Get the statistics for an interrupt
diff --git a/trunk/linux-4.4.x/kernel/pid.c b/trunk/linux-4.4.x/kernel/pid.c
index 5fe7cdb6d..a19e53400 100644
--- a/trunk/linux-4.4.x/kernel/pid.c
+++ b/trunk/linux-4.4.x/kernel/pid.c
@@ -462,6 +462,7 @@ struct task_struct *find_task_by_vpid(pid_t vnr)
 {
 	return find_task_by_pid_ns(vnr, task_active_pid_ns(current));
 }
+EXPORT_SYMBOL(find_task_by_vpid);	/* ASUS EXT */
 
 struct pid *get_task_pid(struct task_struct *task, enum pid_type type)
 {
diff --git a/trunk/linux-4.4.x/mm/oom_kill.c b/trunk/linux-4.4.x/mm/oom_kill.c
index 7e5d3467d..4dae3a0ae 100644
--- a/trunk/linux-4.4.x/mm/oom_kill.c
+++ b/trunk/linux-4.4.x/mm/oom_kill.c
@@ -355,7 +355,7 @@ static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)
 	struct task_struct *p;
 	struct task_struct *task;
 
-	pr_info("[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds swapents oom_score_adj name\n");
+	pr_warning("[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds swapents oom_score_adj name\n");
 	rcu_read_lock();
 	for_each_process(p) {
 		if (oom_unkillable_task(p, memcg, nodemask))
@@ -371,7 +371,7 @@ static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)
 			continue;
 		}
 
-		pr_info("[%5d] %5d %5d %8lu %8lu %7ld %7ld %8lu         %5hd %s\n",
+		pr_warning("[%5d] %5d %5d %8lu %8lu %7ld %7ld %8lu         %5hd %s\n",
 			task->pid, from_kuid(&init_user_ns, task_uid(task)),
 			task->tgid, task->mm->total_vm, get_mm_rss(task->mm),
 			atomic_long_read(&task->mm->nr_ptes),
@@ -668,6 +668,16 @@ int unregister_oom_notifier(struct notifier_block *nb)
 }
 EXPORT_SYMBOL_GPL(unregister_oom_notifier);
 
+/* NOTE(Nelson): Add OOM debug logs for ETH/WIFI debug */
+#ifdef	CONFIG_ETH_WIFI_OOM_DEBUG
+#ifdef	CONFIG_RAETH
+extern void raether_dump_pdma_info(void);
+#endif	/* CONFIG_RAETH */
+#ifdef	CONFIG_CHIP_MT7615E
+extern void wifi_dump_info(void);
+#endif	/* CONFIG_CHIP_MT7615E */
+#endif	/* CONFIG_ETH_WIFI_OOM_DEBUG */
+
 /**
  * out_of_memory - kill the "best" process when we run out of memory
  * @oc: pointer to struct oom_control
@@ -688,6 +698,16 @@ bool out_of_memory(struct oom_control *oc)
 	if (oom_killer_disabled)
 		return false;
 
+	/* NOTE(Nelson): Add OOM debug logs for ETH/WIFI debug */
+#ifdef	CONFIG_ETH_WIFI_OOM_DEBUG
+#ifdef	CONFIG_RAETH
+	raether_dump_pdma_info();
+#endif	/* CONFIG_RAETH */
+#ifdef	CONFIG_CHIP_MT7615E
+	wifi_dump_info();
+#endif	/* CONFIG_CHIP_MT7615E */
+#endif	/* CONFIG_ETH_WIFI_OOM_DEBUG */
+
 	blocking_notifier_call_chain(&oom_notify_list, 0, &freed);
 	if (freed > 0)
 		/* Got some memory back in the last second. */
diff --git a/trunk/linux-4.4.x/mm/util.c b/trunk/linux-4.4.x/mm/util.c
index 4d59b4ffe..20ab06e31 100644
--- a/trunk/linux-4.4.x/mm/util.c
+++ b/trunk/linux-4.4.x/mm/util.c
@@ -315,6 +315,51 @@ unsigned long vm_mmap(struct file *file, unsigned long addr,
 }
 EXPORT_SYMBOL(vm_mmap);
 
+/**
+ * kvmalloc_node - attempt to allocate physically contiguous memory, but upon
+ * failure, fall back to non-contiguous (vmalloc) allocation.
+ * @size: size of the request.
+ * @flags: gfp mask for the allocation - must be compatible (superset) with GFP_KERNEL.
+ * @node: numa node to allocate from
+ *
+ * Uses kmalloc to get the memory but if the allocation fails then falls back
+ * to the vmalloc allocator. Use kvfree for freeing the memory.
+ *
+ * Reclaim modifiers - __GFP_NORETRY, __GFP_REPEAT and __GFP_NOFAIL are not supported
+ *
+ * Any use of gfp flags outside of GFP_KERNEL should be consulted with mm people.
+ */
+void *kvmalloc_node(size_t size, gfp_t flags, int node)
+{
+	gfp_t kmalloc_flags = flags;
+	void *ret;
+
+	/*
+	 * vmalloc uses GFP_KERNEL for some internal allocations (e.g page tables)
+	 * so the given set of flags has to be compatible.
+	 */
+	WARN_ON_ONCE((flags & GFP_KERNEL) != GFP_KERNEL);
+
+	/*
+	 * Make sure that larger requests are not too disruptive - no OOM
+	 * killer and no allocation failure warnings as we have a fallback
+	 */
+	if (size > PAGE_SIZE)
+		kmalloc_flags |= __GFP_NORETRY | __GFP_NOWARN;
+
+	ret = kmalloc_node(size, kmalloc_flags, node);
+
+	/*
+	 * It doesn't really make sense to fallback to vmalloc for sub page
+	 * requests
+	 */
+	if (ret || size <= PAGE_SIZE)
+		return ret;
+
+	return __vmalloc_node_flags(size, node, flags | __GFP_HIGHMEM);
+}
+EXPORT_SYMBOL(kvmalloc_node);
+
 void kvfree(const void *addr)
 {
 	if (is_vmalloc_addr(addr))
diff --git a/trunk/linux-4.4.x/mm/vmalloc.c b/trunk/linux-4.4.x/mm/vmalloc.c
index 006827636..d314cbf96 100644
--- a/trunk/linux-4.4.x/mm/vmalloc.c
+++ b/trunk/linux-4.4.x/mm/vmalloc.c
@@ -1734,7 +1734,7 @@ void *__vmalloc(unsigned long size, gfp_t gfp_mask, pgprot_t prot)
 }
 EXPORT_SYMBOL(__vmalloc);
 
-static inline void *__vmalloc_node_flags(unsigned long size,
+void *__vmalloc_node_flags(unsigned long size,
 					int node, gfp_t flags)
 {
 	return __vmalloc_node(size, 1, flags, PAGE_KERNEL,
diff --git a/trunk/linux-4.4.x/net/8021q/vlan_dev.c b/trunk/linux-4.4.x/net/8021q/vlan_dev.c
index 9955593ef..bffd75d42 100644
--- a/trunk/linux-4.4.x/net/8021q/vlan_dev.c
+++ b/trunk/linux-4.4.x/net/8021q/vlan_dev.c
@@ -762,7 +762,7 @@ static int vlan_dev_get_iflink(const struct net_device *dev)
 
 static int vlan_dev_hnat_check(struct hnat_hw_path *path)
 {
-	struct net_device *dev = path->dev;
+	struct net_device *dev = path->real_dev;
 	struct vlan_dev_priv *vlan = vlan_dev_priv(dev);
 
 	if (path->flags & HNAT_PATH_VLAN)
@@ -771,7 +771,8 @@ static int vlan_dev_hnat_check(struct hnat_hw_path *path)
 	path->flags |= HNAT_PATH_VLAN;
 	path->vlan_proto = vlan->vlan_proto;
 	path->vlan_id = vlan->vlan_id;
-	path->dev = vlan->real_dev;
+	path->virt_dev = dev;
+	path->real_dev = vlan->real_dev;
 
 	if (vlan->real_dev->netdev_ops->ndo_hnat_check)
 		return vlan->real_dev->netdev_ops->ndo_hnat_check(path);
diff --git a/trunk/linux-4.4.x/net/Kconfig b/trunk/linux-4.4.x/net/Kconfig
index 7f9d7fad4..ef99f62a5 100644
--- a/trunk/linux-4.4.x/net/Kconfig
+++ b/trunk/linux-4.4.x/net/Kconfig
@@ -415,13 +415,6 @@ source "net/nat/hw_nat/Kconfig"
 
 endif
 
-config SHORTCUT_FE
-	bool "Enables kernel network stack path for Shortcut Forwarding Engine"
-	depends on NF_CONNTRACK && IPV6
-	select NF_CONNTRACK_EVENTS
-	select NF_CONNTRACK_TIMEOUT
-	select NF_CONNTRACK_CHAIN_EVENTS
-
 config DST_CACHE
 	bool
 	default n
@@ -434,3 +427,10 @@ config HAVE_BPF_JIT
 
 config HAVE_EBPF_JIT
 	bool
+
+config SHORTCUT_FE
+	bool "Enables kernel network stack path for Shortcut  Forwarding Engine"
+	depends on NF_CONNTRACK && IPV6
+	select NF_CONNTRACK_EVENTS
+	select NF_CONNTRACK_TIMEOUT
+	select NF_CONNTRACK_CHAIN_EVENTS
diff --git a/trunk/linux-4.4.x/net/Makefile b/trunk/linux-4.4.x/net/Makefile
index 48db6df32..c203d2eb0 100644
--- a/trunk/linux-4.4.x/net/Makefile
+++ b/trunk/linux-4.4.x/net/Makefile
@@ -83,3 +83,4 @@ obj-y				+= nat/foe_hook/
 endif
 obj-$(CONFIG_RA_HW_NAT)		+= nat/hw_nat/
 obj-$(CONFIG_SHORTCUT_FE)	+= shortcut-fe/
+obj-$(PGB_QUICK_PATH)		+= swrt_fastpath/
diff --git a/trunk/linux-4.4.x/net/bridge/Kconfig b/trunk/linux-4.4.x/net/bridge/Kconfig
index aa0d3b2f1..9bceaa772 100644
--- a/trunk/linux-4.4.x/net/bridge/Kconfig
+++ b/trunk/linux-4.4.x/net/bridge/Kconfig
@@ -47,6 +47,11 @@ config BRIDGE_IGMP_SNOOPING
 
 	  If unsure, say Y.
 
+config BRIDGE_OOP
+	tristate  'broop'
+	depends on BRIDGE
+	default n
+
 config BRIDGE_VLAN_FILTERING
 	bool "VLAN filtering"
 	depends on BRIDGE
diff --git a/trunk/linux-4.4.x/net/bridge/Makefile b/trunk/linux-4.4.x/net/bridge/Makefile
index a1cda5d47..fbd9523d2 100644
--- a/trunk/linux-4.4.x/net/bridge/Makefile
+++ b/trunk/linux-4.4.x/net/bridge/Makefile
@@ -16,6 +16,8 @@ br_netfilter-y := br_netfilter_hooks.o
 br_netfilter-$(subst m,y,$(CONFIG_IPV6)) += br_netfilter_ipv6.o
 obj-$(CONFIG_BRIDGE_NETFILTER) += br_netfilter.o
 
+bridge-$(CONFIG_BRIDGE_OOP) += br_oop.o
+
 bridge-$(CONFIG_BRIDGE_IGMP_SNOOPING) += br_multicast.o br_mdb.o
 
 bridge-$(CONFIG_BRIDGE_VLAN_FILTERING) += br_vlan.o
diff --git a/trunk/linux-4.4.x/net/bridge/br_fdb.c b/trunk/linux-4.4.x/net/bridge/br_fdb.c
index 2bb1653b0..bb3d5cbab 100644
--- a/trunk/linux-4.4.x/net/bridge/br_fdb.c
+++ b/trunk/linux-4.4.x/net/bridge/br_fdb.c
@@ -27,6 +27,10 @@
 #include <net/switchdev.h>
 #include "br_private.h"
 
+#ifdef CONFIG_BRIDGE_OOP
+extern unsigned int broop;
+#endif
+
 static struct kmem_cache *br_fdb_cache __read_mostly;
 static struct net_bridge_fdb_entry *fdb_find(struct hlist_head *head,
 					     const unsigned char *addr,
@@ -581,14 +585,13 @@ void br_fdb_update(struct net_bridge *br, struct net_bridge_port *source,
 	if (likely(fdb)) {
 		/* attempt to update an entry for a local interface */
 		if (unlikely(fdb->is_local)) {
-#if 0
+#ifdef CONFIG_BRIDGE_OOP
+			broop = 1;
+#endif
 			if (net_ratelimit())
-				br_warn(br, "received packet on %s with "
+				br_info(br, "received packet on %s with "
 					"own address as source address\n",
 					source->dev->name);
-#else
-			;
-#endif
 		} else {
 			/* fastpath: update of existing entry */
 			if (unlikely(source != fdb->dst)) {
diff --git a/trunk/linux-4.4.x/net/bridge/br_if.c b/trunk/linux-4.4.x/net/bridge/br_if.c
index bc77a3e92..ce40d64c0 100644
--- a/trunk/linux-4.4.x/net/bridge/br_if.c
+++ b/trunk/linux-4.4.x/net/bridge/br_if.c
@@ -604,8 +604,8 @@ void br_dev_update_stats(struct net_device *dev, struct rtnl_link_stats64 *nlsta
 	struct pcpu_sw_netstats *stats;
 
 	/*
-	* Is this a bridge?
-	*/
+	 * Is this a bridge?
+	 */
 	if (!(dev->priv_flags & IFF_EBRIDGE)) {
 		return;
 	}
diff --git a/trunk/linux-4.4.x/net/bridge/br_oop.c b/trunk/linux-4.4.x/net/bridge/br_oop.c
new file mode 100644
index 000000000..ce61f744f
--- /dev/null
+++ b/trunk/linux-4.4.x/net/bridge/br_oop.c
@@ -0,0 +1,107 @@
+#include <linux/module.h>  
+#include <linux/kernel.h> 
+#include <linux/init.h> 
+#include <net/sock.h>
+#include <net/netlink.h>
+#include <linux/skbuff.h>
+#include <uapi/linux/netlink.h>
+
+
+int broop = 0;
+static struct sock *netlink_sock;
+
+typedef struct broop_state {
+        char ctrl;
+        int val;
+} broop_st;
+
+enum {
+	GET,
+	SET
+};
+
+static void broop_handle(int pid, int seq, broop_st *st)
+{
+	struct sk_buff	*skb;
+	struct nlmsghdr	*nlh;
+	int  size= 4+1;
+	int  len = NLMSG_SPACE(size);
+	void *data;
+	int ret;
+	
+	if(st->ctrl)
+		broop = st->val;
+
+	skb = alloc_skb(len, GFP_ATOMIC);
+	if (!skb)
+		return;
+	nlh= NLMSG_PUT(skb, pid, seq, 0, size);
+	nlh->nlmsg_flags = 0;
+	data=NLMSG_DATA(nlh);
+	memcpy(data, &broop, size);
+	NETLINK_CB(skb).portid = 0;
+	NETLINK_CB(skb).dst_group = 0;   /* unicast */
+
+	ret=netlink_unicast(netlink_sock, skb, pid, MSG_DONTWAIT);
+	if (ret <0)
+	{
+		printk("send failed\n");
+		return;
+	}
+	return;
+	
+nlmsg_failure:			/* Used by NLMSG_PUT */
+	if (skb)
+		kfree_skb(skb);
+}
+
+static void broop_receive(struct sk_buff  *skb)
+{
+	kuid_t  uid;
+  	u_int	pid, seq;
+	void			*data;
+	struct nlmsghdr *nlh;
+
+	nlh = (struct nlmsghdr *)skb->data;
+	pid  = NETLINK_CREDS(skb)->pid;
+	uid  = NETLINK_CREDS(skb)->uid;
+	seq  = nlh->nlmsg_seq;
+	data = NLMSG_DATA(nlh);
+
+	broop_handle(pid,seq,data);
+
+	return ;
+}
+
+struct netlink_kernel_cfg nl_kernel_cfg = {
+	.groups = 0,
+	.flags = 0,
+	.input = broop_receive,
+	.cb_mutex = NULL,
+	.bind = NULL,
+	.compare = NULL,
+};
+
+static int __init broop_init(void)
+{
+	printk("\n\n>> broop create\n\n");
+	netlink_sock = netlink_kernel_create(&init_net, NETLINK_BROOP, &nl_kernel_cfg);
+	if(netlink_sock < 0)
+		printk("invalid netlink sock\n");
+	else
+		printk("netlink driver create successfully\n");
+
+	return 0;
+}
+
+static void __exit broop_exit(void)
+{
+	sock_release(netlink_sock->sk_socket);
+	printk("netlink driver remove successfully\n");
+}
+module_init(broop_init);
+module_exit(broop_exit);
+
+MODULE_DESCRIPTION("broop state module");
+MODULE_AUTHOR("Hamiltonian_Hsue@asus.com");
+MODULE_LICENSE("GPL");
diff --git a/trunk/linux-4.4.x/net/core/dev.c b/trunk/linux-4.4.x/net/core/dev.c
index 221c42074..d96b57d52 100644
--- a/trunk/linux-4.4.x/net/core/dev.c
+++ b/trunk/linux-4.4.x/net/core/dev.c
@@ -138,6 +138,9 @@
 #include <linux/hrtimer.h>
 #include <linux/netfilter_ingress.h>
 
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+#include <linux/imq.h>
+#endif
 #include "net-sysfs.h"
 
 /* Instead of increasing this, you should create a hash table. */
@@ -1913,9 +1916,12 @@ again:
 		 */
 		skb_reset_mac_header(skb2);
 
+		if (skb_network_header(skb2) == skb2->head)
+			skb_reset_network_header(skb2);
+
 		if (skb_network_header(skb2) < skb2->data ||
 		    skb_network_header(skb2) > skb_tail_pointer(skb2)) {
-			net_crit_ratelimited("protocol %04x is buggy, dev %s\n",
+			net_info_ratelimited("protocol %04x is buggy, dev %s\n",
 					     ntohs(skb2->protocol),
 					     dev->name);
 			skb_reset_network_header(skb2);
@@ -2773,12 +2779,17 @@ static int xmit_one(struct sk_buff *skb, struct net_device *dev,
 	unsigned int len;
 	int rc;
 #ifdef CONFIG_SHORTCUT_FE
-	/* If this skb has been fast forwarded then we don't want it to
+	/*
+	 * If this skb has been fast forwarded then we don't want it to
 	 * go to any taps (by definition we're trying to bypass them).
 	 */
 	if (!skb->fast_forwarded) {
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	if ((!list_empty(&ptype_all) || !list_empty(&dev->ptype_all)) && !(skb->imq_flags & IMQ_F_ENQUEUE))
+#else
 	if (!list_empty(&ptype_all) || !list_empty(&dev->ptype_all))
+#endif
 		dev_queue_xmit_nit(skb, dev);
 #ifdef CONFIG_SHORTCUT_FE
 	}
@@ -2818,6 +2829,9 @@ out:
 	*ret = rc;
 	return skb;
 }
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+EXPORT_SYMBOL(dev_hard_start_xmit);
+#endif
 
 static struct sk_buff *validate_xmit_vlan(struct sk_buff *skb,
 					  netdev_features_t features)
diff --git a/trunk/linux-4.4.x/net/core/rtnetlink.c b/trunk/linux-4.4.x/net/core/rtnetlink.c
index d52b63316..74d96b2ab 100644
--- a/trunk/linux-4.4.x/net/core/rtnetlink.c
+++ b/trunk/linux-4.4.x/net/core/rtnetlink.c
@@ -3413,6 +3413,7 @@ static int rtnetlink_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 	if (kind != 2 && !netlink_net_capable(skb, CAP_NET_ADMIN))
 		return -EPERM;
 
+	rtnl_lock();
 	if (kind == 2 && nlh->nlmsg_flags&NLM_F_DUMP) {
 		struct sock *rtnl;
 		rtnl_dumpit_func dumpit;
@@ -3421,7 +3422,8 @@ static int rtnetlink_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 
 		dumpit = rtnl_get_dumpit(family, type);
 		if (dumpit == NULL)
-			return -EOPNOTSUPP;
+			goto err_unlock;
+
 		calcit = rtnl_get_calcit(family, type);
 		if (calcit)
 			min_dump_alloc = calcit(skb, nlh);
@@ -3435,22 +3437,26 @@ static int rtnetlink_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
 			};
 			err = netlink_dump_start(rtnl, skb, nlh, &c);
 		}
-		rtnl_lock();
 		return err;
 	}
 
 	doit = rtnl_get_doit(family, type);
 	if (doit == NULL)
-		return -EOPNOTSUPP;
+		goto err_unlock;
+
+	err = doit(skb, nlh);
+	rtnl_unlock();
+
+	return err;
 
-	return doit(skb, nlh);
+err_unlock:
+	rtnl_unlock();
+	return -EOPNOTSUPP;
 }
 
 static void rtnetlink_rcv(struct sk_buff *skb)
 {
-	rtnl_lock();
 	netlink_rcv_skb(skb, &rtnetlink_rcv_msg);
-	rtnl_unlock();
 }
 
 static int rtnetlink_event(struct notifier_block *this, unsigned long event, void *ptr)
diff --git a/trunk/linux-4.4.x/net/core/skbuff.c b/trunk/linux-4.4.x/net/core/skbuff.c
index 1c2408cf6..112df5bc2 100644
--- a/trunk/linux-4.4.x/net/core/skbuff.c
+++ b/trunk/linux-4.4.x/net/core/skbuff.c
@@ -83,6 +83,91 @@ struct kmem_cache *skbuff_head_cache __read_mostly;
 static struct kmem_cache *skbuff_fclone_cache __read_mostly;
 int sysctl_max_skb_frags __read_mostly = MAX_SKB_FRAGS;
 EXPORT_SYMBOL(sysctl_max_skb_frags);
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+static struct kmem_cache *skbuff_cb_store_cache __read_mostly;
+#endif
+
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+/* Control buffer save/restore for IMQ devices */
+struct skb_cb_table {
+#if defined(CONFIG_BCM_KF_NBUFF)
+	char			cb[64] ____cacheline_aligned;
+#else
+	char			cb[48] __aligned(8);
+#endif
+	void			*cb_next;
+	atomic_t		refcnt;
+};
+
+static DEFINE_SPINLOCK(skb_cb_store_lock);
+
+int skb_save_cb(struct sk_buff *skb)
+{
+	struct skb_cb_table *next;
+
+	next = kmem_cache_alloc(skbuff_cb_store_cache, GFP_ATOMIC);
+	if (!next)
+		return -ENOMEM;
+
+	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
+
+	memcpy(next->cb, skb->cb, sizeof(skb->cb));
+	next->cb_next = skb->cb_next;
+
+	atomic_set(&next->refcnt, 1);
+
+	skb->cb_next = next;
+	return 0;
+}
+EXPORT_SYMBOL(skb_save_cb);
+
+int skb_restore_cb(struct sk_buff *skb)
+{
+	struct skb_cb_table *next;
+
+	if (!skb->cb_next)
+		return 0;
+
+	next = skb->cb_next;
+
+	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
+
+	memcpy(skb->cb, next->cb, sizeof(skb->cb));
+	skb->cb_next = next->cb_next;
+
+	spin_lock(&skb_cb_store_lock);
+
+	if (atomic_dec_and_test(&next->refcnt))
+		kmem_cache_free(skbuff_cb_store_cache, next);
+
+	spin_unlock(&skb_cb_store_lock);
+
+	return 0;
+}
+EXPORT_SYMBOL(skb_restore_cb);
+
+static void skb_copy_stored_cb(struct sk_buff *   , const struct sk_buff *     ) __attribute__ ((unused));
+static void skb_copy_stored_cb(struct sk_buff *new, const struct sk_buff *__old)
+{
+	struct skb_cb_table *next;
+	struct sk_buff *old;
+
+	if (!__old->cb_next) {
+		new->cb_next = NULL;
+		return;
+	}
+
+	spin_lock(&skb_cb_store_lock);
+
+	old = (struct sk_buff *)__old;
+
+	next = old->cb_next;
+	atomic_inc(&next->refcnt);
+	new->cb_next = next;
+
+	spin_unlock(&skb_cb_store_lock);
+}
+#endif
 
 /* Set skb_shinfo(skb)->gso_size to this in case you want skb_segment to
  * segment using its current segmentation instead.
@@ -656,6 +741,28 @@ static void skb_release_head_state(struct sk_buff *skb)
 		WARN_ON(in_irq());
 		skb->destructor(skb);
 	}
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	/*
+	 * This should not happen. When it does, avoid memleak by restoring
+	 * the chain of cb-backups.
+	 */
+	while (skb->cb_next != NULL) {
+		if (net_ratelimit())
+			pr_warn("IMQ: kfree_skb: skb->cb_next: %08lx\n",
+				(unsigned long)skb->cb_next);
+
+		skb_restore_cb(skb);
+	}
+	/*
+	 * This should not happen either, nf_queue_entry is nullified in
+	 * imq_dev_xmit(). If we have non-NULL nf_queue_entry then we are
+	 * leaking entry pointers, maybe memory. We don't know if this is
+	 * pointer to already freed memory, or should this be freed.
+	 * If this happens we need to add refcounting, etc for nf_queue_entry.
+	 */
+	if (skb->nf_queue_entry && net_ratelimit())
+		pr_warn("%s\n", "IMQ: kfree_skb: skb->nf_queue_entry != NULL");
+#endif
 #if IS_ENABLED(CONFIG_NF_CONNTRACK)
 	nf_conntrack_put(skb->nfct);
 #endif
@@ -780,6 +887,10 @@ static void __copy_skb_header(struct sk_buff *new, const struct sk_buff *old)
 	new->sp			= secpath_get(old->sp);
 #endif
 	__nf_copy(new, old, false);
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	new->cb_next = NULL;
+	/*skb_copy_stored_cb(new, old);*/
+#endif
 
 	/* Note : this field could be in headers_start/headers_end section
 	 * It is not yet because we do not want to have a 16 bit hole
@@ -3382,8 +3493,16 @@ done:
 	return 0;
 }
 
+static inline void show_special_structure_size(void)
+{
+	printk("size of sk_buff %d\n", sizeof(struct sk_buff));
+	printk("offset of cb in sk_buff %ld\n", offsetof(struct sk_buff, cb));
+}
+
 void __init skb_init(void)
 {
+	show_special_structure_size();
+
 	skbuff_head_cache = kmem_cache_create("skbuff_head_cache",
 					      sizeof(struct sk_buff),
 					      0,
@@ -3394,6 +3513,13 @@ void __init skb_init(void)
 						0,
 						SLAB_HWCACHE_ALIGN|SLAB_PANIC,
 						NULL);
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	skbuff_cb_store_cache = kmem_cache_create("skbuff_cb_store_cache",
+						  sizeof(struct skb_cb_table),
+						  0,
+						  SLAB_HWCACHE_ALIGN|SLAB_PANIC,
+						  NULL);
+#endif
 }
 
 static int
diff --git a/trunk/linux-4.4.x/net/ipv4/Makefile b/trunk/linux-4.4.x/net/ipv4/Makefile
index 854c4bfd6..323a1a988 100644
--- a/trunk/linux-4.4.x/net/ipv4/Makefile
+++ b/trunk/linux-4.4.x/net/ipv4/Makefile
@@ -30,6 +30,11 @@ obj-$(CONFIG_NET_IPVTI) += ip_vti.o
 obj-$(CONFIG_SYN_COOKIES) += syncookies.o
 obj-$(CONFIG_INET_AH) += ah4.o
 obj-$(CONFIG_INET_ESP) += esp4.o
+ifeq ($(CONFIG_RALINK_HWCRYPTO),m)
+ifeq ($(CONFIG_INET_ESP), y)
+obj-$(CONFIG_INET_ESP) += mtk_esp4.o
+endif
+endif
 obj-$(CONFIG_INET_IPCOMP) += ipcomp.o
 obj-$(CONFIG_INET_XFRM_TUNNEL) += xfrm4_tunnel.o
 obj-$(CONFIG_INET_XFRM_MODE_BEET) += xfrm4_mode_beet.o
diff --git a/trunk/linux-4.4.x/net/ipv4/esp4.c b/trunk/linux-4.4.x/net/ipv4/esp4.c
index 3d8021d55..f8f6f045f 100644
--- a/trunk/linux-4.4.x/net/ipv4/esp4.c
+++ b/trunk/linux-4.4.x/net/ipv4/esp4.c
@@ -18,6 +18,18 @@
 #include <net/protocol.h>
 #include <net/udp.h>
 
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+extern int 
+ipsec_esp_output(
+	struct xfrm_state *x, 
+	struct sk_buff *skb
+);
+extern int 
+ipsec_esp_input(
+	struct xfrm_state *x, 
+	struct sk_buff *skb
+);
+#else
 struct esp_skb_cb {
 	struct xfrm_skb_cb xfrm;
 	void *tmp;
@@ -501,6 +513,7 @@ static int esp_input(struct xfrm_state *x, struct sk_buff *skb)
 out:
 	return err;
 }
+#endif /* #if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE) */
 
 static u32 esp4_get_mtu(struct xfrm_state *x, int mtu)
 {
@@ -749,8 +762,13 @@ static const struct xfrm_type esp_type =
 	.init_state	= esp_init_state,
 	.destructor	= esp_destroy,
 	.get_mtu	= esp4_get_mtu,
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+	.input		= ipsec_esp_input,
+	.output		= ipsec_esp_output
+#else
 	.input		= esp_input,
 	.output		= esp_output
+#endif
 };
 
 static struct xfrm4_protocol esp4_protocol = {
diff --git a/trunk/linux-4.4.x/net/ipv4/ip_input.c b/trunk/linux-4.4.x/net/ipv4/ip_input.c
index eb1834f26..e5716a88e 100644
--- a/trunk/linux-4.4.x/net/ipv4/ip_input.c
+++ b/trunk/linux-4.4.x/net/ipv4/ip_input.c
@@ -148,6 +148,11 @@
 #include <linux/netlink.h>
 #include <net/dst_metadata.h>
 
+#ifdef CONFIG_NF_SHORTCUT_HOOK
+extern int (*smb_nf_local_in_hook)(struct sk_buff *skb);
+extern int (*smb_nf_pre_routing_hook)(struct sk_buff *skb);
+#endif
+
 /*
  *	Process Router Attention IP option (RFC 2113)
  */
@@ -253,7 +258,11 @@ int ip_local_deliver(struct sk_buff *skb)
 		if (ip_defrag(net, skb, IP_DEFRAG_LOCAL_DELIVER))
 			return 0;
 	}
-
+#ifdef CONFIG_NF_SHORTCUT_HOOK
+	if (smb_nf_local_in_hook && smb_nf_local_in_hook(skb))
+		return ip_local_deliver_finish(skb);
+	else 
+#endif
 	return NF_HOOK(NFPROTO_IPV4, NF_INET_LOCAL_IN,
 		       net, NULL, skb, skb->dev, NULL,
 		       ip_local_deliver_finish);
@@ -453,6 +462,11 @@ int ip_rcv(struct sk_buff *skb, struct net_device *dev, struct packet_type *pt,
 	/* Must drop socket now because of tproxy. */
 	skb_orphan(skb);
 
+#ifdef CONFIG_NF_SHORTCUT_HOOK
+	if (smb_nf_pre_routing_hook && smb_nf_pre_routing_hook(skb))
+		return ip_rcv_finish(skb);
+	else 
+#endif
 	return NF_HOOK(NFPROTO_IPV4, NF_INET_PRE_ROUTING,
 		       net, NULL, skb, dev, NULL,
 		       ip_rcv_finish);
diff --git a/trunk/linux-4.4.x/net/ipv4/ip_output.c b/trunk/linux-4.4.x/net/ipv4/ip_output.c
index 87c5c0499..2e69dc34d 100644
--- a/trunk/linux-4.4.x/net/ipv4/ip_output.c
+++ b/trunk/linux-4.4.x/net/ipv4/ip_output.c
@@ -82,6 +82,11 @@
 
 #include <net/ra_nat.h>
 
+#ifdef CONFIG_NF_SHORTCUT_HOOK
+extern int (*smb_nf_local_out_hook)(struct sk_buff *skb);
+extern int (*smb_nf_post_routing_hook)(struct sk_buff *skb);
+#endif
+
 int sysctl_ip_default_ttl __read_mostly = IPDEFTTL;
 EXPORT_SYMBOL(sysctl_ip_default_ttl);
 
@@ -106,7 +111,11 @@ int __ip_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 	ip_send_check(iph);
 
 	skb->protocol = htons(ETH_P_IP);
-
+#ifdef CONFIG_NF_SHORTCUT_HOOK
+	if (smb_nf_local_out_hook && smb_nf_local_out_hook(skb))
+		return dst_output(skb);
+	else 
+#endif 
 	return nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT,
 		       net, sk, skb, NULL, skb_dst(skb)->dev,
 		       dst_output);
@@ -346,6 +355,11 @@ int ip_mc_output(struct net *net, struct sock *sk, struct sk_buff *skb)
 				dev_loopback_xmit);
 	}
 
+/*#ifdef CONFIG_NF_SHORTCUT_HOOK
+	if (smb_nf_post_routing_hook && smb_nf_post_routing_hook(skb))
+		return ip_finish_output(skb);
+	else 
+#endif*/
 	return NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING,
 			    net, sk, skb, NULL, skb->dev,
 			    ip_finish_output,
@@ -361,6 +375,11 @@ int ip_output(struct net *net, struct sock *sk, struct sk_buff *skb)
 	skb->dev = dev;
 	skb->protocol = htons(ETH_P_IP);
 
+#ifdef CONFIG_NF_SHORTCUT_HOOK
+	if (smb_nf_post_routing_hook && smb_nf_post_routing_hook(skb))
+		return ip_finish_output(skb);
+	else 
+#endif
 	return NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING,
 			    net, sk, skb, NULL, dev,
 			    ip_finish_output,
diff --git a/trunk/linux-4.4.x/net/ipv4/mtk_esp4.c b/trunk/linux-4.4.x/net/ipv4/mtk_esp4.c
new file mode 100644
index 000000000..c6bf78801
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/mtk_esp4.c
@@ -0,0 +1,2904 @@
+ /************************************************************************
+ *
+ *	Copyright (C) 2012 MediaTek Technologies, Corp.
+ *	All Rights Reserved.
+ *
+ * MediaTek Confidential; Need to Know only.
+ * Protected as an unpublished work.
+ *
+ * The computer program listings, specifications and documentation
+ * herein are the property of MediaTek Technologies, Co. and shall
+ * not be reproduced, copied, disclosed, or used in whole or in part
+ * for any reason without the prior express written permission of
+ * MediaTek Technologeis, Co.
+ *
+ *************************************************************************/
+
+
+#include <linux/err.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <net/ip.h>
+#include <net/xfrm.h>
+#include <net/esp.h>
+#include <asm/scatterlist.h>
+#include <linux/crypto.h>
+#include <linux/kernel.h>
+#include <linux/pfkeyv2.h>
+#include <linux/random.h>
+#include <net/icmp.h>
+#include <net/protocol.h>
+#include <net/udp.h>
+
+#include <net/mtk_esp.h>
+#include <linux/netfilter_ipv4.h>
+
+#ifdef MTK_EIP97_IPI
+#include <linux/smp.h>		
+#endif		
+/************************************************************************
+*                          C O N S T A N T S
+*************************************************************************
+*/
+
+#define HASH_MD5_HMAC			"hmac(md5)"
+#define HASH_SHA1_HMAC			"hmac(sha1)"
+#define HASH_SHA256_HMAC		"hmac(sha256)"
+#define HASH_NULL_HMAC 			"hmac(digest_null)"
+#define HASH_IPAD				0x36363636
+#define HASH_OPAD				0x5c5c5c5c
+#define CIPHER_DES_CBC			"cbc(des)"
+#define CIPHER_3DES_CBC			"cbc(des3_ede)"
+#define CIPHER_AES_CBC			"cbc(aes)"
+#define CIPHER_NULL_ECB			"ecb(cipher_null)"
+#define SKB_QUEUE_MAX_SIZE		2048
+
+#define RALINK_HWCRYPTO_NAT_T	1
+#define FEATURE_AVOID_QUEUE_PACKET	1
+
+/************************************************************************
+*      P R I V A T E    S T R U C T U R E    D E F I N I T I O N
+*************************************************************************
+*/
+
+
+/************************************************************************
+*              P R I V A T E     D A T A
+*************************************************************************
+*/
+ipsecEip93Adapter_t 	*ipsecEip93AdapterListOut[IPESC_EIP93_ADAPTERS];
+ipsecEip93Adapter_t 	*ipsecEip93AdapterListIn[IPESC_EIP93_ADAPTERS];
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+static unsigned int spi_inbound_tbl[IPESC_EIP93_ADAPTERS]  __attribute__((aligned(32)));
+static unsigned int spi_outbound_tbl[IPESC_EIP93_ADAPTERS] __attribute__((aligned(32)));
+#endif
+static spinlock_t 			cryptoLock[NUM_CMD_RING];
+static spinlock_t				ipsec_adapters_outlock, ipsec_adapters_inlock;
+#ifdef MTK_EIP97_DRIVER
+static eip97DescpHandler_t 	resDescpHandler[NUM_RESULT_RING];
+#else
+static eip93DescpHandler_t 	resDescpHandler[NUM_RESULT_RING];
+#endif
+mcrypto_proc_type 			mcrypto_proc;
+EXPORT_SYMBOL(mcrypto_proc);
+EXPORT_SYMBOL(ipsecEip93AdapterListOut);
+EXPORT_SYMBOL(ipsecEip93AdapterListIn);
+/************************************************************************
+*              E X T E R N A L     D A T A
+*************************************************************************
+*/
+#ifdef MTK_EIP97_DRIVER
+int 
+(*ipsec_packet_put)(
+	void *descpHandler, 
+	struct sk_buff *skb,
+	unsigned int rdx
+);
+#else
+int 
+(*ipsec_packet_put)(
+	void *descpHandler, 
+	struct sk_buff *skb
+);
+#endif
+int 
+(*ipsec_packet_get)(
+	void *descpHandler,
+	unsigned int rdx
+);
+bool 
+(*ipsec_eip93CmdResCnt_check)(
+	unsigned int rdx
+);
+int 
+(*ipsec_preComputeIn_cmdDescp_set)(
+	ipsecEip93Adapter_t *currAdapterPtr,
+	//unsigned int hashAlg, 
+	unsigned int direction
+);
+int 
+(*ipsec_preComputeOut_cmdDescp_set)(
+	ipsecEip93Adapter_t *currAdapterPtr, 
+	//unsigned int hashAlg,
+	unsigned int direction
+);
+int 
+(*ipsec_cmdHandler_cmdDescp_set)(
+	ipsecEip93Adapter_t *currAdapterPtr, 
+	unsigned int direction,
+	unsigned int cipherAlg, 
+	unsigned int hashAlg,
+	unsigned int digestWord,	
+	unsigned int cipherMode,
+	unsigned int enHmac, 
+	unsigned int aesKeyLen, 
+	unsigned int *cipherKey, 
+	unsigned int keyLen, 
+	unsigned int spi, 
+	unsigned int padCrtlStat
+);
+void 
+(*ipsec_espNextHeader_set)(
+	void *cmdHandler, 
+	unsigned char protocol	
+);
+unsigned char 
+(*ipsec_espNextHeader_get)(
+	void *resHandler
+);
+unsigned int 
+(*ipsec_pktLength_get)(
+	void *resHandler
+);
+unsigned int 
+(*ipsec_eip93HashFinal_get)(
+	void *resHandler
+);
+unsigned int 
+(*ipsec_eip93UserId_get)(
+	void *resHandler
+);
+
+void 
+(*ipsec_addrsDigestPreCompute_free)(
+	ipsecEip93Adapter_t *currAdapterPtr
+);
+
+void 
+(*ipsec_cmdHandler_free)(
+	void *cmdHandler
+);
+
+void 
+(*ipsec_hashDigests_get)(
+	ipsecEip93Adapter_t *currAdapterPtr
+);
+
+void 
+(*ipsec_hashDigests_set)(
+	ipsecEip93Adapter_t *currAdapterPtr,
+	unsigned int isInOrOut
+);
+
+unsigned int 
+(*ipsec_espSeqNum_get)(
+	void *resHandler
+);
+
+EXPORT_SYMBOL(ipsec_packet_put);
+EXPORT_SYMBOL(ipsec_packet_get);
+EXPORT_SYMBOL(ipsec_eip93CmdResCnt_check);
+EXPORT_SYMBOL(ipsec_preComputeIn_cmdDescp_set);
+EXPORT_SYMBOL(ipsec_preComputeOut_cmdDescp_set);
+EXPORT_SYMBOL(ipsec_cmdHandler_cmdDescp_set);
+EXPORT_SYMBOL(ipsec_espNextHeader_set);
+EXPORT_SYMBOL(ipsec_espNextHeader_get);
+EXPORT_SYMBOL(ipsec_pktLength_get);
+EXPORT_SYMBOL(ipsec_eip93HashFinal_get);
+EXPORT_SYMBOL(ipsec_eip93UserId_get);
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)
+EXPORT_SYMBOL(ipsec_addrsDigestPreCompute_free);
+EXPORT_SYMBOL(ipsec_cmdHandler_free);
+#endif
+EXPORT_SYMBOL(ipsec_hashDigests_get);
+EXPORT_SYMBOL(ipsec_hashDigests_set);
+EXPORT_SYMBOL(ipsec_espSeqNum_get);
+
+#ifdef MTK_EIP97_IPI
+static void	smp_func_call_BH_handler(unsigned long data);
+static DECLARE_TASKLET( \
+	smp_func_call_tsk, smp_func_call_BH_handler, 0);
+static void smp_func_call(void *info);
+#endif
+//#define MCRYPTO_DBG
+
+#ifdef MCRYPTO_DBG
+#define ra_dbg 	printk
+#else
+#define ra_dbg(fmt, arg...) do {}while(0)
+#endif
+
+#ifdef MCRYPTO_DBG
+static void skb_dump(struct sk_buff* sk, const char* func,int line) {
+        unsigned int i;
+
+        printk("(%d)skb_dump: [%s] with len %d (%08X) headroom=%d tailroom=%d\n",
+                line,func,sk->len,(unsigned int)sk,
+                skb_headroom(sk),skb_tailroom(sk));
+
+        for(i=(unsigned int)sk->head;i<=(unsigned int)sk->data + 160;i++) {
+                if((i % 16) == 0)
+                        printk("\n");
+                if(i==(unsigned int)sk->data) printk("{");
+                //if(i==(unsigned int)sk->h.raw) ra_dbg("#");
+                //if(i==(unsigned int)sk->nh.raw) ra_dbg("|");
+                //if(i==(unsigned int)sk->mac.raw) ra_dbg("*");
+                printk("%02x ",*((unsigned char*)i));
+                if(i==(unsigned int)(sk->tail)-1) printk("}");
+        }
+        printk("\n");
+}
+#else
+#define skb_dump //skb_dump
+#endif
+/************************************************************************
+*              P R I V A T E     F U N C T I O N S
+*************************************************************************
+*/
+/*_______________________________________________________________________
+**function name: ipsec_hashDigest_preCompute
+**
+**description:
+*   EIP93 can only use Hash Digests (not Hash keys) to do authentication!
+*	This funtion is to use EIP93 to generate Hash Digests from Hash keys!
+*	Only the first packet for a IPSec flow need to do this!
+**parameters:
+*   x -- point to the structure that stores IPSec SA information
+*	currAdapterPtr -- point to the structure that stores needed info
+*		for Hash Digest Pre-Compute. After Pre-Compute is done,
+*		currAdapterPtr->addrsPreCompute is used to free resource.
+*	digestPreComputeDir -- indicate direction for encryption or
+*		decryption.
+**global:
+*   none
+**return:
+*   -EPERM, -ENOMEM -- failed: the pakcet will be dropped!
+*	1 -- success
+**call:
+*   none
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+static int 
+ipsec_hashDigest_preCompute(
+	struct xfrm_state *x, 
+	ipsecEip93Adapter_t *currAdapterPtr, 
+	unsigned int digestPreComputeDir
+)
+{
+	char hashKeyName[32];
+	unsigned int blkSize, blkWord, digestWord, hashKeyLen, hashKeyWord;
+	unsigned int *ipad, *opad, *hashKey, *hashKeyTank;
+	dma_addr_t	ipadPhyAddr, opadPhyAddr;
+	unsigned int *pIDigest, *pODigest;
+	unsigned int i, j;
+	int errVal;
+	unsigned int flags = 0;
+	addrsDigestPreCompute_t* addrsPreCompute;
+	int rdx = 0;
+	int nTry;	
+	if (x->aalg)
+	{	
+	strcpy(hashKeyName, x->aalg->alg_name);
+	hashKeyLen = (x->aalg->alg_key_len+7)/8;
+	}
+	else
+	{
+		strcpy(hashKeyName, HASH_NULL_HMAC);
+		hashKeyLen = 0;
+		currAdapterPtr->isHashPreCompute = 3;
+		return 1;
+	}
+	
+	hashKeyWord = hashKeyLen >> 2;
+
+	if (strcmp(hashKeyName, HASH_MD5_HMAC) == 0)
+	{
+		blkSize = 64; //bytes
+		digestWord = 4; //words
+	}
+	else if (strcmp(hashKeyName, HASH_SHA1_HMAC) == 0)
+	{
+		blkSize = 64; //bytes
+		digestWord = 5; //words	
+	}
+	else if (strcmp(hashKeyName, HASH_SHA256_HMAC) == 0)
+	{
+		blkSize = 64; //bytes
+		digestWord = 8; //words	
+	}
+	else if (strcmp(hashKeyName, HASH_NULL_HMAC) == 0)
+	{
+		blkSize = 64; //bytes
+		digestWord = 0; //words	
+	}
+	else
+	{
+		printk("\n !Unsupported Hash Algorithm by EIP93: %s! \n", hashKeyName);
+		return -EPERM;
+	}
+
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+	addrsPreCompute = currAdapterPtr->addrsPreCompute;
+	hashKeyTank = addrsPreCompute->hashKeyTank;
+	ipad = addrsPreCompute->RecPoolHandler.addr + IPAD_OFFSET;
+	ipadPhyAddr = addrsPreCompute->RecPoolHandler.phyAddr + IPAD_OFFSET;
+	opad = addrsPreCompute->RecPoolHandler.addr + OPAD_OFFSET;
+	opadPhyAddr = addrsPreCompute->RecPoolHandler.phyAddr + OPAD_OFFSET;
+#else
+	addrsPreCompute = (addrsDigestPreCompute_t *) kzalloc(sizeof(addrsDigestPreCompute_t), GFP_KERNEL);
+	if (unlikely(addrsPreCompute == NULL))
+	{
+		printk("\n\n !!kmalloc for addrsPreCompute failed!! \n\n");
+		return -ENOMEM;
+	}
+	currAdapterPtr->addrsPreCompute = addrsPreCompute;
+	
+	hashKeyTank = (unsigned int *) kzalloc(blkSize, GFP_KERNEL);
+	if (unlikely(hashKeyTank == NULL))
+	{
+		printk("\n\n !!kmalloc for hashKeyTank failed!! \n\n");
+		errVal = -ENOMEM;
+		goto free_addrsPreCompute;
+	}
+	addrsPreCompute->hashKeyTank = hashKeyTank;
+	if (in_atomic())
+		flags |= GFP_ATOMIC;    // non-sleepable
+	else
+		flags |= GFP_KERNEL;    // sleepable
+#endif
+#ifdef MTK_EIP97_DRIVER
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)
+	addrsPreCompute->RecPoolHandler.size = RECPOOLSIZE;
+	addrsPreCompute->RecPoolHandler.addr = (unsigned int *) dma_alloc_coherent(NULL, addrsPreCompute->RecPoolHandler.size, &addrsPreCompute->RecPoolHandler.phyAddr, flags);
+	
+	if (unlikely(addrsPreCompute->RecPoolHandler.addr == NULL))
+	{
+		printk("\n\n !!dma_alloc for RecPoolHandler failed!! \n\n");
+		errVal = -ENOMEM;
+		goto free_hashKeyTank;
+	}
+
+	ipad = addrsPreCompute->RecPoolHandler.addr + IPAD_OFFSET;
+	ipadPhyAddr = addrsPreCompute->RecPoolHandler.phyAddr + IPAD_OFFSET;
+	opad = addrsPreCompute->RecPoolHandler.addr + OPAD_OFFSET;
+	opadPhyAddr = addrsPreCompute->RecPoolHandler.phyAddr + OPAD_OFFSET;
+#endif
+#endif
+
+#ifndef MTK_EIP97_DRIVER
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)	
+	ipad = (unsigned int *) dma_alloc_coherent(NULL, blkSize, &ipadPhyAddr, flags);
+	if (unlikely(ipad == NULL))
+	{
+		printk("\n\n !!dma_alloc for ipad failed!! \n\n");
+		errVal = -ENOMEM;
+		goto free_hashKeyTank;
+	}
+#endif
+#endif	
+	addrsPreCompute->ipadHandler.addr = (unsigned int)ipad;
+	addrsPreCompute->ipadHandler.phyAddr = ipadPhyAddr;
+	addrsPreCompute->blkSize = blkSize;
+#ifndef MTK_EIP97_DRIVER
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)
+	opad = (unsigned int *) dma_alloc_coherent(NULL, blkSize, &opadPhyAddr, flags);
+	if (unlikely(opad == NULL))
+	{
+		printk("\n\n !!dma_alloc for opad failed!! \n\n");
+		errVal = -ENOMEM;
+		goto free_ipad;
+	}
+#endif
+#endif	
+	addrsPreCompute->opadHandler.addr = (unsigned int)opad;
+	addrsPreCompute->opadHandler.phyAddr = opadPhyAddr;	
+
+	blkWord = blkSize >> 2;
+	if (x->aalg)
+	{	
+	hashKey = (unsigned int *)x->aalg->alg_key;
+	                                     
+	if(hashKeyLen <= blkSize)
+	{
+		for(i = 0; i < hashKeyWord; i++)
+		{
+			hashKeyTank[i] = hashKey[i];
+		}
+		for(j = i; j < blkWord; j++)
+		{
+			hashKeyTank[j] = 0x0;
+		}
+	}
+	else
+	{
+		// EIP93 supports md5, sha1, sha256. Their hash key length and their function output length should be the same, which are 128, 160, and 256 bits respectively! Their block size are 64 bytes which are always larger than all of their hash key length! 
+		printk("\n !Unsupported hashKeyLen:%d by EIP93! \n", hashKeyLen);
+		errVal = -EPERM;
+		goto free_opad;
+	}
+	}
+	else
+		memset(hashKeyTank, 0, blkSize);
+	
+	for(i=0; i<blkWord; i++)
+	{
+		ipad[i] = HASH_IPAD;
+		opad[i] = HASH_OPAD;
+		ipad[i] ^= hashKeyTank[i];
+		opad[i] ^= hashKeyTank[i];			
+	}
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+	pIDigest = addrsPreCompute->pIDigest;
+	pODigest = addrsPreCompute->pODigest;
+#else
+	pIDigest = (unsigned int *) kzalloc(sizeof(unsigned int) << 3, GFP_KERNEL);
+	if(pIDigest == NULL)
+	{
+		printk("\n\n !!kmalloc for Hash Inner Digests failed!! \n\n");
+		errVal = -ENOMEM;
+		goto free_opad;
+	}
+	addrsPreCompute->pIDigest = pIDigest;
+	
+	pODigest = (unsigned int *) kzalloc(sizeof(unsigned int) << 3, GFP_KERNEL);
+	if(pODigest == NULL)
+	{
+		printk("\n\n !!kmalloc for Hash Outer Digests failed!! \n\n");
+		errVal = -ENOMEM;
+		goto free_pIDigest;
+	}
+	addrsPreCompute->pODigest = pODigest;
+#endif		
+	addrsPreCompute->digestWord = digestWord;
+
+	currAdapterPtr->isHashPreCompute = 0; //pre-compute init	
+
+	/* start pre-compute for Hash Inner Digests */
+	errVal = ipsec_preComputeIn_cmdDescp_set(currAdapterPtr, digestPreComputeDir);
+	if (errVal < 0)
+	{
+		goto free_pODigest;
+	}
+#ifdef MTK_EIP97_DRIVER
+		if (currAdapterPtr->isEncryptOrDecrypt==CRYPTO_ENCRYPTION)
+		{	
+			if ((currAdapterPtr->idx&0x2)==0)
+			{	
+			rdx = 0;
+				mcrypto_proc.dbg_pt[0]++;
+			}
+		else
+			{
+				mcrypto_proc.dbg_pt[1]++;	
+				rdx = 2;
+			}	
+		}
+		else
+		{
+			if ((currAdapterPtr->idx&0x2)==0)
+			{	
+				mcrypto_proc.dbg_pt[2]++;
+			rdx = 1;	
+			}
+			else
+			{
+				mcrypto_proc.dbg_pt[3]++;
+				rdx = 3;
+			}	
+		}	
+#endif
+
+	spin_lock(&cryptoLock[rdx]);
+	nTry = 0;
+	while (nTry < 3)
+	{	
+		if (ipsec_eip93CmdResCnt_check(rdx)==false)
+			nTry++;
+		else
+			break;
+	}
+	if (nTry >= 3)
+	{	
+		spin_unlock(&cryptoLock[rdx]);
+		return HWCRYPTO_PREPROCESS_DROP;
+	}	
+	{	
+#ifdef MTK_EIP97_DRIVER
+		ipsec_packet_put(addrsPreCompute->cmdHandler, NULL, rdx); //mtk_packet_put()
+#else
+		ipsec_packet_put(addrsPreCompute->cmdHandler, NULL); //mtk_packet_put()
+#endif
+	}
+	spin_unlock(&cryptoLock[rdx]);
+	
+	/* start pre-compute for Hash Outer Digests */	
+	errVal = ipsec_preComputeOut_cmdDescp_set(currAdapterPtr, digestPreComputeDir);
+	if (errVal < 0)
+	{
+		goto free_pODigest;
+	}
+	
+	spin_lock(&cryptoLock[rdx]);
+	nTry = 0;
+	while (nTry < 3)
+	{	
+		if (ipsec_eip93CmdResCnt_check(rdx)==false)
+			nTry++;
+		else
+			break;
+	}	
+	if (nTry >=3)
+	{
+		spin_unlock(&cryptoLock[rdx]);
+		return HWCRYPTO_PREPROCESS_DROP;
+	}
+	{		
+#ifdef MTK_EIP97_DRIVER
+		ipsec_packet_put(addrsPreCompute->cmdHandler, NULL, rdx); //mtk_packet_put()
+#else
+		ipsec_packet_put(addrsPreCompute->cmdHandler, NULL); //mtk_packet_put()
+#endif
+	}
+	
+	spin_unlock(&cryptoLock[rdx]);
+
+	return 1; //success
+	
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+free_pODigest:
+free_pIDigest:
+free_opad:
+free_ipad:
+free_hashKeyTank:
+free_addrsPreCompute:
+#else
+free_pODigest:
+	kfree(pODigest);
+free_pIDigest:
+	kfree(pIDigest);
+#ifndef MTK_EIP97_DRIVER		
+free_opad:
+	dma_free_coherent(NULL, blkSize, opad, opadPhyAddr);		
+free_ipad:
+	dma_free_coherent(NULL, blkSize, ipad, ipadPhyAddr);
+#endif	
+free_hashKeyTank:
+	kfree(hashKeyTank);
+#ifdef MTK_EIP97_DRIVER		
+free_ipad:
+free_opad:
+#endif	
+free_addrsPreCompute:
+#ifdef MTK_EIP97_DRIVER	
+	if (addrsPreCompute->RecPoolHandler.addr)
+		dma_free_coherent(NULL, addrsPreCompute->RecPoolHandler.size, addrsPreCompute->RecPoolHandler.addr, addrsPreCompute->RecPoolHandler.phyAddr);
+#endif
+	kfree(addrsPreCompute);
+	currAdapterPtr->addrsPreCompute = NULL;	
+#endif /* CONFIG_HWCRYPTO_MEMPOOL */
+	return errVal;	
+}
+
+/*_______________________________________________________________________
+**function name: ipsec_cmdHandler_prepare
+**
+**description:
+*   Prepare a command handler for a IPSec flow. This handler includes 
+*	all needed information for EIP93 to do encryption/decryption.
+*	Only the first packet for a IPSec flow need to do this!
+**parameters:
+*   x -- point to the structure that stores IPSec SA information
+*	currAdapterPtr -- point to the structure that will stores the
+*		command handler
+*	cmdHandlerDir -- indicate direction for encryption or decryption.
+**global:
+*   none
+**return:
+*   -EPERM, -ENOMEM -- failed: the pakcet will be dropped!
+*	1 -- success
+**call:
+*   none
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+static int 
+ipsec_cmdHandler_prepare(
+	struct xfrm_state *x, 
+	ipsecEip93Adapter_t *currAdapterPtr,
+	unsigned int cmdHandlerDir
+)
+{
+	int errVal;
+	struct esp_data *esp = x->data;
+	int padBoundary = ALIGN(crypto_aead_blocksize(esp->aead), 4);
+	unsigned int padCrtlStat, keyLen;
+	char nameString[32];
+	unsigned int cipherAlg, cipherMode, aesKeyLen = 0, hashAlg, enHmac;
+	unsigned int *cipherKey;
+	unsigned int addedLen = 0;
+
+	addedLen += 8; //for esp header	
+
+	/* decide pad boundary */
+	switch(padBoundary){
+		case 1:
+			padCrtlStat = 0x1;
+			addedLen += 1;
+			break;
+		case 4:
+			padCrtlStat = 0x1 << 1;
+			addedLen += 4;
+			break;
+		case 8:
+			padCrtlStat = 0x1 << 2;
+			addedLen += 8;
+			break;
+		case 16:
+			padCrtlStat = 0x1 << 3;
+			addedLen += 16;
+			break;
+		case 32:
+			padCrtlStat = 0x1 << 4;
+			addedLen += 32;
+			break;
+		case 64:
+			padCrtlStat = 0x1 << 5;
+			addedLen += 64;
+			break;
+		case 128:
+			padCrtlStat = 0x1 << 6;
+			addedLen += 128;
+			break;
+		case 256:
+			padCrtlStat = 0x1 << 7;
+			addedLen += 256;
+			break;
+		default:
+			printk("\n !Unsupported pad boundary (%d) by EIP93! \n", padBoundary);
+			errVal = -EPERM;
+			goto free_addrsPreComputes;
+	}
+	
+	
+	/* decide cipher */
+	strcpy(nameString, x->ealg->alg_name);
+
+	keyLen = (x->ealg->alg_key_len+7)/8;
+	if(strcmp(nameString, CIPHER_DES_CBC) == 0)
+	{
+		cipherAlg = 0x0; //des
+		cipherMode = 0x1; //cbc
+		addedLen += (8 + (8 + 1)); //iv + (esp trailer + padding)
+	}
+	else if(strcmp(nameString, CIPHER_3DES_CBC) == 0)
+	{
+		cipherAlg = 0x1; //3des
+		cipherMode = 0x1; //cbc
+		addedLen += (8 + (8 + 1)); //iv + (esp trailer + padding)
+	}
+	else if(strcmp(nameString, CIPHER_AES_CBC) == 0)
+	{
+		cipherAlg = 0x3; //aes
+		cipherMode = 0x1; //cbc
+		addedLen += (16 + (16 + 1)); //iv + (esp trailer + padding)
+
+		switch(keyLen << 3) //keyLen*8
+		{ 
+			case 128:
+				aesKeyLen = 0x2;
+				break;
+			case 192:
+				aesKeyLen = 0x3;
+				break;
+			case 256:
+				aesKeyLen = 0x4;
+				break;
+			default:
+				printk("\n !Unsupported AES key length (%d) by EIP93! \n", keyLen << 3);
+				errVal = -EPERM;
+				goto free_addrsPreComputes;
+		}
+	}
+	else if(strcmp(nameString, CIPHER_NULL_ECB) == 0)
+	{
+		cipherAlg = 0xf; //null
+		cipherMode = 0x0; //ecb
+		addedLen += (8 + (16 + 1) + 16); //iv + (esp trailer + padding) + ICV
+	}
+	else
+	{
+		printk("\n !Unsupported Cipher Algorithm (%s) by EIP93! \n", nameString);
+		errVal = -EPERM;
+		goto free_addrsPreComputes;
+	}
+
+	
+	/* decide hash */
+	if (x->aalg==NULL)
+		strcpy(nameString, HASH_NULL_HMAC);	
+	else
+	strcpy(nameString, x->aalg->alg_name);
+
+	if(strcmp(nameString, HASH_MD5_HMAC) == 0)
+	{
+		hashAlg = 0x0; //md5
+		enHmac = 0x1; //hmac
+		addedLen += 12; //ICV
+	}
+	else if(strcmp(nameString, HASH_SHA1_HMAC) == 0)
+	{
+		hashAlg = 0x1; //sha1
+		enHmac = 0x1; //hmac
+		addedLen += 12; //ICV
+	}
+	else if(strcmp(nameString, HASH_SHA256_HMAC) == 0)
+	{
+		hashAlg = 0x3; //sha256
+		enHmac = 0x1; //hmac
+		addedLen += 16; //ICV
+	}
+	else if(strcmp(nameString, HASH_NULL_HMAC) == 0)
+	{
+		hashAlg = 0xf; //null
+		enHmac = 0x0;//0x1; //hmac
+	}
+	else
+	{
+		printk("\n !Unsupported! Hash Algorithm (%s) by EIP93! \n", nameString);
+		errVal = -EPERM;
+		goto free_addrsPreComputes;
+	}
+
+	cipherKey =	(unsigned int *)x->ealg->alg_key;
+	currAdapterPtr->addedLen = addedLen;
+	errVal = ipsec_cmdHandler_cmdDescp_set(currAdapterPtr, cmdHandlerDir, cipherAlg, hashAlg, \
+			crypto_aead_authsize(esp->aead)/sizeof(unsigned int), cipherMode, enHmac, aesKeyLen, \
+			cipherKey, keyLen, x->id.spi, padCrtlStat);
+	if (errVal < 0)
+	{
+		goto free_addrsPreComputes;
+	}
+
+	return 1; //success
+
+free_addrsPreComputes:
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)
+	ipsec_addrsDigestPreCompute_free(currAdapterPtr);
+#endif
+	return errVal;
+}
+
+static int 
+ipsec_esp_preProcess(
+	struct xfrm_state *x, 
+	struct sk_buff *skb,
+	unsigned int direction
+)
+{
+	ipsecEip93Adapter_t **ipsecEip93AdapterList;
+	unsigned int i, usedEntryNum = 0;
+	ipsecEip93Adapter_t *currAdapterPtr;
+	unsigned int spi = x->id.spi;
+	int currAdapterIdx = -1;
+	int err = 1;
+	unsigned int *addrCurrAdapter;
+	unsigned long flags;
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+	unsigned int* spi_tbl;
+#endif
+
+	if (direction == HASH_DIGEST_OUT)
+	{
+		spin_lock(&ipsec_adapters_outlock);
+		ipsecEip93AdapterList = &ipsecEip93AdapterListOut[0];
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+		spi_tbl = spi_outbound_tbl;
+#endif
+	}
+	else
+	{
+		spin_lock(&ipsec_adapters_inlock);
+		ipsecEip93AdapterList = &ipsecEip93AdapterListIn[0];
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+		spi_tbl = spi_inbound_tbl;
+#endif
+	}
+
+	//try to find the matched ipsecEip93Adapter for the ipsec flow
+	for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+	{
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+		if (spi_tbl[i]!=0xFFFFFFFF)
+		{
+			if (spi_tbl[i]==spi)
+			{
+				currAdapterPtr = ipsecEip93AdapterList[i];
+				if (currAdapterPtr->status != TBL_ACTIVE)
+				{
+					printk("Drop packet for Conn[%d] status=%x\n",i, currAdapterPtr->status);
+					kfree_skb(skb);
+					if (direction == HASH_DIGEST_OUT)
+						spin_unlock(&ipsec_adapters_outlock);
+					else
+						spin_unlock(&ipsec_adapters_inlock);
+					err = HWCRYPTO_PREPROCESS_DROP;	
+					goto EXIT;
+				}	
+				currAdapterIdx = i;
+				break;
+			}
+			usedEntryNum++;
+		}
+#else
+		if ((currAdapterPtr = ipsecEip93AdapterList[i]) != NULL)
+		{
+			if (currAdapterPtr->spi == spi)
+			{
+				currAdapterIdx = i;
+				break;
+			}
+			usedEntryNum++;
+		}
+#endif
+		else
+		{	//try to record the first unused entry in ipsecEip93AdapterList
+			if (currAdapterIdx == -1)
+			{
+				currAdapterIdx = i;
+			}
+		}
+	}
+	
+	if (usedEntryNum == IPESC_EIP93_ADAPTERS)
+	{
+		printk("\n\n !The ipsecEip93AdapterList (dir=%d) table is full!(%d) (spi=%08X)\n\n",direction,usedEntryNum,spi);
+		err = -EPERM;
+		if (direction == HASH_DIGEST_OUT)
+			spin_unlock(&ipsec_adapters_outlock);
+		else
+			spin_unlock(&ipsec_adapters_inlock);
+		goto EXIT;
+	}
+
+	//no ipsecEip93Adapter matched, so create a new one for the ipsec flow. \
+	//Only the first packet of a ipsec flow will encounter this.
+	if (i == IPESC_EIP93_ADAPTERS)
+	{
+		if (x->aalg == NULL)
+		{
+			//printk("\n\n !please set a hash algorithm! \n\n");
+			//err = -EPERM;
+			//goto EXIT;
+		}
+		else if (x->ealg == NULL)
+		{
+			printk("\n\n !please set a cipher algorithm! \n\n");
+			if (direction == HASH_DIGEST_OUT)
+				spin_unlock(&ipsec_adapters_outlock);
+			else
+				spin_unlock(&ipsec_adapters_inlock);
+			err = -EPERM;
+			goto EXIT;
+		}
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+		if ((currAdapterIdx >=0) && (currAdapterIdx<IPESC_EIP93_ADAPTERS))
+			currAdapterPtr = ipsecEip93AdapterList[currAdapterIdx];
+		else	
+			currAdapterPtr = NULL;
+
+		if ((currAdapterPtr == NULL) || (currAdapterIdx==-1))
+#else	
+		currAdapterPtr = (ipsecEip93Adapter_t *) kzalloc(sizeof(ipsecEip93Adapter_t), GFP_KERNEL);	
+		if(currAdapterPtr == NULL)
+#endif
+		{
+			printk("\n\n !!kmalloc for new ipsecEip93Adapter failed index=%d, used entry=%d %08X!! \n\n", currAdapterIdx,usedEntryNum,ipsecEip93AdapterList[currAdapterIdx]);
+			if (direction == HASH_DIGEST_OUT)
+				spin_unlock(&ipsec_adapters_outlock);
+			else
+				spin_unlock(&ipsec_adapters_inlock);
+			err = -ENOMEM;
+			goto EXIT;
+		}
+		
+		spin_lock_init(&currAdapterPtr->lock);
+		spin_lock_init(&currAdapterPtr->seqlock);
+		skb_queue_head_init(&currAdapterPtr->skbQueue);
+#ifdef MTK_EIP97_IPI
+		skb_queue_head_init(&currAdapterPtr->skbIPIQueue);		
+#endif	
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+		spi_tbl[currAdapterIdx] = spi;	
+#endif
+		currAdapterPtr->status = TBL_ACTIVE;
+		currAdapterPtr->spi = spi;
+		currAdapterPtr->x = x;
+		currAdapterPtr->dst = skb_dst(skb);
+		currAdapterPtr->idx = currAdapterIdx;
+		if (x->props.mode == XFRM_MODE_TUNNEL)
+			currAdapterPtr->tunnel = 1;
+		else
+			currAdapterPtr->tunnel = 0;
+
+		if (direction == HASH_DIGEST_IN)
+		{	
+				currAdapterPtr->seqno_in = 0;
+				currAdapterPtr->isEncryptOrDecrypt = CRYPTO_DECRYPTION;
+		}
+		else
+		{
+				currAdapterPtr->seqno_out = 0;	
+				currAdapterPtr->isEncryptOrDecrypt = CRYPTO_ENCRYPTION;
+		}
+		err = ipsec_hashDigest_preCompute(x, currAdapterPtr, direction);
+		if (err < 0)
+		{
+			ra_dbg("\n\n !ipsec_hashDigest_preCompute for direction:%d failed! \n\n", direction);
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)			
+			kfree(currAdapterPtr);
+#endif
+			if (direction == HASH_DIGEST_OUT)
+				spin_unlock(&ipsec_adapters_outlock);
+			else
+				spin_unlock(&ipsec_adapters_inlock);
+			goto EXIT;
+		}
+		if (err == HWCRYPTO_PREPROCESS_DROP)
+		{
+			if (direction == HASH_DIGEST_OUT)
+				spin_unlock(&ipsec_adapters_outlock);
+			else
+				spin_unlock(&ipsec_adapters_inlock);
+			goto EXIT;
+		}
+		err = ipsec_cmdHandler_prepare(x, currAdapterPtr, direction);
+		if (err < 0)
+		{
+			printk("\n\n !ipsec_cmdHandler_prepare for direction:%d failed! \n\n", direction);
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)			
+			kfree(currAdapterPtr);
+#endif			
+			if (direction == HASH_DIGEST_OUT)
+				spin_unlock(&ipsec_adapters_outlock);
+			else
+				spin_unlock(&ipsec_adapters_inlock);
+			goto EXIT;
+		}
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)
+		ipsecEip93AdapterList[currAdapterIdx] = currAdapterPtr;	
+#endif
+	}
+
+	if (direction == HASH_DIGEST_OUT)
+		spin_unlock(&ipsec_adapters_outlock);
+	else
+		spin_unlock(&ipsec_adapters_inlock);
+	
+	currAdapterPtr = ipsecEip93AdapterList[currAdapterIdx];
+
+#if !defined (FEATURE_AVOID_QUEUE_PACKET)
+	//Hash Digests are ready
+	spin_lock(&currAdapterPtr->lock);
+	if (currAdapterPtr->isHashPreCompute == 2)
+	{	 		
+		ipsec_hashDigests_get(currAdapterPtr);
+		currAdapterPtr->isHashPreCompute = 3; //pre-compute done
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)
+		ipsec_addrsDigestPreCompute_free(currAdapterPtr);	
+#endif
+	}
+	spin_unlock(&currAdapterPtr->lock);
+#endif
+	//save needed info skb (cryptoDriver will save skb in EIP93's userID), so the needed \
+	//info can be used by the tasklet which is raised by interrupt.
+	addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+	*addrCurrAdapter = (unsigned int)currAdapterPtr;
+
+EXIT:
+	return err;
+
+	
+}
+
+static int 
+ipsec_esp_pktPut(
+	ipsecEip93Adapter_t *currAdapterPtr,
+	struct sk_buff *skb
+)
+{
+#ifdef MTK_EIP97_DRIVER
+	eip97DescpHandler_t *cmdHandler;
+#else	
+	eip93DescpHandler_t *cmdHandler;
+#endif	
+	struct sk_buff *pSkb;
+	unsigned int isQueueFull = 0;
+	unsigned int addedLen;
+	struct sk_buff *skb2 = NULL;
+	struct dst_entry *dst;
+	unsigned int *addrCurrAdapter;
+	unsigned int flags;
+	
+	if (currAdapterPtr!=NULL)
+	{
+		//spin_lock(&currAdapterPtr->lock);
+		cmdHandler = currAdapterPtr->cmdHandler;
+		addedLen = currAdapterPtr->addedLen;
+		goto DEQUEUE;
+	}		
+
+	dst = skb_dst(skb);
+	addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+	currAdapterPtr = (ipsecEip93Adapter_t *)(*addrCurrAdapter);
+
+	//spin_lock(&currAdapterPtr->lock);
+	cmdHandler = currAdapterPtr->cmdHandler;
+	addedLen = currAdapterPtr->addedLen;
+
+	//resemble paged packets if needed
+	if (skb_is_nonlinear(skb)) 
+	{
+		ra_dbg("skb should linearize\n");
+		mcrypto_proc.nolinear_count++;
+		if (skb_linearize(skb) != 0)
+		{
+			printk("\n !resembling paged packets failed! \n");
+			spin_unlock(&currAdapterPtr->lock);
+			return -EPERM;
+		}
+		
+		//skb_linearize() may return a new skb, so insert currAdapterPtr back to skb!
+		addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+		*addrCurrAdapter = (unsigned int)currAdapterPtr;
+	}
+
+	//make sure that tailroom is enough for the added length due to encryption
+	if (currAdapterPtr->isEncryptOrDecrypt==CRYPTO_ENCRYPTION)
+	{	
+		if (skb_tailroom(skb) < addedLen)
+		{
+		skb2 = skb_copy_expand(skb, skb_headroom(skb), addedLen, GFP_ATOMIC);
+	
+			kfree_skb(skb); //free old skb
+	
+			if (skb2 == NULL)
+			{
+				printk("\n !skb_copy_expand failed! \n");
+				//spin_unlock(&currAdapterPtr->lock);
+				return -EPERM;
+			}
+			
+			skb = skb2; //the new skb
+			skb_dst_set(skb, dst_clone(dst));
+			//skb_dst_set(skb, dst);
+			addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+			*addrCurrAdapter = (unsigned int)currAdapterPtr;
+			
+			mcrypto_proc.copy_expand_count++;
+		}
+	}
+
+	if (currAdapterPtr->skbQueue.qlen < SKB_QUEUE_MAX_SIZE)
+	{
+		skb_queue_tail(&currAdapterPtr->skbQueue, skb);	
+	}
+	else
+	{
+		isQueueFull = 1;
+	}
+DEQUEUE:
+	//ipsec_BH_handler_resultGet has no chance to set isHashPreCompute as 3, \
+	//so currAdapterPtr->lock is not needed here!
+	if (currAdapterPtr->isHashPreCompute == 3) //pre-compute done	
+	{		
+		int rdx = 0;
+	
+#ifdef MTK_EIP97_DRIVER
+		if (currAdapterPtr->isEncryptOrDecrypt==CRYPTO_ENCRYPTION)
+		{	
+			if ((currAdapterPtr->idx&0x2)==0)
+			{	
+			rdx = 0;
+				mcrypto_proc.dbg_pt[0]++;
+			}
+		else
+			{
+				mcrypto_proc.dbg_pt[1]++;	
+				rdx = 2;
+			}	
+		}
+		else
+		{
+			if ((currAdapterPtr->idx&0x2)==0)
+			{	
+				mcrypto_proc.dbg_pt[2]++;
+			rdx = 1;	
+			}
+			else
+			{
+				mcrypto_proc.dbg_pt[3]++;
+				rdx = 3;
+			}	
+		}	
+#endif
+		do
+		{
+			spin_lock(&cryptoLock[rdx]);
+			if (ipsec_eip93CmdResCnt_check(rdx)==false) {
+				spin_unlock(&cryptoLock[rdx]);
+				break;
+			}
+			pSkb = skb_dequeue(&currAdapterPtr->skbQueue);
+			if (pSkb==NULL)	{
+				spin_unlock(&cryptoLock[rdx]);
+				break;
+			}
+#ifdef MTK_EIP97_DRIVER
+			ipsec_packet_put(cmdHandler, pSkb, rdx); //mtk_packet_put
+#else
+			ipsec_packet_put(cmdHandler, pSkb); //mtk_packet_put
+#endif
+			spin_unlock(&cryptoLock[rdx]);
+
+		}while (1);
+
+		if (isQueueFull && (currAdapterPtr->skbQueue.qlen < SKB_QUEUE_MAX_SIZE))
+		{
+			isQueueFull = 0;
+			if (skb)
+				skb_queue_tail(&currAdapterPtr->skbQueue, skb);
+		}
+	}
+
+	if (isQueueFull == 0)
+	{
+		//spin_unlock(&currAdapterPtr->lock);
+
+		return HWCRYPTO_OK; //success
+	}
+	else
+	{
+		ra_dbg("-ENOMEM qlen=%d\n",currAdapterPtr->skbQueue.qlen);
+		mcrypto_proc.oom_in_put++;
+		if(skb2)
+		{	
+			kfree_skb(skb2);
+			//spin_unlock(&currAdapterPtr->lock);
+			return HWCRYPTO_NOMEM;
+		}
+		else
+		{
+			//spin_unlock(&currAdapterPtr->lock);
+			return -ENOMEM; //drop the packet
+		}
+}
+}
+
+/*_______________________________________________________________________
+**function name: ipsec_esp_output_finish
+**
+**description:
+*   Deal with the rest of Linux Kernel's esp_output(). Then,
+*	the encrypted packet can do the correct post-routing.
+**parameters:
+*   resHandler -- point to the result descriptor handler that stores
+*		the needed info comming from EIP93's Result Descriptor Ring.
+**global:
+*   none
+**return:
+*   none
+**call:
+*   ip_output()
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+static void 
+ipsec_esp_output_finish(
+	void *resHandler_ptr
+)
+{
+#if defined (MTK_EIP97_DRIVER)	
+	eip97DescpHandler_t *resHandler = resHandler_ptr;
+#else
+	eip93DescpHandler_t *resHandler = resHandler_ptr;
+#endif
+	struct sk_buff *skb;
+	struct iphdr *top_iph;
+	unsigned int length;
+	struct dst_entry *dst;
+	struct xfrm_state *x;
+	ipsecEip93Adapter_t *currAdapterPtr;
+	unsigned int *addrCurrAdapter;
+	struct net *net;
+	int err;
+	struct ip_esp_hdr *esph;
+		
+	skb = (struct sk_buff *) ipsec_eip93UserId_get(resHandler);
+	if (skb==NULL)
+	{	
+		printk("UserId got NULL skb in %s\n",__func__);
+		return;
+	}
+	addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+	currAdapterPtr = (ipsecEip93Adapter_t *)(*addrCurrAdapter);
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)	
+	if (currAdapterPtr->status==TBL_DEL)
+	{	
+		kfree_skb(skb);
+		return;
+	}
+#endif
+	top_iph = ip_hdr(skb);
+	dst = skb_dst(skb);
+	if (dst==NULL)
+	{	
+		printk("dst got NULL in %s\n",__func__);
+		dst = currAdapterPtr->dst;
+		if (dst==NULL)
+		{	
+			printk("currAdapterPtr->dst got NULL skb in %s\n",__func__);
+			kfree_skb(skb);
+			return;
+		}	
+		x = currAdapterPtr->x;
+	}
+	else
+		x = dst->xfrm;
+	if (x==NULL)
+	{	
+		
+		printk("xfrm got NULL x in %s\n",__func__);
+		x = currAdapterPtr->x;
+		if (x==NULL)
+		{	
+			printk("currAdapterPtr->xfrm got NULL x in %s\n",__func__);
+			kfree_skb(skb);
+			return;
+		}	
+	}
+	length = ipsec_pktLength_get(resHandler);
+	{
+		struct ip_esp_hdr *esph_seq = skb->data;
+		static struct sk_buff *skb_old = NULL;
+		static unsigned char* ptr = NULL;
+		//spin_lock(&currAdapterPtr->lock);
+		if ((currAdapterPtr->seqno_out+1) != ntohl(esph_seq->seq_no))
+		{	
+			if (ptr)
+				printk("seqno_out[%d]: length=%d %08X %08X [%08X %08X][%08X %08X],txpacket=%d\n", \
+						currAdapterPtr->idx, length, currAdapterPtr->seqno_out, \
+						ntohl(esph_seq->seq_no),skb_old, skb,ptr,skb->data,mcrypto_proc.dbg_pt[8]);	
+			else
+				printk("seqno_out[%d]: length=%d %08X %08X, txpacket=%d\n",	\
+						currAdapterPtr->idx, length, currAdapterPtr->seqno_out, \
+						ntohl(esph_seq->seq_no),mcrypto_proc.dbg_pt[8]);
+
+			mcrypto_proc.dbg_pt[15]++;
+		}
+		currAdapterPtr->seqno_out = ntohl(esph_seq->seq_no);	
+		skb_old = skb;
+		ptr = skb->data;	
+		//spin_unlock(&currAdapterPtr->lock);
+	}		
+
+	net = xs_net(x);
+	esph = ip_esp_hdr(skb);
+	
+	
+	skb_put(skb, length - skb->len); //adjust skb->tail
+
+	length += skb->data - skb_network_header(skb); //IP total length
+	
+	
+	__skb_push(skb, -skb_network_offset(skb));
+#ifdef RALINK_HWCRYPTO_NAT_T
+	//if (x->encap)
+	//	skb_push(skb, 8);
+#endif		
+
+	esph = ip_esp_hdr(skb);
+	*skb_mac_header(skb) = IPPROTO_ESP;	      
+#ifdef RALINK_HWCRYPTO_NAT_T
+	if (x->encap) {
+		struct xfrm_encap_tmpl *encap = x->encap;
+		struct udphdr *uh;
+		__be32 *udpdata32;
+		__be16 sport, dport;
+		int encap_type;
+
+		sport = encap->encap_sport;
+		dport = encap->encap_dport;
+		encap_type = encap->encap_type;
+
+		uh = (struct udphdr *)esph;
+		uh->source = sport;
+		uh->dest = dport;
+		uh->len = htons(skb->len - skb_transport_offset(skb));
+		uh->check = 0;
+	
+		switch (encap_type) {
+		default:
+		case UDP_ENCAP_ESPINUDP:
+			esph = (struct ip_esp_hdr *)(uh + 1);
+			break;
+		case UDP_ENCAP_ESPINUDP_NON_IKE:
+			udpdata32 = (__be32 *)(uh + 1);
+			udpdata32[0] = udpdata32[1] = 0;
+			esph = (struct ip_esp_hdr *)(udpdata32 + 2);
+			break;
+		}
+
+		*skb_mac_header(skb) = IPPROTO_UDP;
+		//__skb_push(skb, -skb_network_offset(skb));
+	}
+#endif
+
+	top_iph->tot_len = htons(length);
+	ip_send_check(top_iph);
+#ifdef 	RALINK_ESP_OUTPUT_POLLING	
+	goto out;
+#endif	
+	/* adjust for IPSec post-routing */
+	dst = skb_dst_pop(skb);
+	if (!dst) {
+		XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
+		err = -EHOSTUNREACH;
+		printk("(%d)ipsec_esp_output_finish EHOSTUNREACH\n",__LINE__);
+		kfree_skb(skb);
+		return;
+	}
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,36)	
+	skb_dst_set(skb, dst_clone(dst));
+#else
+	skb_dst_set(skb, dst);
+#endif	
+
+	if (skb_dst(skb)->xfrm)
+	{
+		x = dst->xfrm;
+		if (x->type->proto==IPPROTO_AH)
+		{
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+			extern int xfrm_skb_check_space(struct sk_buff *skb);
+			err = xfrm_skb_check_space(skb);
+#else
+			extern int xfrm_state_check_space(struct xfrm_state *x, struct sk_buff *skb);
+			err = xfrm_state_check_space(x, skb);
+#endif			
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTERROR\n",__LINE__);
+				kfree_skb(skb);
+				return;	
+			}
+	
+			err = x->outer_mode->output(x, skb);
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEMODEERROR);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTSTATEMODEERROR\n",__LINE__);
+				kfree_skb(skb);
+				return;	
+			}
+	
+			spin_lock_bh(&x->lock);
+			
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+			if (unlikely(x->km.state != XFRM_STATE_VALID)) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEINVALID);
+				spin_unlock_bh(&x->lock);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTSTATEINVALID\n",__LINE__);
+				kfree_skb(skb);
+				return;	
+			}
+#endif
+			err = xfrm_state_check_expire(x);
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEEXPIRED);
+				spin_unlock_bh(&x->lock);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTSTATEEXPIRED\n",__LINE__);
+				kfree_skb(skb);
+				return;	
+			}
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+			err = x->repl->overflow(x, skb);
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATESEQERROR);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTSTATESEQERROR\n",__LINE__);
+				kfree_skb(skb);
+				return;
+			}
+#else	
+			if (x->type->flags & XFRM_TYPE_REPLAY_PROT) {
+				XFRM_SKB_CB(skb)->seq.output = ++x->replay.oseq;
+				if (unlikely(x->replay.oseq == 0)) {
+					XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATESEQERROR);
+					x->replay.oseq--;
+					xfrm_audit_state_replay_overflow(x, skb);
+					err = -EOVERFLOW;
+					spin_unlock_bh(&x->lock);
+					printk("(%d)ipsec_esp_output_finish -EOVERFLOW\n",__LINE__);
+					kfree_skb(skb);
+					return;
+				}
+				if (xfrm_aevent_is_on(net))
+					xfrm_replay_notify(x, XFRM_REPLAY_UPDATE);
+			}
+#endif	
+			x->curlft.bytes += skb->len;
+			x->curlft.packets++;
+			spin_unlock_bh(&x->lock);
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)			
+			skb_dst_force(skb);
+#endif			
+			err = x->type->output(x, skb);
+			top_iph = ip_hdr(skb);
+			ip_send_check(top_iph);
+			dst = skb_dst_pop(skb);
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,36)	
+			skb_dst_set(skb, dst_clone(dst));
+#else
+			skb_dst_set(skb, dst);
+#endif
+		}	
+	}
+
+	nf_reset(skb);
+
+	if (!skb_dst(skb)->xfrm)
+	{
+		mcrypto_proc.dbg_pt[8]++;
+		ip_output(skb);
+		return;
+	}
+		      
+	return;
+}
+
+static void 
+ipsec_esp6_output_finish(
+	eip93DescpHandler_t *resHandler
+)
+{
+	struct sk_buff *skb = (struct sk_buff *) ipsec_eip93UserId_get(resHandler);
+	struct ipv6hdr *top_iph = ipv6_hdr(skb);
+	unsigned int length;
+	struct dst_entry *dst = skb_dst(skb);
+	struct xfrm_state *x = dst->xfrm;
+	struct net *net = xs_net(x);
+	int err;
+
+	length = ipsec_pktLength_get(resHandler);
+
+	skb_put(skb, length - skb->len); //adjust skb->tail
+
+	__skb_push(skb, -skb_network_offset(skb));
+
+	*skb_mac_header(skb) = IPPROTO_ESP;	      
+
+	top_iph->payload_len = htons(length);
+
+	/* adjust for IPSec post-routing */
+	dst = skb_dst_pop(skb);
+	
+	if (!dst) {
+		XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
+		err = -EHOSTUNREACH;
+		printk("(%d)ipsec_esp_output_finish EHOSTUNREACH\n",__LINE__);
+		kfree_skb(skb);
+		return;
+	}
+	
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,36)	
+	skb_dst_set(skb, dst_clone(dst));
+#else
+	skb_dst_set(skb, dst);
+#endif
+
+	if (skb_dst(skb)->xfrm)
+	{
+		x = dst->xfrm;
+		if (x->type->proto==IPPROTO_AH)
+		{
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+			extern int xfrm_skb_check_space(struct sk_buff *skb);
+			err = xfrm_skb_check_space(skb);
+#else
+			extern int xfrm_state_check_space(struct xfrm_state *x, struct sk_buff *skb);
+			err = xfrm_state_check_space(x, skb);
+#endif
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTERROR\n",__LINE__);
+				kfree_skb(skb);
+				return;	
+			}
+	
+			err = x->outer_mode->output(x, skb);
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEMODEERROR);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTSTATEMODEERROR\n",__LINE__);
+				kfree_skb(skb);
+				return;	
+			}
+	
+			spin_lock_bh(&x->lock);
+			err = xfrm_state_check_expire(x);
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEEXPIRED);
+				spin_unlock_bh(&x->lock);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTSTATEEXPIRED\n",__LINE__);
+				kfree_skb(skb);
+				return;	
+			}
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+			err = x->repl->overflow(x, skb);
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATESEQERROR);
+				printk("(%d)ipsec_esp_output_finish LINUX_MIB_XFRMOUTSTATESEQERROR\n",__LINE__);
+				kfree_skb(skb);
+				return;
+			}
+#else	
+			if (x->type->flags & XFRM_TYPE_REPLAY_PROT) {
+				XFRM_SKB_CB(skb)->seq.output = ++x->replay.oseq;
+				if (unlikely(x->replay.oseq == 0)) {
+					XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATESEQERROR);
+					x->replay.oseq--;
+					xfrm_audit_state_replay_overflow(x, skb);
+					err = -EOVERFLOW;
+					spin_unlock_bh(&x->lock);
+					printk("(%d)ipsec_esp_output_finish -EOVERFLOW\n",__LINE__);
+					kfree_skb(skb);
+					return;
+				}
+				if (xfrm_aevent_is_on(net))
+					xfrm_replay_notify(x, XFRM_REPLAY_UPDATE);
+			}
+#endif
+	
+			x->curlft.bytes += skb->len;
+			x->curlft.packets++;
+			spin_unlock_bh(&x->lock);
+			err = x->type->output(x, skb);
+			dst = skb_dst_pop(skb);
+	#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,36)	
+			skb_dst_set(skb, dst_clone(dst));
+	#else
+			skb_dst_set(skb, dst);
+	#endif
+		}
+	}
+
+	nf_reset(skb);
+
+	if (!skb_dst(skb)->xfrm)
+	{
+		mcrypto_proc.dbg_pt[8]++;
+		dst_output(skb);
+		return;
+	}
+
+	return;
+}
+
+/*_______________________________________________________________________
+**function name: ipsec_esp_input_finish
+**
+**description:
+*   Deal with the rest of Linux Kernel's esp_input(). Then,
+*	the decrypted packet can do the correct post-routing.
+**parameters:
+*   resHandler -- point to the result descriptor handler that stores
+*		the needed info comming from EIP93's Result Descriptor Ring.
+*   x -- point to the structure that stores IPSec SA information
+**global:
+*   none
+**return:
+*   none
+**call:
+*   netif_rx() for tunnel mode, or xfrm4_rcv_encap_finish() for transport
+*		mode.
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+static void 
+ipsec_esp_input_finish(
+	void *resHandler_ptr, 
+	struct xfrm_state *x
+)
+{
+#if defined (MTK_EIP97_DRIVER)	
+	eip97DescpHandler_t *resHandler = resHandler_ptr;
+#else
+	eip93DescpHandler_t *resHandler = resHandler_ptr;
+#endif	
+	struct sk_buff *skb = (struct sk_buff *) ipsec_eip93UserId_get(resHandler);
+	struct iphdr *iph;
+	unsigned int ihl, pktLen;
+	struct esp_data *esp = x->data;
+	int decaps = 0;
+	__be32 spi, seq;
+	int err;
+	struct net *net = dev_net(skb->dev);
+	int nexthdr = 0;
+	struct xfrm_mode *inner_mode = x->inner_mode;
+	int async = 0;
+	struct ip_esp_hdr *esph = (struct ip_esp_hdr *)skb->data;	
+	ipsecEip93Adapter_t *currAdapterPtr;
+	unsigned int *addrCurrAdapter;
+
+	addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+	currAdapterPtr = (ipsecEip93Adapter_t *)(*addrCurrAdapter);
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+	if (currAdapterPtr->status==TBL_DEL)
+	{	
+		kfree_skb(skb);
+		return;
+	}
+#endif
+	spi = currAdapterPtr->spi;
+
+#if defined (MTK_EIP97_DRIVER)
+	seq = resHandler->seq_no;
+#else
+	esph->seq_no = htonl(ipsec_espSeqNum_get(resHandler));
+	seq = esph->seq_no;
+	esph->spi = spi;
+#endif
+	skb->ip_summed = CHECKSUM_NONE;	
+	iph = ip_hdr(skb);
+	ihl = iph->ihl << 2;
+	if (x->props.mode == XFRM_MODE_TRANSPORT)
+	{	
+		iph->protocol = ipsec_espNextHeader_get(resHandler);
+		nexthdr = iph->protocol;
+	}
+	else	
+		nexthdr	= ipsec_espNextHeader_get(resHandler);
+
+	//adjest skb->tail & skb->len
+	pktLen = ipsec_pktLength_get(resHandler);
+	//*(skb->data-20+9) = 0x32;
+#ifdef RALINK_HWCRYPTO_NAT_T	
+	if (x->encap) {
+		struct xfrm_encap_tmpl *encap = x->encap;
+		struct udphdr *uh = (void *)(skb_network_header(skb) + ihl);
+
+		/*
+		 * 1) if the NAT-T peer's IP or port changed then
+		 *    advertize the change to the keying daemon.
+		 *    This is an inbound SA, so just compare
+		 *    SRC ports.
+		 */
+		if (iph->saddr != x->props.saddr.a4 ||
+		    uh->source != encap->encap_sport) {
+			xfrm_address_t ipaddr;
+
+			ipaddr.a4 = iph->saddr;
+			km_new_mapping(x, &ipaddr, uh->source);
+
+			/* XXX: perhaps add an extra
+			 * policy check here, to see
+			 * if we should allow or
+			 * reject a packet from a
+			 * different source
+			 * address/port.
+			 */
+		}
+
+		/*
+		 * 2) ignore UDP/TCP checksums in case
+		 *    of NAT-T in Transport Mode, or
+		 *    perform other post-processing fixes
+		 *    as per draft-ietf-ipsec-udp-encaps-06,
+		 *    section 3.1.2
+		 */
+		if (x->props.mode == XFRM_MODE_TRANSPORT)
+			skb->ip_summed = CHECKSUM_UNNECESSARY;
+	}
+#endif
+	skb->len = pktLen;
+	skb_set_tail_pointer(skb, pktLen);
+#if !defined (MTK_EIP97_DRIVER)
+	__skb_pull(skb, crypto_aead_ivsize(esp->aead));
+#endif	
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,10,14)	
+	skb_set_transport_header(skb, -ihl);
+#else	
+	if (x->props.mode == XFRM_MODE_TUNNEL)
+		skb_reset_transport_header(skb);
+	else
+		skb_set_transport_header(skb, -ihl);
+#endif		
+
+	/* adjust for IPSec post-routing */
+	spin_lock(&x->lock);
+	if (nexthdr <= 0) {
+		if (nexthdr == -EBADMSG) {
+			xfrm_audit_state_icvfail(x, skb, x->type->proto);
+			x->stats.integrity_failed++;
+		}
+		XFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEPROTOERROR);
+		printk("(%d)ipsec_esp_input_finish LINUX_MIB_XFRMINSTATEPROTOERROR nexthdr=%x\n",__LINE__,nexthdr);
+		spin_unlock(&x->lock);
+		goto drop;
+	}
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,36)
+	if (x->props.replay_window)
+			xfrm_replay_advance(x, seq);
+#else	
+	if (async && x->repl->recheck(x, skb, seq)) {
+			XFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATESEQERROR);
+			spin_unlock(&x->lock);
+			goto drop;
+		}
+		x->repl->advance(x, seq);
+#endif
+
+	x->curlft.bytes += skb->len;
+	x->curlft.packets++;
+	spin_unlock(&x->lock);
+
+	XFRM_MODE_SKB_CB(skb)->protocol = nexthdr;
+
+	inner_mode = x->inner_mode;
+
+	if (x->sel.family == AF_UNSPEC) {
+		inner_mode = xfrm_ip2inner_mode(x, XFRM_MODE_SKB_CB(skb)->protocol);
+		if (inner_mode == NULL)
+		{
+			printk("(%d)ipsec_esp_input_finish inner_mode NULL\n",__LINE__);	
+			goto drop;
+		}	
+	}
+
+	if (inner_mode->input(x, skb)) {
+		printk("(%d)ipsec_esp_input_finish LINUX_MIB_XFRMINSTATEMODEERROR\n",__LINE__);
+		XFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEMODEERROR);
+		goto drop;
+	}
+
+	if (x->outer_mode->flags & XFRM_MODE_FLAG_TUNNEL) {
+		decaps = 1;
+	}
+	else
+	{	
+		/*
+		 * We need the inner address.  However, we only get here for
+		 * transport mode so the outer address is identical.
+		 */
+		
+		err = xfrm_parse_spi(skb, nexthdr, &spi, &seq);
+		if (err < 0) {
+			printk("(%d)ipsec_esp_input_finish LINUX_MIB_XFRMINHDRERROR\n",__LINE__);
+			XFRM_INC_STATS(net, LINUX_MIB_XFRMINHDRERROR);
+			goto drop;
+		}
+	}
+
+	nf_reset(skb);
+	mcrypto_proc.dbg_pt[9]++;
+#ifdef MTK_EIP97_IPI
+	if (decaps) {
+		skb_dst_drop(skb);
+		mcrypto_proc.dbg_pt[10]++;
+		if (mcrypto_proc.ipicpu[0] < 0)
+			netif_rx(skb);
+		else
+		{	
+			skb_queue_tail(&currAdapterPtr->skbIPIQueue, skb);
+			if (currAdapterPtr->skbIPIQueue.qlen > 100)
+			{
+				smp_call_function_single(mcrypto_proc.ipicpu[0], smp_func_call ,currAdapterPtr, 0);
+			}
+		}	
+		return ;
+	} else {
+		if (mcrypto_proc.ipicpu[0] < 0)
+		{	
+			async = 1;
+			mcrypto_proc.dbg_pt[5]++;
+			x->inner_mode->afinfo->transport_finish(skb, async);
+		}
+		else
+		{		
+			skb_queue_tail(&currAdapterPtr->skbIPIQueue, skb);
+			if (currAdapterPtr->skbIPIQueue.qlen > 100)
+			{
+				smp_call_function_single(mcrypto_proc.ipicpu[0], smp_func_call ,currAdapterPtr, 0);
+			}
+		}
+		return;
+}
+#else
+if (decaps) {
+		skb_dst_drop(skb);
+		netif_rx(skb);
+		return ;
+	} else {
+		async = 1;
+		x->inner_mode->afinfo->transport_finish(skb, async);
+		return;
+	}
+#endif	
+
+drop:
+	printk("(%d)%s:drop\n",__LINE__,__func__);
+	kfree_skb(skb);
+	return;
+}
+
+static void 
+ipsec_esp6_input_finish(
+	eip93DescpHandler_t *resHandler, 
+	struct xfrm_state *x
+)
+{
+	struct sk_buff *skb = (struct sk_buff *) ipsec_eip93UserId_get(resHandler);
+	struct ipv6hdr *iph;
+	unsigned int ihl, pktLen;
+	struct esp_data *esp = x->data;
+	int decaps = 0;
+	__be32 spi, seq;
+	int err;
+	struct net *net = dev_net(skb->dev);
+	int nexthdr = 0;
+	struct xfrm_mode *inner_mode = x->inner_mode;
+	int async = 0;
+	struct ip_esp_hdr *esph = (struct ip_esp_hdr *)skb->data;
+	ipsecEip93Adapter_t *currAdapterPtr;
+	unsigned int *addrCurrAdapter;
+
+	addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+	currAdapterPtr = (ipsecEip93Adapter_t *)(*addrCurrAdapter);
+
+	esph->seq_no = htonl(ipsec_espSeqNum_get(resHandler));
+	esph->spi = currAdapterPtr->spi;
+
+	skb->ip_summed = CHECKSUM_NONE;	
+	iph = ipv6_hdr(skb);
+	ihl = 40;	
+	iph->nexthdr = ipsec_espNextHeader_get(resHandler);
+	nexthdr = iph->nexthdr;
+		
+	//adjest skb->tail & skb->len
+	pktLen = ipsec_pktLength_get(resHandler);
+
+	//*(skb->data-20+9) = 0x32;
+	skb->len = pktLen;
+	skb_set_tail_pointer(skb, pktLen);
+	__skb_pull(skb, crypto_aead_ivsize(esp->aead));
+	
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,10,14)
+	skb_set_transport_header(skb, -ihl);
+#else	
+	if (x->props.mode == XFRM_MODE_TUNNEL)
+		skb_reset_transport_header(skb);
+	else
+		skb_set_transport_header(skb, -ihl);
+#endif
+	
+	/* adjust for IPSec post-routing */
+	spin_lock(&x->lock);
+	if (nexthdr <= 0) {
+		if (nexthdr == -EBADMSG) {
+			xfrm_audit_state_icvfail(x, skb, x->type->proto);
+			x->stats.integrity_failed++;
+		}
+		XFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEPROTOERROR);
+		printk("(%d)ipsec_esp_input_finish LINUX_MIB_XFRMINSTATEPROTOERROR\n",__LINE__);
+		spin_unlock(&x->lock);
+		goto drop;
+	}
+
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,36)
+	if (x->props.replay_window)
+			xfrm_replay_advance(x, esph->seq_no);
+#else	
+	seq = esph->seq_no;
+	if (async && x->repl->recheck(x, skb, seq)) {
+			XFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATESEQERROR);
+			spin_unlock(&x->lock);
+			goto drop;
+	}
+	x->repl->advance(x, seq);
+#endif
+
+	x->curlft.bytes += skb->len;
+	x->curlft.packets++;
+	spin_unlock(&x->lock);
+
+	XFRM_MODE_SKB_CB(skb)->protocol = nexthdr;
+
+	inner_mode = x->inner_mode;
+
+	if (x->sel.family == AF_UNSPEC) {
+		inner_mode = xfrm_ip2inner_mode(x, XFRM_MODE_SKB_CB(skb)->protocol);
+		if (inner_mode == NULL)
+		{
+			printk("(%d)ipsec_esp_input_finish inner_mode NULL\n",__LINE__);	
+			goto drop;
+		}	
+	}
+
+	if (inner_mode->input(x, skb)) {
+		printk("(%d)ipsec_esp_input_finish LINUX_MIB_XFRMINSTATEMODEERROR\n",__LINE__);
+		XFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEMODEERROR);
+		goto drop;
+	}
+
+	if (x->outer_mode->flags & XFRM_MODE_FLAG_TUNNEL) {
+		decaps = 1;
+	}
+	else
+	{	
+		/*
+		 * We need the inner address.  However, we only get here for
+		 * transport mode so the outer address is identical.
+		 */
+	
+		err = xfrm_parse_spi(skb, nexthdr, &spi, &seq);
+		if (err < 0) {
+			printk("(%d)ipsec_esp_input_finish LINUX_MIB_XFRMINHDRERROR\n",__LINE__);
+			XFRM_INC_STATS(net, LINUX_MIB_XFRMINHDRERROR);
+			goto drop;
+		}
+	}
+
+	nf_reset(skb);
+	mcrypto_proc.dbg_pt[9]++;
+	if (decaps) {
+		skb_dst_drop(skb);
+		netif_rx(skb);
+		return ;
+	} else {
+		async = 1;
+		x->inner_mode->afinfo->transport_finish(skb, async);
+		return;
+	}	
+
+drop:
+	printk("(%d)%s:drop\n",__LINE__,__func__);
+	kfree_skb(skb);
+	return;
+}
+/************************************************************************
+*              P U B L I C     F U N C T I O N S
+*************************************************************************
+*/
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+void 
+ipsec_eip93Adapter_clean(
+	unsigned int index, ipsecEip93Adapter_t *currAdapterPtr, unsigned int dir
+)
+{
+	unsigned char* ptr;
+	addrHandler_t tmpaddr;
+	addrsDigestPreCompute_t* addrsPreCompute;
+#if defined (MTK_EIP97_DRIVER)	
+	eip97DescpHandler_t *cmdHandler;
+#else
+	eip93DescpHandler_t *cmdHandler;
+#endif	
+	currAdapterPtr->seqno_out = 0;
+	currAdapterPtr->seqno_in = 0;	
+	currAdapterPtr->isHashPreCompute = 0;
+	
+	addrsPreCompute = currAdapterPtr->addrsPreCompute;	
+	
+	tmpaddr.addr = addrsPreCompute->RecPoolHandler.addr;
+	tmpaddr.phyAddr = addrsPreCompute->RecPoolHandler.phyAddr;
+	ptr = addrsPreCompute->LocalPool;
+	cmdHandler = addrsPreCompute->cmdHandler;
+	memset(addrsPreCompute, 0 , sizeof(addrsDigestPreCompute_t));
+#if defined (MTK_EIP97_DRIVER)	
+	memset(cmdHandler, 0 , sizeof(eip97DescpHandler_t));
+#else
+	memset(cmdHandler, 0 , sizeof(eip93DescpHandler_t));
+#endif	
+	addrsPreCompute->cmdHandler = cmdHandler;	
+	addrsPreCompute->RecPoolHandler.size = RECPOOLSIZE;
+	addrsPreCompute->RecPoolHandler.addr = tmpaddr.addr;
+	addrsPreCompute->RecPoolHandler.phyAddr = tmpaddr.phyAddr;
+	memset(addrsPreCompute->RecPoolHandler.addr, 0, RECPOOLSIZE);
+	
+	addrsPreCompute->LocalPool = ptr;
+	addrsPreCompute->hashKeyTank = addrsPreCompute->LocalPool + HASHKEYTANK_OFFSET;
+	addrsPreCompute->pIDigest = addrsPreCompute->LocalPool + PRECOMPUTE_IDIGEST_OFFSET;
+	addrsPreCompute->pODigest = addrsPreCompute->LocalPool + PRECOMPUTE_ODIGEST_OFFSET;
+	
+	memset(addrsPreCompute->LocalPool, 0, LOCALPOOLSIZE);
+	
+	
+	cmdHandler = currAdapterPtr->cmdHandler;
+#if defined (MTK_EIP97_DRIVER)
+	cmdHandler->pIDigest = cmdHandler->LocalPool + CMD_IDIGEST_OFFSET;
+	cmdHandler->pODigest = cmdHandler->LocalPool + CMD_ODIGEST_OFFSET;
+	memset(cmdHandler->LocalPool, 0, CMDLOCALPOOLSIZE);
+#endif	
+	memset(cmdHandler->saAddr.addr, 0, SAPOOLSIZE);
+	
+	if (dir==HASH_DIGEST_OUT)
+	{	
+		spi_outbound_tbl[index] = 0xFFFFFFFF;
+		mcrypto_proc.dbg_pt[11] &= ~(1<<index);
+	}
+	else
+	{	
+		spi_inbound_tbl[index] = 0xFFFFFFFF;
+		mcrypto_proc.dbg_pt[11] &= ~(1<<(index+IPESC_EIP93_ADAPTERS));
+	}
+	if (currAdapterPtr->skbQueue.qlen > 0 )
+		printk("CONN_%s[%d] qlen=%d\n",(dir==HASH_DIGEST_IN)? "IN" : "OUT",index,currAdapterPtr->skbQueue.qlen);
+	while (currAdapterPtr->skbQueue.qlen > 0)
+	{
+		struct sk_buff *pSkb = skb_dequeue(&currAdapterPtr->skbQueue);
+		if (pSkb)
+			kfree_skb(pSkb);
+	}
+	currAdapterPtr->packet_count = 0;
+	currAdapterPtr->status = TBL_EMPTY;
+}
+#endif
+void 
+ipsec_eip93Adapter_mark_free(
+	unsigned int spi
+)
+{
+	unsigned int i;
+	ipsecEip93Adapter_t *currAdapterPtr;
+	spin_lock_bh(&ipsec_adapters_outlock);
+	for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+	{
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+		if (spi_outbound_tbl[i] == spi)
+		{
+			currAdapterPtr = ipsecEip93AdapterListOut[i];
+			spin_lock(&currAdapterPtr->lock);
+			if (currAdapterPtr->packet_count <= 0)
+			{
+				spin_unlock(&currAdapterPtr->lock);
+				printk("free AdapterListOut[%d] spi=%x packet_count=%d\n",i,spi,currAdapterPtr->packet_count);					
+				ipsec_eip93Adapter_clean(i, currAdapterPtr, HASH_DIGEST_OUT);
+			}
+			else
+			{	
+				spin_unlock(&currAdapterPtr->lock);
+				currAdapterPtr->status = TBL_DEL;
+				mcrypto_proc.dbg_pt[11] |= (1<<i);
+				printk("mark free AdapterListOut[%d] currAdapterPtr=%08X \
+						packet_count=%d \n",i,currAdapterPtr,currAdapterPtr->packet_count);
+			}
+			break;
+		}
+#else
+		if ((currAdapterPtr = ipsecEip93AdapterListOut[i]) != NULL)
+		{
+			if (currAdapterPtr->spi == spi)
+			{
+				if (currAdapterPtr->packet_count <= 0)
+				{
+					printk("free AdapterListOut[%d] spi=%x \n",i,spi);
+					ipsec_cmdHandler_free(currAdapterPtr->cmdHandler);
+					kfree(currAdapterPtr);
+					ipsecEip93AdapterListOut[i] = NULL;
+					mcrypto_proc.dbg_pt[3] &= ~(1<<i);
+				}
+				else
+				{	
+					currAdapterPtr->status = TBL_DEL;
+					mcrypto_proc.dbg_pt[3] |= (1<<i);
+					printk("mark free AdapterListOut[%d] currAdapterPtr=%08X \
+							packet_count=%d \n",i,currAdapterPtr,currAdapterPtr->packet_count);
+				}
+				spin_unlock_bh(&ipsec_adapters_outlock);
+				return;
+			}
+		}
+#endif
+	}
+	spin_unlock_bh(&ipsec_adapters_outlock);
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+	if (i < IPESC_EIP93_ADAPTERS)
+		return;
+#endif
+	spin_lock_bh(&ipsec_adapters_inlock);
+	for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+	{
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+		if (spi_inbound_tbl[i] == spi)
+		{
+			currAdapterPtr = ipsecEip93AdapterListIn[i];
+			spin_lock(&currAdapterPtr->lock);
+			if (currAdapterPtr->packet_count <= 0)
+			{
+				spin_unlock(&currAdapterPtr->lock);
+				printk("free AdapterListIn[%d] spi=%x packet_count=%d\n",i,spi,currAdapterPtr->packet_count);
+				ipsec_eip93Adapter_clean(i, currAdapterPtr, HASH_DIGEST_IN);
+			}
+			else
+			{
+				spin_unlock(&currAdapterPtr->lock);
+				printk("mark free AdapterListIn[%d] currAdapterPtr=%08X \
+						packet_count=%d \n",i,currAdapterPtr,currAdapterPtr->packet_count);
+				currAdapterPtr->status = TBL_DEL;
+				mcrypto_proc.dbg_pt[11] |= (1<<(i+IPESC_EIP93_ADAPTERS));
+			}
+			break;
+		}
+#else
+		if ((currAdapterPtr = ipsecEip93AdapterListIn[i]) != NULL)
+		{
+			if (currAdapterPtr->spi == spi)
+			{
+				if (currAdapterPtr->packet_count <= 0)
+				{
+					printk("free AdapterListIn[%d] spi=%x \n",i,spi);
+					ipsec_cmdHandler_free(currAdapterPtr->cmdHandler);
+					kfree(currAdapterPtr);
+					ipsecEip93AdapterListIn[i] = NULL;
+					mcrypto_proc.dbg_pt[3] &= ~(1<<(i+IPESC_EIP93_ADAPTERS));
+				}
+				else
+				{
+					printk("mark free AdapterListIn[%d] currAdapterPtr=%08X\
+						   	packet_count=%d \n",i,currAdapterPtr,currAdapterPtr->packet_count);
+					currAdapterPtr->status = TBL_DEL;
+					mcrypto_proc.dbg_pt[3] |= (1<<(i+IPESC_EIP93_ADAPTERS));
+				}
+				spin_unlock_bh(&ipsec_adapters_inlock);
+				return;
+			}
+		}
+#endif
+	}
+	spin_unlock_bh(&ipsec_adapters_inlock);
+	if (i == IPESC_EIP93_ADAPTERS)
+	printk("(%d)%s: spi=%x not found!!\n",__LINE__,__func__,spi);
+
+}
+
+void 
+ipsec_eip93Adapter_free(
+	unsigned int spi
+)
+{
+	unsigned int i;
+	ipsecEip93Adapter_t *currAdapterPtr;
+	printk("(%d)%s:free spi=%x \n",__LINE__,__func__,spi);
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+	spin_lock(&ipsec_adapters_outlock);
+	for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+	{
+		if (spi_outbound_tbl[i] == spi)
+		{
+			currAdapterPtr = ipsecEip93AdapterListOut[i];			
+			ipsec_eip93Adapter_clean(i, currAdapterPtr, HASH_DIGEST_OUT);
+			break;
+		}
+	}
+	spin_unlock(&ipsec_adapters_outlock);
+#else
+	spin_lock(&ipsec_adapters_outlock);
+	for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+	{
+		if ((currAdapterPtr = ipsecEip93AdapterListOut[i]) != NULL)
+		{
+			if (currAdapterPtr->spi == spi)
+			{
+				ipsec_cmdHandler_free(currAdapterPtr->cmdHandler);
+				kfree(currAdapterPtr);
+				ipsecEip93AdapterListOut[i] = NULL;
+				spin_unlock(&ipsec_adapters_outlock);
+				return;
+			}
+		}
+	}
+	spin_unlock(&ipsec_adapters_outlock);
+#endif
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+if (i < IPESC_EIP93_ADAPTERS)
+		return;
+	spin_lock(&ipsec_adapters_inlock);
+	for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+	{
+		if (spi_inbound_tbl[i] == spi)
+		{
+			currAdapterPtr = ipsecEip93AdapterListIn[i];
+			ipsec_eip93Adapter_clean(i, currAdapterPtr, HASH_DIGEST_IN);
+			break;
+		}
+	}
+	spin_unlock(&ipsec_adapters_inlock);
+	if (i == IPESC_EIP93_ADAPTERS)
+		printk("(%d)%s: spi=%x not found!!\n",__LINE__,__func__,spi);
+#else
+	spin_lock(&ipsec_adapters_inlock);
+	for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+	{
+		if ((currAdapterPtr = ipsecEip93AdapterListIn[i]) != NULL)
+		{
+			if (currAdapterPtr->spi == spi)
+			{
+				ipsec_cmdHandler_free(currAdapterPtr->cmdHandler);
+				kfree(currAdapterPtr);
+				ipsecEip93AdapterListIn[i] = NULL;
+				spin_unlock(&ipsec_adapters_inlock);
+				return;
+			}
+		}
+	}
+	spin_unlock(&ipsec_adapters_inlock);
+#endif
+}
+/*_______________________________________________________________________
+**function name: ipsec_esp_output
+**
+**description:
+*   Replace Linux Kernel's esp_output(), in order to use EIP93
+*	to do encryption for a IPSec ESP flow.
+**parameters:
+*   x -- point to the structure that stores IPSec SA information
+*	skb -- the packet that is going to be encrypted.
+**global:
+*   none
+**return:
+*   -EPERM, -ENOMEM -- failed: the pakcet will be dropped!
+*	1 -- success: the packet's command decsriptor is put into
+*		EIP93's Command Descriptor Ring.
+**call:
+*   none
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+int 
+ipsec_esp_output(
+	struct xfrm_state *x, 
+	struct sk_buff *skb
+)
+{
+	ipsecEip93Adapter_t *currAdapterPtr;
+	int err;
+	eip93DescpHandler_t *cmdHandler;
+	struct iphdr *top_iph = ip_hdr(skb);
+	unsigned int *addrCurrAdapter;
+	
+	err = ipsec_esp_preProcess(x, skb, HASH_DIGEST_OUT);
+	if (err < 0)
+	{
+		printk("\n\n ipsec_esp_preProcess for HASH_DIGEST_OUT failed! \n\n");
+		return -EINPROGRESS;
+	}
+
+	if (err == HWCRYPTO_PREPROCESS_DROP)
+	{
+		return HWCRYPTO_OK;
+	}	
+	addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+	currAdapterPtr = (ipsecEip93Adapter_t *)(*addrCurrAdapter);
+	cmdHandler = currAdapterPtr->cmdHandler;
+
+#ifdef RALINK_HWCRYPTO_NAT_T
+#else		
+	/* this is non-NULL only with UDP Encapsulation for NAT-T */
+	if (unlikely(x->encap)) 
+	{		
+		printk("\n\n NAT-T is not supported yet! \n\n");
+		//return -EPERM;
+		return -EINPROGRESS;
+	}
+#endif	
+	/* in case user will change between tunnel and transport mode,
+	 * we have to set "padValue" every time before every packet 
+	 * goes into EIP93 for esp outbound! */
+	ipsec_espNextHeader_set(cmdHandler, top_iph->protocol);
+	//let skb->data point to the payload which is going to be encrypted
+	if (x->encap==0)	
+		__skb_pull(skb, skb_transport_offset(skb));
+
+#if defined (FEATURE_AVOID_QUEUE_PACKET)
+	err = ipsec_esp_pktPut(NULL, skb);
+	return err;
+#else
+	return ipsec_esp_pktPut(NULL, skb);
+#endif
+}
+
+int ipsec_esp6_output(
+	struct xfrm_state *x, 
+	struct sk_buff *skb
+)
+{
+	ipsecEip93Adapter_t *currAdapterPtr;
+	int err;
+	eip93DescpHandler_t *cmdHandler;
+	struct ipv6hdr *top_iph = ipv6_hdr(skb);
+	unsigned int *addrCurrAdapter;
+
+	err = ipsec_esp_preProcess(x, skb, HASH_DIGEST_OUT);
+	if (err < 0)
+	{
+		printk("\n\n ipsec_esp_preProcess for HASH_DIGEST_OUT failed! \n\n");
+		return err;
+	}
+
+	if (err == HWCRYPTO_PREPROCESS_DROP)
+	{
+		return HWCRYPTO_OK;
+	}	
+	
+	addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+	currAdapterPtr = (ipsecEip93Adapter_t *)(*addrCurrAdapter);
+	cmdHandler = currAdapterPtr->cmdHandler;	
+#ifdef RALINK_HWCRYPTO_NAT_T
+#else		
+	/* this is non-NULL only with UDP Encapsulation for NAT-T */
+	if (unlikely(x->encap)) 
+	{		
+		printk("\n\n NAT-T is not supported yet! \n\n");
+		return -EPERM;
+	}
+#endif	
+	/* in case user will change between tunnel and transport mode,
+	 * we have to set "padValue" every time before every packet 
+	 * goes into EIP93 for esp outbound! */
+
+	ipsec_espNextHeader_set(cmdHandler, top_iph->nexthdr);
+	//let skb->data point to the payload which is going to be encrypted
+	if (x->encap==0)	
+		__skb_pull(skb, skb_transport_offset(skb));
+
+	return ipsec_esp_pktPut(NULL, skb);
+
+}
+/*_______________________________________________________________________
+**function name: ipsec_esp_input
+**
+**description:
+*   Replace Linux Kernel's esp_input(), in order to use EIP93
+*	to do decryption for a IPSec ESP flow.
+**parameters:
+*   x -- point to the structure that stores IPSec SA information
+*	skb -- the packet that is going to be decrypted.
+**global:
+*   none
+**return:
+*   -EPERM, -ENOMEM -- failed: the pakcet will be dropped!
+*	1 -- success: the packet's command decsriptor is put into
+*		EIP93's Command Descriptor Ring.
+**call:
+*   none
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+int 
+ipsec_esp_input(
+	struct xfrm_state *x, 
+	struct sk_buff *skb
+)
+{	
+	int err;
+	struct esp_data *esp = x->data;
+	int blksize = ALIGN(crypto_aead_blocksize(esp->aead), 4);
+	int alen = crypto_aead_authsize(esp->aead);
+	int elen = skb->len - sizeof(struct ip_esp_hdr) - crypto_aead_ivsize(esp->aead) - alen;	
+
+	err = ipsec_esp_preProcess(x, skb, HASH_DIGEST_IN);
+	if (err < 0)
+	{
+		printk("\n\n ipsec_esp_preProcess for HASH_DIGEST_IN failed! \n\n");
+		return err;
+	}
+
+	if (err == HWCRYPTO_PREPROCESS_DROP)
+	{
+		return HWCRYPTO_OK;
+	}	
+	
+	{
+		ipsecEip93Adapter_t *currAdapterPtr;
+		unsigned int *addrCurrAdapter;
+		static struct sk_buff *skb_old = NULL;
+		static unsigned char* ptr = NULL;
+		struct ip_esp_hdr *esph = skb->data;
+		addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+		currAdapterPtr = (ipsecEip93Adapter_t *)(*addrCurrAdapter);
+		unsigned int seqno_in = 0;	
+		spin_lock(&currAdapterPtr->seqlock);
+		seqno_in = currAdapterPtr->seqno_in; 
+		if ((seqno_in+1) != ntohl(esph->seq_no))
+		{	
+			if (seqno_in >= ntohl(esph->seq_no))
+			{	
+			if (ptr)
+				ra_dbg("seqno_in[%d]: %08X %08X (%08X %08X) (%08X %08X)\n",	\
+						currAdapterPtr->idx,seqno_in,ntohl(esph->seq_no),skb_old,skb,ptr,skb->data);	
+			else
+				ra_dbg("seqno_in[%d]: %08X %08X (%08X %08X)\n",	\
+						currAdapterPtr->idx, seqno_in,ntohl(esph->seq_no));	
+			}
+			mcrypto_proc.dbg_pt[14]++;
+		}
+		currAdapterPtr->seqno_in = ntohl(esph->seq_no);
+		skb_old = skb;
+		ptr = skb->data;		
+		spin_unlock(&currAdapterPtr->seqlock);
+	}
+	if (!pskb_may_pull(skb, sizeof(struct ip_esp_hdr)))
+	{
+		printk("\n skb.len=%d esp_hdr=%d\n",skb->len,sizeof(struct ip_esp_hdr));	
+		goto out;
+	}
+
+	if (elen <= 0 || (elen & (blksize-1)))
+	{
+		printk("\n skb->len=%d elen=%d blksize=%d esp=%d iv=%d alen=%d\n",\
+				skb->len,elen,blksize,sizeof(struct ip_esp_hdr),crypto_aead_ivsize(esp->aead),alen);	
+		goto out;
+	}
+#ifdef RALINK_HWCRYPTO_NAT_T
+#else
+	if (x->encap) 
+	{
+		printk("\n !NAT-T is not supported! \n");
+		goto out;
+	}
+#endif
+
+	err = ipsec_esp_pktPut(NULL, skb);
+	return err;	
+
+out:
+	printk("\n Something's wrong! Go out! \n");
+	kfree_skb(skb);
+	//return -EINVAL;
+	return -EINPROGRESS;
+}
+
+int 
+ipsec_esp6_input(
+	struct xfrm_state *x, 
+	struct sk_buff *skb
+)
+{	
+	int err;
+	struct esp_data *esp = x->data;
+	int blksize = ALIGN(crypto_aead_blocksize(esp->aead), 4);
+	int alen = crypto_aead_authsize(esp->aead);
+	int elen = skb->len - sizeof(struct ip_esp_hdr) - crypto_aead_ivsize(esp->aead) - alen;	
+
+	err = ipsec_esp_preProcess(x, skb, HASH_DIGEST_IN);
+	if (err < 0)
+	{
+		printk("\n\n ipsec_esp_preProcess for HASH_DIGEST_IN failed! \n\n");
+		return err;
+	}
+
+	if (err == HWCRYPTO_PREPROCESS_DROP)
+	{
+		return HWCRYPTO_OK;
+	}	
+	
+	if (!pskb_may_pull(skb, sizeof(struct ip_esp_hdr)))
+	{	
+		printk("[%s]pskb_may_pull failed\n",__func__);
+		goto out;
+	}
+		
+	if (elen <= 0 || (elen & (blksize-1)))
+	{	
+		printk("[%s]elen=%d blksize=%d\n",__func__,elen,blksize);
+		goto out;
+	}
+#ifdef RALINK_HWCRYPTO_NAT_T
+#else
+	if (x->encap) 
+	{
+		printk("\n !NAT-T is not supported! \n");
+		goto out;
+	}
+#endif
+
+	err = ipsec_esp_pktPut(NULL, skb);
+	return err;	
+
+out:
+	printk("\n[%s] Something's wrong! Go out! \n",__func__);
+	return -EINVAL;
+}
+/************************************************************************
+*              E X T E R N E L     F U N C T I O N S
+*************************************************************************
+*/
+/*_______________________________________________________________________
+**function name: ipsec_eip93_adapters_init
+**
+**description:
+*   initialize ipsecEip93AdapterListOut[] and ipsecEip93AdapterListIn[]
+*	durin EIP93's initialization.
+**parameters:
+*   none
+**global:
+*   none
+**return:
+*   none
+**call:
+*   none
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+void 
+ipsec_eip93_adapters_init(
+	void
+)
+{
+	unsigned int i, j;
+	
+	for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+	{
+		ipsecEip93AdapterListOut[i] = NULL;
+		ipsecEip93AdapterListIn[i] = NULL;
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)
+		spi_outbound_tbl[i] = 0xFFFFFFFF;
+		spi_inbound_tbl[i] = 0xFFFFFFFF;
+#endif
+	}
+#if defined (CONFIG_HWCRYPTO_MEMPOOL)	
+	for (j = 0; j < 2; j++)
+	{
+		for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+		{
+			ipsecEip93Adapter_t *currAdapterPtr;
+#if defined (MTK_EIP97_DRIVER)			
+			eip97DescpHandler_t *cmdHandler;
+#else
+			eip93DescpHandler_t *cmdHandler;
+#endif			
+			addrsDigestPreCompute_t* addrsPreCompute;
+			
+			currAdapterPtr = (ipsecEip93Adapter_t *) kzalloc(sizeof(ipsecEip93Adapter_t), GFP_KERNEL);
+			addrsPreCompute = (addrsDigestPreCompute_t *) kzalloc(sizeof(addrsDigestPreCompute_t), GFP_KERNEL);
+#if defined (MTK_EIP97_DRIVER)			
+			cmdHandler = (eip97DescpHandler_t *) kzalloc(sizeof(eip97DescpHandler_t), GFP_KERNEL);
+#else
+			cmdHandler = (eip93DescpHandler_t *) kzalloc(sizeof(eip93DescpHandler_t), GFP_KERNEL);
+#endif			
+			currAdapterPtr->addrsPreCompute = addrsPreCompute;
+			addrsPreCompute->cmdHandler = cmdHandler;
+			
+			
+			addrsPreCompute->RecPoolHandler.size = RECPOOLSIZE;
+			addrsPreCompute->RecPoolHandler.addr = (unsigned int *) dma_alloc_coherent(NULL, addrsPreCompute->RecPoolHandler.size, &addrsPreCompute->RecPoolHandler.phyAddr, GFP_KERNEL);
+			memset(addrsPreCompute->RecPoolHandler.addr, 0, RECPOOLSIZE);
+			
+			addrsPreCompute->LocalPool = kzalloc(LOCALPOOLSIZE, GFP_KERNEL);
+			addrsPreCompute->hashKeyTank = addrsPreCompute->LocalPool + HASHKEYTANK_OFFSET;	
+			addrsPreCompute->pIDigest = addrsPreCompute->LocalPool + PRECOMPUTE_IDIGEST_OFFSET;
+			addrsPreCompute->pODigest = addrsPreCompute->LocalPool + PRECOMPUTE_ODIGEST_OFFSET;
+			
+#if defined (MTK_EIP97_DRIVER)			
+			cmdHandler = (eip97DescpHandler_t *) kzalloc(sizeof(eip97DescpHandler_t), GFP_KERNEL);
+#else
+			cmdHandler = (eip93DescpHandler_t *) kzalloc(sizeof(eip93DescpHandler_t), GFP_KERNEL);
+#endif
+			currAdapterPtr->cmdHandler = cmdHandler;
+#if defined (MTK_EIP97_DRIVER)			
+			cmdHandler->LocalPool = kzalloc(CMDLOCALPOOLSIZE, GFP_KERNEL);
+			cmdHandler->pIDigest = cmdHandler->LocalPool + CMD_IDIGEST_OFFSET;//kzalloc(512, GFP_KERNEL);
+			cmdHandler->pODigest = cmdHandler->LocalPool + CMD_ODIGEST_OFFSET;//kzalloc(512, GFP_KERNEL);
+#endif			
+			cmdHandler->saAddr.addr = dma_alloc_coherent(NULL, SAPOOLSIZE, &cmdHandler->saAddr.phyAddr, GFP_KERNEL);
+			if (j==0)
+			{	
+				ipsecEip93AdapterListOut[i] = currAdapterPtr;
+				ra_dbg("ipsecEip93AdapterListOut[%d]=%08X\n",i,currAdapterPtr);	
+			}
+			else
+			{	
+				ipsecEip93AdapterListIn[i] = currAdapterPtr;
+				ra_dbg("ipsecEip93AdapterListIn[%d]=%08X\n",i,currAdapterPtr);	
+			}
+	}
+	}
+#endif
+}
+
+/*_______________________________________________________________________
+**function name: ipsec_cryptoLock_init
+**
+**description:
+*   initialize cryptoLock durin EIP93's initialization. cryptoLock is
+*	used to make sure only one process can access EIP93 at a time.
+**parameters:
+*   none
+**global:
+*   none
+**return:
+*   none
+**call:
+*   none
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+void 
+ipsec_cryptoLock_init(
+	void
+)
+{
+	int i;
+	for ( i = 0 ; i < NUM_CMD_RING; i++ )
+		spin_lock_init(&cryptoLock[i]);
+	
+	spin_lock_init(&ipsec_adapters_outlock);
+	spin_lock_init(&ipsec_adapters_inlock);
+}
+
+EXPORT_SYMBOL(ipsec_eip93_adapters_init);
+EXPORT_SYMBOL(ipsec_cryptoLock_init);
+
+/*_______________________________________________________________________
+**function name: ipsec_BH_handler_resultGet
+**
+**description:
+*   This tasklet is raised by EIP93's interrupt after EIP93 finishs
+*	a command descriptor and puts the result in Result Descriptor Ring.
+*	This tasklet gets a result descriptor from EIP93 at a time and do
+*	the corresponding atcion until all results from EIP93 are finished.
+**parameters:
+*   none
+**global:
+*   none
+**return:
+*   none
+**call:
+*   ipsec_esp_output_finish() when the result is for encryption.
+*	ipsec_esp_input_finish() when the result is for decryption.
+**revision:
+*   1.Trey 20120209
+**_______________________________________________________________________*/
+void 
+ipsec_BH_handler_resultGet(
+	unsigned long data
+)
+{
+	int retVal;
+	struct sk_buff *skb = NULL;
+	ipsecEip93Adapter_t *currAdapterPtr;
+	unsigned int *addrCurrAdapter;
+
+	while (1)	
+	{
+#ifdef MTK_EIP97_DRIVER
+		if ((data >= 4) || (data < 0))
+			printk("==[%s] data=%d==\n",__func__,data);
+		memset(&resDescpHandler[data], 0, sizeof(eip97DescpHandler_t));
+#else
+		data = 0;		
+		memset(&resDescpHandler[data], 0, sizeof(eip93DescpHandler_t));
+#endif
+		retVal = ipsec_packet_get(&resDescpHandler[data], data);
+		//got the correct result from eip93
+#ifdef MTK_EIP97_DRIVER
+		if (likely(retVal > 0))
+#else		
+		if (likely(retVal == 1))
+#endif
+		{
+			//the result is for encrypted or encrypted packet
+#ifdef MTK_EIP97_DRIVER
+			if (likely(retVal > 1))
+#else			
+			if (ipsec_eip93HashFinal_get(&resDescpHandler[data]) == 0x1)
+#endif
+			{		
+				skb = (struct sk_buff *) ipsec_eip93UserId_get(&resDescpHandler[data]);
+				if (skb==NULL)
+				{	
+					printk("UserId got NULL skb\n");
+					break;
+				}
+
+				addrCurrAdapter = (unsigned int *) &(skb->cb[36]);
+				currAdapterPtr = (ipsecEip93Adapter_t *)(*addrCurrAdapter);
+				if (currAdapterPtr==NULL)
+				{	
+					printk("cb got NULL currAdapterPtr\n");
+					break;
+				}
+
+				if (currAdapterPtr->status==TBL_DEL)
+				{
+#ifndef MTK_EIP97_IPI					
+					mcrypto_proc.dbg_pt[5]++;
+#endif					
+					kfree_skb(skb);
+					if (currAdapterPtr->packet_count <= 0)
+					{
+						ipsec_eip93Adapter_free(currAdapterPtr->spi);
+						break;
+					}
+				}		
+				if (skb->protocol == htons(ETH_P_IPV6))
+				{
+					if (currAdapterPtr->isEncryptOrDecrypt == CRYPTO_ENCRYPTION)
+					{
+						ipsec_esp6_output_finish(&resDescpHandler[data]);
+					}
+					else if (currAdapterPtr->isEncryptOrDecrypt == CRYPTO_DECRYPTION)
+					{			
+						ipsec_esp6_input_finish(&resDescpHandler[data], currAdapterPtr->x);
+					}
+					else
+					{
+						printk("\n\n !can't tell encrypt or decrypt! %08X\n\n",currAdapterPtr->isEncryptOrDecrypt);
+						return;
+					}
+				}
+				else
+				{			
+					if (currAdapterPtr->isEncryptOrDecrypt == CRYPTO_ENCRYPTION)
+					{
+						ipsec_esp_output_finish(&resDescpHandler[data]);
+					}
+					else if (currAdapterPtr->isEncryptOrDecrypt == CRYPTO_DECRYPTION)
+					{			
+						ipsec_esp_input_finish(&resDescpHandler[data], currAdapterPtr->x);
+					}
+					else
+					{
+						printk("\n\n !can't tell encrypt or decrypt! %08X\n\n",currAdapterPtr->isEncryptOrDecrypt);
+						return;
+					}
+				}
+
+			}
+			//the result is for inner and outer hash digest pre-compute
+			else
+			{
+				currAdapterPtr = (ipsecEip93Adapter_t *) ipsec_eip93UserId_get(&resDescpHandler[data]);
+				if (currAdapterPtr)
+				printk("=== Build IPSec %s Connection[%d] [P%d](SPI=%X)===\n",\
+							(currAdapterPtr->isEncryptOrDecrypt==CRYPTO_ENCRYPTION) ? "outbound" : " inbound",\
+								currAdapterPtr->idx,currAdapterPtr->isHashPreCompute, currAdapterPtr->spi);
+				else
+				{	
+					printk("No connection entry in table\n");
+					return;				
+				}
+
+				//for the inner digests	
+				if (currAdapterPtr->isHashPreCompute == 0)
+				{
+					//resDescpHandler only has physical addresses, so we have to get saState's virtual address from addrsPreCompute.
+					ipsec_hashDigests_set(currAdapterPtr, 1);
+					//inner digest done
+					currAdapterPtr->isHashPreCompute = 1; 
+				}
+				//for the outer digests	
+				else if (currAdapterPtr->isHashPreCompute == 1)
+				{
+					ipsec_hashDigests_set(currAdapterPtr, 2);
+					//outer digest done
+					currAdapterPtr->isHashPreCompute = 2;				
+#if defined (FEATURE_AVOID_QUEUE_PACKET)
+					//Hash Digests are ready
+					ipsec_hashDigests_get(currAdapterPtr);
+					currAdapterPtr->isHashPreCompute = 3; //pre-compute done
+#if !defined (CONFIG_HWCRYPTO_MEMPOOL)
+					ipsec_addrsDigestPreCompute_free(currAdapterPtr);
+#endif
+					ipsec_esp_pktPut(currAdapterPtr, NULL);
+#endif
+				}
+				else
+				{
+					printk("\n\n !can't tell inner or outer digests! \n\n");				
+					return;
+				}
+			}
+		}
+		//if packet is not done, don't wait! (for speeding up)
+		else if (retVal == 0)
+		{
+			int i;
+			
+			for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+			{
+				currAdapterPtr = ipsecEip93AdapterListIn[i];
+				if (currAdapterPtr!=NULL)
+				{
+					if (currAdapterPtr->status == TBL_ACTIVE)
+					{
+						if (currAdapterPtr->skbQueue.qlen > 0)
+					ipsec_esp_pktPut(currAdapterPtr, NULL);
+#ifdef MTK_EIP97_IPI
+					if (currAdapterPtr->skbIPIQueue.qlen >0)
+						smp_call_function_single(mcrypto_proc.ipicpu[0], smp_func_call ,currAdapterPtr, 0);
+#endif
+				}
+			}
+			}
+			for (i = 0; i < IPESC_EIP93_ADAPTERS; i++)
+			{
+				currAdapterPtr = ipsecEip93AdapterListOut[i];
+				if (currAdapterPtr!=NULL)
+				{	
+					if (currAdapterPtr->status == TBL_ACTIVE)
+					{	
+						if (currAdapterPtr->skbQueue.qlen > 0)
+					ipsec_esp_pktPut(currAdapterPtr, NULL);	
+#ifdef MTK_EIP97_IPI
+					if (currAdapterPtr->skbIPIQueue.qlen >0)
+						smp_call_function_single(mcrypto_proc.ipicpu[0], smp_func_call ,currAdapterPtr, 0);
+#endif
+				}
+			}
+			}
+			break;
+		}
+		else if (retVal < 0)
+			break;
+	} //end while (1)
+	
+	return;
+}
+EXPORT_SYMBOL(ipsec_BH_handler_resultGet);
+
+#ifdef MTK_EIP97_IPI
+static void smp_func_call_BH_handler(unsigned long data)
+{
+	struct sk_buff *skb;
+	ipsecEip93Adapter_t *currAdapterPtr = data;
+	struct xfrm_state *x ;
+
+	if (smp_processor_id()!=mcrypto_proc.ipicpu[0])
+	{
+		mcrypto_proc.dbg_pt[6]++;
+		return;
+	}
+	else
+		mcrypto_proc.dbg_pt[7]++;	
+	x = currAdapterPtr->x;
+	
+	spin_lock(&currAdapterPtr->lock);
+	
+	while (currAdapterPtr->skbIPIQueue.qlen > 0)
+	{
+		skb = skb_dequeue(&currAdapterPtr->skbIPIQueue);
+		if (skb)
+		{
+			if (currAdapterPtr->tunnel==0)	
+				x->inner_mode->afinfo->transport_finish(skb, 1);
+			else
+				netif_rx(skb);
+		}	
+	}
+	spin_unlock(&currAdapterPtr->lock);
+	return;
+}
+
+static void smp_func_call(void *info)
+{
+	if (smp_processor_id()!=mcrypto_proc.ipicpu[0])
+	{
+		mcrypto_proc.dbg_pt[4]++;
+	}	
+	smp_func_call_tsk.data = info;
+	tasklet_hi_schedule(&smp_func_call_tsk);
+	return;
+}
+#endif
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/Kconfig b/trunk/linux-4.4.x/net/ipv4/netfilter/Kconfig
index 2d44c5e1a..5ecc95154 100644
--- a/trunk/linux-4.4.x/net/ipv4/netfilter/Kconfig
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/Kconfig
@@ -140,6 +140,30 @@ config NFT_REDIR_IPV4
 	  This is the expression that provides IPv4 redirect support for
 	  nf_tables.
 
+config BCM_KF_NETFILTER
+	tristate "IPv4 fullcone support"
+	depends on NF_NAT_MASQUERADE_IPV4
+#	depends on NETFILTER_ADVANCED
+#	select NETFILTER_XT_TARGET_FULLCONENAT
+	help
+	  Porting from broadcom.
+
+config IP_NF_TARGET_TOS
+	tristate "TOS target support"
+	depends on IP_NF_MANGLE
+	help
+	  This option adds a `TOS' target, which allows you to create rules in
+	  the `mangle' table which alter the Type Of Service field of an IP
+	  packet prior to routing.
+
+	  To compile it as a module, choose M here.  If unsure, say N.
+
+config IP_NF_TARGET_TRIGGER
+	tristate "TRIGGER target support (port-trigger)"
+	depends on NF_NAT
+	help
+	  To compile it as a module, choose M here.  If unsure, say N.
+
 config NF_NAT_SNMP_BASIC
 	tristate "Basic SNMP-ALG support"
 	depends on NF_CONNTRACK_SNMP
@@ -167,6 +191,16 @@ config NF_NAT_PPTP
 	default NF_CONNTRACK_PPTP
 	select NF_NAT_PROTO_GRE
 
+config NF_NAT_QUAKE3
+	tristate
+	depends on NF_CONNTRACK && NF_NAT
+	default NF_NAT && NF_CONNTRACK_QUAKE3
+
+config NF_NAT_RTSP
+	tristate
+	depends on NF_CONNTRACK && NF_NAT
+	default NF_NAT && NF_CONNTRACK_RTSP
+
 config NF_NAT_H323
 	tristate
 	depends on NF_CONNTRACK
@@ -188,7 +222,6 @@ config IP_NF_IPTABLES
 
 if IP_NF_IPTABLES
 
-# The matches.
 config IP_NF_MATCH_AH
 	tristate '"ah" match support'
 	depends on NETFILTER_ADVANCED
@@ -227,6 +260,33 @@ config IP_NF_MATCH_TTL
 	(e.g. when running oldconfig). It selects
 	CONFIG_NETFILTER_XT_MATCH_HL.
 
+config IP_NF_MATCH_TOS
+	tristate "TOS match support"
+	depends on NETFILTER_ADVANCED
+	help
+	  TOS matching allows you to match packets based on the Type Of
+	  Service fields of the IP packet.
+
+	  To compile it as a module, choose M here.  If unsure, say N.
+
+config IP_NF_MATCH_IPP2P
+	tristate  'IPP2P match support'
+	depends on IP_NF_IPTABLES
+	help
+	  This option makes possible to match some P2P packets
+	  therefore helps controlling such traffic.
+
+	  If you want to compile it as a module, say M here and read
+	  <file:Documentation/modules.txt>.  If unsure, say `N'.
+
+config IP_NF_MATCH_WEBMON
+	tristate  'Web Monitor match'
+	depends on IP_NF_IPTABLES
+
+config IP_NF_MATCH_WEB
+	tristate  'web match'
+	depends on IP_NF_IPTABLES
+
 # `filter', generic and specific targets
 config IP_NF_FILTER
 	tristate "Packet filtering"
@@ -250,6 +310,12 @@ config IP_NF_TARGET_REJECT
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config IP_NF_TARGET_ROUTE
+	tristate "ROUTE target support"
+	depends on IP_NF_MANGLE
+	help
+	  To compile it as a module, choose M here.  If unsure, say N.
+
 config IP_NF_TARGET_SYNPROXY
 	tristate "SYNPROXY target support"
 	depends on NF_CONNTRACK && NETFILTER_ADVANCED
@@ -302,15 +368,6 @@ config IP_NF_TARGET_NETMAP
 	(e.g. when running oldconfig). It selects
 	CONFIG_NETFILTER_XT_TARGET_NETMAP.
 
-config IP_NF_TARGET_FULLCONENAT
-  tristate "FULLCONENAT target support"
-  depends on NETFILTER_ADVANCED
-  select NETFILTER_XT_TARGET_FULLCONENAT
-  ---help---
-  This is a backwards-compat option for the user's convenience
-  (e.g. when running oldconfig). It selects
-  CONFIG_NETFILTER_XT_TARGET_FULLCONENAT.
-
 config IP_NF_TARGET_REDIRECT
 	tristate "REDIRECT target support"
 	depends on NETFILTER_ADVANCED
@@ -322,6 +379,25 @@ config IP_NF_TARGET_REDIRECT
 
 endif # IP_NF_NAT
 
+config NF_NAT_PROTO_ESP
+	tristate
+	depends on BCM_KF_NETFILTER && NF_NAT_IPV4 && NF_CT_PROTO_ESP
+	default NF_NAT_IPV4 && NF_CT_PROTO_ESP
+
+
+config NF_NAT_IPSEC
+	tristate
+	depends on  BCM_KF_NETFILTER && NF_CONNTRACK && NF_NAT_IPV4
+	default NF_NAT_IPV4 && NF_CONNTRACK_IPSEC
+
+config NF_NAT_PT
+	tristate "Port Triggering support"
+	depends on NF_NAT_IPV4 && BCM_KF_NETFILTER
+	help
+	  Port Triggering support
+
+	  To compile it as a module, choose M here.  If unsure, say Y.
+
 # mangle + specific targets
 config IP_NF_MANGLE
 	tristate "Packet mangling"
@@ -426,5 +502,10 @@ config IP_NF_ARP_MANGLE
 
 endif # IP_NF_ARPTABLES
 
+config IP_NF_DNSMQ
+	tristate  'dnsmq'
+	depends on NF_CONNTRACK
+	default n
+
 endmenu
 
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/Makefile b/trunk/linux-4.4.x/net/ipv4/netfilter/Makefile
index 87b073da1..2db3756d7 100644
--- a/trunk/linux-4.4.x/net/ipv4/netfilter/Makefile
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/Makefile
@@ -29,11 +29,22 @@ obj-$(CONFIG_NF_REJECT_IPV4) += nf_reject_ipv4.o
 # NAT helpers (nf_conntrack)
 obj-$(CONFIG_NF_NAT_H323) += nf_nat_h323.o
 obj-$(CONFIG_NF_NAT_PPTP) += nf_nat_pptp.o
+obj-$(CONFIG_NF_NAT_RTSP) += nf_nat_rtsp.o
+ifdef BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
+obj-$(CONFIG_NF_NAT_IPSEC) += nf_nat_ipsec.o
+endif #BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
 obj-$(CONFIG_NF_NAT_SNMP_BASIC) += nf_nat_snmp_basic.o
 obj-$(CONFIG_NF_NAT_MASQUERADE_IPV4) += nf_nat_masquerade_ipv4.o
 
+ifdef BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
+obj-$(CONFIG_NF_NAT_PT) += nf_nat_pt.o
+endif #BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
+
 # NAT protocols (nf_nat)
 obj-$(CONFIG_NF_NAT_PROTO_GRE) += nf_nat_proto_gre.o
+ifdef BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
+obj-$(CONFIG_NF_NAT_PROTO_ESP) += nf_nat_proto_esp.o
+endif #BCM_KF # defined(CONFIG_BCM_KF_NETFILTER
 
 obj-$(CONFIG_NF_TABLES_IPV4) += nf_tables_ipv4.o
 obj-$(CONFIG_NFT_CHAIN_ROUTE_IPV4) += nft_chain_route_ipv4.o
@@ -57,13 +68,20 @@ obj-$(CONFIG_IP_NF_SECURITY) += iptable_security.o
 # matches
 obj-$(CONFIG_IP_NF_MATCH_AH) += ipt_ah.o
 obj-$(CONFIG_IP_NF_MATCH_RPFILTER) += ipt_rpfilter.o
+obj-$(CONFIG_IP_NF_MATCH_TOS) += ipt_tos.o
+obj-$(CONFIG_IP_NF_MATCH_IPP2P) += ipt_ipp2p.o
+obj-$(CONFIG_IP_NF_MATCH_WEB) += ipt_web.o
+obj-$(CONFIG_IP_NF_MATCH_WEBMON) += ipt_webmon.o
 
 # targets
 obj-$(CONFIG_IP_NF_TARGET_CLUSTERIP) += ipt_CLUSTERIP.o
 obj-$(CONFIG_IP_NF_TARGET_ECN) += ipt_ECN.o
 obj-$(CONFIG_IP_NF_TARGET_MASQUERADE) += ipt_MASQUERADE.o
 obj-$(CONFIG_IP_NF_TARGET_REJECT) += ipt_REJECT.o
+obj-$(CONFIG_IP_NF_TARGET_ROUTE) += ipt_ROUTE.o
 obj-$(CONFIG_IP_NF_TARGET_SYNPROXY) += ipt_SYNPROXY.o
+obj-$(CONFIG_IP_NF_TARGET_TOS) += ipt_TOS.o
+obj-$(CONFIG_IP_NF_TARGET_TRIGGER) += ipt_TRIGGER.o
 
 # generic ARP tables
 obj-$(CONFIG_IP_NF_ARPTABLES) += arp_tables.o
@@ -73,3 +91,6 @@ obj-$(CONFIG_IP_NF_ARP_MANGLE) += arpt_mangle.o
 obj-$(CONFIG_IP_NF_ARPFILTER) += arptable_filter.o
 
 obj-$(CONFIG_NF_DUP_IPV4) += nf_dup_ipv4.o
+
+# DNSMQ
+obj-$(CONFIG_IP_NF_DNSMQ) += dnsmq.o
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/dnsmq.c b/trunk/linux-4.4.x/net/ipv4/netfilter/dnsmq.c
new file mode 100644
index 000000000..681a15a50
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/dnsmq.c
@@ -0,0 +1,372 @@
+/*
+ * Packet matching code.
+ *
+ * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling
+ * Copyright (C) 2009-2002 Netfilter core team <coreteam@netfilter.org>
+ *
+ * 19 Jan 2002 Harald Welte <laforge@gnumonks.org>
+ * 	- increase module usage count as soon as we have rules inside
+ * 	  a table
+ */
+#include <linux/version.h>
+#include <linux/cache.h>
+#include <linux/skbuff.h>
+#include <linux/kmod.h>
+#include <linux/vmalloc.h>
+#include <linux/netdevice.h>
+#include <linux/module.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <net/addrconf.h>
+#include <linux/tcp.h>
+#include <linux/udp.h>
+#include <linux/in.h>
+#include <linux/if_vlan.h>
+#include <net/route.h>
+#include <net/ip.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+#include <net/netfilter/nf_nat_core.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <linux/netfilter/nf_conntrack_common.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/proc_fs.h>
+#include <linux/inet.h>
+
+#define DEBUGP(format, args...)
+
+unsigned int dnsmq_ip = 0;
+struct in6_addr dnsmq_ipv6 = IN6ADDR_ANY_INIT;
+char dnsmq_name[32];
+char dnsmq_name_ipv6[32];
+unsigned char dnsmq_mac[ETH_ALEN] = { 0x00, 0xe0, 0x11, 0x22, 0x33, 0x44 };
+typedef int (*dnsmqHitHook)(struct sk_buff *skb);
+dnsmqHitHook dnsmq_hit_hook = NULL;
+
+static inline void dnsmq_hit_hook_func(dnsmqHitHook hook_func)
+{
+	dnsmq_hit_hook = hook_func;
+}
+
+void dump_packet(struct sk_buff *skb, char *title)
+{
+	int i;
+
+	printk("dump packet[%s] %x %x %x", title, skb->len, skb->mac_len, skb->data_len);
+	if (skb->dev) printk("%s\n", skb->dev->name);
+	else printk("\n");
+
+	if (skb && skb->data) {
+		for(i = 0; i < skb->len && i < 160; i++) {
+			if (i%16 == 0) printk("\n");
+			printk("%02X ",*((unsigned char*)(skb->data + i)));
+		}
+	}
+	printk("\n\n\n");
+}
+
+EXPORT_SYMBOL(dump_packet);
+
+#define MAXDNSNAME 256
+#pragma pack(1) // let struct be neat by byte
+
+typedef struct Flags_Pack {
+	uint16_t reply_1:4,
+	non_auth_ok:1,
+	answer_auth:1,
+	reserved:1,
+	recur_avail:1,
+	recur_desired:1,
+	truncated:1,
+	authori:1,
+	opcode:4,
+	response:1;
+} flag_pack;
+
+typedef struct DNS_HEADER {
+	uint16_t tid;
+	union {
+		uint16_t flag_num;
+		flag_pack flags;
+	} flag_set;
+	uint16_t questions;
+	uint16_t answer_rrs;
+	uint16_t auth_rrs;
+	uint16_t additional_rss;
+} dns_header;
+
+typedef struct DNS_QUERIES {
+	char name[MAXDNSNAME];
+	uint16_t type;
+	uint16_t ip_class;
+} dns_queries;
+
+typedef struct DNS_REQUEST {
+	dns_header header;
+	dns_queries queries;
+} dns_query_packet;
+
+static inline int dnschar_cmp(char a, char b)
+{
+	char a1;
+
+	if (a == b) return 0;
+
+	if (a >= 'a' && a <= 'z') a1 = 'A' + a - 'a';
+	else if (a >= 'A' && a <= 'Z') a1 = 'a' + a - 'A';
+	else return 1;
+
+	if (a1 == b) return 0;
+
+	return 1;
+}
+
+static inline int dnsmq_hit(struct udphdr *udph)
+{
+	dns_query_packet *dns_query;
+	int i, j;
+
+	dns_query = (dns_query_packet *)((unsigned char *)udph + sizeof(struct udphdr));
+
+	j = 0;
+	//printk("dns hit\n");
+	for(i = 0; dns_query->queries.name[i] != 0; i++) {
+		//printk("%x %x %x\n", i, dns_query->queries.name[i], dnsmq_name[i]);
+		if (dnschar_cmp(dns_query->queries.name[i],dnsmq_name[j])) return 0;
+		j++;
+	}
+	return 1;
+}
+
+static inline int dnsmq_func(struct sk_buff *skb)
+{
+	struct ethhdr *ethh;
+	struct vlan_ethhdr *vethh;
+	struct iphdr *iph;
+	struct ipv6hdr *ip6h;
+	struct udphdr *udph;
+	struct tcphdr *tcph;
+	u32 hlen;
+	u16 proto;
+
+	if (dnsmq_ip == 0) return 0;
+
+	if (!skb || !skb->data) return 0;
+
+	ethh = (struct ethhdr *)skb->data;
+
+	proto = ntohs(ethh->h_proto);
+
+	if (proto == ETH_P_IP || proto == ETH_P_IPV6) hlen = ETH_HLEN;
+	else if (proto == ETH_P_8021Q) {
+		vethh = (struct vlan_ethhdr *)skb->data;
+		if (vethh->h_vlan_encapsulated_proto == htons(ETH_P_IP) ||
+			vethh->h_vlan_encapsulated_proto == htons(ETH_P_IPV6)) {
+			hlen = VLAN_ETH_HLEN;
+			if (vethh->h_vlan_encapsulated_proto == htons(ETH_P_IPV6))
+				proto = ETH_P_IPV6;
+			else
+				proto = ETH_P_IP;
+		} else return 0;
+	}
+	else return 0;
+
+	if (proto == ETH_P_IPV6) {
+		ip6h = (struct ipv6hdr *)(skb->data + hlen);
+
+		// IP & DNS & Looking for my host name
+		if (ip6h->nexthdr == IPPROTO_UDP) {
+			udph = (struct udphdr *)(skb->data + hlen + sizeof(struct ipv6hdr));
+			if (ntohs(udph->dest) == 53) {
+				if (dnsmq_hit(udph)) {
+					memcpy(ethh->h_dest, dnsmq_mac, ETH_ALEN);
+					//dump_packet(skb, "ipv6 dnshit");
+					return 1;
+				}
+			}
+		}
+		// IP & HTTP & Original Locol IP & Looking for my host name
+		else if (ip6h->nexthdr == IPPROTO_TCP) {
+			tcph = (struct tcphdr *)(skb->data + hlen + sizeof(struct ipv6hdr));
+			if (ipv6_addr_equal(&ip6h->daddr, &dnsmq_ipv6) && ntohs(tcph->dest) == 80) {
+				memcpy(ethh->h_dest, dnsmq_mac, ETH_ALEN);
+				//dump_packet(skb, "ipv6 httphit");
+				return 1;
+			}
+		}
+	} else {
+		iph = (struct iphdr *)(skb->data + hlen);
+
+		// IP & DNS & Looking for my host name
+		if (iph->protocol == IPPROTO_UDP) {
+			udph = (struct udphdr *)(skb->data + hlen + (iph->ihl<<2));
+			if (ntohs(udph->dest) == 53) {
+				if (dnsmq_hit(udph)) {
+					memcpy(ethh->h_dest, dnsmq_mac, ETH_ALEN);
+					//dump_packet(skb, "dnshit");
+					return 1;
+				}
+			}
+		}
+		// IP & HTTP & Original Locol IP & Looking for my host name
+		else if (iph->protocol == IPPROTO_TCP) {
+			tcph = (struct tcphdr *)(skb->data + hlen + (iph->ihl<<2));
+			if (iph->daddr == dnsmq_ip && ntohs(tcph->dest) == 80) {
+				memcpy(ethh->h_dest, dnsmq_mac, ETH_ALEN);
+				//dump_packet(skb, "httphit");
+				return 1;
+			}
+		}
+	}
+
+	return 0;
+}
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3,10,13)
+static ssize_t dnsmq_ctrl(struct file *file, const char __user *buffer, size_t length, loff_t *data)
+#else
+static int dnsmq_ctrl(struct file *file, const char *buffer, unsigned long length, void *data)
+#endif
+{
+	char s[32];
+	char *ptr;
+	int i, j;
+
+	// "[dnsmq ip] [dnsmq name]
+	if ((length > 0) && (length < 32)) {
+		memcpy(s, buffer, length);
+		s[length] = 0;
+		for(i = 0; i < length; i++) {
+			if (s[i] == ' ') break;
+		}
+		if (i < length) {
+			s[i] = 0;
+			ptr = s + i + 1;
+			dnsmq_ip = simple_strtoul(s, NULL, 16);
+
+			// convert to dnsname format
+			j = 0;
+			for(; i < length; i++) {
+				if (s[i] == '.') {
+					s[i] = 0;
+					dnsmq_name[j] = strlen(ptr);
+					memcpy(dnsmq_name + j + 1, ptr, strlen(ptr));
+					j += strlen(ptr) + 1;
+					ptr = s + i + 1;
+				}
+			}
+			dnsmq_name[j] = strlen(ptr);
+			memcpy(dnsmq_name + j + 1, ptr, strlen(ptr));
+			dnsmq_name[j + 1 + strlen(ptr)] = 0;
+		}
+	}
+	else dnsmq_ip = 0;
+
+	printk(KERN_DEBUG "dnsmq ctrl: %x %s\n", dnsmq_ip, dnsmq_name);
+
+	if (dnsmq_ip == 0) dnsmq_hit_hook_func (NULL);
+	else dnsmq_hit_hook_func(dnsmq_func);
+
+	return length;
+}
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3,10,13)
+static ssize_t dnsmq_ctrl_ipv6(struct file *file, const char __user *buffer, size_t length, loff_t *data)
+#else
+static int dnsmq_ctrl_ipv6(struct file *file, const char *buffer, unsigned long length, void *data)
+#endif
+{
+	char s[64];
+	char *ptr;
+	int i, j;
+
+	// "[dnsmq ipv6] [dnsmq name]
+	if ((length > 0) && (length < 64)) {
+		memcpy(s, buffer, length);
+		s[length] = 0;
+		for(i = 0; i < length; i++) {
+			if (s[i] == ' ') break;
+		}
+		if (i < length) {
+			s[i] = 0;
+			ptr = s + i + 1;
+			in6_pton(s, length, (void *)&dnsmq_ipv6, '\n', NULL);
+
+			// convert to dnsname format
+			j = 0;
+			for(; i < length; i++) {
+				if (s[i] == '.') {
+					s[i] = 0;
+					dnsmq_name_ipv6[j] = strlen(ptr);
+					memcpy(dnsmq_name_ipv6 + j + 1, ptr, strlen(ptr));
+					j += strlen(ptr) + 1;
+					ptr = s + i + 1;
+				}
+			}
+			dnsmq_name_ipv6[j] = strlen(ptr);
+			memcpy(dnsmq_name_ipv6 + j + 1, ptr, strlen(ptr));
+			dnsmq_name_ipv6[j + 1 + strlen(ptr)] = 0;
+		}
+	}
+	else memset(&dnsmq_ipv6, 0, sizeof(struct in6_addr));
+
+	printk(KERN_DEBUG "dnsmq ctrl ipv6: %pI6 %s\n", &dnsmq_ipv6, dnsmq_name_ipv6);
+
+	if (ipv6_addr_equal(&dnsmq_ipv6, &in6addr_any)) dnsmq_hit_hook_func (NULL);
+	else dnsmq_hit_hook_func(dnsmq_func);
+
+	return length;
+}
+
+#ifdef CONFIG_PROC_FS
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3,10,13)
+static const struct file_operations dnsmq_ctrl_proc_ops = {
+	.write = dnsmq_ctrl,
+};
+
+static const struct file_operations dnsmq_ctrl_ipv6_proc_ops = {
+	.write = dnsmq_ctrl_ipv6,
+};
+#endif
+#endif
+
+static int __init init(void)
+{
+#ifdef CONFIG_PROC_FS
+	struct proc_dir_entry *p;
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3,10,13)
+	p = proc_create("dnsmqctrl", 0200, init_net.proc_net, &dnsmq_ctrl_proc_ops);
+#else
+	p = create_proc_entry("dnsmqctrl", 0200, init_net.proc_net);
+
+	if (p)
+		p->write_proc = dnsmq_ctrl;
+#endif
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(3,10,13)
+	p = proc_create("dnsmqctrl_ipv6", 0200, init_net.proc_net, &dnsmq_ctrl_ipv6_proc_ops);
+#else
+	p = create_proc_entry("dnsmqctrl_ipv6", 0200, init_net.proc_net);
+
+	if (p)
+		p->write_proc = dnsmq_ctrl_ipv6;
+#endif
+#endif
+	// it will be enabled later
+	dnsmq_hit_hook_func (NULL);
+	return 0;
+}
+
+static void __exit fini(void)
+{
+	dnsmq_hit_hook_func (NULL);
+}
+
+EXPORT_SYMBOL(dnsmq_hit_hook);
+
+module_init(init);
+module_exit(fini);
+MODULE_LICENSE("Proprietary");
+
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ip_tables.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ip_tables.c
index 4d783fdb9..be232f7f5 100644
--- a/trunk/linux-4.4.x/net/ipv4/netfilter/ip_tables.c
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ip_tables.c
@@ -494,6 +494,23 @@ ipt_do_table(struct sk_buff *skb,
 		ip = ip_hdr(skb);
 		if (verdict == XT_CONTINUE)
 			e = ipt_next_entry(e);
+#if 0
+		else if (verdict == XT_RETURN) {		// added -- zzz
+			e = jumpstack[--stackidx];
+			if (stackidx == 0) {
+				e = get_entry(table_base,
+				    private->underflow[hook]);
+				pr_debug("Underflow (this is normal) "
+					 "to %p\n", e);
+			} else {
+				e = jumpstack[--stackidx];
+				pr_debug("Pulled %p out from pos %u\n",
+					 e, stackidx);
+				e = ipt_next_entry(e);
+			}
+			continue;
+		}
+#endif
 		else
 			/* Verdict */
 			break;
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_MASQUERADE.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_MASQUERADE.c
index 0bf6d84e9..d13647023 100644
--- a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_MASQUERADE.c
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_MASQUERADE.c
@@ -55,8 +55,10 @@ masquerade_tg(struct sk_buff *skb, const struct xt_action_param *par)
 	range.min_proto = mr->range[0].min;
 	range.max_proto = mr->range[0].max;
 
+#if defined(CONFIG_BCM_KF_NETFILTER)
 	range.min_addr.ip = mr->range[0].min_ip;
 	range.max_addr.ip = mr->range[0].max_ip;
+#endif
 
 	return nf_nat_masquerade_ipv4(skb, par->hooknum, &range, par->out);
 }
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_ROUTE.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_ROUTE.c
new file mode 100644
index 000000000..f6bbef5c1
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_ROUTE.c
@@ -0,0 +1,501 @@
+/*
+ * This implements the ROUTE target, which enables you to setup unusual
+ * routes not supported by the standard kernel routing table.
+ *
+ * Copyright (C) 2002 Cedric de Launois <delaunois@info.ucl.ac.be>
+ *
+ * v 1.11 2004/11/23
+ *
+ * This software is distributed under GNU GPL v2, 1991
+ */
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/ip.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <linux/netfilter_ipv4.h>
+#include <linux/netfilter_ipv4/ipt_ROUTE.h>
+#include <linux/netdevice.h>
+#include <linux/route.h>
+#include <linux/version.h>
+#include <linux/if_arp.h>
+#include <net/ip.h>
+#include <net/route.h>
+#include <net/icmp.h>
+#include <net/checksum.h>
+
+#if 0
+#define DEBUGP printk
+#else
+#define DEBUGP(format, args...)
+#endif
+
+#define NF_IP_PRE_ROUTING	NF_INET_PRE_ROUTING
+#define NF_IP_LOCAL_IN		NF_INET_LOCAL_IN
+#define NF_IP_FORWARD		NF_INET_FORWARD
+#define NF_IP_LOCAL_OUT		NF_INET_LOCAL_OUT
+#define NF_IP_POST_ROUTING	NF_INET_POST_ROUTING
+#define NF_IP_NUMHOOKS		NF_INET_NUMHOOKS
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+#define IPT_CONTINUE XT_CONTINUE
+#endif
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cedric de Launois <delaunois@info.ucl.ac.be>");
+MODULE_DESCRIPTION("iptables ROUTE target module");
+
+/* Try to route the packet according to the routing keys specified in
+ * route_info. Keys are :
+ *  - ifindex : 
+ *      0 if no oif preferred, 
+ *      otherwise set to the index of the desired oif
+ *  - route_info->gw :
+ *      0 if no gateway specified,
+ *      otherwise set to the next host to which the pkt must be routed
+ * If success, skb->dev is the output device to which the packet must 
+ * be sent and skb->dst is not NULL
+ *
+ * RETURN: -1 if an error occured
+ *          1 if the packet was succesfully routed to the 
+ *            destination desired
+ *          0 if the kernel routing table could not route the packet
+ *            according to the keys specified
+ */
+static int route(struct sk_buff *skb,
+		 unsigned int ifindex,
+		 const struct ipt_route_target_info *route_info)
+{
+	int err;
+	struct rtable *rt;
+	struct iphdr *iph  = ip_hdr(skb);
+	struct flowi fl = {
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+		.u = {
+			.ip4 = {
+				.flowi4_oif = ifindex,
+				.daddr = iph->daddr,
+				.saddr = 0,
+				.flowi4_tos = RT_TOS(iph->tos),
+				.flowi4_scope = RT_SCOPE_UNIVERSE,
+			}
+		}
+#else
+		.oif = ifindex,
+		.nl_u = {
+			.ip4_u = {
+				.daddr = iph->daddr,
+				.saddr = 0,
+				.tos = RT_TOS(iph->tos),
+				.scope = RT_SCOPE_UNIVERSE,
+			}
+		} 
+#endif
+	};
+	
+	/* The destination address may be overloaded by the target */
+	if (route_info->gw)
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+		fl.u.ip4.daddr = route_info->gw;
+#else
+		fl.fl4_dst = route_info->gw;
+#endif
+	
+	/* Trying to route the packet using the standard routing table. */
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+	rt = ip_route_output_key(&init_net, (struct flowi4*)&fl);
+	if (IS_ERR(rt)) {
+		err = (int)PTR_ERR(rt);
+#else
+	if ((err = ip_route_output_key(&init_net, &rt, &fl))) {
+#endif
+		if (net_ratelimit()) 
+			DEBUGP("ipt_ROUTE: couldn't route pkt (err: %i)",err);
+		return -1;
+	}
+	
+	/* Drop old route. */
+	dst_release(skb_dst(skb));
+	skb_dst_set(skb, NULL);
+
+	if (!ifindex || rt->dst.dev->ifindex == ifindex) {
+		struct dst_entry *dst;
+
+		skb_dst_set(skb, &rt->dst);
+		dst = skb_dst(skb);
+		skb->dev = dst->dev;
+		skb->protocol = htons(ETH_P_IP);
+		return 1;
+	}
+
+	if (net_ratelimit()) 
+		DEBUGP("ipt_ROUTE: failed to route as desired gw=%u.%u.%u.%u oif=%i (got oif=%i)\n", 
+		       NIPQUAD(route_info->gw), ifindex, rt->dst.dev->ifindex);
+	return 0;
+}
+
+
+/* Stolen from ip_finish_output2
+ * PRE : skb->dev is set to the device we are leaving by
+ *       skb->dst is not NULL
+ * POST: the packet is sent with the link layer header pushed
+ *       the packet is destroyed
+ */
+static void ip_direct_send(struct sk_buff *skb)
+{
+	struct dst_entry *dst = skb_dst(skb);
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+	struct neighbour *neigh = dst_neigh_lookup_skb(dst, skb) ;
+#else
+	struct hh_cache *hh = dst->hh;
+#endif
+	struct net_device *dev = dst->dev;
+	int hh_len = LL_RESERVED_SPACE(dev);
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,6,36)
+	unsigned seq;
+#endif
+
+	/* Be paranoid, rather than too clever. */
+	if (unlikely(skb_headroom(skb) < hh_len && dev->header_ops->create)) {
+		struct sk_buff *skb2;
+
+		skb2 = skb_realloc_headroom(skb, LL_RESERVED_SPACE(dev));
+		if (skb2 == NULL) {
+			kfree_skb(skb);
+			return;
+		}
+		if (skb->sk)
+			skb_set_owner_w(skb2, skb->sk);
+		kfree_skb(skb);
+		skb = skb2;
+	}
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+	if (neigh)
+		dst_neigh_output(dst, neigh, skb);
+#else
+	if (hh) {
+		do {
+			int hh_alen;
+
+			seq = read_seqbegin(&hh->hh_lock);
+			hh_alen = HH_DATA_ALIGN(hh->hh_len);
+			memcpy(skb->data - hh_alen, hh->hh_data, hh_alen);
+		} while (read_seqretry(&hh->hh_lock, seq));
+		skb_push(skb, hh->hh_len);
+		hh->hh_output(skb);
+	} else if (dst->neighbour)
+		dst->neighbour->output(skb);
+#endif
+	else {
+		if (net_ratelimit())
+			DEBUGP(KERN_DEBUG "ipt_ROUTE: no hdr & no neighbour cache!\n");
+		kfree_skb(skb);
+	}
+}
+
+
+/* PRE : skb->dev is set to the device we are leaving by
+ * POST: - the packet is directly sent to the skb->dev device, without 
+ *         pushing the link layer header.
+ *       - the packet is destroyed
+ */
+static inline int dev_direct_send(struct sk_buff *skb)
+{
+	return dev_queue_xmit(skb);
+}
+
+
+static unsigned int route_oif(const struct ipt_route_target_info *route_info,
+			      struct sk_buff *skb) 
+{
+	unsigned int ifindex = 0;
+	struct net_device *dev_out = NULL;
+
+	/* The user set the interface name to use.
+	 * Getting the current interface index.
+	 */
+	if ((dev_out = dev_get_by_name(&init_net, route_info->oif))) {
+		ifindex = dev_out->ifindex;
+	} else {
+		/* Unknown interface name : packet dropped */
+		if (net_ratelimit()) 
+			DEBUGP("ipt_ROUTE: oif interface %s not found\n", route_info->oif);
+		return NF_DROP;
+	}
+
+	/* Trying the standard way of routing packets */
+	switch (route(skb, ifindex, route_info)) {
+	case 1:
+		dev_put(dev_out);
+		if (route_info->flags & IPT_ROUTE_CONTINUE)
+			return IPT_CONTINUE;
+
+		ip_direct_send(skb);
+		return NF_STOLEN;
+
+	case 0:
+		/* Failed to send to oif. Trying the hard way */
+		if (route_info->flags & IPT_ROUTE_CONTINUE)
+			return NF_DROP;
+
+		if (net_ratelimit()) 
+			DEBUGP("ipt_ROUTE: forcing the use of %i\n",
+			       ifindex);
+
+		/* We have to force the use of an interface.
+		 * This interface must be a tunnel interface since
+		 * otherwise we can't guess the hw address for
+		 * the packet. For a tunnel interface, no hw address
+		 * is needed.
+		 */
+		if ((dev_out->type != ARPHRD_TUNNEL)
+		    && (dev_out->type != ARPHRD_IPGRE)) {
+			if (net_ratelimit()) 
+				DEBUGP("ipt_ROUTE: can't guess the hw addr !\n");
+			dev_put(dev_out);
+			return NF_DROP;
+		}
+	
+		/* Send the packet. This will also free skb
+		 * Do not go through the POST_ROUTING hook because 
+		 * skb->dst is not set and because it will probably
+		 * get confused by the destination IP address.
+		 */
+		skb->dev = dev_out;
+		dev_direct_send(skb);
+		dev_put(dev_out);
+		return NF_STOLEN;
+		
+	default:
+		/* Unexpected error */
+		dev_put(dev_out);
+		return NF_DROP;
+	}
+}
+
+
+static unsigned int route_iif(const struct ipt_route_target_info *route_info,
+			      struct sk_buff *skb) 
+{
+	struct net_device *dev_in = NULL;
+
+	/* Getting the current interface index. */
+	if (!(dev_in = dev_get_by_name(&init_net, route_info->iif))) {
+		if (net_ratelimit()) 
+			DEBUGP("ipt_ROUTE: iif interface %s not found\n", route_info->iif);
+		return NF_DROP;
+	}
+
+	skb->dev = dev_in;
+	dst_release(skb_dst(skb));
+	skb_dst_set(skb, NULL);
+
+	netif_rx(skb);
+	dev_put(dev_in);
+	return NF_STOLEN;
+}
+
+
+static unsigned int route_gw(const struct ipt_route_target_info *route_info,
+			     struct sk_buff *skb) 
+{
+	if (route(skb, 0, route_info)!=1)
+		return NF_DROP;
+
+	if (route_info->flags & IPT_ROUTE_CONTINUE)
+		return IPT_CONTINUE;
+
+	ip_direct_send(skb);
+	return NF_STOLEN;
+}
+
+
+/* To detect and deter routed packet loopback when using the --tee option,
+ * we take a page out of the raw.patch book: on the copied skb, we set up
+ * a fake ->nfct entry, pointing to the local &route_tee_track. We skip
+ * routing packets when we see they already have that ->nfct.
+ */
+
+static struct nf_conn route_tee_track;
+
+static unsigned int ipt_route_target (struct sk_buff *skb,
+				    const struct xt_action_param *par)
+{
+	const struct ipt_route_target_info *route_info = par->targinfo;
+	unsigned int res;
+
+	if (skb->nfct == &route_tee_track.ct_general) {
+		/* Loopback - a packet we already routed, is to be
+		 * routed another time. Avoid that, now.
+		 */
+		if (net_ratelimit()) 
+			DEBUGP(KERN_DEBUG "ipt_ROUTE: loopback - DROP!\n");
+		return NF_DROP;
+	}
+
+	/* If we are at PREROUTING or INPUT hook
+	 * the TTL isn't decreased by the IP stack
+	 */
+	if (par->hooknum == NF_IP_PRE_ROUTING ||
+	    par->hooknum == NF_IP_LOCAL_IN) {
+
+		struct iphdr *iph = ip_hdr(skb);
+
+		if (iph->ttl <= 1) {
+			struct rtable *rt;
+			struct flowi fl = {
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+				.u = {
+					.ip4 = {
+						.flowi4_oif = 0,
+						.daddr = iph->daddr,
+						.saddr = iph->saddr,
+						.flowi4_tos = RT_TOS(iph->tos),
+						.flowi4_scope = ((iph->tos & RTO_ONLINK) ?
+							  RT_SCOPE_LINK :
+							  RT_SCOPE_UNIVERSE)
+					}
+				}
+#else
+				.oif = 0,
+				.nl_u = {
+					.ip4_u = {
+						.daddr = iph->daddr,
+						.saddr = iph->saddr,
+						.tos = RT_TOS(iph->tos),
+						.scope = ((iph->tos & RTO_ONLINK) ?
+							  RT_SCOPE_LINK :
+							  RT_SCOPE_UNIVERSE)
+					}
+				} 
+#endif
+			};
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+			rt = ip_route_output_key(&init_net, (struct flowi4*)&fl);
+			if (IS_ERR(rt)) {
+#else
+			if (ip_route_output_key(&init_net, &rt, &fl)) {
+#endif
+				return NF_DROP;
+			}
+
+			if (skb->dev == rt->dst.dev) {
+				/* Drop old route. */
+				dst_release(skb_dst(skb));
+				skb_dst_set(skb, &rt->dst);
+
+				/* this will traverse normal stack, and 
+				 * thus call conntrack on the icmp packet */
+				icmp_send(skb, ICMP_TIME_EXCEEDED, 
+					  ICMP_EXC_TTL, 0);
+			}
+
+			return NF_DROP;
+		}
+
+		/*
+		 * If we are at INPUT the checksum must be recalculated since
+		 * the length could change as the result of a defragmentation.
+		 */
+		if(par->hooknum == NF_IP_LOCAL_IN) {
+			iph->ttl = iph->ttl - 1;
+			iph->check = 0;
+			iph->check = ip_fast_csum((unsigned char *)iph, iph->ihl);
+		} else {
+			ip_decrease_ttl(iph);
+		}
+	}
+
+	if ((route_info->flags & IPT_ROUTE_TEE)) {
+		/*
+		 * Copy the *pskb, and route the copy. Will later return
+		 * IPT_CONTINUE for the original skb, which should continue
+		 * on its way as if nothing happened. The copy should be
+		 * independantly delivered to the ROUTE --gw.
+		 */
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,36)
+		skb = skb_copy(skb, GFP_ATOMIC);
+#else
+		skb = skb_copy(*pskb, GFP_ATOMIC);
+#endif
+		if (!skb) {
+			if (net_ratelimit()) 
+				DEBUGP(KERN_DEBUG "ipt_ROUTE: copy failed!\n");
+			return IPT_CONTINUE;
+		}
+	}
+
+	/* Tell conntrack to forget this packet since it may get confused 
+	 * when a packet is leaving with dst address == our address.
+	 * Good idea ? Dunno. Need advice.
+	 *
+	 * NEW: mark the skb with our &route_tee_track, so we avoid looping
+	 * on any already routed packet.
+	 */
+	if (!(route_info->flags & IPT_ROUTE_CONTINUE)) {
+		nf_conntrack_put(skb->nfct);
+		skb->nfct = &route_tee_track.ct_general;
+		skb->nfctinfo = IP_CT_NEW;
+		nf_conntrack_get(skb->nfct);
+	}
+
+	if (route_info->oif[0] != '\0') {
+		res = route_oif(route_info, skb);
+	} else if (route_info->iif[0] != '\0') {
+		res = route_iif(route_info, skb);
+	} else if (route_info->gw) {
+		res = route_gw(route_info, skb);
+	} else {
+		if (net_ratelimit()) 
+			DEBUGP(KERN_DEBUG "ipt_ROUTE: no parameter !\n");
+		res = IPT_CONTINUE;
+	}
+
+	if ((route_info->flags & IPT_ROUTE_TEE))
+		res = IPT_CONTINUE;
+
+	return res;
+}
+
+
+static int ipt_route_checkentry(const struct xt_tgchk_param *par)
+{
+	return 0;	/* means success */
+}
+
+
+static struct xt_target xt_route_reg = { 
+	.name = "ROUTE",
+	.target = ipt_route_target,
+	.family     = AF_INET,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,17)
+	.targetsize = sizeof(struct ipt_route_target_info),
+#endif
+	.checkentry = ipt_route_checkentry,
+	.me = THIS_MODULE,
+};
+
+static int __init init(void)
+{
+	/* Set up fake conntrack (stolen from raw.patch):
+	    - to never be deleted, not in any hashes */
+	atomic_set(&route_tee_track.ct_general.use, 1);
+	/*  - and look it like as a confirmed connection */
+	set_bit(IPS_CONFIRMED_BIT, &route_tee_track.status);
+	/* Initialize fake conntrack so that NAT will skip it */
+	route_tee_track.status |= IPS_NAT_DONE_MASK;
+
+	return xt_register_target(&xt_route_reg);
+}
+
+
+static void __exit fini(void)
+{
+	xt_unregister_target(&xt_route_reg);
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_TOS.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_TOS.c
new file mode 100644
index 000000000..39c42ff86
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_TOS.c
@@ -0,0 +1,76 @@
+/* This is a module which is used for setting the TOS field of a packet. */
+
+/* (C) 1999-2001 Paul `Rusty' Russell
+ * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/ip.h>
+#include <net/checksum.h>
+
+#include <linux/netfilter/x_tables.h>
+#include <linux/netfilter_ipv4/ipt_TOS.h>
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Netfilter Core Team <coreteam@netfilter.org>");
+MODULE_DESCRIPTION("iptables TOS mangling module");
+
+static unsigned int target(struct sk_buff *skb, const struct xt_action_param *par)
+{
+	const struct ipt_tos_target_info *tosinfo = par->targinfo;
+	struct iphdr *iph = ip_hdr(skb);
+
+	if ((iph->tos & IPTOS_TOS_MASK) != tosinfo->tos) {
+		__u8 oldtos;
+		if (!skb_make_writable(skb, sizeof(struct iphdr)))
+			return NF_DROP;
+		iph = ip_hdr(skb);
+		oldtos = iph->tos;
+		iph->tos = (iph->tos & IPTOS_PREC_MASK) | tosinfo->tos;
+		csum_replace2(&iph->check, htons(oldtos), htons(iph->tos));
+	}
+	return XT_CONTINUE;
+}
+
+static int checkentry(const struct xt_tgchk_param *par)
+{
+	const u_int8_t tos = ((struct ipt_tos_target_info *)par->targinfo)->tos;
+
+	if (tos != IPTOS_LOWDELAY
+	    && tos != IPTOS_THROUGHPUT
+	    && tos != IPTOS_RELIABILITY
+	    && tos != IPTOS_MINCOST
+	    && tos != IPTOS_NORMALSVC) {
+		printk(KERN_WARNING "TOS: bad tos value %#x\n", tos);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static struct xt_target ipt_tos_reg = {
+	.name		= "TOS",
+	.family		= NFPROTO_IPV4,
+	.target		= target,
+	.targetsize	= sizeof(struct ipt_tos_target_info),
+	.table		= "mangle",
+	.checkentry	= checkentry,
+	.me		= THIS_MODULE,
+};
+
+static int __init ipt_tos_init(void)
+{
+	return xt_register_target(&ipt_tos_reg);
+}
+
+static void __exit ipt_tos_fini(void)
+{
+	xt_unregister_target(&ipt_tos_reg);
+}
+
+module_init(ipt_tos_init);
+module_exit(ipt_tos_fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_TRIGGER.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_TRIGGER.c
new file mode 100644
index 000000000..4b5ab712a
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_TRIGGER.c
@@ -0,0 +1,447 @@
+/* Kernel module to match the port-ranges, trigger related port-ranges,
+ * and alters the destination to a local IP address.
+ *
+ * Copyright (C) 2003, CyberTAN Corporation
+ * All Rights Reserved.
+ *
+ * Description:
+ *   This is kernel module for port-triggering.
+ *
+ *   The module follows the Netfilter framework, called extended packet 
+ *   matching modules. 
+ *
+ * History:
+ *
+ * 2008.07: code cleaning by Delta Networks Inc.
+ */
+
+#include <linux/types.h>
+#include <linux/skbuff.h>
+#include <linux/version.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>
+#include <net/sock.h>
+#include <linux/timer.h>
+#include <linux/module.h>
+#include <linux/netfilter.h>
+#include <linux/netdevice.h>
+#include <linux/if.h>
+#include <linux/inetdevice.h>
+#include <net/protocol.h>
+#include <net/checksum.h>
+
+#include <linux/netfilter_ipv4.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/netfilter_ipv4/ip_autofw.h>
+
+#include <net/netfilter/nf_nat.h>
+#include <net/netfilter/nf_nat_helper.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <net/netfilter/nf_conntrack_helper.h>
+#include <net/netfilter/nf_conntrack_expect.h>
+
+#ifdef CONFIG_NF_NAT_NEEDED
+#include <net/netfilter/nf_nat_rule.h>
+#else
+#include <linux/netfilter_ipv4/ip_nat_rule.h>
+#endif
+#include <linux/netfilter_ipv4/ipt_TRIGGER.h>
+#include <uapi/linux/netfilter/nf_nat.h>
+
+/* This rwlock protects the main hash table, protocol/helper/expected
+ * registrations, conntrack timers
+ */
+static DEFINE_RWLOCK(trigger_lock);
+
+#include <linux/list.h>
+
+#if 0
+#define DEBUGP printk
+#else
+#define DEBUGP(format, args...)
+#endif
+
+#define LIST_FIND(head, cmpfn, type, args...)		\
+({							\
+	const struct list_head *__i, *__j = NULL;	\
+							\
+	read_lock_bh(&trigger_lock);			\
+	list_for_each(__i, (head))			\
+		if (cmpfn((const type)__i , ## args)) {	\
+			__j = __i;			\
+			break;				\
+		}					\
+	read_unlock_bh(&trigger_lock);			\
+	(type)__j;					\
+})
+
+struct ipt_trigger {
+	struct list_head list;	/* Trigger list */
+	struct timer_list timeout;	/* Timer for list destroying */
+	u_int32_t srcip;	/* Outgoing source address */
+	u_int16_t mproto;	/* Trigger protocol */
+	u_int16_t rproto;	/* Related protocol */
+	struct ipt_trigger_ports ports;	/* Trigger and related ports */
+	u_int8_t reply;		/* Confirm a reply connection */
+	struct net *net;
+};
+
+static LIST_HEAD(trigger_list);
+
+static void trigger_timer_refresh(struct ipt_trigger *trig)
+{
+	DEBUGP("%s: mport=%u-%u\n", __FUNCTION__, trig->ports.mport[0], trig->ports.mport[1]);
+	NF_CT_ASSERT(trig);
+	write_lock_bh(&trigger_lock);
+
+	/* Need del_timer for race avoidance (may already be dying). */
+	if (del_timer(&trig->timeout)) {
+		trig->timeout.expires = jiffies + (TRIGGER_TIMEOUT * HZ);
+		add_timer(&trig->timeout);
+	}
+
+	write_unlock_bh(&trigger_lock);
+}
+
+static void __del_trigger(struct ipt_trigger *trig)
+{
+	DEBUGP("%s: mport=%u-%u\n", __FUNCTION__, trig->ports.mport[0], trig->ports.mport[1]);
+	NF_CT_ASSERT(trig);
+
+	/* delete from 'trigger_list' */
+	list_del(&trig->list);
+	kfree(trig);
+}
+
+static int ip_ct_kill_triggered(struct nf_conn *i, void *ifindex)
+{
+	u_int16_t proto, dport;
+	struct ipt_trigger *trig;
+
+	if (!(i->status & IPS_TRIGGER))
+		return 0;
+
+	trig = ifindex;
+	proto = i->tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.protonum;
+	dport = ntohs(i->tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.u.all);
+
+	if (trig->rproto == proto || trig->rproto == 0)
+		return (trig->ports.rport[0] <= dport && trig->ports.rport[1] >= dport);
+	else
+		return 0;
+}
+
+static void trigger_timeout(unsigned long ul_trig)
+{
+	struct ipt_trigger *trig = (void *)ul_trig;
+
+	DEBUGP("%s: mport=%u-%u\n", __FUNCTION__, trig->ports.mport[0], trig->ports.mport[1]);
+
+	nf_ct_iterate_cleanup(&init_net, ip_ct_kill_triggered, (void *)trig, 0, 0);
+
+	write_lock_bh(&trigger_lock);
+	__del_trigger(trig);
+	write_unlock_bh(&trigger_lock);
+}
+
+static void trigger_flush(void)
+{
+	struct list_head *cur_item, *tmp_item;
+
+	DEBUGP("%s\n", __FUNCTION__);
+	write_lock_bh(&trigger_lock);
+	list_for_each_safe(cur_item, tmp_item, &trigger_list) {
+		struct ipt_trigger *trig = (void *)cur_item;
+
+		DEBUGP("%s: list_for_each_safe(): %p.\n", __FUNCTION__, trig);
+		del_timer(&trig->timeout);
+		nf_ct_iterate_cleanup(trig->net, ip_ct_kill_triggered, (void *)trig, 0, 0);
+		__del_trigger(trig);
+	}
+	write_unlock_bh(&trigger_lock);
+}
+
+/*
+ *	Service-Name	OutBound	InBound
+ * 1.	TMD		UDP:1000	TCP/UDP:2000..2010
+ * 2.	WOKAO		UDP:1000	TCP/UDP:3000..3010
+ * 3.	net2phone-1	UDP:6801	TCP:30000..30000
+ * 4.	net2phone-2	UDP:6801	UDP:30000..30000
+ *
+ * For supporting to use the same outgoing port to trigger different port rules,
+ * it should check the inbound protocol and port range value. If all conditions
+ * are matched, it is a same trigger item, else it needs to create a new one.
+ */
+static inline int trigger_out_matched(const struct ipt_trigger *i,
+				      const u_int16_t proto, const u_int16_t dport, const struct ipt_trigger_info *info)
+{
+	return
+	    i->mproto == proto &&
+	    i->ports.mport[0] <= dport &&
+	    i->ports.mport[1] >= dport &&
+	    i->rproto == info->proto && i->ports.rport[0] == info->ports.rport[0] && i->ports.rport[1] == info->ports.rport[1];
+}
+
+static unsigned int trigger_out(struct sk_buff **pskb, const void *targinfo)
+{
+	const struct ipt_trigger_info *info = targinfo;
+	struct ipt_trigger *trig;
+	struct iphdr *iph = ip_hdr(*pskb);
+	struct tcphdr *tcph = (void *)iph + (iph->ihl << 2);	/* Might be TCP, UDP */
+
+	/* Check if the trigger range has already existed in 'trigger_list'. */
+	trig = LIST_FIND(&trigger_list, trigger_out_matched, struct ipt_trigger *, iph->protocol, ntohs(tcph->dest), info);
+
+	if (trig != NULL) {
+		DEBUGP("Tirgger Out Refresh: %pI4 %u\n", &iph->saddr, ntohs(tcph->dest));
+		/* Yeah, it exists. We need to update(delay) the destroying timer. */
+		trigger_timer_refresh(trig);
+		/* In order to allow multiple hosts use the same port range, we update
+		   the 'saddr' after previous trigger has a reply connection. */
+#if 0
+		if (trig->reply) {
+			trig->srcip = iph->saddr;
+			trig->reply = 0;
+		}
+#else
+		/*
+		 * Well, CD-Router verifies Port-Triggering to support multiple LAN hosts can
+		 * use trigger ports after mappings are aged out. It tests as bellowing ...
+		 *
+		 * net2phone-1  UDP:6801        TCP:30000..30000
+		 * net2phone-2  UDP:6801        UDP:3000..3000
+		 *
+		 * 1. 192.168.1.2 --> UDP:6801 --> verify TCP:30000 opened ?
+		 * 2. waiting for all trigger port mappings to be deleted.
+		 * 3. 192.168.1.3 --> UDP:6801 --> verify TCP:30000 opened ?
+		 *
+		 * 4. 192.168.1.2 --> UDP:6801 --> verify UDP:3000 opened ?
+		 * 5. waiting for all trigger port mappings to be deleted.
+		 * 6. 192.168.1.3 --> UDP:6801 --> verify UDP:3000 opened ?
+		 *
+		 * Between steps 3 and 4, it doesn't wait time out, and on step 3, it has created
+		 * two trigger items: [A].  TCP:30000 ('reply' = 1); B). UDP:3000 ('reply' = 0). so
+		 * on step 4, it can't update the 'srcip' value from '192.168.1.3' to '192.168.1.2'.
+		 * For passing test, and let the customer be happy, we ... ^_^, it is not so bad.
+		 */
+		trig->srcip = iph->saddr;
+#endif
+	} else {
+		/* Create new trigger */
+		trig = (struct ipt_trigger *)kzalloc(sizeof(struct ipt_trigger), GFP_ATOMIC);
+		if (trig == NULL) {
+			DEBUGP("No memory for adding Tigger!\n");
+			return XT_CONTINUE;
+		}
+
+		INIT_LIST_HEAD(&trig->list);
+		init_timer(&trig->timeout);
+		trig->timeout.data = (unsigned long)trig;
+		trig->timeout.function = trigger_timeout;
+		trig->timeout.expires = jiffies + (TRIGGER_TIMEOUT * HZ);
+
+		trig->srcip = iph->saddr;
+		trig->mproto = iph->protocol;
+		trig->rproto = info->proto;
+		trig->reply = 0;
+		trig->net = dev_net((*pskb)->dev);
+		memcpy(&trig->ports, &info->ports, sizeof(struct ipt_trigger_ports));
+
+		/* add to global table of trigger and start timer. */
+		write_lock_bh(&trigger_lock);
+		list_add(&trig->list, &trigger_list);
+		add_timer(&trig->timeout);
+		write_unlock_bh(&trigger_lock);
+	}
+
+	return XT_CONTINUE;	/* We don't block any packet. */
+}
+
+static inline int trigger_in_matched(const struct ipt_trigger *i, const u_int16_t proto, const u_int16_t dport)
+{
+	u_int16_t rproto = i->rproto ? : proto;
+
+	return ((rproto == proto) && (i->ports.rport[0] <= dport)
+		&& (i->ports.rport[1] >= dport));
+}
+
+static unsigned int trigger_in(struct sk_buff **pskb)
+{
+	struct ipt_trigger *trig;
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+	struct iphdr *iph;
+	struct tcphdr *tcph;
+
+	ct = nf_ct_get(*pskb, &ctinfo);
+	if ((ct == NULL) || !(ct->status & IPS_TRIGGER))
+		return XT_CONTINUE;
+
+	iph = ip_hdr(*pskb);
+	tcph = (void *)iph + (iph->ihl << 2);	/* Might be TCP, UDP */
+
+	/* Check if the trigger-ed range has already existed in 'trigger_list'. */
+	trig = LIST_FIND(&trigger_list, trigger_in_matched, struct ipt_trigger *, iph->protocol, ntohs(tcph->dest));
+
+	if (trig != NULL) {
+		DEBUGP("Trigger In: from %pI4, destination port %u\n", &iph->saddr, ntohs(tcph->dest));
+		/* Yeah, it exists. We need to update(delay) the destroying timer. */
+		trigger_timer_refresh(trig);
+
+		return NF_ACCEPT;	/* Accept it, or the imcoming packet could be 
+					   dropped in the FORWARD chain */
+	}
+
+	return XT_CONTINUE;	/* Our job is the interception. */
+}
+
+static unsigned int trigger_dnat(struct sk_buff **pskb, unsigned int hooknum)
+{
+	struct ipt_trigger *trig;
+	struct iphdr *iph;
+	struct tcphdr *tcph;
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+	struct nf_nat_range newrange;
+
+	iph = ip_hdr(*pskb);
+	tcph = (void *)iph + (iph->ihl << 2);	/* Might be TCP, UDP */
+
+	NF_CT_ASSERT(hooknum == NF_INET_PRE_ROUTING);
+	/* Check if the trigger-ed range has already existed in 'trigger_list'. */
+	trig = LIST_FIND(&trigger_list, trigger_in_matched, struct ipt_trigger *, iph->protocol, ntohs(tcph->dest));
+
+	if (trig == NULL || trig->srcip == 0)
+		return XT_CONTINUE;	/* We don't block any packet. */
+
+	trig->reply = 1;	/* Confirm there has been a reply connection. */
+	ct = nf_ct_get(*pskb, &ctinfo);
+	NF_CT_ASSERT(ct && (ctinfo == IP_CT_NEW));
+
+	DEBUGP("Trigger DNAT: %pI4 ", &trig->srcip);
+	nf_ct_dump_tuple_ip(&ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple);
+
+	/* Alter the destination of imcoming packet. */
+	memset(&newrange, 0, sizeof(newrange));
+	newrange.flags       = NF_NAT_RANGE_MAP_IPS;
+	newrange.min_addr.ip = trig->srcip;
+	newrange.max_addr.ip = trig->srcip;
+
+	ct->status |= IPS_TRIGGER;
+
+	/* Hand modified range to generic setup. */
+	return nf_nat_setup_info(ct, &newrange, NF_NAT_MANIP_DST);
+}
+
+static inline int trigger_refresh_matched(const struct ipt_trigger *i, u_int16_t proto, u_int16_t sport)
+{
+	u_int16_t rproto = i->rproto ? : proto;
+
+	return rproto == proto && i->ports.rport[0] <= sport && i->ports.rport[1] >= sport;
+}
+
+static unsigned int trigger_refresh(struct sk_buff **pskb)
+{
+	struct iphdr *iph;
+	struct tcphdr *tcph;
+	struct ipt_trigger *trig;
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+
+	ct = nf_ct_get(*pskb, &ctinfo);
+	if ((ct == NULL) || !(ct->status & IPS_TRIGGER))
+		return XT_CONTINUE;
+
+	iph = ip_hdr(*pskb);
+	tcph = (void *)iph + (iph->ihl << 2);	/* Might be TCP, UDP */
+
+	trig = LIST_FIND(&trigger_list, trigger_refresh_matched, struct ipt_trigger *, iph->protocol, tcph->source);
+	if (trig != NULL) {
+		DEBUGP("Trigger Refresh: from %pI4, %u\n", &iph->saddr, ntohs(tcph->source));
+		trigger_timer_refresh(trig);
+	}
+
+	return XT_CONTINUE;
+}
+
+static unsigned int target(struct sk_buff *skb, const struct xt_action_param *par)
+{
+	const struct ipt_trigger_info *info = par->targinfo;
+	unsigned int hooknum = par->hooknum;
+	const struct iphdr *iph = ip_hdr(skb);
+
+	/* DEBUGP("%s: type = %s\n", __FUNCTION__, 
+	   (info->type == IPT_TRIGGER_DNAT) ? "dnat" :
+	   (info->type == IPT_TRIGGER_IN) ? "in" : "out"); */
+
+	/* The Port-trigger only supports TCP and UDP. */
+	if ((iph->protocol != IPPROTO_TCP) && (iph->protocol != IPPROTO_UDP))
+		return XT_CONTINUE;
+
+	if (info->type == IPT_TRIGGER_OUT)
+		return trigger_out(&skb, par->targinfo);
+	else if (info->type == IPT_TRIGGER_IN)
+		return trigger_in(&skb);
+	else if (info->type == IPT_TRIGGER_DNAT)
+		return trigger_dnat(&skb, hooknum);
+	else if (info->type == IPT_TRIGGER_REFRESH)
+		return trigger_refresh(&skb);
+
+	return XT_CONTINUE;
+}
+
+static int checkentry(const struct xt_tgchk_param *par)
+{
+	unsigned int hook_mask = par->hook_mask;
+	const struct ipt_trigger_info *info = par->targinfo;
+	const char *tablename = par->table;
+
+	if ((strcmp(tablename, "mangle") == 0)) {
+		DEBUGP("trigger_check: bad table `%s'.\n", tablename);
+		return -EINVAL;
+	}
+	if (hook_mask & ~((1 << NF_INET_PRE_ROUTING) | (1 << NF_INET_FORWARD))) {
+		DEBUGP("trigger_check: bad hooks %x.\n", hook_mask);
+		return -EINVAL;
+	}
+	if (info->proto) {
+		if (info->proto != IPPROTO_TCP && info->proto != IPPROTO_UDP) {
+			DEBUGP("trigger_check: bad proto %d.\n", info->proto);
+			return -EINVAL;
+		}
+	}
+	if (info->type == IPT_TRIGGER_OUT) {
+		if (!info->ports.mport[0] || !info->ports.rport[0]) {
+			DEBUGP("trigger_check: Try 'iptables -j TRIGGER -h' for help.\n");
+			return -EINVAL;
+		}
+	}
+
+	/* Empty the 'trigger_list' */
+	trigger_flush();
+
+	return 0;
+}
+
+static struct xt_target redirect_reg = {
+	.name = "TRIGGER",
+	.family = NFPROTO_IPV4,
+	.target = target,
+	.targetsize = sizeof(struct ipt_trigger_info),
+	.checkentry = checkentry,
+	.me = THIS_MODULE,
+};
+
+static int __init init(void)
+{
+	return xt_register_target(&redirect_reg);
+}
+
+static void __exit fini(void)
+{
+	xt_unregister_target(&redirect_reg);
+	trigger_flush();
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_ipp2p.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_ipp2p.c
new file mode 100644
index 000000000..f646bcc71
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_ipp2p.c
@@ -0,0 +1,780 @@
+#if defined(MODVERSIONS)
+#include <linux/modversions.h>
+#endif
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/netfilter_ipv4/ipt_ipp2p.h>
+#include <net/tcp.h>
+#include <net/udp.h>
+
+#define get_u8(X,O)  (*(__u8 *)(X + O))
+#define get_u16(X,O)  (*(__u16 *)(X + O))
+#define get_u32(X,O)  (*(__u32 *)(X + O))
+
+MODULE_AUTHOR("Eicke Friedrich/Klaus Degner <ipp2p@ipp2p.org>");
+MODULE_DESCRIPTION("An extension to iptables to identify P2P traffic.");
+MODULE_LICENSE("GPL");
+
+/*Search for UDP eDonkey/eMule/Kad commands*/
+int udp_search_edk(unsigned char *haystack, int packet_len)
+{
+	unsigned char *t = haystack;
+	t += 8;
+
+	switch (t[0]) {
+	case 0xe3:
+		{		/*edonkey */
+			switch (t[1]) {
+				/* client -> server status request */
+			case 0x96:
+				if (packet_len == 14)
+					return ((IPP2P_EDK * 100) + 50);
+				break;
+				/* server -> client status request */
+			case 0x97:
+				if (packet_len == 42)
+					return ((IPP2P_EDK * 100) + 51);
+				break;
+				/* server description request */
+				/* e3 2a ff f0 .. | size == 6 */
+			case 0xa2:
+				if ((packet_len == 14) && (get_u16(t, 2) == __constant_htons(0xfff0)))
+					return ((IPP2P_EDK * 100) + 52);
+				break;
+				/* server description response */
+				/* e3 a3 ff f0 ..  | size > 40 && size < 200 */
+				//case 0xa3: return ((IPP2P_EDK * 100) + 53);
+				//      break;
+			case 0x9a:
+				if (packet_len == 26)
+					return ((IPP2P_EDK * 100) + 54);
+				break;
+
+			case 0x92:
+				if (packet_len == 18)
+					return ((IPP2P_EDK * 100) + 55);
+				break;
+			}
+			break;
+		}
+	case 0xe4:
+		{
+			switch (t[1]) {
+				/* e4 20 .. | size == 43 */
+			case 0x20:
+				if ((packet_len == 43) && (t[2] != 0x00) && (t[34] != 0x00))
+					return ((IPP2P_EDK * 100) + 60);
+				break;
+				/* e4 00 .. 00 | size == 35 ? */
+			case 0x00:
+				if ((packet_len == 35) && (t[26] == 0x00))
+					return ((IPP2P_EDK * 100) + 61);
+				break;
+				/* e4 10 .. 00 | size == 35 ? */
+			case 0x10:
+				if ((packet_len == 35) && (t[26] == 0x00))
+					return ((IPP2P_EDK * 100) + 62);
+				break;
+				/* e4 18 .. 00 | size == 35 ? */
+			case 0x18:
+				if ((packet_len == 35) && (t[26] == 0x00))
+					return ((IPP2P_EDK * 100) + 63);
+				break;
+				/* e4 52 .. | size = 44 */
+			case 0x52:
+				if (packet_len == 44)
+					return ((IPP2P_EDK * 100) + 64);
+				break;
+				/* e4 58 .. | size == 6 */
+			case 0x58:
+				if (packet_len == 14)
+					return ((IPP2P_EDK * 100) + 65);
+				break;
+				/* e4 59 .. | size == 2 */
+			case 0x59:
+				if (packet_len == 10)
+					return ((IPP2P_EDK * 100) + 66);
+				break;
+				/* e4 28 .. | packet_len == 52,77,102,127... */
+			case 0x28:
+				if (((packet_len - 52) % 25) == 0)
+					return ((IPP2P_EDK * 100) + 67);
+				break;
+				/* e4 50 xx xx | size == 4 */
+			case 0x50:
+				if (packet_len == 12)
+					return ((IPP2P_EDK * 100) + 68);
+				break;
+				/* e4 40 xx xx | size == 48 */
+			case 0x40:
+				if (packet_len == 56)
+					return ((IPP2P_EDK * 100) + 69);
+				break;
+			}
+			break;
+		}
+	}			/* end of switch (t[0]) */
+	return 0;
+}				/*udp_search_edk */
+
+/*Search for UDP Gnutella commands*/
+int udp_search_gnu(unsigned char *haystack, int packet_len)
+{
+	unsigned char *t = haystack;
+	t += 8;
+
+	if (memcmp(t, "GND", 3) == 0)
+		return ((IPP2P_GNU * 100) + 51);
+	if (memcmp(t, "GNUTELLA ", 9) == 0)
+		return ((IPP2P_GNU * 100) + 52);
+	return 0;
+}				/*udp_search_gnu */
+
+/*Search for UDP KaZaA commands*/
+int udp_search_kazaa(unsigned char *haystack, int packet_len)
+{
+	unsigned char *t = haystack;
+
+	if (t[packet_len - 1] == 0x00) {
+		t += (packet_len - 6);
+		if (memcmp(t, "KaZaA", 5) == 0)
+			return (IPP2P_KAZAA * 100 + 50);
+	}
+
+	return 0;
+}				/*udp_search_kazaa */
+
+/*Search for UDP DirectConnect commands*/
+int udp_search_directconnect(unsigned char *haystack, int packet_len)
+{
+	unsigned char *t = haystack;
+	if ((*(t + 8) == 0x24) && (*(t + packet_len - 1) == 0x7c)) {
+		t += 8;
+		if (memcmp(t, "SR ", 3) == 0)
+			return ((IPP2P_DC * 100) + 60);
+		if (memcmp(t, "Ping ", 5) == 0)
+			return ((IPP2P_DC * 100) + 61);
+	}
+	return 0;
+}				/*udp_search_directconnect */
+
+/*Search for UDP BitTorrent commands*/
+int udp_search_bit(unsigned char *haystack, int packet_len)
+{
+	switch (packet_len) {
+	case 24:
+		/* ^ 00 00 04 17 27 10 19 80 */
+		if ((ntohl(get_u32(haystack, 8)) == 0x00000417) && (ntohl(get_u32(haystack, 12)) == 0x27101980))
+			return (IPP2P_BIT * 100 + 50);
+		break;
+	case 44:
+		if (get_u32(haystack, 16) == __constant_htonl(0x00000400)
+		    && get_u32(haystack, 36) == __constant_htonl(0x00000104))
+			return (IPP2P_BIT * 100 + 51);
+		if (get_u32(haystack, 16) == __constant_htonl(0x00000400))
+			return (IPP2P_BIT * 100 + 61);
+		break;
+	case 65:
+		if (get_u32(haystack, 16) == __constant_htonl(0x00000404)
+		    && get_u32(haystack, 36) == __constant_htonl(0x00000104))
+			return (IPP2P_BIT * 100 + 52);
+		if (get_u32(haystack, 16) == __constant_htonl(0x00000404))
+			return (IPP2P_BIT * 100 + 62);
+		break;
+	case 67:
+		if (get_u32(haystack, 16) == __constant_htonl(0x00000406)
+		    && get_u32(haystack, 36) == __constant_htonl(0x00000104))
+			return (IPP2P_BIT * 100 + 53);
+		if (get_u32(haystack, 16) == __constant_htonl(0x00000406))
+			return (IPP2P_BIT * 100 + 63);
+		break;
+	case 211:
+		if (get_u32(haystack, 8) == __constant_htonl(0x00000405))
+			return (IPP2P_BIT * 100 + 54);
+		break;
+	case 29:
+		if ((get_u32(haystack, 8) == __constant_htonl(0x00000401)))
+			return (IPP2P_BIT * 100 + 55);
+		break;
+	case 52:
+		if (get_u32(haystack, 8) == __constant_htonl(0x00000827) &&
+		    get_u32(haystack, 12) == __constant_htonl(0x37502950))
+			return (IPP2P_BIT * 100 + 80);
+		break;
+	default:
+		/* this packet does not have a constant size */
+		if (packet_len >= 40 && get_u32(haystack, 16) == __constant_htonl(0x00000402)
+		    && get_u32(haystack, 36) == __constant_htonl(0x00000104))
+			return (IPP2P_BIT * 100 + 56);
+		break;
+	}
+
+	/* some extra-bitcomet rules:
+	 * "d1:" [a|r] "d2:id20:"
+	 */
+	if (packet_len > 30 && get_u8(haystack, 8) == 'd' && get_u8(haystack, 9) == '1' && get_u8(haystack, 10) == ':') {
+		if (get_u8(haystack, 11) == 'a' || get_u8(haystack, 11) == 'r') {
+			if (memcmp(haystack + 12, "d2:id20:", 8) == 0)
+				return (IPP2P_BIT * 100 + 57);
+		}
+	}
+
+	return 0;
+}				/*udp_search_bit */
+
+/*Search for Ares commands*/
+//#define IPP2P_DEBUG_ARES
+int search_ares(const unsigned char *payload, const u16 plen)
+//int search_ares (unsigned char *haystack, int packet_len, int head_len)
+{
+//      const unsigned char *t = haystack + head_len;
+
+	/* all ares packets start with  */
+	if (payload[1] == 0 && (plen - payload[0]) == 3) {
+		switch (payload[2]) {
+		case 0x5a:
+			/* ares connect */
+			if (plen == 6 && payload[5] == 0x05)
+				return ((IPP2P_ARES * 100) + 1);
+			break;
+		case 0x09:
+			/* ares search, min 3 chars --> 14 bytes
+			 * lets define a search can be up to 30 chars --> max 34 bytes
+			 */
+			if (plen >= 14 && plen <= 34)
+				return ((IPP2P_ARES * 100) + 1);
+			break;
+#ifdef IPP2P_DEBUG_ARES
+		default:
+			printk(KERN_DEBUG "Unknown Ares command %x recognized, len: %u \n", (unsigned int)payload[2], plen);
+#endif /* IPP2P_DEBUG_ARES */
+		}
+	}
+
+	return 0;
+}				/*search_ares */
+
+/*Search for SoulSeek commands*/
+int search_soul(const unsigned char *payload, const u16 plen)
+{
+//#define IPP2P_DEBUG_SOUL
+	/* match: xx xx xx xx | xx = sizeof(payload) - 4 */
+	if (get_u32(payload, 0) == (plen - 4)) {
+		const __u32 m = get_u32(payload, 4);
+		/* match 00 yy yy 00, yy can be everything */
+		if (get_u8(payload, 4) == 0x00 && get_u8(payload, 7) == 0x00) {
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "0: Soulseek command 0x%x recognized\n", get_u32(payload, 4));
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 1);
+		}
+
+		/* next match: 01 yy 00 00 | yy can be everything */
+		if (get_u8(payload, 4) == 0x01 && get_u16(payload, 6) == 0x0000) {
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "1: Soulseek command 0x%x recognized\n", get_u16(payload, 4));
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 2);
+		}
+
+		/* other soulseek commandos are: 1-5,7,9,13-18,22,23,26,28,35-37,40-46,50,51,60,62-69,91,92,1001 */
+		/* try to do this in an intelligent way */
+		/* get all small commandos */
+		switch (m) {
+		case 7:
+		case 9:
+		case 22:
+		case 23:
+		case 26:
+		case 28:
+		case 50:
+		case 51:
+		case 60:
+		case 91:
+		case 92:
+		case 1001:
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "2: Soulseek command 0x%x recognized\n", get_u16(payload, 4));
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 3);
+		}
+
+		if (m > 0 && m < 6) {
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "3: Soulseek command 0x%x recognized\n", get_u16(payload, 4));
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 4);
+		}
+		if (m > 12 && m < 19) {
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "4: Soulseek command 0x%x recognized\n", get_u16(payload, 4));
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 5);
+		}
+
+		if (m > 34 && m < 38) {
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "5: Soulseek command 0x%x recognized\n", get_u16(payload, 4));
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 6);
+		}
+
+		if (m > 39 && m < 47) {
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "6: Soulseek command 0x%x recognized\n", get_u16(payload, 4));
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 7);
+		}
+
+		if (m > 61 && m < 70) {
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "7: Soulseek command 0x%x recognized\n", get_u16(payload, 4));
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 8);
+		}
+#ifdef IPP2P_DEBUG_SOUL
+		printk(KERN_DEBUG "unknown SOULSEEK command: 0x%x, first 16 bit: 0x%x, first 8 bit: 0x%x ,soulseek ???\n",
+		       get_u32(payload, 4), get_u16(payload, 4) >> 16, get_u8(payload, 4) >> 24);
+#endif /* IPP2P_DEBUG_SOUL */
+	}
+
+	/* match 14 00 00 00 01 yy 00 00 00 STRING(YY) 01 00 00 00 00 46|50 00 00 00 00 */
+	/* without size at the beginning !!! */
+	if (get_u32(payload, 0) == 0x14 && get_u8(payload, 4) == 0x01) {
+		__u32 y = get_u32(payload, 5);
+		/* we need 19 chars + string */
+		if ((y + 19) <= (plen)) {
+			const unsigned char *w = payload + 9 + y;
+			if (get_u32(w, 0) == 0x01 && (get_u16(w, 4) == 0x4600 || get_u16(w, 4) == 0x5000)
+			    && get_u32(w, 6) == 0x00) ;
+#ifdef IPP2P_DEBUG_SOUL
+			printk(KERN_DEBUG "Soulssek special client command recognized\n");
+#endif /* IPP2P_DEBUG_SOUL */
+			return ((IPP2P_SOUL * 100) + 9);
+		}
+	}
+	return 0;
+}
+
+/*Search for WinMX commands*/
+int search_winmx(const unsigned char *payload, const u16 plen)
+{
+//#define IPP2P_DEBUG_WINMX
+	if (((plen) == 4) && (memcmp(payload, "SEND", 4) == 0))
+		return ((IPP2P_WINMX * 100) + 1);
+	if (((plen) == 3) && (memcmp(payload, "GET", 3) == 0))
+		return ((IPP2P_WINMX * 100) + 2);
+	//if (packet_len < (head_len + 10)) return 0;
+	if (plen < 10)
+		return 0;
+
+	if ((memcmp(payload, "SEND", 4) == 0) || (memcmp(payload, "GET", 3) == 0)) {
+		u16 c = 4;
+		const u16 end = plen - 2;
+		u8 count = 0;
+		while (c < end) {
+			if (payload[c] == 0x20 && payload[c + 1] == 0x22) {
+				c++;
+				count++;
+				if (count >= 2)
+					return ((IPP2P_WINMX * 100) + 3);
+			}
+			c++;
+		}
+	}
+
+	if (plen == 149 && payload[0] == '8') {
+#ifdef IPP2P_DEBUG_WINMX
+		printk(KERN_INFO "maybe WinMX\n");
+#endif
+		if (get_u32(payload, 17) == 0 && get_u32(payload, 21) == 0 && get_u32(payload, 25) == 0 &&
+		    get_u16(payload, 39) == 0 && get_u16(payload, 135) == __constant_htons(0x7edf)
+		    && get_u16(payload, 147) == __constant_htons(0xf792))
+		{
+#ifdef IPP2P_DEBUG_WINMX
+			printk(KERN_INFO "got WinMX\n");
+#endif
+			return ((IPP2P_WINMX * 100) + 4);
+		}
+	}
+	return 0;
+}				/*search_winmx */
+
+/*Search for appleJuice commands*/
+int search_apple(const unsigned char *payload, const u16 plen)
+{
+	if ((plen > 7) && (payload[6] == 0x0d) && (payload[7] == 0x0a) && (memcmp(payload, "ajprot", 6) == 0))
+		return (IPP2P_APPLE * 100);
+
+	return 0;
+}
+
+/*Search for BitTorrent commands*/
+int search_bittorrent(const unsigned char *payload, const u16 plen)
+{
+	if (plen > 20) {
+		/* test for match 0x13+"BitTorrent protocol" */
+		if (payload[0] == 0x13) {
+			if (memcmp(payload + 1, "BitTorrent protocol", 19) == 0)
+				return (IPP2P_BIT * 100);
+		}
+
+		/* get tracker commandos, all starts with GET /
+		 * then it can follow: scrape| announce
+		 * and then ?hash_info=
+		 */
+		if (memcmp(payload, "GET /", 5) == 0) {
+			/* message scrape */
+			if (memcmp(payload + 5, "scrape?info_hash=", 17) == 0)
+				return (IPP2P_BIT * 100 + 1);
+			/* message announce */
+			if (memcmp(payload + 5, "announce?info_hash=", 19) == 0)
+				return (IPP2P_BIT * 100 + 2);
+		}
+	} else {
+		/* bitcomet encryptes the first packet, so we have to detect another
+		 * one later in the flow */
+		/* first try failed, too many missdetections */
+		//if ( size == 5 && get_u32(t,0) == __constant_htonl(1) && t[4] < 3) return (IPP2P_BIT * 100 + 3);
+
+		/* second try: block request packets */
+		if (plen == 17 && get_u32(payload, 0) == __constant_htonl(0x0d) && payload[4] == 0x06
+		    && get_u32(payload, 13) == __constant_htonl(0x4000))
+			return (IPP2P_BIT * 100 + 3);
+	}
+
+	return 0;
+}
+
+/*check for Kazaa get command*/
+int search_kazaa(const unsigned char *payload, const u16 plen)
+{
+	if ((payload[plen - 2] == 0x0d) && (payload[plen - 1] == 0x0a) && memcmp(payload, "GET /.hash=", 11) == 0)
+		return (IPP2P_DATA_KAZAA * 100);
+
+	return 0;
+}
+
+/*check for gnutella get command*/
+int search_gnu(const unsigned char *payload, const u16 plen)
+{
+	if ((payload[plen - 2] == 0x0d) && (payload[plen - 1] == 0x0a)) {
+		if (memcmp(payload, "GET /get/", 9) == 0)
+			return ((IPP2P_DATA_GNU * 100) + 1);
+		if (memcmp(payload, "GET /uri-res/", 13) == 0)
+			return ((IPP2P_DATA_GNU * 100) + 2);
+	}
+	return 0;
+}
+
+/*check for gnutella get commands and other typical data*/
+int search_all_gnu(const unsigned char *payload, const u16 plen)
+{
+
+	if ((payload[plen - 2] == 0x0d) && (payload[plen - 1] == 0x0a)) {
+
+		if (memcmp(payload, "GNUTELLA CONNECT/", 17) == 0)
+			return ((IPP2P_GNU * 100) + 1);
+		if (memcmp(payload, "GNUTELLA/", 9) == 0)
+			return ((IPP2P_GNU * 100) + 2);
+
+		if ((memcmp(payload, "GET /get/", 9) == 0) || (memcmp(payload, "GET /uri-res/", 13) == 0)) {
+			u16 c = 8;
+			const u16 end = plen - 22;
+			while (c < end) {
+				if (payload[c] == 0x0a && payload[c + 1] == 0x0d
+				    && ((memcmp(&payload[c + 2], "X-Gnutella-", 11) == 0)
+					|| (memcmp(&payload[c + 2], "X-Queue:", 8) == 0)))
+					return ((IPP2P_GNU * 100) + 3);
+				c++;
+			}
+		}
+	}
+	return 0;
+}
+
+/*check for KaZaA download commands and other typical data*/
+int search_all_kazaa(const unsigned char *payload, const u16 plen)
+{
+	if ((payload[plen - 2] == 0x0d) && (payload[plen - 1] == 0x0a)) {
+
+		if (memcmp(payload, "GIVE ", 5) == 0)
+			return ((IPP2P_KAZAA * 100) + 1);
+
+		if (memcmp(payload, "GET /", 5) == 0) {
+			u16 c = 8;
+			const u16 end = plen - 22;
+			while (c < end) {
+				if (payload[c] == 0x0a && payload[c + 1] == 0x0d
+				    && ((memcmp(&payload[c + 2], "X-Kazaa-Username: ", 18) == 0)
+					|| (memcmp(&payload[c + 2], "User-Agent: PeerEnabler/", 24) == 0)))
+					return ((IPP2P_KAZAA * 100) + 2);
+				c++;
+			}
+		}
+	}
+	return 0;
+}
+
+/*fast check for edonkey file segment transfer command*/
+int search_edk(const unsigned char *payload, const u16 plen)
+{
+	if (payload[0] != 0xe3)
+		return 0;
+	else {
+		if (payload[5] == 0x47)
+			return (IPP2P_DATA_EDK * 100);
+		else
+			return 0;
+	}
+}
+
+/*intensive but slower search for some edonkey packets including size-check*/
+int search_all_edk(const unsigned char *payload, const u16 plen)
+{
+	if (payload[0] != 0xe3)
+		return 0;
+	else {
+		//t += head_len;
+		const u16 cmd = get_u16(payload, 1);
+		if (cmd == (plen - 5)) {
+			switch (payload[5]) {
+			case 0x01:
+				return ((IPP2P_EDK * 100) + 1);	/*Client: hello or Server:hello */
+			case 0x4c:
+				return ((IPP2P_EDK * 100) + 9);	/*Client: Hello-Answer */
+			}
+		}
+		return 0;
+	}
+}
+
+/*fast check for Direct Connect send command*/
+int search_dc(const unsigned char *payload, const u16 plen)
+{
+
+	if (payload[0] != 0x24)
+		return 0;
+	else {
+		if (memcmp(&payload[1], "Send|", 5) == 0)
+			return (IPP2P_DATA_DC * 100);
+		else
+			return 0;
+	}
+
+}
+
+/*intensive but slower check for all direct connect packets*/
+int search_all_dc(const unsigned char *payload, const u16 plen)
+{
+//    unsigned char *t = haystack;
+
+	if (payload[0] == 0x24 && payload[plen - 1] == 0x7c) {
+		const unsigned char *t = &payload[1];
+		/* Client-Hub-Protocol */
+		if (memcmp(t, "Lock ", 5) == 0)
+			return ((IPP2P_DC * 100) + 1);
+		/* Client-Client-Protocol, some are already recognized by client-hub (like lock) */
+		if (memcmp(t, "MyNick ", 7) == 0)
+			return ((IPP2P_DC * 100) + 38);
+	}
+	return 0;
+}
+
+/*check for mute*/
+int search_mute(const unsigned char *payload, const u16 plen)
+{
+	if (plen == 209 || plen == 345 || plen == 473 || plen == 609 || plen == 1121) {
+		//printk(KERN_DEBUG "size hit: %u",size);
+		if (memcmp(payload, "PublicKey: ", 11) == 0) {
+			return ((IPP2P_MUTE * 100) + 0);
+		}
+	}
+	return 0;
+}
+
+/* check for xdcc */
+int search_xdcc(const unsigned char *payload, const u16 plen)
+{
+	/* search in small packets only */
+	if (plen > 20 && plen < 200 && payload[plen - 1] == 0x0a && payload[plen - 2] == 0x0d
+	    && memcmp(payload, "PRIVMSG ", 8) == 0) {
+
+		u16 x = 10;
+		const u16 end = plen - 13;
+
+		/* is seems to be a irc private massage, chedck for xdcc command */
+		while (x < end) {
+			if (payload[x] == ':') {
+				if (memcmp(&payload[x + 1], "xdcc send #", 11) == 0)
+					return ((IPP2P_XDCC * 100) + 0);
+			}
+			x++;
+		}
+	}
+	return 0;
+}
+
+/* search for waste */
+int search_waste(const unsigned char *payload, const u16 plen)
+{
+	if (plen >= 8 && memcmp(payload, "GET.sha1:", 9) == 0)
+		return ((IPP2P_WASTE * 100) + 0);
+
+	return 0;
+}
+
+static struct {
+	int command;
+	__u8 short_hand;	/*for fucntions included in short hands */
+	int packet_len;
+	int (*function_name) (const unsigned char *, const u16);
+} matchlist[] = {
+	{IPP2P_EDK, SHORT_HAND_IPP2P, 20, &search_all_edk},
+//	{IPP2P_DATA_KAZAA,SHORT_HAND_DATA,200, &search_kazaa},
+//	{IPP2P_DATA_EDK,SHORT_HAND_DATA,60, &search_edk},
+//	{IPP2P_DATA_DC,SHORT_HAND_DATA,26, &search_dc},
+	{IPP2P_DC, SHORT_HAND_IPP2P, 5, search_all_dc},
+//	{IPP2P_DATA_GNU,SHORT_HAND_DATA,40, &search_gnu},
+	{IPP2P_GNU, SHORT_HAND_IPP2P, 5, &search_all_gnu},
+	{IPP2P_KAZAA, SHORT_HAND_IPP2P, 5, &search_all_kazaa},
+	{IPP2P_BIT, SHORT_HAND_IPP2P, 20, &search_bittorrent},
+	{IPP2P_APPLE, SHORT_HAND_IPP2P, 5, &search_apple},
+	{IPP2P_SOUL, SHORT_HAND_IPP2P, 5, &search_soul},
+	{IPP2P_WINMX, SHORT_HAND_IPP2P, 2, &search_winmx},
+	{IPP2P_ARES, SHORT_HAND_IPP2P, 5, &search_ares},
+	{IPP2P_MUTE, SHORT_HAND_NONE, 200, &search_mute},
+	{IPP2P_WASTE, SHORT_HAND_NONE, 5, &search_waste},
+	{IPP2P_XDCC, SHORT_HAND_NONE, 5, &search_xdcc},
+	{0, 0, 0, NULL}
+};
+
+static struct {
+	int command;
+	__u8 short_hand;	/*for fucntions included in short hands */
+	int packet_len;
+	int (*function_name) (unsigned char *, int);
+} udp_list[] = {
+	{IPP2P_KAZAA, SHORT_HAND_IPP2P, 14, &udp_search_kazaa},
+	{IPP2P_BIT, SHORT_HAND_IPP2P, 23, &udp_search_bit},
+	{IPP2P_GNU, SHORT_HAND_IPP2P, 11, &udp_search_gnu},
+	{IPP2P_EDK, SHORT_HAND_IPP2P, 9, &udp_search_edk},
+	{IPP2P_DC, SHORT_HAND_IPP2P, 12, &udp_search_directconnect},
+	{0, 0, 0, NULL}
+};
+
+static bool match(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct ipt_p2p_info *info = par->matchinfo;
+	const int offset = par->fragoff;
+	unsigned char *haystack;
+	struct iphdr *ip = ip_hdr(skb);
+	int p2p_result = 0, i = 0;
+	int hlen = ntohs(ip->tot_len) - (ip->ihl * 4);	/*hlen = packet-data length */
+
+	/*must not be a fragment */
+	if (offset) {
+		if (info->debug)
+			printk("IPP2P.match: offset found %i \n", offset);
+		return 0;
+	}
+
+	/*make sure that skb is linear */
+	if (skb_is_nonlinear(skb)) {
+		if (info->debug)
+			printk("IPP2P.match: nonlinear skb found\n");
+		return 0;
+	}
+
+	haystack = (char *)ip + (ip->ihl * 4);	/*haystack = packet data */
+
+	switch (ip->protocol) {
+	case IPPROTO_TCP:	/*what to do with a TCP packet */
+		{
+			struct tcphdr *tcph = (void *)ip + ip->ihl * 4;
+
+			if (tcph->fin)
+				return 0;	/*if FIN bit is set bail out */
+			if (tcph->syn)
+				return 0;	/*if SYN bit is set bail out */
+			if (tcph->rst)
+				return 0;	/*if RST bit is set bail out */
+
+			haystack += tcph->doff * 4;	/*get TCP-Header-Size */
+			hlen -= tcph->doff * 4;
+			while (matchlist[i].command) {
+				if ((((info->cmd & matchlist[i].command) == matchlist[i].command) ||
+				     ((info->cmd & matchlist[i].short_hand) == matchlist[i].short_hand)) &&
+				    (hlen > matchlist[i].packet_len)) {
+					p2p_result = matchlist[i].function_name(haystack, hlen);
+					if (p2p_result) {
+						if (info->debug)
+							printk
+							    ("IPP2P.debug:TCP-match: %i from: %pI4:%i to: %pI4:%i Length: %i\n",
+							     p2p_result, &ip->saddr, ntohs(tcph->source),
+							     &ip->daddr, ntohs(tcph->dest), hlen);
+						return p2p_result;
+					}
+				}
+				i++;
+			}
+			return p2p_result;
+		}
+
+	case IPPROTO_UDP:	/*what to do with an UDP packet */
+		{
+			struct udphdr *udph = (void *)ip + ip->ihl * 4;
+
+			while (udp_list[i].command) {
+				if ((((info->cmd & udp_list[i].command) == udp_list[i].command) ||
+				     ((info->cmd & udp_list[i].short_hand) == udp_list[i].short_hand)) &&
+				    (hlen > udp_list[i].packet_len)) {
+					p2p_result = udp_list[i].function_name(haystack, hlen);
+					if (p2p_result) {
+						if (info->debug)
+							printk
+							    ("IPP2P.debug:UDP-match: %i from: %pI4:%i to: %pI4:%i Length: %i\n",
+							     p2p_result, &ip->saddr, ntohs(udph->source),
+							     &ip->daddr, ntohs(udph->dest), hlen);
+						return p2p_result;
+					}
+				}
+				i++;
+			}
+			return p2p_result;
+		}
+
+	default:
+		return 0;
+	}
+}
+
+static int checkentry(const struct xt_mtchk_param *par)
+{
+	return 0;
+}
+
+static struct xt_match ipp2p_match = {
+	.name = "ipp2p",
+	.family = AF_INET,
+	.match = &match,
+	.matchsize = sizeof(struct ipt_p2p_info),
+	.checkentry = &checkentry,
+	.me = THIS_MODULE,
+};
+
+static int __init init(void)
+{
+	printk(KERN_INFO "IPP2P v%s loading\n", IPP2P_VERSION);
+	return xt_register_match(&ipp2p_match);
+}
+
+static void __exit fini(void)
+{
+	xt_unregister_match(&ipp2p_match);
+	printk(KERN_INFO "IPP2P v%s unloaded\n", IPP2P_VERSION);
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_tos.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_tos.c
new file mode 100644
index 000000000..4a3d5a465
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_tos.c
@@ -0,0 +1,47 @@
+/* Kernel module to match TOS values. */
+
+/* (C) 1999-2001 Paul `Rusty' Russell
+ * (C) 2002-2004 Netfilter Core Team <coreteam@netfilter.org>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/ip.h>
+#include <linux/module.h>
+#include <linux/skbuff.h>
+
+#include <linux/netfilter_ipv4/ipt_tos.h>
+#include <linux/netfilter/x_tables.h>
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("iptables TOS match module");
+
+static bool match(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct ipt_tos_info *info = par->matchinfo;
+
+	return (ip_hdr(skb)->tos == info->tos) ^ info->invert;
+}
+
+static struct xt_match tos_match = {
+	.name		= "tos",
+	.family		= NFPROTO_IPV4,
+	.match		= match,
+	.matchsize	= sizeof(struct ipt_tos_info),
+	.me		= THIS_MODULE,
+};
+
+static int __init ipt_multiport_init(void)
+{
+	return xt_register_match(&tos_match);
+}
+
+static void __exit ipt_multiport_fini(void)
+{
+	xt_unregister_match(&tos_match);
+}
+
+module_init(ipt_multiport_init);
+module_exit(ipt_multiport_fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_web.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_web.c
new file mode 100644
index 000000000..fb0540f4e
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_web.c
@@ -0,0 +1,214 @@
+/*
+
+	web (experimental)
+	HTTP client request match
+	Copyright (C) 2006 Jonathan Zarate
+
+	Licensed under GNU GPL v2 or later.
+
+*/
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/version.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>
+#include <net/sock.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/netfilter_ipv4/ipt_web.h>
+
+MODULE_AUTHOR("Jonathan Zarate");
+MODULE_DESCRIPTION("HTTP client request match (experimental)");
+MODULE_LICENSE("GPL");
+
+#define LOG(...)	do { } while (0);
+
+static int find(const char *data, const char *tail, const char *text)
+{
+	int n, o;
+	int dlen;
+	const char *p, *e;
+
+	while ((data < tail) && (*data == ' ')) ++data;
+	while ((tail > data) && (*(tail - 1) == ' ')) --tail;
+
+	dlen = tail - data;
+
+	// 012345
+	// text
+	// ^text
+	// text$
+	// ^text$
+	// 012345
+
+	while (*text) {
+		n = o = strlen(text);
+		if (*text == '^') {
+			--n;
+			if (*(text + n) == '$') {
+				// exact
+				--n;
+				if ((dlen == n) && (memcmp(data, text + 1, n) == 0)) {
+					LOG(KERN_INFO "matched %s\n", text);
+					return 1;
+				}
+			}
+			else {
+				// begins with
+				if ((dlen >= n) && (memcmp(data, text + 1, n) == 0)) {
+					LOG(KERN_INFO "matched %s\n", text);
+					return 1;
+				}
+			}
+		}
+		else if (*(text + n - 1) == '$') {
+			// ends with
+			--n;
+			if (memcmp(tail - n, text, n) == 0) {
+				LOG(KERN_INFO "matched %s\n", text);
+				return 1;
+			}
+		}
+		else {
+			// contains
+			p = data;
+			e = tail - n;
+			while (p <= e) {
+				if (memcmp(p, text, n) == 0) {
+					LOG(KERN_INFO "matched %s\n", text);
+					return 1;
+				}
+				++p;
+			}
+		}
+
+		text += o + 1;
+	}
+	return 0;
+}
+
+static inline const char *findend(const char *data, const char *tail, int min)
+{
+	int n = tail - data;
+	if (n >= min) {
+		while (data < tail) {
+			if (*data == '\r') return data;
+			++data;
+		}
+	}
+	return NULL;
+}
+
+
+static bool
+match(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct ipt_web_info *info = par->matchinfo;
+	const int offset = par->fragoff;
+	const struct iphdr *iph = ip_hdr(skb);
+	const struct tcphdr *tcph = (void *)iph + iph->ihl * 4;
+	const char *data;
+	const char *tail;
+	const char *p, *q;
+	int doff, dlen;
+	__u32 sig;
+
+	if (offset != 0) return info->invert;
+
+	doff = (tcph->doff * 4);
+ 	data = (void *)tcph + doff;
+	dlen = ntohs(ip_hdr(skb)->tot_len);
+
+	// POST / HTTP/1.0$$$$
+	// GET / HTTP/1.0$$$$
+	// 1234567890123456789
+	if (dlen < 18) return info->invert;
+
+	// "GET " or "POST"
+	sig = *(__u32 *)data;
+	if ((sig != __constant_htonl(0x47455420)) && (sig != __constant_htonl(0x504f5354))) {
+		return info->invert;
+	}
+
+	tail = data + dlen;
+	if (dlen > 1024) {
+		dlen = 1024;
+		tail = data + 1024;
+	}
+
+	// POST / HTTP/1.0$$$$
+	// GET / HTTP/1.0$$$$	-- minimum
+	// 0123456789012345678
+	//      9876543210
+	if (((p = findend(data + 14, tail, 18)) == NULL) || (memcmp(p - 9, " HTTP/", 6) != 0))
+		return info->invert;
+
+	switch (info->mode) {
+	case IPT_WEB_HTTP:
+		return !info->invert;
+	case IPT_WEB_HORE:
+		// entire request line, else host line
+		if (find(data + 4, p - 9, info->text)) return !info->invert;
+		break;
+	case IPT_WEB_PATH:
+		// left side of '?' or entire line
+		q = data += 4;
+		p -= 9;
+		while ((q < p) && (*q != '?')) ++q;
+		return find(data, q, info->text) ^ info->invert;
+	case IPT_WEB_QUERY:
+		// right side of '?' or none
+		q = data + 4;
+		p -= 9;
+		while ((q < p) && (*q != '?')) ++q;
+		if (q >= p) return info->invert;
+		return find(q + 1, p, info->text) ^ info->invert;
+	case IPT_WEB_RURI:
+		// entire request line
+		return find(data + 4, p - 9, info->text) ^ info->invert;
+	default:
+		// shutup compiler
+		break;
+	}
+
+	// else, IPT_WEB_HOST
+
+	while (1) {
+		data = p + 2;				// skip previous \r\n
+		p = findend(data, tail, 8);	// p = current line's \r
+		if (p == NULL) return 0;
+
+		if (memcmp(data, "Host: ", 6) == 0)
+			return find(data + 6, p, info->text) ^ info->invert;
+	}
+
+	return !info->invert;
+}
+
+static int
+checkentry(const struct xt_mtchk_param *par)
+{
+	return 0;
+}
+
+static struct xt_match web_match = {
+	.name		= "web",
+	.family		= AF_INET,
+	.match		= &match,
+	.matchsize	= sizeof(struct ipt_web_info),
+	.checkentry	= &checkentry,
+	.destroy	= NULL,
+	.me		= THIS_MODULE
+};
+
+static int __init init(void)
+{
+	return xt_register_match(&web_match);
+}
+
+static void __exit fini(void)
+{
+	xt_unregister_match(&web_match);
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_webmon.c b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_webmon.c
new file mode 100644
index 000000000..83fd55caa
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/ipt_webmon.c
@@ -0,0 +1,1053 @@
+/*  webmon --	A netfilter module to match URLs in HTTP requests
+ *  		This module can match using string match or regular expressions
+ *  		Originally designed for use with Gargoyle router firmware (gargoyle-router.com)
+ *
+ *
+ *  Copyright  2008-2010 by Eric Bishop <eric@gargoyle-router.com>
+ *
+ *  This file is free software: you may copy, redistribute and/or modify it
+ *  under the terms of the GNU General Public License as published by the
+ *  Free Software Foundation, either version 2 of the License, or (at your
+ *  option) any later version.
+ *
+ *  This file is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/if_ether.h>
+#include <linux/string.h>
+#include <linux/ctype.h>
+#include <net/sock.h>
+#include <net/ip.h>
+#include <net/tcp.h>
+#include <linux/time.h>
+#include <linux/spinlock.h>
+#include <linux/proc_fs.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/netfilter_ipv4/ipt_webmon.h>
+#include <linux/ktime.h>
+#include <linux/ip.h>
+#include <linux/netfilter/x_tables.h>
+
+#include "tree_map.h"
+
+#define STRIP "%pI4"
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Eric Bishop");
+MODULE_DESCRIPTION("Monitor URL in HTTP Requests, designed for use with Gargoyle web interface (www.gargoyle-router.com)");
+
+typedef struct qn {
+	uint32_t src_ip;
+	char *value;
+	struct timeval time;
+	struct qn *next;
+	struct qn *previous;
+} queue_node;
+
+typedef struct {
+	queue_node *first;
+	queue_node *last;
+	int length;
+} queue;
+
+static string_map *domain_map = NULL;
+static queue *recent_domains = NULL;
+
+static string_map *search_map = NULL;
+static queue *recent_searches = NULL;
+
+static int max_domain_queue_length = 5;
+static int max_search_queue_length = 5;
+
+static DEFINE_SPINLOCK(webmon_lock);
+
+char domain[650];
+char path[650];
+char domain_key[700];
+char search_key[700];
+char search[650];
+char recent_key[700];
+              
+static struct proc_dir_entry *proc_webmon_recent_domains;
+static struct proc_dir_entry *proc_webmon_recent_searches;
+
+static void update_queue_node_time(queue_node * update_node, queue * full_queue)
+{
+	struct timeval t;
+	do_gettimeofday(&t);
+	update_node->time = t;
+
+	/* move to front of queue if not already at front of queue */
+	if (update_node->previous != NULL) {
+		queue_node *p = update_node->previous;
+		queue_node *n = update_node->next;
+		p->next = n;
+		if (n != NULL) {
+			n->previous = p;
+		} else {
+			full_queue->last = p;
+		}
+		update_node->previous = NULL;
+		update_node->next = full_queue->first;
+		full_queue->first->previous = update_node;
+		full_queue->first = update_node;
+	}
+}
+
+void add_queue_node(uint32_t src_ip, char *value, queue * full_queue, string_map * queue_index, char *queue_index_key,
+		    uint32_t max_queue_length)
+{
+
+	queue_node *new_node = (queue_node *) kmalloc(sizeof(queue_node), GFP_ATOMIC);
+	char *dyn_value = kernel_strdup(value);
+	struct timeval t;
+
+	if (new_node == NULL || dyn_value == NULL) {
+		if (dyn_value) {
+			kfree(dyn_value);
+		}
+		if (new_node) {
+			kfree(new_node);
+		};
+
+		return;
+	}
+	set_map_element(queue_index, queue_index_key, (void *)new_node);
+
+	do_gettimeofday(&t);
+	new_node->time = t;
+	new_node->src_ip = src_ip;
+	new_node->value = dyn_value;
+	new_node->previous = NULL;
+
+	new_node->next = full_queue->first;
+	if (full_queue->first != NULL) {
+		full_queue->first->previous = new_node;
+	}
+	full_queue->first = new_node;
+	full_queue->last = (full_queue->last == NULL) ? new_node : full_queue->last;
+	full_queue->length = full_queue->length + 1;
+
+	if (full_queue->length > max_queue_length) {
+		queue_node *old_node = full_queue->last;
+		full_queue->last = old_node->previous;
+		full_queue->last->next = NULL;
+		full_queue->first = old_node->previous == NULL ? NULL : full_queue->first;	/*shouldn't be needed, but just in case... */
+		full_queue->length = full_queue->length - 1;
+
+		sprintf(queue_index_key, STRIP "@%s", &old_node->src_ip, old_node->value);
+		remove_map_element(queue_index, queue_index_key);
+
+		kfree(old_node->value);
+		kfree(old_node);
+	}
+
+	/*
+	   queue_node* n = full_queue->first;
+	   while(n != NULL)
+	   {
+	   printf("%ld\t%s\t%s\t%s\n", (unsigned long)n->time, n->src_ip, n->dst_ip, n->domain);
+	   n = (queue_node*)n->next;
+	   }
+	   printf("\n\n");
+	 */
+}
+
+void add_queue_node_last(uint32_t src_ip, char *value, time_t sec, queue * full_queue, string_map * queue_index,
+			 char *queue_index_key, uint32_t max_queue_length)
+{
+	queue_node *new_node;
+	char *dyn_value;
+
+	if (full_queue->length >= max_queue_length)
+		return;
+
+	new_node = (queue_node *) kzalloc(sizeof(queue_node), GFP_ATOMIC);
+	dyn_value = kernel_strdup(value);
+
+	if (new_node == NULL || dyn_value == NULL) {
+		kfree(dyn_value);
+		kfree(new_node);
+		return;
+	}
+	set_map_element(queue_index, queue_index_key, (void *)new_node);
+
+	new_node->time.tv_sec = sec;
+	new_node->src_ip = src_ip;
+	new_node->value = dyn_value;
+
+	new_node->previous = full_queue->last;
+	if (full_queue->last != NULL) {
+		full_queue->last->next = new_node;
+	}
+	full_queue->last = new_node;
+	full_queue->first = (full_queue->first == NULL) ? new_node : full_queue->first;
+	full_queue->length = full_queue->length + 1;
+}
+
+void destroy_queue(queue * q)
+{
+	queue_node *last_node = q->last;
+	while (last_node != NULL) {
+		queue_node *previous_node = last_node->previous;
+		free(last_node->value);
+		free(last_node);
+		last_node = previous_node;
+	}
+	free(q);
+}
+
+static int strnicmp(const char *cs, const char *ct, size_t count)
+{
+	register signed char __res = 0;
+
+	while (count) {
+		if ((__res = toupper(*cs) - toupper(*ct++)) != 0 || !*cs++) {
+			break;
+		}
+		count--;
+	}
+	return __res;
+}
+
+char *strnistr(const char *s, const char *find, size_t slen)
+{
+	char c, sc;
+	size_t len;
+
+	if ((c = *find++) != '\0') {
+		len = strlen(find);
+		do {
+			do {
+				if (slen < 1 || (sc = *s) == '\0') {
+					return (NULL);
+				}
+				--slen;
+				++s;
+			}
+			while (toupper(sc) != toupper(c));
+
+			if (len > slen) {
+				return (NULL);
+			}
+		}
+		while (strnicmp(s, find, len) != 0);
+
+		s--;
+	}
+	return ((char *)s);
+}
+
+/* NOTE: This is not quite real edit distance -- all differences are assumed to be in one contiguous block
+ *       If differences are not in a contiguous block computed edit distance will be greater than real edit distance.
+ *       Edit distance computed here is an upper bound on real edit distance.
+ */
+int within_edit_distance(char *s1, char *s2, int max_edit)
+{
+	int edit1, edit2;
+	char *s1sp, *s2sp, *s1ep, *s2ep;
+
+	if (s1 == NULL || s2 == NULL) {
+		return 0;
+	}
+
+	edit1 = strlen(s1);
+	edit2 = strlen(s2);
+	s1sp = s1;
+	s2sp = s2;
+	s1ep = s1 + (edit1 - 1);
+	s2ep = s2 + (edit2 - 1);
+	while (*s1sp != '\0' && *s2sp != '\0' && *s1sp == *s2sp) {
+		s1sp++;
+		s2sp++;
+		edit1--;
+		edit2--;
+	}
+
+	/* if either is zero we got to the end of one of the strings */
+	while (s1ep > s1sp && s2ep > s2sp && *s1ep == *s2ep) {
+		s1ep--;
+		s2ep--;
+		edit1--;
+		edit2--;
+	}
+
+	return edit1 <= max_edit && edit2 <= max_edit ? 1 : 0;
+}
+
+/*
+ * line is the line to be parsed -- it is not modified in any way
+ * max_pieces indicates number of pieces to return, if negative this is determined dynamically
+ * include_remainder_at_max indicates whether the last piece, when max pieces are reached,
+ * 	should be what it would normally be (0) or the entire remainder of the line (1)
+ * 	if max_pieces < 0 this parameter is ignored
+ *
+ *
+ * returns all non-separator pieces in a line
+ * result is dynamically allocated, MUST be freed after call-- even if
+ * line is empty (you still get a valid char** pointer to to a NULL char*)
+ */
+char **split_on_separators(char *line, char *separators, int num_separators, int max_pieces, int include_remainder_at_max,
+			   unsigned long *num_pieces)
+{
+	char **split;
+
+	*num_pieces = 0;
+	if (line != NULL) {
+		int split_index;
+		int non_separator_found;
+		char *dup_line;
+		char *start;
+
+		if (max_pieces < 0) {
+			/* count number of separator characters in line -- this count + 1 is an upperbound on number of pieces */
+			int separator_count = 0;
+			int line_index;
+			for (line_index = 0; line[line_index] != '\0'; line_index++) {
+				int sep_index;
+				int found = 0;
+				for (sep_index = 0; found == 0 && sep_index < num_separators; sep_index++) {
+					found = separators[sep_index] == line[line_index] ? 1 : 0;
+				}
+				separator_count = separator_count + found;
+			}
+			max_pieces = separator_count + 1;
+		}
+		split = (char **)malloc((1 + max_pieces) * sizeof(char *));
+		split_index = 0;
+		split[split_index] = NULL;
+
+		dup_line = strdup(line);
+		start = dup_line;
+		non_separator_found = 0;
+		while (non_separator_found == 0) {
+			int matches = 0;
+			int sep_index;
+			for (sep_index = 0; sep_index < num_separators; sep_index++) {
+				matches = matches == 1 || separators[sep_index] == start[0] ? 1 : 0;
+			}
+			non_separator_found = matches == 0 || start[0] == '\0' ? 1 : 0;
+			if (non_separator_found == 0) {
+				start++;
+			}
+		}
+
+		while (start[0] != '\0' && split_index < max_pieces) {
+			/* find first separator index */
+			int first_separator_index = 0;
+			int separator_found = 0;
+			while (separator_found == 0) {
+				int sep_index;
+				for (sep_index = 0; separator_found == 0 && sep_index < num_separators; sep_index++) {
+					separator_found = separators[sep_index] == start[first_separator_index]
+					    || start[first_separator_index] == '\0' ? 1 : 0;
+				}
+				if (separator_found == 0) {
+					first_separator_index++;
+				}
+			}
+
+			/* copy next piece to split array */
+			if (first_separator_index > 0) {
+				char *next_piece = NULL;
+				if (split_index + 1 < max_pieces || include_remainder_at_max <= 0) {
+					next_piece = (char *)malloc((first_separator_index + 1) * sizeof(char));
+					memcpy(next_piece, start, first_separator_index);
+					next_piece[first_separator_index] = '\0';
+				} else {
+					next_piece = strdup(start);
+				}
+				split[split_index] = next_piece;
+				split[split_index + 1] = NULL;
+				split_index++;
+			}
+
+			/* find next non-separator index, indicating start of next piece */
+			start = start + first_separator_index;
+			non_separator_found = 0;
+			while (non_separator_found == 0) {
+				int matches = 0;
+				int sep_index;
+				for (sep_index = 0; sep_index < num_separators; sep_index++) {
+					matches = matches == 1 || separators[sep_index] == start[0] ? 1 : 0;
+				}
+				non_separator_found = matches == 0 || start[0] == '\0' ? 1 : 0;
+				if (non_separator_found == 0) {
+					start++;
+				}
+			}
+		}
+		free(dup_line);
+		*num_pieces = split_index;
+	} else {
+		split = (char **)malloc((1) * sizeof(char *));
+		split[0] = NULL;
+	}
+	return split;
+}
+
+static void extract_url(const unsigned char *packet_data, int packet_length, char *domain, char *path)
+{
+
+	int path_start_index;
+	int path_end_index;
+	int last_header_index;
+	char last_two_buf[2];
+	int end_found;
+	char *domain_match;
+	char *start_ptr;
+
+	domain[0] = '\0';
+	path[0] = '\0';
+
+	/* get path portion of URL */
+	start_ptr = strnistr((char *)packet_data, " ", packet_length);
+	if (start_ptr == NULL) {
+		return;
+	}
+
+	path_start_index = (int)(start_ptr - (char *)packet_data);
+	start_ptr = strnistr((char *)(packet_data + path_start_index), " ", packet_length - (path_start_index + 2));
+	if (start_ptr == NULL) {
+		return;
+	}
+
+	while (packet_data[path_start_index] == ' ') {
+		path_start_index++;
+	}
+	path_end_index = (int)(strstr((char *)(packet_data + path_start_index), " ") - (char *)packet_data);
+	if (path_end_index > 0) {
+		int path_length = path_end_index - path_start_index;
+		path_length = path_length < 625 ? path_length : 624;	/* prevent overflow */
+		memcpy(path, packet_data + path_start_index, path_length);
+		path[path_length] = '\0';
+	} else {
+		return;
+	}
+
+	/* get header length */
+	last_header_index = 2;
+	memcpy(last_two_buf, (char *)packet_data, 2);
+	end_found = 0;
+	while (end_found == 0 && last_header_index < packet_length) {
+		char next = (char)packet_data[last_header_index];
+		if (next == '\n') {
+			end_found = last_two_buf[1] == '\n' || (last_two_buf[0] == '\n' && last_two_buf[1] == '\r') ? 1 : 0;
+		}
+		if (end_found == 0) {
+			last_two_buf[0] = last_two_buf[1];
+			last_two_buf[1] = next;
+			last_header_index++;
+		}
+	}
+
+	/* get domain portion of URL */
+	domain_match = strnistr((char *)packet_data, "Host:", last_header_index);
+	if (domain_match != NULL) {
+		int domain_end_index;
+		domain_match = domain_match + 5;	/* character after "Host:" */
+		while (domain_match[0] == ' ' && ((char *)domain_match - (char *)packet_data) < last_header_index) {
+			domain_match = domain_match + 1;
+		}
+
+		domain_end_index = 0;
+		while (domain_match[domain_end_index] != '\n' &&
+		       domain_match[domain_end_index] != '\r' &&
+		       domain_match[domain_end_index] != ' ' &&
+		       domain_match[domain_end_index] != ':' &&
+		       ((char *)domain_match - (char *)packet_data) + domain_end_index < last_header_index) {
+			domain_end_index++;
+		}
+		domain_end_index = domain_end_index < 625 ? domain_end_index : 624;	/* prevent overflow */
+		memcpy(domain, domain_match, domain_end_index);
+		domain[domain_end_index] = '\0';
+
+		for (domain_end_index = 0; domain[domain_end_index] != '\0'; domain_end_index++) {
+			domain[domain_end_index] = (char)tolower(domain[domain_end_index]);
+		}
+	}
+}
+
+#ifdef CONFIG_PROC_FS
+
+static void *webmon_proc_start(struct seq_file *seq, loff_t * loff_pos)
+{
+	static unsigned long counter = 0;
+
+	/* beginning a new sequence ? */
+	if (*loff_pos == 0) {
+		/* yes => return a non null value to begin the sequence */
+		return &counter;
+	} else {
+		/* no => it's the end of the sequence, return end to stop reading */
+		*loff_pos = 0;
+		return NULL;
+	}
+}
+
+static void *webmon_proc_next(struct seq_file *seq, void *v, loff_t * pos)
+{
+	return NULL;
+}
+
+static void webmon_proc_stop(struct seq_file *seq, void *v)
+{
+	//don't need to do anything
+}
+
+static int webmon_proc_domain_show(struct seq_file *s, void *v)
+{
+	queue_node *next_node;
+
+	spin_lock_bh(&webmon_lock);
+
+	next_node = recent_domains->first;
+	while (next_node != NULL) {
+		seq_printf(s, "%ld\t" STRIP "\t%s\n", (unsigned long)(next_node->time).tv_sec, &next_node->src_ip,
+			   next_node->value);
+		next_node = (queue_node *) next_node->next;
+	}
+	spin_unlock_bh(&webmon_lock);
+
+	return 0;
+}
+
+static int webmon_proc_search_show(struct seq_file *s, void *v)
+{
+	queue_node *next_node;
+
+	spin_lock_bh(&webmon_lock);
+
+	next_node = recent_searches->first;
+	while (next_node != NULL) {
+		seq_printf(s, "%ld\t" STRIP "\t%s\n", (unsigned long)(next_node->time).tv_sec, &next_node->src_ip,
+			   next_node->value);
+		next_node = (queue_node *) next_node->next;
+	}
+	spin_unlock_bh(&webmon_lock);
+
+	return 0;
+}
+
+static struct seq_operations webmon_proc_domain_sops = {
+	.start = webmon_proc_start,
+	.next = webmon_proc_next,
+	.stop = webmon_proc_stop,
+	.show = webmon_proc_domain_show
+};
+
+static struct seq_operations webmon_proc_search_sops = {
+	.start = webmon_proc_start,
+	.next = webmon_proc_next,
+	.stop = webmon_proc_stop,
+	.show = webmon_proc_search_show
+};
+
+static int webmon_proc_domain_open(struct inode *inode, struct file *file)
+{
+	return seq_open(file, &webmon_proc_domain_sops);
+}
+
+static int webmon_proc_search_open(struct inode *inode, struct file *file)
+{
+	return seq_open(file, &webmon_proc_search_sops);
+}
+
+static struct file_operations webmon_proc_domain_fops = {
+	.owner = THIS_MODULE,
+	.open = webmon_proc_domain_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = seq_release
+};
+
+static struct file_operations webmon_proc_search_fops = {
+	.owner = THIS_MODULE,
+	.open = webmon_proc_search_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = seq_release
+};
+
+#endif
+
+static int ipt_webmon_set_ctl(struct sock *sk, int cmd, void *user, u_int32_t len)
+{
+
+	char *buffer = kmalloc(len, GFP_ATOMIC);
+	if (buffer == NULL) {	/* check for malloc failure */
+		return 0;
+	}
+	copy_from_user(buffer, user, len);
+
+	if (len > 1 + sizeof(uint32_t)) {
+		unsigned char type = buffer[0];
+		uint32_t max_queue_length = *((uint32_t *) (buffer + 1));
+		char *data = buffer + 1 + sizeof(uint32_t);
+		char newline_terminator[] = { '\n', '\r' };
+		char whitespace_chars[] = { '\t', ' ' };
+
+		spin_lock_bh(&webmon_lock);
+		if (type == WEBMON_DOMAIN || type == WEBMON_SEARCH) {
+			unsigned long num_lines;
+			unsigned long line_index;
+			unsigned long num_destroyed;
+			char **lines = split_on_separators(data, newline_terminator, 2, -1, 0, &num_lines);
+
+			/* destroy and re-initialize queue and map */
+			if (type == WEBMON_DOMAIN) {
+				destroy_map(domain_map, DESTROY_MODE_IGNORE_VALUES, &num_destroyed);
+				destroy_queue(recent_domains);
+				recent_domains = (queue *) malloc(sizeof(queue));
+				recent_domains->first = NULL;
+				recent_domains->last = NULL;
+				recent_domains->length = 0;
+				domain_map = initialize_map(0);
+
+				max_domain_queue_length = max_queue_length;
+			} else if (type == WEBMON_SEARCH) {
+				destroy_map(search_map, DESTROY_MODE_IGNORE_VALUES, &num_destroyed);
+				destroy_queue(recent_searches);
+				recent_searches = (queue *) malloc(sizeof(queue));
+				recent_searches->first = NULL;
+				recent_searches->last = NULL;
+				recent_searches->length = 0;
+				search_map = initialize_map(0);
+
+				max_search_queue_length = max_queue_length;
+			}
+
+			for (line_index = 0; line_index < num_lines; line_index++) {
+				char *line = lines[line_index];
+				unsigned long num_pieces;
+				char **split = split_on_separators(line, whitespace_chars, 2, -1, 0, &num_pieces);
+
+				//check that there are 3 pieces (time, src_ip, value)
+				int length;
+				for (length = 0; split[length] != NULL; length++) {
+				}
+				if (length == 3) {
+					time_t time;
+					int parsed_ip[4];
+					int valid_ip =
+					    sscanf(split[1], "%d.%d.%d.%d", parsed_ip, parsed_ip + 1, parsed_ip + 2,
+						   parsed_ip + 3);
+					if (valid_ip == 4) {
+						valid_ip = parsed_ip[0] <= 255 && parsed_ip[1] <= 255 && parsed_ip[2] <= 255
+						    && parsed_ip[3] <= 255 ? valid_ip : 0;
+					}
+					if (sscanf(split[0], "%ld", &time) > 0 && valid_ip == 4) {
+						char *value = split[2];
+						char value_key[700];
+						uint32_t ip =
+						    (parsed_ip[0] << 24) + (parsed_ip[1] << 16) + (parsed_ip[2] << 8) +
+						    (parsed_ip[3]);
+						ip = htonl(ip);
+						sprintf(value_key, STRIP "@%s", &ip, value);
+						if (type == WEBMON_DOMAIN) {
+							add_queue_node_last(ip, value, time, recent_domains, domain_map,
+									    value_key, max_domain_queue_length);
+						} else if (type == WEBMON_SEARCH) {
+							add_queue_node_last(ip, value, time, recent_searches, search_map,
+									    value_key, max_search_queue_length);
+						}
+					}
+				}
+
+				for (length = 0; split[length] != NULL; length++) {
+					free(split[length]);
+				}
+				free(split);
+				free(line);
+			}
+			free(lines);
+		}
+
+		spin_unlock_bh(&webmon_lock);
+	}
+
+	return 1;
+}
+
+static struct nf_sockopt_ops ipt_webmon_sockopts = {
+	.pf = PF_INET,
+	.set_optmin = WEBMON_SET,
+	.set_optmax = WEBMON_SET + 1,
+	.set = ipt_webmon_set_ctl,
+};
+
+static bool match(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct ipt_webmon_info *info = (const struct ipt_webmon_info *)(par->matchinfo);
+
+	struct iphdr *iph;
+
+	/* linearize skb if necessary */
+	struct sk_buff *linear_skb;
+	int skb_copied;
+	if (skb_is_nonlinear(skb)) {
+		linear_skb = skb_copy(skb, GFP_ATOMIC);
+		skb_copied = 1;
+	} else {
+		linear_skb = (struct sk_buff *)skb;
+		skb_copied = 0;
+	}
+
+	/* ignore packets that are not TCP */
+	iph = (struct iphdr *)(skb_network_header(skb));
+	if (iph->protocol == IPPROTO_TCP) {
+		/* get payload */
+		struct tcphdr *tcp_hdr = (struct tcphdr *)(((unsigned char *)iph) + (iph->ihl * 4));
+		unsigned short payload_offset = (tcp_hdr->doff * 4) + (iph->ihl * 4);
+		unsigned char *payload = ((unsigned char *)iph) + payload_offset;
+		unsigned short payload_length = ntohs(iph->tot_len) - payload_offset;
+
+		/* if payload length <= 10 bytes don't bother doing a check, otherwise check for match */
+		if (payload_length > 10) {
+			/* are we dealing with a web page request */
+			if (strnicmp((char *)payload, "GET ", 4) == 0 || strnicmp((char *)payload, "POST ", 5) == 0
+			    || strnicmp((char *)payload, "HEAD ", 5) == 0) {
+				unsigned char save = info->exclude_type == WEBMON_EXCLUDE ? 1 : 0;
+				uint32_t ip_index;
+
+				for (ip_index = 0; ip_index < info->num_exclude_ips; ip_index++) {
+					if ((info->exclude_ips)[ip_index] == iph->saddr) {
+						save = info->exclude_type == WEBMON_EXCLUDE ? 0 : 1;
+					}
+				}
+				for (ip_index = 0; ip_index < info->num_exclude_ranges; ip_index++) {
+					struct ipt_webmon_ip_range r = (info->exclude_ranges)[ip_index];
+					if (ntohl(r.start) >= ntohl(iph->saddr) && ntohl(r.end) <= ntohl(iph->saddr)) {
+						save = info->exclude_type == WEBMON_EXCLUDE ? 0 : 1;
+					}
+				}
+
+				if (save) {
+					extract_url(payload, payload_length, domain, path);
+
+					sprintf(domain_key, STRIP "@%s", &iph->saddr, domain);
+
+					if (strlen(domain) > 0) {
+						char *search_part = NULL;
+						spin_lock_bh(&webmon_lock);
+
+						if (get_string_map_element(domain_map, domain_key)) {
+							//update time
+							update_queue_node_time((queue_node *)
+									       get_map_element(domain_map, domain_key),
+									       recent_domains);
+						} else {
+							//add
+							add_queue_node(iph->saddr, domain, recent_domains, domain_map,
+								       domain_key, max_domain_queue_length);
+						}
+
+						/* printk("domain,path=\"%s\", \"%s\"\n", domain, path); */
+
+						if (strnistr(domain, "google.", 625) != NULL) {
+							search_part = strstr(path, "&q=");
+							search_part = search_part == NULL ? strstr(path, "#q=") : search_part;
+							search_part = search_part == NULL ? strstr(path, "?q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "bing.") != NULL) {
+							search_part = strstr(path, "?q=");
+							search_part = search_part == NULL ? strstr(path, "&q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "yahoo.") != NULL) {
+							search_part = strstr(path, "?p=");
+							search_part = search_part == NULL ? strstr(path, "&p=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "lycos.") != NULL) {
+							search_part = strstr(path, "&query=");
+							search_part =
+							    search_part == NULL ? strstr(path, "?query=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 7;
+						} else if (strstr(domain, "altavista.") != NULL) {
+							search_part = strstr(path, "&q=");
+							search_part = search_part == NULL ? strstr(path, "?q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "duckduckgo.") != NULL) {
+							search_part = strstr(path, "?q=");
+							search_part = search_part == NULL ? strstr(path, "&q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "baidu.") != NULL) {
+							search_part = strstr(path, "?wd=");
+							search_part = search_part == NULL ? strstr(path, "&wd=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 4;
+						} else if (strstr(domain, "search.") != NULL) {
+							search_part = strstr(path, "?q=");
+							search_part = search_part == NULL ? strstr(path, "&q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "aol.") != NULL) {
+							search_part = strstr(path, "&q=");
+							search_part = search_part == NULL ? strstr(path, "?q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "ask.") != NULL) {
+							search_part = strstr(path, "?q=");
+							search_part = search_part == NULL ? strstr(path, "&q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "yandex.") != NULL) {
+							search_part = strstr(path, "?text=");
+							search_part =
+							    search_part == NULL ? strstr(path, "&text=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 6;
+						} else if (strstr(domain, "naver.") != NULL) {
+							search_part = strstr(path, "&query=");
+							search_part =
+							    search_part == NULL ? strstr(path, "?query=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 7;
+						} else if (strstr(domain, "daum.") != NULL) {
+							search_part = strstr(path, "&q=");
+							search_part = search_part == NULL ? strstr(path, "?q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "cuil.") != NULL) {
+							search_part = strstr(path, "?q=");
+							search_part = search_part == NULL ? strstr(path, "&q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "kosmix.") != NULL) {
+							search_part = strstr(path, "/topic/");
+							search_part = search_part == NULL ? search_part : search_part + 7;
+						} else if (strstr(domain, "yebol.") != NULL) {
+							search_part = strstr(path, "?key=");
+							search_part = search_part == NULL ? strstr(path, "&key=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 5;
+						} else if (strstr(domain, "sogou.") != NULL) {
+							search_part = strstr(path, "&query=");
+							search_part =
+							    search_part == NULL ? strstr(path, "?query=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 7;
+						} else if (strstr(domain, "youdao.") != NULL) {
+							search_part = strstr(path, "?q=");
+							search_part = search_part == NULL ? strstr(path, "&q=") : search_part;
+							search_part = search_part == NULL ? search_part : search_part + 3;
+						} else if (strstr(domain, "metacrawler.") != NULL) {
+							search_part = strstr(path, "/ws/results/Web/");
+							search_part = search_part == NULL ? search_part : search_part + 16;
+						} else if (strstr(domain, "webcrawler.") != NULL) {
+							search_part = strstr(path, "/ws/results/Web/");
+							search_part = search_part == NULL ? search_part : search_part + 16;
+						}
+
+						if (search_part != NULL) {
+							int spi, si;
+							queue_node *recent_node = recent_searches->first;
+
+							/*unescape, replacing whitespace with + */
+							si = 0;
+							for (spi = 0;
+							     search_part[spi] != '\0' && search_part[spi] != '&'
+							     && search_part[spi] != '/'; spi++) {
+								int parsed_hex = 0;
+								if (search_part[spi] == '%') {
+									if (search_part[spi + 1] != '\0'
+									    && search_part[spi + 1] != '&'
+									    && search_part[spi + 1] != '/') {
+										if (search_part[spi + 2] != '\0'
+										    && search_part[spi + 2] != '&'
+										    && search_part[spi + 2] != '/') {
+											char enc[3];
+											int hex;
+											enc[0] = search_part[spi + 1];
+											enc[1] = search_part[spi + 2];
+											enc[2] = '\0';
+											if (sscanf(enc, "%x", &hex) > 0) {
+												parsed_hex = 1;
+												search[si] = hex == ' '
+												    || hex == '\t'
+												    || hex == '\r'
+												    || hex ==
+												    '\n' ? '+' : (char)hex;
+												spi = spi + 2;
+											}
+										}
+									}
+								}
+								if (parsed_hex == 0) {
+									search[si] = search_part[spi];
+								}
+								si++;
+							}
+							search[si] = '\0';
+
+							sprintf(search_key, STRIP "@%s", &iph->saddr, search);
+
+							/* Often times search engines will initiate a search as you type it in, but these intermediate queries aren't the real search query
+							 * So, if the most recent query is a substring of the current one, discard it in favor of this one
+							 */
+							if (recent_node != NULL) {
+								if (recent_node->src_ip == iph->saddr) {
+									struct timeval t;
+									do_gettimeofday(&t);
+									if ((recent_node->time).tv_sec + 1 >= t.tv_sec
+									    || ((recent_node->time).tv_sec + 5 >= t.tv_sec
+										&& within_edit_distance(search,
+													recent_node->value,
+													2))) {
+										sprintf(recent_key, STRIP "@%s",
+											&recent_node->src_ip,
+											recent_node->value);
+										remove_map_element(search_map, recent_key);
+
+										recent_searches->first = recent_node->next;
+										recent_searches->last =
+										    recent_searches->first ==
+										    NULL ? NULL : recent_searches->last;
+										if (recent_searches->first != NULL) {
+											recent_searches->first->previous = NULL;
+										}
+										recent_searches->length =
+										    recent_searches->length - 1;
+										free(recent_node->value);
+										free(recent_node);
+									}
+								}
+							}
+
+							if (get_string_map_element(search_map, search_key)) {
+								//update time
+								update_queue_node_time((queue_node *)
+										       get_map_element(search_map, search_key),
+										       recent_searches);
+							} else {
+								//add
+								add_queue_node(iph->saddr, search, recent_searches, search_map,
+									       search_key, max_search_queue_length);
+							}
+						}
+						spin_unlock_bh(&webmon_lock);
+					}
+				}
+			}
+		}
+	}
+
+	/* free skb if we made a copy to linearize it */
+	if (skb_copied == 1) {
+		kfree_skb(linear_skb);
+	}
+
+	/* printk("returning %d from webmon\n\n\n", test); */
+	return 0;
+}
+
+static int checkentry(const struct xt_mtchk_param *par)
+{
+	struct ipt_webmon_info *info = (struct ipt_webmon_info *)(par->matchinfo);
+
+	if (info->ref_count == NULL) {	/* first instance, we're inserting rule */
+		info->ref_count = (uint32_t *) kmalloc(sizeof(uint32_t), GFP_ATOMIC);
+		if (info->ref_count == NULL) {	/* deal with kmalloc failure */
+			printk("ipt_webmon: kmalloc failure in checkentry!\n");
+			return -ENOMEM;
+		}
+		*(info->ref_count) = 1;
+
+		spin_lock_bh(&webmon_lock);
+
+		max_search_queue_length = info->max_searches;
+		max_domain_queue_length = info->max_domains;
+
+		spin_unlock_bh(&webmon_lock);
+
+	} else {
+		*(info->ref_count) = *(info->ref_count) + 1;
+	}
+	return 0;
+}
+
+static void destroy(const struct xt_mtdtor_param *par)
+{
+	struct ipt_webmon_info *info = (struct ipt_webmon_info *)(par->matchinfo);
+
+	*(info->ref_count) = *(info->ref_count) - 1;
+	if (*(info->ref_count) == 0) {
+		kfree(info->ref_count);
+	}
+}
+
+static struct xt_match webmon_match = {
+	.name = "webmon",
+	.match = &match,
+	.family = AF_INET,
+	.matchsize = sizeof(struct ipt_webmon_info),
+	.checkentry = &checkentry,
+	.destroy = &destroy,
+	.me = THIS_MODULE,
+};
+
+static int __init init(void)
+{
+	spin_lock_bh(&webmon_lock);
+
+	recent_domains = (queue *) malloc(sizeof(queue));
+	recent_domains->first = NULL;
+	recent_domains->last = NULL;
+	recent_domains->length = 0;
+	domain_map = initialize_string_map(0);
+
+	recent_searches = (queue *) malloc(sizeof(queue));
+	recent_searches->first = NULL;
+	recent_searches->last = NULL;
+	recent_searches->length = 0;
+	search_map = initialize_string_map(0);
+
+#ifdef CONFIG_PROC_FS
+	{
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,10,14)
+		proc_webmon_recent_domains = proc_create_data("webmon_recent_domains", 0, NULL, &webmon_proc_domain_fops, NULL);
+		proc_webmon_recent_searches = proc_create_data("webmon_recent_searches", 0, NULL, &webmon_proc_search_fops, NULL);
+#else
+		proc_webmon_recent_domains = create_proc_entry("webmon_recent_domains", 0, NULL);
+		proc_webmon_recent_searches = create_proc_entry("webmon_recent_searches", 0, NULL);
+		if (proc_webmon_recent_domains)
+			proc_webmon_recent_domains->proc_fops = &webmon_proc_domain_fops;
+		if (proc_webmon_recent_searches)
+			proc_webmon_recent_searches->proc_fops = &webmon_proc_search_fops;
+#endif
+	}
+#endif
+
+	if (nf_register_sockopt(&ipt_webmon_sockopts) < 0) {
+		printk("ipt_webmon: Can't register sockopts. Aborting\n");
+		spin_unlock_bh(&webmon_lock);
+		return -1;
+	}
+	spin_unlock_bh(&webmon_lock);
+
+	return xt_register_match(&webmon_match);
+}
+
+static void __exit fini(void)
+{
+
+	unsigned long num_destroyed;
+
+	spin_lock_bh(&webmon_lock);
+
+#ifdef CONFIG_PROC_FS
+	remove_proc_entry("webmon_recent_domains", NULL);
+	remove_proc_entry("webmon_recent_searches", NULL);
+#endif
+	nf_unregister_sockopt(&ipt_webmon_sockopts);
+	xt_unregister_match(&webmon_match);
+	destroy_map(domain_map, DESTROY_MODE_IGNORE_VALUES, &num_destroyed);
+	destroy_map(search_map, DESTROY_MODE_IGNORE_VALUES, &num_destroyed);
+	destroy_queue(recent_domains);
+	destroy_queue(recent_searches);
+
+	spin_unlock_bh(&webmon_lock);
+
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_masquerade_ipv4.c b/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_masquerade_ipv4.c
index 8e82db812..c49dd3448 100644
--- a/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_masquerade_ipv4.c
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_masquerade_ipv4.c
@@ -21,13 +21,16 @@
 #include <linux/netfilter/x_tables.h>
 #include <net/netfilter/nf_nat.h>
 #include <net/netfilter/ipv4/nf_nat_masquerade.h>
+
+#if defined(CONFIG_BCM_KF_NETFILTER)
 #include <net/netfilter/nf_conntrack_zones.h>
 #include <net/netfilter/nf_conntrack_helper.h>
 #include <net/netfilter/nf_conntrack_core.h>
+#endif
 
-
+#if defined(CONFIG_BCM_KF_NETFILTER)
 /****************************************************************************/
-static void swrt_nat_expect(struct nf_conn *ct,
+static void bcm_nat_expect(struct nf_conn *ct,
 			   struct nf_conntrack_expect *exp)
 {
 	struct nf_nat_range range;
@@ -49,7 +52,7 @@ static void swrt_nat_expect(struct nf_conn *ct,
 }
 
 /****************************************************************************/
-static int swrt_nat_help(struct sk_buff *skb, unsigned int protoff,
+static int bcm_nat_help(struct sk_buff *skb, unsigned int protoff,
 			struct nf_conn *ct, enum ip_conntrack_info ctinfo)
 {
 	int dir = CTINFO2DIR(ctinfo);
@@ -60,7 +63,7 @@ static int swrt_nat_help(struct sk_buff *skb, unsigned int protoff,
 	    help->expecting[NF_CT_EXPECT_CLASS_DEFAULT])
 		return NF_ACCEPT;
 
-	pr_debug("swrt_nat: packet[%d bytes] ", skb->len);
+	pr_debug("bcm_nat: packet[%d bytes] ", skb->len);
 	nf_ct_dump_tuple(&ct->tuplehash[dir].tuple);
 	pr_debug("reply: ");
 	nf_ct_dump_tuple(&ct->tuplehash[!dir].tuple);
@@ -76,31 +79,31 @@ static int swrt_nat_help(struct sk_buff *skb, unsigned int protoff,
 	exp->saved_addr = ct->tuplehash[dir].tuple.src.u3;
 	exp->saved_proto.udp.port = ct->tuplehash[dir].tuple.src.u.udp.port;
 	exp->dir = !dir;
-	exp->expectfn = swrt_nat_expect;
+	exp->expectfn = bcm_nat_expect;
 
 	/* Setup expect */
 	nf_ct_expect_related(exp);
 	nf_ct_expect_put(exp);
-	pr_debug("swrt_nat: expect setup\n");
+	pr_debug("bcm_nat: expect setup\n");
 
 	return NF_ACCEPT;
 }
 
 /****************************************************************************/
-static struct nf_conntrack_expect_policy swrt_nat_exp_policy __read_mostly = {
+static struct nf_conntrack_expect_policy bcm_nat_exp_policy __read_mostly = {
 	.max_expected 	= 1000,
 	.timeout	= 240,
 };
 
 /****************************************************************************/
-static struct nf_conntrack_helper nf_conntrack_helper_swrt_nat __read_mostly = {
-	.name = "SWRT-NAT",
+static struct nf_conntrack_helper nf_conntrack_helper_bcm_nat __read_mostly = {
+	.name = "BCM-NAT",
 	.me = THIS_MODULE,
 	.tuple.src.l3num = AF_INET,
 	.tuple.dst.protonum = IPPROTO_UDP,
-	.expect_policy = &swrt_nat_exp_policy,
+	.expect_policy = &bcm_nat_exp_policy,
 	.expect_class_max = 1,
-	.help = swrt_nat_help,
+	.help = bcm_nat_help,
 };
 
 /****************************************************************************/
@@ -150,6 +153,7 @@ static inline struct nf_conntrack_expect *find_fullcone_exp(struct nf_conn *ct)
 
 	return exp;
 }
+#endif /* CONFIG_KF_NETFILTER */
 
 
 unsigned int
@@ -188,12 +192,13 @@ nf_nat_masquerade_ipv4(struct sk_buff *skb, unsigned int hooknum,
 
 	nat->masq_index = out->ifindex;
 
+#if defined(CONFIG_BCM_KF_NETFILTER)
 
 /* RFC 4787 - 4.2.2.  Port Parity
    i.e., an even port will be mapped to an even port, and an odd port will be mapped to an odd port.
 */
 #define CHECK_PORT_PARITY(a, b) ((a%2)==(b%2))
-#define NF_NAT_RANGE_PROTO_PSID	(1 << 7)
+
 	if (!(range->flags & NF_NAT_RANGE_PROTO_PSID)
 	    && range->min_addr.ip != 0 /* nat_mode == full cone */
 	    && (nfct_help(ct) == NULL || nfct_help(ct)->helper == NULL)
@@ -203,7 +208,7 @@ nf_nat_masquerade_ipv4(struct sk_buff *skb, unsigned int hooknum,
 		u_int16_t maxport;
 		struct nf_conntrack_expect *exp;
 
-		pr_debug("swrt_nat: need full cone NAT\n");
+		pr_debug("bcm_nat: need full cone NAT\n");
 
 		/* Choose port */
 		spin_lock_bh(&nf_conntrack_expect_lock);
@@ -211,7 +216,7 @@ nf_nat_masquerade_ipv4(struct sk_buff *skb, unsigned int hooknum,
 		exp = find_fullcone_exp(ct);
 		if (exp) {
 			minport = maxport = exp->tuple.dst.u.udp.port;
-			pr_debug("swrt_nat: existing mapped port = %hu\n",
+			pr_debug("bcm_nat: existing mapped port = %hu\n",
 			       	 ntohs(minport));
 		} else { /* no previous expect */
 			u_int16_t newport, tmpport, orgport;
@@ -225,7 +230,7 @@ nf_nat_masquerade_ipv4(struct sk_buff *skb, unsigned int hooknum,
 			for (newport = ntohs(minport),tmpport = ntohs(maxport); 
 			     newport <= tmpport; newport++) {
 			     	if (CHECK_PORT_PARITY(orgport, newport) && !find_exp(newsrc, htons(newport), ct)) {
-                                        pr_debug("swrt_nat: new mapped port = "
+                                        pr_debug("bcm_nat: new mapped port = "
 					       	 "%hu\n", newport);
 					minport = maxport = htons(newport);
 					break;
@@ -248,14 +253,15 @@ nf_nat_masquerade_ipv4(struct sk_buff *skb, unsigned int hooknum,
 		if (ret == NF_ACCEPT) {
 			struct nf_conn_help *help = nfct_help(ct);
 			if (help == NULL)
-				help = nf_ct_helper_ext_add(ct, &nf_conntrack_helper_swrt_nat, GFP_ATOMIC);
+				help = nf_ct_helper_ext_add(ct, &nf_conntrack_helper_bcm_nat, GFP_ATOMIC);
 			if (help != NULL) {
-				help->helper = &nf_conntrack_helper_swrt_nat;
-				pr_debug("swrt_nat: helper set\n");
+				help->helper = &nf_conntrack_helper_bcm_nat;
+				pr_debug("bcm_nat: helper set\n");
 			}
 		}
 		return ret;
 	}
+#endif /* CONFIG_KF_NETFILTER */
 
 	/* Transfer from original range. */
 	memset(&newrange.min_addr, 0, sizeof(newrange.min_addr));
@@ -347,7 +353,9 @@ EXPORT_SYMBOL_GPL(nf_nat_masquerade_ipv4_register_notifier);
 
 void nf_nat_masquerade_ipv4_unregister_notifier(void)
 {
-	nf_conntrack_helper_unregister(&nf_conntrack_helper_swrt_nat);
+#if defined(CONFIG_BCM_KF_NETFILTER)
+	nf_conntrack_helper_unregister(&nf_conntrack_helper_bcm_nat);
+#endif
 	/* check if the notifier still has clients */
 	if (atomic_dec_return(&masquerade_notifier_refcount) > 0)
 		return;
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_proto_icmp.c b/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_proto_icmp.c
index 7b98baa13..562a0daed 100644
--- a/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_proto_icmp.c
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_proto_icmp.c
@@ -20,9 +20,22 @@
 static bool
 icmp_in_range(const struct nf_conntrack_tuple *tuple,
 	      enum nf_nat_manip_type maniptype,
-	      const union nf_conntrack_man_proto *min,
-	      const union nf_conntrack_man_proto *max)
+	      const struct nf_nat_range *range)
 {
+	const union nf_conntrack_man_proto *min = &range->min_proto;
+	const union nf_conntrack_man_proto *max = &range->max_proto;
+
+	if (range->flags & NF_NAT_RANGE_PROTO_PSID) {
+		unsigned int a = range->min_proto.psid.offset;
+		unsigned int k = range->min_proto.psid.length;
+		unsigned int m = 16 - a - k;
+		u_int16_t psid = range->max_proto.psid.id;
+		u_int16_t id = ntohs(tuple->src.u.icmp.id);
+
+		return (a == 0 || (id >> (16 - a))) &&
+		       !(((id >> m) ^ psid) & ~(~0U << k));
+	}
+
 	return ntohs(tuple->src.u.icmp.id) >= ntohs(min->icmp.id) &&
 	       ntohs(tuple->src.u.icmp.id) <= ntohs(max->icmp.id);
 }
@@ -38,6 +51,26 @@ icmp_unique_tuple(const struct nf_nat_l3proto *l3proto,
 	unsigned int range_size;
 	unsigned int i;
 
+	if (range->flags & NF_NAT_RANGE_PROTO_PSID) {
+		unsigned int a = range->min_proto.psid.offset;
+		unsigned int k = range->min_proto.psid.length;
+		unsigned int m = 16 - a - k;
+		u_int16_t psid = range->max_proto.psid.id << m;
+
+		range_size = (1 << (16 - k)) - (!!a << m);
+		if (range_size == 0)
+			return;
+
+		for (i = 0; ; ++id) {
+			unsigned int n = id % range_size;
+			tuple->src.u.icmp.id = htons((((n >> m) + !!a) << (16 - a)) |
+						     psid | (n & ~(~0U << m)));
+			if (++i >= range_size || !nf_nat_used_tuple(tuple, ct))
+				return;
+		}
+		return;
+	};
+
 	range_size = ntohs(range->max_proto.icmp.id) -
 		     ntohs(range->min_proto.icmp.id) + 1;
 	/* If no range specified... */
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_quake3.c b/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_quake3.c
new file mode 100644
index 000000000..d8f3890b7
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_quake3.c
@@ -0,0 +1,92 @@
+/* Quake3 extension for UDP NAT alteration.
+ * (C) 2002 by Filip Sneppe <filip.sneppe@cronos.be>
+ * (C) 2005 by Harald Welte <laforge@netfilter.org>
+ * based on nf_nat_ftp.c and nf_nat_tftp.c
+ *
+ * nf_nat_quake3.c v0.0.3 2002-08-31
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ *
+ *      Module load syntax:
+ *      insmod nf_nat_quake3.o ports=port1,port2,...port<MAX_PORTS>
+ *
+ *      please give the ports of all Quake3 master servers You wish to
+ *      connect to. If you don't specify ports, the default will be UDP
+ *      port 27950.
+ *
+ *      Thanks to the Ethereal folks for their analysis of the Quake3 protocol.
+ *
+ *      Notes:
+ *      - If you're one of those people who would try anything to lower
+ *        latency while playing Quake (and who isn't :-) ), you may want to
+ *        consider not loading nf_nat_quake3 at all and just MASQUERADE all
+ *        outgoing UDP traffic.
+ *        This will make nf_conntrack_quake3 add the necessary expectations,
+ *        but there will be no overhead for client->server UDP streams. If
+ *        nf_nat_quake3 is loaded, quake3_nat_expected will be called per NAT
+ *        hook for every packet in the client->server UDP stream.
+ *      - Only SNAT/MASQUEARDE targets are useful for nf_nat_quake3.
+ *        The IP addresses in the master connection payload (=IP addresses
+ *        of Quake servers) have no relation with the master server so
+ *        DNAT'ing the master connection to a server should not change the
+ *        expected connections.
+ *      - Not tested due to lack of equipment:
+ *        - multiple Quake3 clients behind one MASQUERADE gateway
+ *        - what if Quake3 client is running on router too
+ */
+
+#include <linux/module.h>
+#include <linux/ip.h>
+#include <linux/udp.h>
+
+#include <net/netfilter/nf_nat_helper.h>
+#include <net/netfilter/nf_nat_rule.h>
+#include <net/netfilter/nf_conntrack_helper.h>
+#include <net/netfilter/nf_conntrack_expect.h>
+#include <linux/netfilter/nf_conntrack_quake3.h>
+
+MODULE_AUTHOR("Filip Sneppe <filip.sneppe@cronos.be>");
+MODULE_DESCRIPTION("Netfilter NAT helper for Quake III Arena");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("ip_nat_quake3");
+
+/* Quake3 master server reply will add > 100 expectations per reply packet; when
+   doing lots of printk's, klogd may not be able to read /proc/kmsg fast enough */
+
+static unsigned int
+quake3_nat_help(struct sk_buff *skb,
+		enum ip_conntrack_info ctinfo,
+		struct nf_conntrack_expect *exp)
+{
+	const struct nf_conn *ct = exp->master;
+
+	/* What is this?  Why don't we try to alter the port? -HW */
+	exp->tuple.src.u3.ip = ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src.u3.ip;
+	exp->saved_proto.udp.port = exp->tuple.dst.u.udp.port;
+	exp->expectfn = nf_nat_follow_master;
+	//exp->dir = !dir;
+
+	if (nf_ct_expect_related(exp) != 0)
+		return NF_DROP;
+
+	return NF_ACCEPT;
+}
+
+static void fini(void)
+{
+	rcu_assign_pointer(nf_nat_quake3_hook, NULL);
+	synchronize_rcu();
+}
+
+static int __init init(void)
+{
+	BUG_ON(nf_nat_quake3_hook != NULL);
+	rcu_assign_pointer(nf_nat_quake3_hook, quake3_nat_help);
+	return 0;
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_rtsp.c b/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_rtsp.c
new file mode 100644
index 000000000..bf514ec3d
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/nf_nat_rtsp.c
@@ -0,0 +1,617 @@
+/*
+ * RTSP extension for TCP NAT alteration
+ * (C) 2003 by Tom Marshall <tmarshall at real.com>
+ *
+ * 2013-03-04: Il'inykh Sergey <sergeyi at inango-sw.com>. Inango Systems Ltd
+ *	- fixed rtcp nat mapping and other port mapping fixes
+ *	- fixed system hard lock because of bug in the parser
+ *	- codestyle fixes and less significant fixes
+ *
+ * based on ip_nat_irc.c
+ *
+ *	This program is free software; you can redistribute it and/or
+ *	modify it under the terms of the GNU General Public License
+ *	as published by the Free Software Foundation; either version
+ *	2 of the License, or (at your option) any later version.
+ *
+ * Module load syntax:
+ *	insmod nf_nat_rtsp.o ports=port1,port2,...port<MAX_PORTS>
+ *	                     stunaddr=<address>
+ *	                     destaction=[auto|strip|none]
+ *
+ * If no ports are specified, the default will be port 554 only.
+ *
+ * stunaddr specifies the address used to detect that a client is using STUN.
+ * If this address is seen in the destination parameter, it is assumed that
+ * the client has already punched a UDP hole in the firewall, so we don't
+ * mangle the client_port.  If none is specified, it is autodetected.  It
+ * only needs to be set if you have multiple levels of NAT.  It should be
+ * set to the external address that the STUN clients detect.  Note that in
+ * this case, it will not be possible for clients to use UDP with servers
+ * between the NATs.
+ *
+ * If no destaction is specified, auto is used.
+ *   destaction=auto:  strip destination parameter if it is not stunaddr.
+ *   destaction=strip: always strip destination parameter (not recommended).
+ *   destaction=none:  do not touch destination parameter (not recommended).
+ */
+
+#include <linux/module.h>
+#include <linux/version.h>
+#include <net/tcp.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+# include <net/netfilter/nf_nat.h>
+#else
+# include <net/netfilter/nf_nat_rule.h>
+#endif
+#include <net/netfilter/nf_nat_helper.h>
+#include <linux/netfilter/nf_conntrack_rtsp.h>
+#include <net/netfilter/nf_conntrack_expect.h>
+
+#include <linux/inet.h>
+#include <linux/ctype.h>
+#define NF_NEED_STRNCASECMP
+#define NF_NEED_STRTOU16
+#include <linux/netfilter_helpers.h>
+#define NF_NEED_MIME_NEXTLINE
+#include <linux/netfilter_mime.h>
+
+#define MAX_PORTS     8
+#define DSTACT_AUTO   0
+#define DSTACT_STRIP  1
+#define DSTACT_NONE   2
+
+static char* stunaddr = NULL;
+static char* destaction = NULL;
+
+static u_int32_t extip = 0;
+static int       dstact = 0;
+
+static void nf_nat_rtsp_expected(struct nf_conn* ct, struct nf_conntrack_expect *exp);
+
+MODULE_AUTHOR("Tom Marshall <tmarshall at real.com>");
+MODULE_DESCRIPTION("RTSP network address translation module");
+MODULE_LICENSE("GPL");
+module_param(stunaddr, charp, 0644);
+MODULE_PARM_DESC(stunaddr, "Address for detecting STUN");
+module_param(destaction, charp, 0644);
+MODULE_PARM_DESC(destaction, "Action for destination parameter (auto/strip/none)");
+
+#define SKIP_WSPACE(ptr,len,off) while(off < len && isspace(*(ptr+off))) { off++; }
+
+/*** helper functions ***/
+
+static void
+get_skb_tcpdata(struct sk_buff* skb, char** pptcpdata, uint* ptcpdatalen)
+{
+	struct iphdr*   iph  = ip_hdr(skb);
+	struct tcphdr*  tcph = (void *)iph + ip_hdrlen(skb);
+
+	*pptcpdata = (char*)tcph +  tcph->doff*4;
+	*ptcpdatalen = ((char*)skb_transport_header(skb) + skb->len) - *pptcpdata;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+/* copy of sip_sprintf_addr */
+static int rtsp_sprintf_addr(const struct nf_conn *ct, char *buffer,
+			     const union nf_inet_addr *addr, bool delim)
+{
+	if (nf_ct_l3num(ct) == NFPROTO_IPV4) {
+		return sprintf(buffer, "%pI4", &addr->ip);
+	} else {
+		if (delim)
+			return sprintf(buffer, "[%pI6c]", &addr->ip6);
+		else
+			return sprintf(buffer, "%pI6c", &addr->ip6);
+	}
+}
+#endif
+
+/*** nat functions ***/
+
+/*
+ * Mangle the "Transport:" header:
+ *   - Replace all occurences of "client_port=<spec>"
+ *   - Handle destination parameter
+ *
+ * In:
+ *   ct, ctinfo = conntrack context
+ *   skb        = packet
+ *   tranoff    = Transport header offset from TCP data
+ *   tranlen    = Transport header length (incl. CRLF)
+ *   rport_lo   = replacement low  port (host endian)
+ *   rport_hi   = replacement high port (host endian)
+ *
+ * Returns packet size difference.
+ *
+ * Assumes that a complete transport header is present, ending with CR or LF
+ */
+static int
+rtsp_mangle_tran(enum ip_conntrack_info ctinfo,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+		 unsigned int protoff,
+#endif
+		 struct nf_conntrack_expect* rtp_exp,
+		 struct nf_conntrack_expect* rtcp_exp,
+		 struct ip_ct_rtsp_expect* prtspexp,
+		 struct sk_buff* skb, uint tranoff, uint tranlen)
+{
+	char*  ptcp;
+	uint   tcplen;
+	char*  ptran;
+	char   rbuf1[16];	  /* Replacement buffer (one port) */
+	uint   rbuf1len;	  /* Replacement len (one port) */
+	char   rbufa[16];	  /* Replacement buffer (all ports) */
+	uint   rbufalen;	  /* Replacement len (all ports) */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	union nf_inet_addr newip;
+#else
+	u_int32_t  newip;
+#endif
+	u_int16_t loport, hiport;
+	uint      off = 0;
+	uint      diff;		   /* Number of bytes we removed */
+
+	struct nf_conn *ct = rtp_exp->master;
+	/* struct nf_conn *ct = nf_ct_get(skb, &ctinfo); */
+	struct nf_conntrack_tuple *rtp_t;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	char szextaddr[INET6_ADDRSTRLEN];
+#else
+	char szextaddr[INET_ADDRSTRLEN];
+#endif
+	uint extaddrlen;
+	int  is_stun;
+
+	get_skb_tcpdata(skb, &ptcp, &tcplen);
+	ptran = ptcp+tranoff;
+
+	if (tranoff+tranlen > tcplen || tcplen-tranoff < tranlen ||
+	    tranlen < 10 || !iseol(ptran[tranlen-1]) ||
+	    nf_strncasecmp(ptran, "Transport:", 10) != 0) {
+		pr_info("sanity check failed\n");
+		return 0;
+	}
+	off += 10;
+	SKIP_WSPACE(ptcp+tranoff, tranlen, off);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	newip = ct->tuplehash[IP_CT_DIR_REPLY].tuple.dst.u3;
+	rtp_t = &rtp_exp->tuple;
+	rtp_t->dst.u3 = newip;
+	if (rtcp_exp) {
+		rtcp_exp->tuple.dst.u3 = newip;
+	}
+	extaddrlen = rtsp_sprintf_addr(ct, szextaddr, &newip, true); // FIXME handle extip
+	pr_debug("stunaddr=%s (auto)\n", szextaddr);
+#else
+	newip = ct->tuplehash[IP_CT_DIR_REPLY].tuple.dst.u3.ip;
+	rtp_t = &rtp_exp->tuple;
+	rtp_t->dst.u3.ip = newip;
+	if (rtcp_exp) {
+		rtcp_exp->tuple.dst.u3.ip = newip;
+	}
+	extaddrlen = extip ? sprintf(szextaddr, "%pI4", &extip)
+			   : sprintf(szextaddr, "%pI4", &newip);
+	pr_debug("stunaddr=%s (%s)\n", szextaddr, (extip?"forced":"auto"));
+#endif
+	hiport = 0;
+	rbuf1len = rbufalen = 0;
+	switch (prtspexp->pbtype) {
+	case pb_single:
+		for (loport = prtspexp->loport; loport != 0; loport++) { /* XXX: improper wrap? */
+			rtp_t->dst.u.udp.port = htons(loport);
+			if (nf_ct_expect_related(rtp_exp) == 0) {
+				pr_debug("using port %hu\n", loport);
+				break;
+			}
+		}
+		if (loport != 0) {
+			rbuf1len = sprintf(rbuf1, "%hu", loport);
+			rbufalen = sprintf(rbufa, "%hu", loport);
+		}
+		break;
+	case pb_range:
+		for (loport = prtspexp->loport; loport != 0; loport += 2) { /* XXX: improper wrap? */
+			rtp_t->dst.u.udp.port = htons(loport);
+			if (nf_ct_expect_related(rtp_exp) != 0) {
+				continue;
+			}
+			hiport = loport + 1;
+			rtcp_exp->tuple.dst.u.udp.port = htons(hiport);
+			if (nf_ct_expect_related(rtcp_exp) != 0) {
+				nf_ct_unexpect_related(rtp_exp);
+				continue;
+			}
+
+			/* FIXME: invalid print in case of ipv6 */
+			pr_debug("nat expect_related %pI4:%u-%u-%pI4:%u-%u\n",
+				 &rtp_exp->tuple.src.u3.ip,
+				 ntohs(rtp_exp->tuple.src.u.udp.port),
+				 ntohs(rtcp_exp->tuple.src.u.udp.port),
+				 &rtp_exp->tuple.dst.u3.ip,
+				 ntohs(rtp_exp->tuple.dst.u.udp.port),
+				 ntohs(rtcp_exp->tuple.dst.u.udp.port));
+			break;
+		}
+		if (loport != 0) {
+			rbuf1len = sprintf(rbuf1, "%hu", loport);
+			rbufalen = sprintf(rbufa, "%hu-%hu", loport, hiport);
+		}
+		break;
+	case pb_discon:
+		for (loport = prtspexp->loport; loport != 0; loport++) { /* XXX: improper wrap? */
+			rtp_t->dst.u.udp.port = htons(loport);
+			if (nf_ct_expect_related(rtp_exp) == 0) {
+				pr_debug("using port %hu (1 of 2)\n", loport);
+				break;
+			}
+		}
+		for (hiport = prtspexp->hiport; hiport != 0; hiport++) { /* XXX: improper wrap? */
+			rtp_t->dst.u.udp.port = htons(hiport);
+			if (nf_ct_expect_related(rtp_exp) == 0) {
+				pr_debug("using port %hu (2 of 2)\n", hiport);
+				break;
+			}
+		}
+		if (loport != 0 && hiport != 0) {
+			rbuf1len = sprintf(rbuf1, "%hu", loport);
+			rbufalen = sprintf(rbufa, hiport == loport+1 ?
+					   "%hu-%hu":"%hu/%hu", loport, hiport);
+		}
+		break;
+	}
+
+	if (rbuf1len == 0)
+		return 0;   /* cannot get replacement port(s) */
+
+	/* Transport: tran;field;field=val,tran;field;field=val,...
+	   `off` is set to the start of Transport value from start of line
+	*/
+	while (off < tranlen) {
+		uint        saveoff;
+		const char* pparamend;
+		uint        nextparamoff;
+
+		pparamend = memchr(ptran+off, ',', tranlen-off);
+		pparamend = (pparamend == NULL) ? ptran+tranlen : pparamend+1;
+		nextparamoff = pparamend-ptran;
+
+		/*
+		 * We pass over each param twice.  On the first pass, we look for a
+		 * destination= field.  It is handled by the security policy.  If it
+		 * is present, allowed, and equal to our external address, we assume
+		 * that STUN is being used and we leave the client_port= field alone.
+		 */
+		is_stun = 0;
+		saveoff = off;
+		while (off < nextparamoff) {
+			const char* pfieldend;
+			uint        nextfieldoff;
+
+			pfieldend = memchr(ptran+off, ';', nextparamoff-off);
+			nextfieldoff = (pfieldend == NULL) ? nextparamoff : pfieldend-ptran+1;
+
+			if (dstact != DSTACT_NONE && strncmp(ptran+off, "destination=", 12) == 0) {
+				if (strncmp(ptran+off+12, szextaddr, extaddrlen) == 0)
+					is_stun = 1;
+
+				if (dstact == DSTACT_STRIP || (dstact == DSTACT_AUTO && !is_stun)) {
+					uint dstoff = (ptran-ptcp)+off;
+					uint dstlen = nextfieldoff-off;
+					char* pdstrep = NULL;
+					uint dstreplen = 0;
+					diff = dstlen;
+					if (dstact == DSTACT_AUTO && !is_stun) {
+						pr_debug("RTSP: replace dst addr\n");
+						dstoff += 12;
+						dstlen -= 13;
+						pdstrep = szextaddr;
+						dstreplen = extaddrlen;
+						diff = nextfieldoff-off-13-extaddrlen;
+					}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+					if (!nf_nat_mangle_tcp_packet(skb, ct, ctinfo, protoff,
+								      dstoff, dstlen, pdstrep, dstreplen)) {
+#else
+					if (!nf_nat_mangle_tcp_packet(skb, ct, ctinfo,
+								      dstoff, dstlen, pdstrep, dstreplen)) {
+#endif
+						/* mangle failed, all we can do is bail */
+						nf_ct_unexpect_related(rtp_exp);
+						if (rtcp_exp)
+							nf_ct_unexpect_related(rtcp_exp);
+						return 0;
+					}
+					get_skb_tcpdata(skb, &ptcp, &tcplen);
+					ptran = ptcp+tranoff;
+					tranlen -= diff;
+					nextparamoff -= diff;
+					nextfieldoff -= diff;
+				}
+			}
+
+			off = nextfieldoff;
+		}
+
+		if (is_stun)
+			continue;
+
+		off = saveoff;
+		while (off < nextparamoff) {
+			const char* pfieldend;
+			uint        nextfieldoff;
+
+			pfieldend = memchr(ptran+off, ';', nextparamoff-off);
+			nextfieldoff = (pfieldend == NULL) ? nextparamoff : pfieldend-ptran+1;
+
+			if (strncmp(ptran+off, "client_port=", 12) == 0) {
+				u_int16_t port;
+				uint	  numlen;
+				uint      origoff;
+				uint      origlen;
+				char*     rbuf = rbuf1;
+				uint      rbuflen = rbuf1len;
+
+				off += 12;
+				origoff = (ptran-ptcp)+off;
+				origlen = 0;
+				numlen = nf_strtou16(ptran+off, &port);
+				off += numlen;
+				origlen += numlen;
+				if (port != prtspexp->loport) {
+					pr_debug("multiple ports found, port %hu ignored\n", port);
+				} else {
+					if (ptran[off] == '-' || ptran[off] == '/') {
+						off++;
+						origlen++;
+						numlen = nf_strtou16(ptran+off, &port);
+						off += numlen;
+						origlen += numlen;
+						rbuf = rbufa;
+						rbuflen = rbufalen;
+					}
+
+					/*
+					 * note we cannot just memcpy() if the sizes are the same.
+					 * the mangle function does skb resizing, checks for a
+					 * cloned skb, and updates the checksums.
+					 *
+					 * parameter 4 below is offset from start of tcp data.
+					 */
+					diff = origlen-rbuflen;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+					if (!nf_nat_mangle_tcp_packet(skb, ct, ctinfo, protoff,
+								      origoff, origlen, rbuf, rbuflen)) {
+#else
+					if (!nf_nat_mangle_tcp_packet(skb, ct, ctinfo,
+								      origoff, origlen, rbuf, rbuflen)) {
+#endif
+						/* mangle failed, all we can do is bail */
+						nf_ct_unexpect_related(rtp_exp);
+						if (rtcp_exp)
+							nf_ct_unexpect_related(rtcp_exp);
+						return 0;
+					}
+					get_skb_tcpdata(skb, &ptcp, &tcplen);
+					ptran = ptcp+tranoff;
+					tranlen -= diff;
+					nextparamoff -= diff;
+					nextfieldoff -= diff;
+				}
+			}
+
+			off = nextfieldoff;
+		}
+
+		off = nextparamoff;
+	}
+
+	return 1;
+}
+
+static uint
+help_out(struct sk_buff *skb, enum ip_conntrack_info ctinfo,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	 unsigned int protoff,
+#endif
+	 unsigned int matchoff, unsigned int matchlen,
+	 struct ip_ct_rtsp_expect* prtspexp,
+	 struct nf_conntrack_expect* rtp_exp,
+	 struct nf_conntrack_expect* rtcp_exp)
+{
+	char* ptcp;
+	uint  tcplen;
+	uint  hdrsoff;
+	uint  hdrslen;
+	uint  lineoff;
+	uint  linelen;
+	uint  off;
+	int   dir = CTINFO2DIR(ctinfo);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	union nf_inet_addr saddr = rtp_exp->master->tuplehash[dir].tuple.src.u3;
+#else
+	__be32 saddr = rtp_exp->master->tuplehash[dir].tuple.src.u3.ip;
+#endif
+
+	//struct iphdr* iph = (struct iphdr*)(*pskb)->nh.iph;
+	//struct tcphdr* tcph = (struct tcphdr*)((void*)iph + iph->ihl*4);
+
+	get_skb_tcpdata(skb, &ptcp, &tcplen);
+	hdrsoff = matchoff;//exp->seq - ntohl(tcph->seq);
+	hdrslen = matchlen;
+	off = hdrsoff;
+	pr_debug("NAT rtsp help_out\n");
+
+	while (nf_mime_nextline(ptcp, hdrsoff+hdrslen, &off, &lineoff, &linelen)) {
+		if (linelen == 0)
+			break;
+
+		if (off > hdrsoff+hdrslen) {
+			pr_info("!! overrun !!");
+			break;
+		}
+		pr_debug("hdr: len=%u, %.*s", linelen, (int)linelen, ptcp+lineoff);
+
+		if (nf_strncasecmp(ptcp+lineoff, "Transport:", 10) == 0) {
+			uint oldtcplen = tcplen;
+			pr_debug("hdr: Transport\n");
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+			if (!rtsp_mangle_tran(ctinfo, protoff, rtp_exp, rtcp_exp,
+					      prtspexp, skb, lineoff, linelen)) {
+#else
+			if (!rtsp_mangle_tran(ctinfo, rtp_exp, rtcp_exp, prtspexp,
+					      skb, lineoff, linelen)) {
+#endif
+				pr_debug("hdr: Transport mangle failed");
+				break;
+			}
+			rtp_exp->expectfn = nf_nat_rtsp_expected;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+			rtp_exp->saved_addr = saddr;
+#else
+			rtp_exp->saved_ip = saddr;
+#endif
+			rtp_exp->saved_proto.udp.port = htons(prtspexp->loport);
+			rtp_exp->dir = !dir;
+			if (rtcp_exp) {
+				rtcp_exp->expectfn = nf_nat_rtsp_expected;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+				rtcp_exp->saved_addr = saddr;
+#else
+				rtcp_exp->saved_ip = saddr;
+#endif
+				rtcp_exp->saved_proto.udp.port = htons(prtspexp->hiport);
+				rtcp_exp->dir = !dir;
+			}
+			get_skb_tcpdata(skb, &ptcp, &tcplen);
+			hdrslen -= (oldtcplen-tcplen);
+			off -= (oldtcplen-tcplen);
+			lineoff -= (oldtcplen-tcplen);
+			linelen -= (oldtcplen-tcplen);
+			pr_debug("rep: len=%u, %.*s", linelen, (int)linelen, ptcp+lineoff);
+		}
+	}
+
+	return NF_ACCEPT;
+}
+
+static unsigned int
+nf_nat_rtsp(struct sk_buff *skb, enum ip_conntrack_info ctinfo,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	    unsigned int protoff,
+#endif
+	    unsigned int matchoff, unsigned int matchlen,
+	    struct ip_ct_rtsp_expect* prtspexp,
+	    struct nf_conntrack_expect* rtp_exp,
+	    struct nf_conntrack_expect* rtcp_exp)
+{
+	int dir = CTINFO2DIR(ctinfo);
+	int rc = NF_ACCEPT;
+
+	switch (dir) {
+	case IP_CT_DIR_ORIGINAL:
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+		rc = help_out(skb, ctinfo, protoff, matchoff, matchlen, prtspexp,
+			      rtp_exp, rtcp_exp);
+#else
+		rc = help_out(skb, ctinfo, matchoff, matchlen, prtspexp,
+			      rtp_exp, rtcp_exp);
+#endif
+		break;
+	case IP_CT_DIR_REPLY:
+		pr_debug("unmangle ! %u\n", ctinfo);
+		/* XXX: unmangle */
+		rc = NF_ACCEPT;
+		break;
+	}
+	//UNLOCK_BH(&ip_rtsp_lock);
+
+	return rc;
+}
+
+static void nf_nat_rtsp_expected(struct nf_conn* ct, struct nf_conntrack_expect *exp)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,3,0) || LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	struct nf_nat_range range;
+#else
+	struct nf_nat_ipv4_range range;
+#endif
+
+	/* This must be a fresh one. */
+	BUG_ON(ct->status & IPS_NAT_DONE_MASK);
+
+	/* For DST manip, map port here to where it's expected. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	range.min_proto = range.max_proto = exp->saved_proto;
+	range.min_addr = range.max_addr = exp->saved_addr;
+#else
+	range.min = range.max = exp->saved_proto;
+	range.min_ip = range.max_ip = exp->saved_ip;
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
+	range.flags = (NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED);
+	nf_nat_setup_info(ct, &range, NF_NAT_MANIP_DST);
+#else
+	range.flags = (IP_NAT_RANGE_MAP_IPS | IP_NAT_RANGE_PROTO_SPECIFIED);
+	nf_nat_setup_info(ct, &range, IP_NAT_MANIP_DST);
+#endif
+
+	/* Change src to where master sends to, but only if the connection
+	 * actually came from the same source. */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	if (nf_inet_addr_cmp(&ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src.u3,
+			     &ct->master->tuplehash[exp->dir].tuple.src.u3)) {
+		range.min_addr = range.max_addr
+			= ct->master->tuplehash[!exp->dir].tuple.dst.u3;
+#else
+	if (ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src.u3.ip ==
+	    ct->master->tuplehash[exp->dir].tuple.src.u3.ip) {
+		range.min_ip = range.max_ip
+			= ct->master->tuplehash[!exp->dir].tuple.dst.u3.ip;
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
+		range.flags = NF_NAT_RANGE_MAP_IPS;
+		nf_nat_setup_info(ct, &range, NF_NAT_MANIP_SRC);
+#else
+		range.flags = IP_NAT_RANGE_MAP_IPS;
+		nf_nat_setup_info(ct, &range, IP_NAT_MANIP_SRC);
+#endif
+	}
+}
+
+
+static void __exit fini(void)
+{
+	rcu_assign_pointer(nf_nat_rtsp_hook, NULL);
+	synchronize_net();
+}
+
+static int __init init(void)
+{
+	printk("nf_nat_rtsp v" IP_NF_RTSP_VERSION " loading\n");
+
+	BUG_ON(nf_nat_rtsp_hook);
+	rcu_assign_pointer(nf_nat_rtsp_hook, nf_nat_rtsp);
+
+	if (stunaddr != NULL)
+		extip = in_aton(stunaddr);
+
+	if (destaction != NULL) {
+		if (strcmp(destaction, "auto") == 0)
+			dstact = DSTACT_AUTO;
+
+		if (strcmp(destaction, "strip") == 0)
+			dstact = DSTACT_STRIP;
+
+		if (strcmp(destaction, "none") == 0)
+			dstact = DSTACT_NONE;
+	}
+
+	return 0;
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/ipv4/netfilter/tree_map.h b/trunk/linux-4.4.x/net/ipv4/netfilter/tree_map.h
new file mode 100644
index 000000000..37755aa31
--- /dev/null
+++ b/trunk/linux-4.4.x/net/ipv4/netfilter/tree_map.h
@@ -0,0 +1,1084 @@
+/*
+ * Copyright  2008 by Eric Bishop <eric@gargoyle-router.com>
+ *
+ * This work 'as-is' we provide.
+ * No warranty, express or implied.
+ * We've done our best,
+ * to debug and test.
+ * Liability for damages denied.
+ *
+ * Permission is granted hereby,
+ * to copy, share, and modify.
+ * Use as is fit,
+ * free or for profit.
+ * On this notice these rights rely.
+ *
+ *
+ *
+ *  Note that unlike other portions of Gargoyle this code
+ *  does not fall under the GPL, but the rather whimsical
+ *  'Poetic License' above.
+ *
+ *  Basically, this library contains a bunch of utilities
+ *  that I find useful.  I'm sure other libraries exist
+ *  that are just as good or better, but I like these tools
+ *  because I personally wrote them, so I know their quirks.
+ *  (i.e. I know where the bodies are buried).  I want to
+ *  make sure that I can re-use these utilities for whatever
+ *  code I may want to write in the future be it
+ *  proprietary or open-source, so I've put them under
+ *  a very, very permissive license.
+ *
+ *  If you find this code useful, use it.  If not, don't.
+ *  I really don't care.
+ *
+ */
+
+
+#if __KERNEL__
+	#define malloc(foo)	kmalloc(foo,GFP_ATOMIC)
+	#define free(foo)	kfree(foo)
+	#define printf(format,args...)	printk(format,##args)
+
+	/* kernel strdup */
+	static inline char *kernel_strdup(const char *str);
+	static inline char *kernel_strdup(const char *str)
+	{
+		char *tmp;
+		long int s;
+		s=strlen(str) + 1;
+		tmp = kmalloc(s, GFP_ATOMIC);
+		if (tmp != NULL)
+		{
+			memcpy(tmp, str, s);
+		}
+		return tmp;
+	}
+	#define strdup kernel_strdup
+
+#endif
+
+
+
+/* tree_map structs / prototypes */
+typedef struct long_tree_map_node
+{
+	unsigned long key;
+	void* value;
+
+	signed char balance;
+	struct long_tree_map_node* left;
+	struct long_tree_map_node* right;
+} long_map_node;
+
+typedef struct
+{
+	long_map_node* root;
+	unsigned long num_elements;
+
+}long_map;
+
+typedef struct
+{
+	long_map lm;
+	unsigned char store_keys;
+	unsigned long num_elements;
+
+}string_map;
+
+
+
+/* long map functions */
+long_map* initialize_long_map(void);
+void* get_long_map_element(long_map* map, unsigned long key);
+void* get_smallest_long_map_element(long_map* map, unsigned long* smallest_key);
+void* get_largest_long_map_element(long_map* map, unsigned long* largest_key);
+void* remove_smallest_long_map_element(long_map* map, unsigned long* smallest_key);
+void* remove_largest_long_map_element(long_map* map, unsigned long* largest_key);
+void* set_long_map_element(long_map* map, unsigned long key, void* value);
+void* remove_long_map_element(long_map* map, unsigned long key);
+unsigned long* get_sorted_long_map_keys(long_map* map, unsigned long* num_keys_returned);
+void** get_sorted_long_map_values(long_map* map, unsigned long* num_values_returned);
+void** destroy_long_map(long_map* map, int destruction_type, unsigned long* num_destroyed);
+void apply_to_every_long_map_value(long_map* map, void (*apply_func)(unsigned long key, void* value));
+
+/* string map functions */
+string_map* initialize_string_map(unsigned char store_keys);
+void* get_string_map_element(string_map* map, const char* key);
+void* set_string_map_element(string_map* map, const char* key, void* value);
+void* remove_string_map_element(string_map* map, const char* key);
+char** get_string_map_keys(string_map* map, unsigned long* num_keys_returned);
+void** get_string_map_values(string_map* map, unsigned long* num_values_returned);
+void** destroy_string_map(string_map* map, int destruction_type, unsigned long* num_destroyed);
+void apply_to_every_string_map_value(string_map* map, void (*apply_func)(char* key, void* value));
+
+
+/*
+ * three different ways to deal with values when data structure is destroyed
+ */
+#define DESTROY_MODE_RETURN_VALUES	20
+#define DESTROY_MODE_FREE_VALUES 	21
+#define DESTROY_MODE_IGNORE_VALUES	22
+
+
+/*
+ * for convenience & backwards compatibility alias _string_map_ functions to
+ *  _map_ functions since string map is used more often than long map
+ */
+#define initialize_map		initialize_string_map
+#define set_map_element		set_string_map_element
+#define get_map_element		get_string_map_element
+#define remove_map_element	remove_string_map_element
+#define get_map_keys		get_string_map_keys
+#define get_map_values		get_string_map_values
+#define destroy_map		destroy_string_map
+
+
+/* internal utility structures/ functions */
+typedef struct stack_node_struct
+{
+	long_map_node** node_ptr;
+	signed char direction;
+	struct stack_node_struct* previous;
+} stack_node;
+
+static void free_stack(stack_node* stack);
+static void** destroy_long_map_values(long_map* map, int destruction_type, unsigned long* num_destroyed);
+static void apply_to_every_long_map_node(long_map_node* node, void (*apply_func)(unsigned long key, void* value));
+static void apply_to_every_string_map_node(long_map_node* node, unsigned char has_key, void (*apply_func)(char* key, void* value));
+static void get_sorted_node_keys(long_map_node* node, unsigned long* key_list, unsigned long* next_key_index, int depth);
+static void get_sorted_node_values(long_map_node* node, void** value_list, unsigned long* next_value_index, int depth);
+static signed char rebalance (long_map_node** n, signed char direction, signed char update_op);
+static void rotate_right (long_map_node** parent);
+static void rotate_left (long_map_node** parent);
+
+/* internal for string map */
+typedef struct
+{
+	char* key;
+	void* value;
+} string_map_key_value;
+static unsigned long sdbm_string_hash(const char *key);
+
+
+
+
+/***************************************************
+ * For testing only
+ ***************************************************/
+/*
+void print_list(stack_node *l);
+
+void print_list(stack_node *l)
+{
+	if(l != NULL)
+	{
+		printf(" list key = %ld, dir=%d, \n", (*(l->node_ptr))->key, l->direction);
+		print_list(l->previous);
+	}
+}
+*/
+/******************************************************
+ * End testing Code
+ *******************************************************/
+
+
+
+
+/***************************************************
+ * string_map function definitions
+ ***************************************************/
+
+string_map* initialize_string_map(unsigned char store_keys)
+{
+	string_map* map = (string_map*)malloc(sizeof(string_map));
+	if(map != NULL)
+	{
+		map->store_keys = store_keys;
+		map->lm.root = NULL;
+		map->lm.num_elements = 0;
+		map->num_elements = map->lm.num_elements;
+	}
+	return map;
+}
+
+void* get_string_map_element(string_map* map, const char* key)
+{
+	unsigned long hashed_key = sdbm_string_hash(key);
+	void* return_value =  get_long_map_element( &(map->lm), hashed_key);
+	if(return_value != NULL && map->store_keys)
+	{
+		string_map_key_value* r = (string_map_key_value*)return_value;
+		return_value = r->value;
+	}
+	map->num_elements = map->lm.num_elements;
+	return return_value;
+}
+
+void* set_string_map_element(string_map* map, const char* key, void* value)
+{
+	unsigned long hashed_key = sdbm_string_hash(key);
+	void* return_value = NULL;
+	if(map->store_keys)
+	{
+		string_map_key_value* kv = (string_map_key_value*)malloc(sizeof(string_map_key_value));
+		if(kv == NULL) /* deal with malloc failure */
+		{
+			return NULL;
+		}
+		kv->key = strdup(key);
+		if(kv->key == NULL) /* deal with malloc failure */
+		{
+			free(kv);
+			return NULL;
+		}
+		kv->value = value;
+		return_value = set_long_map_element(  &(map->lm), hashed_key, kv);
+		if(return_value != NULL)
+		{
+			string_map_key_value* r = (string_map_key_value*)return_value;
+			return_value = r->value;
+			free(r->key);
+			free(r);
+		}
+	}
+	else
+	{
+		return_value = set_long_map_element( &(map->lm), hashed_key, value);
+	}
+	map->num_elements = map->lm.num_elements;
+	return return_value;
+}
+
+void* remove_string_map_element(string_map* map, const char* key)
+{
+	unsigned long hashed_key = sdbm_string_hash(key);
+	void* return_value =  remove_long_map_element( &(map->lm), hashed_key);
+
+	if(return_value != NULL && map->store_keys)
+	{
+		string_map_key_value* r = (string_map_key_value*)return_value;
+		return_value = r->value;
+		free(r->key);
+		free(r);
+	}
+	map->num_elements = map->lm.num_elements;
+	return return_value;
+}
+
+char** get_string_map_keys(string_map* map, unsigned long* num_keys_returned)
+{
+	char** str_keys;
+	str_keys = (char**)malloc((map->num_elements+1)*sizeof(char*));
+	if(str_keys == NULL) /* deal with malloc failure */
+	{
+		return NULL;
+	}
+	str_keys[0] = NULL;
+	*num_keys_returned = 0;
+	if(map->store_keys && map->num_elements > 0)
+	{
+		unsigned long list_length;
+		void** long_values = get_sorted_long_map_values( &(map->lm),  &list_length);
+		unsigned long key_index;
+		/*list_length will be 0 on malloc failure in get_sorted_long_map_values, so this code shouldn't seg fault if that happens */
+		for(key_index = 0; key_index < list_length; key_index++)
+		{
+			str_keys[key_index] = strdup( ((string_map_key_value*)(long_values[key_index]))->key);
+			if(str_keys[key_index] == NULL) /* deal with malloc failure */
+			{
+				//just return the incomplete list (hey, it's null terminated...)
+				free(long_values);
+				return str_keys;
+			}
+			*num_keys_returned = *num_keys_returned + 1;
+		}
+		str_keys[list_length] = NULL;
+		free(long_values);
+	}
+	return str_keys;
+}
+
+
+void** get_string_map_values(string_map* map, unsigned long* num_values_returned)
+{
+	void** values = NULL;
+	if(map != NULL)
+	{
+		values = get_sorted_long_map_values ( &(map->lm), num_values_returned );
+	}
+	return values;
+}
+
+
+void** destroy_string_map(string_map* map, int destruction_type, unsigned long* num_destroyed)
+{
+	void** return_values = NULL;
+	if(map != NULL)
+	{
+		if(map->store_keys)
+		{
+			void** kvs = destroy_long_map_values( &(map->lm), DESTROY_MODE_RETURN_VALUES, num_destroyed );
+			unsigned long kv_index = 0;
+			for(kv_index=0; kv_index < *num_destroyed; kv_index++)
+			{
+				string_map_key_value* kv = (string_map_key_value*)kvs[kv_index];
+				void* value = kv->value;
+
+				free(kv->key);
+				free(kv);
+				if(destruction_type == DESTROY_MODE_FREE_VALUES)
+				{
+					free(value);
+				}
+				if(destruction_type == DESTROY_MODE_RETURN_VALUES)
+				{
+					kvs[kv_index] = value;
+				}
+			}
+			if(destruction_type == DESTROY_MODE_RETURN_VALUES)
+			{
+				return_values = kvs;
+			}
+			else
+			{
+				free(kvs);
+			}
+		}
+		else
+		{
+			return_values = destroy_long_map_values( &(map->lm), destruction_type, num_destroyed );
+		}
+		free(map);
+	}
+	return return_values;
+}
+
+
+
+
+/***************************************************
+ * long_map function definitions
+ ***************************************************/
+
+long_map* initialize_long_map(void)
+{
+	long_map* map = (long_map*)malloc(sizeof(long_map));
+	if(map != NULL) /* test for malloc failure */
+	{
+		map->root = NULL;
+		map->num_elements = 0;
+	}
+	return map;
+}
+
+void* get_long_map_element(long_map* map, unsigned long key)
+{
+	void* value = NULL;
+
+	if(map->root != NULL)
+	{
+		long_map_node* parent_node = map->root;
+		long_map_node* next_node;
+		while( key != parent_node->key && (next_node = (long_map_node *)(key < parent_node->key ? parent_node->left : parent_node->right))  != NULL)
+		{
+			parent_node = next_node;
+		}
+		if(parent_node->key == key)
+		{
+			value = parent_node->value;
+		}
+	}
+	return value;
+}
+
+void* get_smallest_long_map_element(long_map* map, unsigned long* smallest_key)
+{
+	void* value = NULL;
+	if(map->root != NULL)
+	{
+		long_map_node* next_node = map->root;
+		while( next_node->left != NULL)
+		{
+			next_node = next_node->left;
+		}
+		value = next_node->value;
+		*smallest_key = next_node->key;
+	}
+	return value;
+}
+
+void* get_largest_long_map_element(long_map* map, unsigned long* largest_key)
+{
+	void* value = NULL;
+	if(map->root != NULL)
+	{
+		long_map_node* next_node = map->root;
+		while( next_node->right != NULL)
+		{
+			next_node = next_node->right;
+		}
+		value = next_node->value;
+		*largest_key = next_node->key;
+	}
+	return value;
+}
+
+void* remove_smallest_long_map_element(long_map* map, unsigned long* smallest_key)
+{
+	get_smallest_long_map_element(map, smallest_key);
+	return remove_long_map_element(map, *smallest_key);
+}
+
+void* remove_largest_long_map_element(long_map* map, unsigned long* largest_key)
+{
+	get_largest_long_map_element(map, largest_key);
+	return remove_long_map_element(map, *largest_key);
+}
+
+
+/* if replacement performed, returns replaced value, otherwise null */
+void* set_long_map_element(long_map* map, unsigned long key, void* value)
+{
+	stack_node* parent_list = NULL;
+	void* old_value = NULL;
+	int old_value_found = 0;
+
+	long_map_node* parent_node;
+	long_map_node* next_node;
+	stack_node* next_parent;
+	stack_node* previous_parent;
+	signed char new_balance;
+
+
+	long_map_node* new_node = (long_map_node*)malloc(sizeof(long_map_node));
+	if(new_node == NULL)
+	{
+		return NULL;
+	}
+	new_node->value = value;
+	new_node->key = key;
+	new_node->left = NULL;
+	new_node->right = NULL;
+	new_node->balance = 0;
+
+
+
+	if(map->root == NULL)
+	{
+		map->root = new_node;
+	}
+	else
+	{
+		parent_node = map->root;
+
+		next_parent = (stack_node*)malloc(sizeof(stack_node));
+		if(next_parent == NULL) /* deal with malloc failure */
+		{
+			free(new_node);
+			return NULL; /* won't insert but won't seg fault */
+		}
+		next_parent->node_ptr =  &(map->root);
+		next_parent->previous = parent_list;
+		parent_list = next_parent;
+
+		while( key != parent_node->key && (next_node = (key < parent_node->key ? parent_node->left : parent_node->right) )  != NULL)
+		{
+			next_parent = (stack_node*)malloc(sizeof(stack_node));
+			if(next_parent == NULL) /* deal with malloc failure */
+			{
+				/* free previous stack nodes to prevent memory leak */
+				free_stack(parent_list);
+				free(new_node);
+				return NULL;
+			}
+			next_parent->node_ptr = key < parent_node->key ? &(parent_node->left) : &(parent_node->right);
+			next_parent->previous = parent_list;
+			next_parent->previous->direction = key < parent_node->key ? -1 : 1;
+			parent_list = next_parent;
+
+			parent_node = next_node;
+		}
+
+
+		if(key == parent_node->key)
+		{
+			old_value = parent_node->value;
+			old_value_found = 1;
+			parent_node->value = value;
+			free(new_node);
+			/* we merely replaced a node, no need to rebalance */
+		}
+		else
+		{
+			if(key < parent_node->key)
+			{
+				parent_node->left = (void*)new_node;
+				parent_list->direction = -1;
+			}
+			else
+			{
+				parent_node->right = (void*)new_node;
+				parent_list->direction = 1;
+			}
+
+
+			/* we inserted a node, rebalance */
+			previous_parent = parent_list;
+			new_balance  = 1; /* initial value is not used, but must not be 0 for initial loop condition */
+
+
+			while(previous_parent != NULL && new_balance != 0)
+			{
+				new_balance = rebalance(previous_parent->node_ptr, previous_parent->direction, 1);
+				previous_parent = previous_parent->previous;
+			}
+		}
+	}
+
+	free_stack(parent_list);
+
+	if(old_value_found == 0)
+	{
+		map->num_elements = map->num_elements + 1;
+	}
+
+	return old_value;
+}
+
+
+void* remove_long_map_element(long_map* map, unsigned long key)
+{
+
+	void* value = NULL;
+
+	long_map_node* root_node = map->root;
+	stack_node* parent_list = NULL;
+
+
+	long_map_node* remove_parent;
+	long_map_node* remove_node;
+	long_map_node* next_node;
+
+	long_map_node* replacement;
+	long_map_node* replacement_parent;
+	long_map_node* replacement_next;
+
+	stack_node* next_parent;
+	stack_node* previous_parent;
+	stack_node* replacement_stack_node;
+
+
+	signed char new_balance;
+
+
+
+	if(root_node != NULL)
+	{
+		remove_parent = root_node;
+		remove_node = key < remove_parent->key ? remove_parent->left : remove_parent->right;
+
+		if(remove_node != NULL && key != remove_parent->key)
+		{
+			next_parent = (stack_node*)malloc(sizeof(stack_node));
+			if(next_parent == NULL) /* deal with malloc failure */
+			{
+				return NULL;
+			}
+			next_parent->node_ptr =  &(map->root);
+			next_parent->previous = parent_list;
+			parent_list = next_parent;
+			while( key != remove_node->key && (next_node = (key < remove_node->key ? remove_node->left : remove_node->right))  != NULL)
+			{
+				next_parent = (stack_node*)malloc(sizeof(stack_node));
+				if(next_parent == NULL) /* deal with malloc failure */
+				{
+					/* free previous stack nodes to prevent memory leak */
+					free_stack(parent_list);
+					return NULL;
+				}
+				next_parent->node_ptr = key < remove_parent->key ? &(remove_parent->left) : &(remove_parent->right);
+				next_parent->previous = parent_list;
+				next_parent->previous->direction = key < remove_parent->key ? -1 : 1;
+				parent_list = next_parent;
+
+
+				remove_parent = remove_node;
+				remove_node = next_node;
+			}
+			parent_list->direction = key < remove_parent-> key ? -1 : 1;
+		}
+		else
+		{
+			remove_node = remove_parent;
+		}
+
+
+		if(key == remove_node->key)
+		{
+
+			/* find replacement for node we are deleting */
+			if( remove_node->right == NULL )
+			{
+				replacement = remove_node->left;
+			}
+			else if( remove_node->right->left == NULL)
+			{
+
+				replacement = remove_node->right;
+				replacement->left = remove_node->left;
+				replacement->balance = remove_node->balance;
+
+				/* put pointer to replacement node into list for balance update */
+				replacement_stack_node = (stack_node*)malloc(sizeof(stack_node));
+				if(replacement_stack_node == NULL) /* deal with malloc failure */
+				{
+					/* free previous stack nodes to prevent memory leak */
+					free_stack(parent_list);
+					return NULL;
+				}
+				replacement_stack_node->previous = parent_list;
+				replacement_stack_node->direction = 1; /* replacement is from right */
+				if(remove_node == remove_parent) /* special case for root node */
+				{
+					replacement_stack_node->node_ptr = &(map->root);
+				}
+				else
+				{
+					replacement_stack_node->node_ptr = key < remove_parent-> key ? &(remove_parent->left) : &(remove_parent->right);
+				}
+				parent_list = replacement_stack_node;
+
+			}
+			else
+			{
+				/* put pointer to replacement node into list for balance update */
+				replacement_stack_node = (stack_node*)malloc(sizeof(stack_node));
+				if(replacement_stack_node == NULL) /* deal with malloc failure */
+				{
+					/* free previous stack nodes to prevent memory leak */
+					free_stack(parent_list);
+					return NULL;
+				}
+
+				replacement_stack_node->previous = parent_list;
+				replacement_stack_node->direction = 1; /* we always look for replacement on right */
+				if(remove_node == remove_parent) /* special case for root node */
+				{
+					replacement_stack_node->node_ptr = &(map->root);
+				}
+				else
+				{
+					replacement_stack_node->node_ptr = key < remove_parent-> key ? &(remove_parent->left) : &(remove_parent->right);
+				}
+
+				parent_list = replacement_stack_node;
+
+
+				/*
+				 * put pointer to replacement node->right into list for balance update
+				 * this node will have to be updated with the proper pointer
+				 * after we have identified the replacement
+				 */
+				replacement_stack_node = (stack_node*)malloc(sizeof(stack_node));
+				if(replacement_stack_node == NULL) /* deal with malloc failure */
+				{
+					/* free previous stack nodes to prevent memory leak */
+					free_stack(parent_list);
+					return NULL;
+				}
+
+				replacement_stack_node->previous = parent_list;
+				replacement_stack_node->direction = -1; /* we always look for replacement to left of this node */
+				parent_list = replacement_stack_node;
+
+				/* find smallest node on right (large) side of tree */
+				replacement_parent = remove_node->right;
+				replacement = replacement_parent->left;
+
+				while((replacement_next = replacement->left)  != NULL)
+				{
+					next_parent = (stack_node*)malloc(sizeof(stack_node));
+					if(next_parent == NULL) /* deal with malloc failure */
+					{
+						/* free previous stack nodes to prevent memory leak */
+						free_stack(parent_list);
+						return NULL;
+					}
+
+					next_parent->node_ptr = &(replacement_parent->left);
+					next_parent->previous = parent_list;
+					next_parent->direction = -1; /* we always go left */
+					parent_list = next_parent;
+
+					replacement_parent = replacement;
+					replacement = replacement_next;
+
+				}
+
+				replacement_parent->left = replacement->right;
+
+				replacement->left = remove_node->left;
+				replacement->right = remove_node->right;
+				replacement->balance = remove_node->balance;
+				replacement_stack_node->node_ptr = &(replacement->right);
+			}
+
+			/* insert replacement at proper location in tree */
+			if(remove_node == remove_parent)
+			{
+				map->root = replacement;
+			}
+			else
+			{
+				remove_parent->left = remove_node == remove_parent->left ? replacement : remove_parent->left;
+				remove_parent->right = remove_node == remove_parent->right ? replacement : remove_parent->right;
+			}
+
+
+			/* rebalance tree */
+			previous_parent = parent_list;
+			new_balance = 0;
+			while(previous_parent != NULL && new_balance == 0)
+			{
+				new_balance = rebalance(previous_parent->node_ptr, previous_parent->direction, -1);
+				previous_parent = previous_parent->previous;
+			}
+
+
+
+
+			/*
+			 * since we found a value to remove, decrease number of elements in map
+			 *  set return value to the deleted node's value and free the node
+			 */
+			map->num_elements = map->num_elements - 1;
+			value = remove_node->value;
+			free(remove_node);
+		}
+	}
+
+	free_stack(parent_list);
+
+	return value;
+}
+
+
+/* note: returned keys are dynamically allocated, you need to free them! */
+unsigned long* get_sorted_long_map_keys(long_map* map, unsigned long* num_keys_returned)
+{
+	unsigned long* key_list = (unsigned long*)malloc((map->num_elements)*sizeof(unsigned long));
+	unsigned long next_key_index;
+	if(key_list == NULL)
+	{
+		*num_keys_returned = 0;
+		return NULL;
+	}
+	next_key_index = 0;
+	get_sorted_node_keys(map->root, key_list, &next_key_index, 0);
+
+	*num_keys_returned = map->num_elements;
+
+	return key_list;
+}
+
+
+void** get_sorted_long_map_values(long_map* map, unsigned long* num_values_returned)
+{
+	void** value_list = (void**)malloc((map->num_elements+1)*sizeof(void*));
+	unsigned long next_value_index;
+
+	if(value_list == NULL)
+	{
+		*num_values_returned = 0;
+		return NULL;
+	}
+	next_value_index = 0;
+	get_sorted_node_values(map->root, value_list, &next_value_index, 0);
+	value_list[map->num_elements] = NULL; /* since we're dealing with pointers make list null terminated */
+
+	*num_values_returned = map->num_elements;
+	return value_list;
+
+}
+
+
+
+void** destroy_long_map(long_map* map, int destruction_type, unsigned long* num_destroyed)
+{
+	void** return_values = destroy_long_map_values(map, destruction_type, num_destroyed);
+	free(map);
+	return return_values;
+}
+
+
+
+void apply_to_every_long_map_value(long_map* map, void (*apply_func)(unsigned long key, void* value))
+{
+	apply_to_every_long_map_node(map->root, apply_func);
+}
+void apply_to_every_string_map_value(string_map* map, void (*apply_func)(char* key, void* value))
+{
+	apply_to_every_string_map_node( (map->lm).root, map->store_keys, apply_func);
+}
+
+
+/***************************************************
+ * internal utility function definitions
+ ***************************************************/
+static void free_stack(stack_node* stack)
+{
+	while(stack != NULL)
+	{
+		stack_node* prev_node = stack;
+		stack = prev_node->previous;
+		free(prev_node);
+	}
+
+}
+
+static void** destroy_long_map_values(long_map* map, int destruction_type, unsigned long* num_destroyed)
+{
+	void** return_values = NULL;
+	unsigned long return_index = 0;
+
+	*num_destroyed = 0;
+
+	if(destruction_type == DESTROY_MODE_RETURN_VALUES)
+	{
+		return_values = (void**)malloc((map->num_elements+1)*sizeof(void*));
+		if(return_values == NULL) /* deal with malloc failure */
+		{
+			destruction_type = DESTROY_MODE_IGNORE_VALUES; /* could cause memory leak, but there's no other way to be sure we won't seg fault */
+		}
+		else
+		{
+			return_values[map->num_elements] = NULL;
+		}
+	}
+	while(map->num_elements > 0)
+	{
+		unsigned long smallest_key;
+		void* removed_value = remove_smallest_long_map_element(map, &smallest_key);
+		if(destruction_type == DESTROY_MODE_RETURN_VALUES)
+		{
+			return_values[return_index] = removed_value;
+		}
+		if(destruction_type == DESTROY_MODE_FREE_VALUES)
+		{
+			free(removed_value);
+		}
+		return_index++;
+		*num_destroyed = *num_destroyed + 1;
+	}
+	return return_values;
+}
+
+static void apply_to_every_long_map_node(long_map_node* node, void (*apply_func)(unsigned long key, void* value))
+{
+	if(node != NULL)
+	{
+		apply_to_every_long_map_node(node->left,  apply_func);
+
+		apply_func(node->key, node->value);
+
+		apply_to_every_long_map_node(node->right, apply_func);
+	}
+}
+static void apply_to_every_string_map_node(long_map_node* node, unsigned char has_key, void (*apply_func)(char* key, void* value))
+{
+	if(node != NULL)
+	{
+		apply_to_every_string_map_node(node->left, has_key,  apply_func);
+
+		if(has_key)
+		{
+			string_map_key_value* kv = (string_map_key_value*)(node->value);
+			apply_func(kv->key, kv->value);
+		}
+		else
+		{
+			apply_func(NULL, node->value);
+		}
+		apply_to_every_string_map_node(node->right, has_key, apply_func);
+	}
+}
+
+
+
+static void get_sorted_node_keys(long_map_node* node, unsigned long* key_list, unsigned long* next_key_index, int depth)
+{
+	if(node != NULL)
+	{
+		get_sorted_node_keys(node->left, key_list, next_key_index, depth+1);
+
+		key_list[ *next_key_index ] = node->key;
+		(*next_key_index)++;
+
+		get_sorted_node_keys(node->right, key_list, next_key_index, depth+1);
+	}
+}
+
+static void get_sorted_node_values(long_map_node* node, void** value_list, unsigned long* next_value_index, int depth)
+{
+	if(node != NULL)
+	{
+		get_sorted_node_values(node->left, value_list, next_value_index, depth+1);
+
+		value_list[ *next_value_index ] = node->value;
+		(*next_value_index)++;
+
+		get_sorted_node_values(node->right, value_list, next_value_index, depth+1);
+	}
+}
+
+
+
+/*
+ * direction = -1 indicates left subtree updated, direction = 1 for right subtree
+ * update_op = -1 indicates delete node, update_op = 1 for insert node
+ */
+static signed char rebalance (long_map_node** n, signed char direction, signed char update_op)
+{
+	/*
+	printf( "original: key = %ld, balance = %d, update_op=%d, direction=%d\n", (*n)->key, (*n)->balance, update_op, direction);
+	*/
+
+	(*n)->balance = (*n)->balance + (update_op*direction);
+
+	if( (*n)->balance <  -1)
+	{
+		if((*n)->left->balance < 0)
+		{
+			rotate_right(n);
+			(*n)->right->balance = 0;
+			(*n)->balance = 0;
+		}
+		else if((*n)->left->balance == 0)
+		{
+			rotate_right(n);
+			(*n)->right->balance = -1;
+			(*n)->balance = 1;
+		}
+		else if((*n)->left->balance > 0)
+		{
+			rotate_left( &((*n)->left) );
+			rotate_right(n);
+			/*
+			if( (*n)->balance < 0 )
+			{
+				(*n)->left->balance = 0;
+				(*n)->right->balance = 1;
+			}
+			else if( (*n)->balance == 0 )
+			{
+				(*n)->left->balance = 0;
+				(*n)->right->balance = 0;
+			}
+			else if( (*n)->balance > 0 )
+			{
+				(*n)->left->balance = -1;
+				(*n)->right->balance = 0;
+			}
+			*/
+			(*n)->left->balance  = (*n)->balance > 0 ? -1 : 0;
+			(*n)->right->balance = (*n)->balance < 0 ?  1 : 0;
+			(*n)->balance = 0;
+		}
+	}
+	if( (*n)->balance >  1)
+	{
+		if((*n)->right->balance > 0)
+		{
+			rotate_left(n);
+			(*n)->left->balance = 0;
+			(*n)->balance = 0;
+		}
+		else if ((*n)->right->balance == 0)
+		{
+			rotate_left(n);
+			(*n)->left->balance = 1;
+			(*n)->balance = -1;
+		}
+		else if((*n)->right->balance < 0)
+		{
+			rotate_right( &((*n)->right) );
+			rotate_left(n);
+			/*
+			if( (*n)->balance < 0 )
+			{
+				(*n)->left->balance = 0;
+				(*n)->right->balance = 1;
+			}
+			else if( (*n)->balance == 0 )
+			{
+				(*n)->left->balance = 0;
+				(*n)->right->balance = 0;
+			}
+			else if( (*n)->balance > 0 )
+			{
+				(*n)->left->balance = -1;
+				(*n)->right->balance = 0;
+			}
+			*/
+			(*n)->left->balance   = (*n)->balance > 0 ? -1 : 0;
+			(*n)->right->balance  = (*n)->balance < 0 ?  1 : 0;
+			(*n)->balance = 0;
+		}
+	}
+
+	/*
+	printf( "key = %ld, balance = %d\n", (*n)->key, (*n)->balance);
+	*/
+
+	return (*n)->balance;
+}
+
+
+static void rotate_right (long_map_node** parent)
+{
+	long_map_node* old_parent = *parent;
+	long_map_node* pivot = old_parent->left;
+	old_parent->left = pivot->right;
+	pivot->right  = old_parent;
+
+	*parent = pivot;
+}
+
+static void rotate_left (long_map_node** parent)
+{
+	long_map_node* old_parent = *parent;
+	long_map_node* pivot = old_parent->right;
+	old_parent->right = pivot->left;
+	pivot->left  = old_parent;
+
+	*parent = pivot;
+}
+
+
+
+/***************************************************************************
+ * This algorithm was created for the sdbm database library (a public-domain
+ * reimplementation of ndbm) and seems to work relatively well in
+ * scrambling bits
+ *
+ *
+ * This code was derived from code found at:
+ * http://www.cse.yorku.ca/~oz/hash.html
+ ***************************************************************************/
+static unsigned long sdbm_string_hash(const char *key)
+{
+	unsigned long hashed_key = 0;
+
+	int index = 0;
+	unsigned int nextch;
+	while(key[index] != '\0')
+	{
+		nextch = key[index];
+		hashed_key = nextch + (hashed_key << 6) + (hashed_key << 16) - hashed_key;
+		index++;
+	}
+	return hashed_key;
+}
+
+
diff --git a/trunk/linux-4.4.x/net/ipv4/xfrm4_mode_transport.c b/trunk/linux-4.4.x/net/ipv4/xfrm4_mode_transport.c
index fd840c7d7..12a888cb7 100644
--- a/trunk/linux-4.4.x/net/ipv4/xfrm4_mode_transport.c
+++ b/trunk/linux-4.4.x/net/ipv4/xfrm4_mode_transport.c
@@ -23,7 +23,29 @@ static int xfrm4_transport_output(struct xfrm_state *x, struct sk_buff *skb)
 	struct iphdr *iph = ip_hdr(skb);
 	int ihl = iph->ihl * 4;
 
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+	{
+		int offset = 0;
+		if (x->props.mode == XFRM_MODE_TUNNEL)
+		{	
+			if (x->encap)
+				offset = 20+8;
+			else
+				offset = 20;
+		}
+		else
+		{
+			if (x->encap)
+				offset = 8;
+			else
+				offset = 0;
+		}		
+		skb_set_network_header(skb, -offset);
+	}
+#else
 	skb_set_network_header(skb, -x->props.header_len);
+#endif
+
 	skb->mac_header = skb->network_header +
 			  offsetof(struct iphdr, protocol);
 	skb->transport_header = skb->network_header + ihl;
diff --git a/trunk/linux-4.4.x/net/ipv4/xfrm4_mode_tunnel.c b/trunk/linux-4.4.x/net/ipv4/xfrm4_mode_tunnel.c
index 35feda676..12844603a 100644
--- a/trunk/linux-4.4.x/net/ipv4/xfrm4_mode_tunnel.c
+++ b/trunk/linux-4.4.x/net/ipv4/xfrm4_mode_tunnel.c
@@ -33,7 +33,29 @@ static int xfrm4_mode_tunnel_output(struct xfrm_state *x, struct sk_buff *skb)
 	struct iphdr *top_iph;
 	int flags;
 
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+	{
+		int offset = 0;
+		if (x->props.mode == XFRM_MODE_TUNNEL)
+		{	
+			if (x->encap)
+				offset = 20+8;
+			else
+				offset = 20;
+		}
+		else
+		{
+			if (x->encap)
+				offset = 8;
+			else
+				offset = 0;
+		}		
+		skb_set_network_header(skb, -offset);
+	}
+#else
 	skb_set_network_header(skb, -x->props.header_len);
+#endif
+
 	skb->mac_header = skb->network_header +
 			  offsetof(struct iphdr, protocol);
 	skb->transport_header = skb->network_header + sizeof(*top_iph);
diff --git a/trunk/linux-4.4.x/net/ipv6/addrconf.c b/trunk/linux-4.4.x/net/ipv6/addrconf.c
index c3d832632..36b82f15a 100644
--- a/trunk/linux-4.4.x/net/ipv6/addrconf.c
+++ b/trunk/linux-4.4.x/net/ipv6/addrconf.c
@@ -290,7 +290,6 @@ static struct ipv6_devconf ipv6_devconf_dflt __read_mostly = {
 };
 
 /* Check if a valid qdisc is available */
-
 // mark@wdl, copy from linux-4.9.162 for CE LOGO test wan_rfc4862.
 // some race condition casue only check qdisc_tx_is_noop() isn't correct.
 static inline bool addrconf_link_ready(const struct net_device *dev)
@@ -1860,7 +1859,7 @@ void addrconf_dad_failure(struct inet6_ifaddr *ifp)
 	}
 
 	net_info_ratelimited("%s: IPv6 duplicate address %pI6c detected!\n",
-                            ifp->idev->dev->name, &ifp->addr);
+			     ifp->idev->dev->name, &ifp->addr);
 
 	spin_lock_bh(&ifp->lock);
 
@@ -3198,7 +3197,8 @@ static void addrconf_gre_config(struct net_device *dev)
 #endif
 
 // mark@wdl, copy from linux-4.20.15 for CE LOGO test wan_rfc4862.
-static int fixup_permanent_addr(struct inet6_dev *idev,
+static int fixup_permanent_addr(struct net *net,
+				struct inet6_dev *idev,
 				struct inet6_ifaddr *ifp)
 {
 	/* rt6i_ref == 0 means the host route was removed from the
@@ -3232,7 +3232,7 @@ static int fixup_permanent_addr(struct inet6_dev *idev,
 	return 0;
 }
 
-static void addrconf_permanent_addr(struct net_device *dev)
+static void addrconf_permanent_addr(struct net *net, struct net_device *dev)
 {
 	struct inet6_ifaddr *ifp, *tmp;
 	struct inet6_dev *idev;
@@ -3245,7 +3245,7 @@ static void addrconf_permanent_addr(struct net_device *dev)
 
 	list_for_each_entry_safe(ifp, tmp, &idev->addr_list, if_list) {
 		if ((ifp->flags & IFA_F_PERMANENT) &&
-		    fixup_permanent_addr(idev, ifp) < 0) {
+		    fixup_permanent_addr(net, idev, ifp) < 0) {
 			write_unlock_bh(&idev->lock);
 			in6_ifa_hold(ifp);
 			ipv6_del_addr(ifp);
@@ -3269,7 +3269,6 @@ static int addrconf_notify(struct notifier_block *this, unsigned long event,
 	int run_pending = 0;
 	int err;
 
-
 	switch (event) {
 	case NETDEV_REGISTER:
 		if (!idev && dev->mtu >= IPV6_MIN_MTU) {
@@ -3315,12 +3314,12 @@ static int addrconf_notify(struct notifier_block *this, unsigned long event,
 
 		if (event == NETDEV_UP) {
 			/* restore routes for permanent addresses */
-			addrconf_permanent_addr(dev);
+			addrconf_permanent_addr(net, dev);
 
 			if (!addrconf_link_ready(dev)) {
 				/* device is not ready yet. */
 				pr_info("ADDRCONF(NETDEV_UP): %s: link is not ready\n",
-                                       dev->name);
+					dev->name);
 				break;
 			}
 
@@ -3352,12 +3351,11 @@ static int addrconf_notify(struct notifier_block *this, unsigned long event,
 					            dev->name);
 
 					addrconf_dad_run(idev, true);
-                    
 					break;
 				}
 				idev->if_flags |= IF_READY;
 			}
-            
+
 			pr_info("ADDRCONF(NETDEV_CHANGE): %s: link becomes ready\n",
 				dev->name);
 
@@ -3385,7 +3383,7 @@ static int addrconf_notify(struct notifier_block *this, unsigned long event,
 		}
 
 		if (!IS_ERR_OR_NULL(idev)) {
-			if (run_pending) 
+			if (run_pending)
 				addrconf_dad_run(idev, false);
 
 			/*
@@ -3638,18 +3636,16 @@ static void addrconf_dad_kick(struct inet6_ifaddr *ifp, unsigned long delay)
 	unsigned long rand_num;
 	struct inet6_dev *idev = ifp->idev;
 
-	if (0 == delay)
-	{
+	if (delay == 0) {
 		if (ifp->flags & IFA_F_OPTIMISTIC)
 			rand_num = 0;
 		else
 			rand_num = prandom_u32() % (idev->cnf.rtr_solicit_delay ? : 1);
-	}
-	else
+	} else {
 		rand_num = delay;
-    
-	ifp->dad_probes = idev->cnf.dad_transmits;
+	}
 
+	ifp->dad_probes = idev->cnf.dad_transmits;
 	addrconf_mod_dad_work(ifp, rand_num);
 }
 
@@ -3744,7 +3740,6 @@ static void addrconf_dad_work(struct work_struct *w)
 		DAD_ABORT,
 	} action = DAD_PROCESS;
 
-
 	rtnl_lock();
 
 	spin_lock_bh(&ifp->lock);
@@ -3775,7 +3770,7 @@ static void addrconf_dad_work(struct work_struct *w)
 		write_unlock_bh(&idev->lock);
 		goto out;
 	}
-    
+
 	spin_lock(&ifp->lock);
 	if (ifp->state == INET6_IFADDR_STATE_DEAD) {
 		spin_unlock(&ifp->lock);
@@ -3790,8 +3785,10 @@ static void addrconf_dad_work(struct work_struct *w)
 
 		ifp->flags &= ~(IFA_F_TENTATIVE|IFA_F_OPTIMISTIC|IFA_F_DADFAILED);
 		spin_unlock(&ifp->lock);
-		write_unlock_bh(&idev->lock); 
+		write_unlock_bh(&idev->lock);
+
 		addrconf_dad_completed(ifp);
+
 		goto out;
 	}
 
@@ -3803,9 +3800,7 @@ static void addrconf_dad_work(struct work_struct *w)
 
 	/* send a neighbour solicitation for our addr */
 	addrconf_addr_solict_mult(&ifp->addr, &mcaddr);
-
 	pr_debug("addrconf_dad_work: send ns, %s: addr=%pI6c\n", idev->dev->name, &ifp->addr);
-    
 	ndisc_send_ns(ifp->idev->dev, &ifp->addr, &mcaddr, &in6addr_any);
 out:
 	in6_ifa_put(ifp);
@@ -3914,17 +3909,17 @@ static void addrconf_dad_run(struct inet6_dev *idev, bool restart)
 	read_lock_bh(&idev->lock);
 	list_for_each_entry(ifp, &idev->addr_list, if_list) {
 		spin_lock(&ifp->lock);
-		if (ifp->flags & IFA_F_TENTATIVE &&
-		    ifp->state == INET6_IFADDR_STATE_DAD)
-		    if (restart)
+		if ((ifp->flags & IFA_F_TENTATIVE &&
+		     ifp->state == INET6_IFADDR_STATE_DAD) || restart) {
+			if (restart)
 				ifp->state = INET6_IFADDR_STATE_PREDAD;
 			addrconf_dad_kick(ifp, delay);
+		}
 		spin_unlock(&ifp->lock);
 	}
 	read_unlock_bh(&idev->lock);
 }
 
-
 #ifdef CONFIG_PROC_FS
 struct if6_iter_state {
 	struct seq_net_private p;
diff --git a/trunk/linux-4.4.x/net/ipv6/ip6_output.c b/trunk/linux-4.4.x/net/ipv6/ip6_output.c
index d97f5177c..91216d7b1 100644
--- a/trunk/linux-4.4.x/net/ipv6/ip6_output.c
+++ b/trunk/linux-4.4.x/net/ipv6/ip6_output.c
@@ -65,8 +65,10 @@ static int ip6_finish_output2(struct net *net, struct sock *sk, struct sk_buff *
 	struct in6_addr *nexthop;
 	int ret;
 
+#if !(defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE))
 	skb->protocol = htons(ETH_P_IPV6);
 	skb->dev = dev;
+#endif
 
 	if (ipv6_addr_is_multicast(&ipv6_hdr(skb)->daddr)) {
 		struct inet6_dev *idev = ip6_dst_idev(skb_dst(skb));
@@ -142,6 +144,15 @@ int ip6_output(struct net *net, struct sock *sk, struct sk_buff *skb)
 		return 0;
 	}
 
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	/*
+	 * IMQ-patch: moved setting skb->dev and skb->protocol from
+	 * ip6_finish_output2 to fix crashing at netif_skb_features().
+	 */
+	skb->protocol = htons(ETH_P_IPV6);
+	skb->dev = dev;
+#endif
+
 	return NF_HOOK_COND(NFPROTO_IPV6, NF_INET_POST_ROUTING,
 			    net, sk, skb, NULL, dev,
 			    ip6_finish_output,
diff --git a/trunk/linux-4.4.x/net/ipv6/ip6_tunnel.c b/trunk/linux-4.4.x/net/ipv6/ip6_tunnel.c
index 300998124..8056512a9 100644
--- a/trunk/linux-4.4.x/net/ipv6/ip6_tunnel.c
+++ b/trunk/linux-4.4.x/net/ipv6/ip6_tunnel.c
@@ -1680,14 +1680,14 @@ EXPORT_SYMBOL(ip6_tnl_get_iflink);
 static int ipip6_dev_hnat_check(struct hnat_hw_path *path)
 {
 
-	struct net_device *dev = path->dev;
+	struct net_device *dev = path->real_dev;
 	struct ip6_tnl *tnl = netdev_priv(dev);
 
 	if (path->flags & HNAT_PATH_DSLITE)
 		return -EEXIST;
 
 	path->flags |= HNAT_PATH_DSLITE;
-	path->dev = tnl->dev;
+	path->real_dev = tnl->dev;
 
 	return 0;
 
diff --git a/trunk/linux-4.4.x/net/ipv6/ndisc.c b/trunk/linux-4.4.x/net/ipv6/ndisc.c
index 3103fe8c6..e16a05ca4 100644
--- a/trunk/linux-4.4.x/net/ipv6/ndisc.c
+++ b/trunk/linux-4.4.x/net/ipv6/ndisc.c
@@ -491,7 +491,6 @@ void ndisc_send_na(struct net_device *dev, const struct in6_addr *daddr,
 	struct nd_msg *msg;
 	int optlen = 0;
 
-    
 	/* for anycast or proxy, solicited_addr != src_addr */
 	ifp = ipv6_get_ifaddr(dev_net(dev), solicited_addr, dev, 1);
 	if (ifp) {
@@ -532,6 +531,7 @@ void ndisc_send_na(struct net_device *dev, const struct in6_addr *daddr,
 		ndisc_fill_addr_option(skb, ND_OPT_TARGET_LL_ADDR,
 				       dev->dev_addr);
 
+
 	ndisc_send_skb(skb, daddr, src_addr);
 }
 
@@ -580,6 +580,7 @@ void ndisc_send_ns(struct net_device *dev, const struct in6_addr *solicit,
 	skb = ndisc_alloc_skb(dev, sizeof(*msg) + optlen);
 	if (!skb)
 		return;
+
 	msg = (struct nd_msg *)skb_put(skb, sizeof(*msg));
 	*msg = (struct nd_msg) {
 		.icmph = {
@@ -791,7 +792,6 @@ have_ifp:
 
 		idev = ifp->idev;
 	} else {
-
 		struct net *net = dev_net(dev);
 
 		/* perhaps an address on the master device */
diff --git a/trunk/linux-4.4.x/net/ipv6/netfilter/nf_nat_proto_icmpv6.c b/trunk/linux-4.4.x/net/ipv6/netfilter/nf_nat_proto_icmpv6.c
index 57593b00c..4e29cd3dd 100644
--- a/trunk/linux-4.4.x/net/ipv6/netfilter/nf_nat_proto_icmpv6.c
+++ b/trunk/linux-4.4.x/net/ipv6/netfilter/nf_nat_proto_icmpv6.c
@@ -22,9 +22,11 @@
 static bool
 icmpv6_in_range(const struct nf_conntrack_tuple *tuple,
 		enum nf_nat_manip_type maniptype,
-		const union nf_conntrack_man_proto *min,
-		const union nf_conntrack_man_proto *max)
+		const struct nf_nat_range *range)
 {
+	const union nf_conntrack_man_proto *min = &range->min_proto;
+	const union nf_conntrack_man_proto *max = &range->max_proto;
+
 	return ntohs(tuple->src.u.icmp.id) >= ntohs(min->icmp.id) &&
 	       ntohs(tuple->src.u.icmp.id) <= ntohs(max->icmp.id);
 }
diff --git a/trunk/linux-4.4.x/net/ipv6/route.c b/trunk/linux-4.4.x/net/ipv6/route.c
index 8b1b7e3ef..8fcc561e7 100644
--- a/trunk/linux-4.4.x/net/ipv6/route.c
+++ b/trunk/linux-4.4.x/net/ipv6/route.c
@@ -1380,9 +1380,8 @@ static void __ip6_rt_update_pmtu(struct dst_entry *dst, const struct sock *sk,
 	 * packets sent on the path to less than the IPv6 minimun link MTU,
 	 * but rather must include a Fragment header in those packets
 	 */
-	if( mtu < IPV6_MIN_MTU )
-	{
-		dst_metric_set( dst, RTAX_FEATURES, dst_feature(dst, RTAX_FEATURES) | RTAX_FEATURE_ALLFRAG );
+	if (mtu < IPV6_MIN_MTU) {
+		dst_metric_set(dst, RTAX_FEATURES, dst_feature(dst, RTAX_FEATURES) | RTAX_FEATURE_ALLFRAG);
 	}
 
 	mtu = max_t(u32, mtu, IPV6_MIN_MTU);
diff --git a/trunk/linux-4.4.x/net/ipv6/sit.c b/trunk/linux-4.4.x/net/ipv6/sit.c
index 5039486c4..cbfcd48f2 100644
--- a/trunk/linux-4.4.x/net/ipv6/sit.c
+++ b/trunk/linux-4.4.x/net/ipv6/sit.c
@@ -55,6 +55,7 @@
 #include <net/dsfield.h>
 #include <net/net_namespace.h>
 #include <net/netns/generic.h>
+#include <net/netfilter/nf_hnat.h>
 
 /*
    This version of net/ipv6/sit.c is cloned of net/ipv4/ip_gre.c
@@ -1337,6 +1338,22 @@ static int ipip6_tunnel_change_mtu(struct net_device *dev, int new_mtu)
 	return 0;
 }
 
+static int ipip6_dev_hnat_check(struct hnat_hw_path *path)
+{
+
+	struct net_device *dev = path->real_dev;
+	struct ip_tunnel *tnl = netdev_priv(dev);
+
+	if (path->flags & HNAT_PATH_6RD)
+		return -EEXIST;
+
+	path->flags |= HNAT_PATH_6RD;
+	path->real_dev = tnl->dev;
+
+	return 0;
+
+}
+
 static const struct net_device_ops ipip6_netdev_ops = {
 	.ndo_init	= ipip6_tunnel_init,
 	.ndo_uninit	= ipip6_tunnel_uninit,
@@ -1345,6 +1362,7 @@ static const struct net_device_ops ipip6_netdev_ops = {
 	.ndo_change_mtu	= ipip6_tunnel_change_mtu,
 	.ndo_get_stats64 = ip_tunnel_get_stats64,
 	.ndo_get_iflink = ip_tunnel_get_iflink,
+	.ndo_hnat_check = ipip6_dev_hnat_check,
 };
 
 static void ipip6_dev_free(struct net_device *dev)
diff --git a/trunk/linux-4.4.x/net/l2tp/l2tp_core.c b/trunk/linux-4.4.x/net/l2tp/l2tp_core.c
index 519362991..9e0fadd3c 100644
--- a/trunk/linux-4.4.x/net/l2tp/l2tp_core.c
+++ b/trunk/linux-4.4.x/net/l2tp/l2tp_core.c
@@ -1126,7 +1126,7 @@ int l2tp_xmit_skb(struct l2tp_session *session, struct sk_buff *skb, int hdr_len
 	 * UDP and L2TP headers. If not enough, expand it to
 	 * make room. Adjust truesize.
 	 */
-	headroom = NET_SKB_PAD + sizeof(struct iphdr) +
+	headroom = NET_SKB_PAD_ORIG + sizeof(struct iphdr) +
 		uhlen + hdr_len;
 	if (skb_cow_head(skb, headroom)) {
 		kfree_skb(skb);
diff --git a/trunk/linux-4.4.x/net/l2tp/l2tp_ppp.c b/trunk/linux-4.4.x/net/l2tp/l2tp_ppp.c
index d3f1222c1..5b62d898a 100644
--- a/trunk/linux-4.4.x/net/l2tp/l2tp_ppp.c
+++ b/trunk/linux-4.4.x/net/l2tp/l2tp_ppp.c
@@ -409,7 +409,7 @@ static int pppol2tp_xmit(struct ppp_channel *chan, struct sk_buff *skb)
 		goto abort_put_sess;
 
 	uhlen = (tunnel->encap == L2TP_ENCAPTYPE_UDP) ? sizeof(struct udphdr) : 0;
-	headroom = NET_SKB_PAD +
+	headroom = NET_SKB_PAD_ORIG +
 		   sizeof(struct iphdr) + /* IP header */
 		   uhlen +		/* UDP header (if L2TP_ENCAPTYPE_UDP) */
 		   session->hdr_len +	/* L2TP header */
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/fast_path.c b/trunk/linux-4.4.x/net/nat/hw_nat/fast_path.c
index c68786449..b10c6cef0 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/fast_path.c
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/fast_path.c
@@ -17,7 +17,7 @@
 #include "ra_nat.h"
 #include "util.h"
 
-#if 0
+#if defined(CONFIG_SUPPORT_OPENWRT)
 #if defined(CONFIG_GE_RGMII_INTERNAL_P4_AN) || defined(CONFIG_GE_RGMII_INTERNAL_P0_AN)
 char *ifname="eth1";
 #else
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c b/trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c
index 68eefd7d9..4dcf6e178 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/foe_fdb.c
@@ -17,7 +17,6 @@
 #include <linux/timer.h>
 #include <linux/skbuff.h>
 #include <linux/netdevice.h>
-#include <linux/ppp_defs.h>
 
 #include "frame_engine.h"
 #include "foe_fdb.h"
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_config.h b/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_config.h
index fccb1f9e9..5f72f3e03 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_config.h
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_config.h
@@ -169,7 +169,7 @@
 #define PACKET_SAMPLING		(0)
 #endif
 
-#if 0
+#ifdef CONFIG_SUPPORT_OPENWRT
 #define HNAT_OPENWRT	BIT(13)
 #else
 #define HNAT_OPENWRT		(0)
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c b/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c
index 42e1e5cab..78e651bab 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/hwnat_ioctl.c
@@ -25,9 +25,9 @@
 #include "mcast_tbl.h"
 #endif
 
-unsigned char bind_dir __read_mostly = BIDIRECTION;
-unsigned short lan_vid __read_mostly = CONFIG_RA_HW_NAT_LAN_VLANID;
-extern unsigned short wan_vid;
+unsigned char bind_dir = BIDIRECTION;
+unsigned short lan_vid = CONFIG_RA_HW_NAT_LAN_VLANID;
+unsigned short wan_vid = CONFIG_RA_HW_NAT_WAN_VLANID;
 int debug_level;
 
 #if defined (CONFIG_HW_NAT_IPI)
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c b/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c
index 3bdc3530b..fc750e69e 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.c
@@ -49,15 +49,10 @@
 #include "util.h"
 #include "hwnat_ioctl.h"
 #include "hwnat_define.h"
-
-unsigned short wan_vid __read_mostly = CONFIG_RA_HW_NAT_WAN_VLANID;
-module_param(wan_vid, ushort, S_IRUGO|S_IWUSR);
-MODULE_PARM_DESC(wan_vid, "VLAN ID for WAN traffic");
-
 struct timer_list hwnat_clear_entry_timer;
 static void hwnat_clear_entry(unsigned long data)
 {
-	//printk("HW_NAT work normally\n");
+	printk("HW_NAT work normally\n");
 	reg_modify_bits(PPE_FOE_CFG, FWD_CPU_BUILD_ENTRY, 4, 2);
 	//del_timer_sync(&hwnat_clear_entry_timer);
 
@@ -293,7 +288,7 @@ uint16_t remove_vlan_tag(struct sk_buff *skb)
 	/* something wrong */
 	if ((veth->h_vlan_proto != htons(ETH_P_8021Q)) && (veth->h_vlan_proto != 0x5678)) {
 		//if (pr_debug_ratelimited())
-		//	pr_info("HNAT: Reentry packet is untagged frame?\n");
+			pr_info("HNAT: Reentry packet is untagged frame?\n");
 		return 65535;
 	}
 	/*we just want to get vid*/
@@ -574,7 +569,7 @@ int get_bridge_info(void)
 {
 	struct net_device *br0_dev; 
 	struct in_device *br0_in_dev;
-#if 0
+#if defined(CONFIG_SUPPORT_OPENWRT)
 	br0_dev = dev_get_by_name(&init_net,"br-lan");
 #else
 	br0_dev = dev_get_by_name(&init_net,"br0");
@@ -599,8 +594,8 @@ int get_bridge_info(void)
 	else
 		pr_info("br0_in_dev = NULL\n");
 	
-	pr_debug("br0Ip = %x\n", br0Ip);
-	pr_debug("brNetmask = %x\n", brNetmask);
+	pr_info("br0Ip = %x\n", br0Ip);
+	pr_info("brNetmask = %x\n", brNetmask);
 	getBrLan = 1;
 	
 	return 0;
@@ -2109,7 +2104,7 @@ int32_t ppe_setforce_port_info(struct sk_buff *skb, struct foe_entry *entry, int
 	if (IS_IPV4_GRP(entry)) {
 		if (skb->mark > 63)
 			skb->mark = 0;
-		qidx = skb->mark;
+		qidx = M2Q_table[skb->mark];
 #if defined(CONFIG_ARCH_MT7622) 
 		entry->ipv4_hnapt.iblk2.qid1 = ((qidx & 0x30) >> 4);
 #endif
@@ -2134,12 +2129,12 @@ int32_t ppe_setforce_port_info(struct sk_buff *skb, struct foe_entry *entry, int
 	else if (IS_IPV6_GRP(entry)) {
 		if (skb->mark > 63)
 			skb->mark = 0;
-		qidx = skb->mark;
-		entry->ipv6_3t_route.iblk2.qid = (qidx & 0x0f);
 #ifdef CONFIG_PSEUDO_SUPPORT
+		qidx = M2Q_table[skb->mark];
 #if defined(CONFIG_ARCH_MT7622) 
 		entry->ipv6_3t_route.iblk2.qid1 = ((qidx & 0x30) >> 4);
 #endif
+		entry->ipv6_3t_route.iblk2.qid = (qidx & 0x0f);
 		if (lan_wan_separate == 1 && gmac_no == 2) {
 			entry->ipv6_3t_route.iblk2.qid += 8;
 #if defined(CONFIG_HW_SFQ)
@@ -2655,7 +2650,7 @@ defined(CONFIG_MT7610_AP_APCLI) || defined(CONFIG_APCLI_SUPPORT)
 			offset = RTMP_GET_PACKET_IF(skb) + DP_RA0;
 #endif				/* CONFIG_RT2860V2_AP_WDS // */
 	}
-#if 0
+#if defined(CONFIG_SUPPORT_OPENWRT)
 	else if (strncmp(skb->dev->name, "eth0", 4) == 0)
 		offset = DP_GMAC;
 #ifdef CONFIG_RAETH_GMAC2
@@ -2704,46 +2699,21 @@ defined(CONFIG_MT7610_AP_APCLI) || defined(CONFIG_APCLI_SUPPORT)
 
 	if (IS_IPV4_HNAT(entry) || IS_IPV4_HNAPT(entry)) {
 		entry->ipv4_hnapt.act_dp = offset;
-#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv4_hnapt.iblk2.acnt = offset;
-#else
-		entry->ipv4_hnapt.iblk2.port_mg = 0x3f;
-		entry->ipv4_hnapt.iblk2.port_ag = offset;
-#endif
 	}
 #if defined(CONFIG_RA_HW_NAT_IPV6)
 	else if (IS_IPV4_DSLITE(entry)) {
 		entry->ipv4_dslite.act_dp = offset;
-#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv4_dslite.iblk2.acnt = offset;
-#else
-		entry->ipv4_dslite.iblk2.port_mg = 0x3f;
-		entry->ipv4_dslite.iblk2.port_ag = offset;
-#endif
 	} else if (IS_IPV6_3T_ROUTE(entry)) {
 		entry->ipv6_3t_route.act_dp = offset;
-#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv6_3t_route.iblk2.acnt = offset;
-#else
-		entry->ipv6_3t_route.iblk2.port_mg = 0x3f;
-		entry->ipv6_3t_route.iblk2.port_ag = offset;
-#endif
 	} else if (IS_IPV6_5T_ROUTE(entry)) {
 		entry->ipv6_5t_route.act_dp = offset;
-#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv6_5t_route.iblk2.acnt = offset;
-#else
-		entry->ipv6_5t_route.iblk2.port_mg = 0x3f;
-		entry->ipv6_5t_route.iblk2.port_ag = offset;
-#endif
 	} else if (IS_IPV6_6RD(entry)) {
 		entry->ipv6_6rd.act_dp = offset;
-#if defined(CONFIG_ARCH_MT7622)
 		entry->ipv6_6rd.iblk2.acnt = offset;
-#else
-		entry->ipv6_6rd.iblk2.port_mg = 0x3f;
-		entry->ipv6_6rd.iblk2.port_ag = offset;
-#endif
 	} else {
 		return 1;
 	}
@@ -2793,14 +2763,9 @@ void ppe_set_entry_bind(struct sk_buff *skb, struct foe_entry *entry)
 void ppe_dev_reg_handler(struct net_device *dev)
 {
 	int i;
-
-	/* skip apcli interface */
-	if (strncmp(dev->name, "apcli", 5) == 0)
-		return;
-
 	for (i = 0; i < MAX_IF_NUM; i++) {
 		if (dst_port[i] == dev) {
-			pr_debug("%s : %s dst_port table has beed registered(%d)\n", __func__, dev->name, i);
+			pr_info("%s : %s dst_port table has beed registered(%d)\n", __func__, dev->name, i);
 			return;
 		}
 		if (dst_port[i] == NULL) {
@@ -3023,8 +2988,7 @@ int32_t ppe_tx_handler(struct sk_buff *skb, int gmac_no)
 				pr_info("ppe_set_entry_bind\n");
 			/* Set Pseudo Interface info in Foe entry */
 			/* Enter binding state */
-			memset(FOE_INFO_START_ADDR(skb), 0, FOE_INFO_LEN);
-			/*ppe_set_entry_bind(skb, entry);*/
+			ppe_set_entry_bind(skb, entry);
 			return 1;
 		}
 	}
@@ -3104,12 +3068,12 @@ int32_t ppe_tx_handler(struct sk_buff *skb, int gmac_no)
 		if (ppe_parse_result.is_mcast) {
 			foe_mcast_entry_qid(ppe_parse_result.vlan1,
 					    ppe_parse_result.dmac,
-					    skb->mark);
+					    M2Q_table[skb->mark]);
 #ifdef CONFIG_PSEUDO_SUPPORT
 			if (lan_wan_separate == 1 && gmac_no == 2) {
 				foe_mcast_entry_qid(ppe_parse_result.vlan1,
 						    ppe_parse_result.dmac,
-						    skb->mark + 8);
+						    M2Q_table[skb->mark] + 8);
 #if defined(CONFIG_HW_SFQ)
 				if (web_sfq_enable == 1 && (skb->mark == 2))
 					foe_mcast_entry_qid(ppe_parse_result.vlan1,
@@ -3660,7 +3624,7 @@ defined(CONFIG_MT7610_AP_MESH)
 #if defined(CONFIG_RA_HW_NAT_WIFI_NEW_ARCH)
 		struct net_device *dev;
 		int i;
-#if 0
+#if defined(CONFIG_SUPPORT_OPENWRT)
 		dev = ra_dev_get_by_name("eth0");
 		ppe_dev_reg_handler(dev);
 		for (i = 0; i < MAX_IF_NUM; i++) {
@@ -3705,7 +3669,7 @@ defined(CONFIG_MT7610_AP_MESH)
 #endif
 
 #else
-#if 0
+#if defined(CONFIG_SUPPORT_OPENWRT)
 		dst_port[DP_GMAC] = ra_dev_get_by_name("eth0");
 #ifdef CONFIG_RAETH_GMAC2
 		dst_port[DP_GMAC2] = ra_dev_get_by_name("eth1");
@@ -3986,7 +3950,7 @@ static void set_acl_fwd(uint32_t ebl)
 	unsigned int i, value;
 
 	if (ebl) {
-#if 0
+#if defined(CONFIG_SUPPORT_OPENWRT)
 #if defined(CONFIG_RAETH_SPECIAL_TAG)
 #if defined(CONFIG_WAN_AT_P4)
 		wan_int = ra_dev_get_by_name("eth0.5");
@@ -4313,14 +4277,14 @@ void foe_clear_entry(struct neighbour *neigh)
 				    (entry->ipv4_hnapt.dmac_hi[0] != mac3) ||
 				    (entry->ipv4_hnapt.dmac_lo[1] != mac4) ||
 				    (entry->ipv4_hnapt.dmac_lo[0] != mac5)) {
-				    	//printk("%s: state=%d\n",__func__,neigh->nud_state);
+				    	printk("%s: state=%d\n",__func__,neigh->nud_state);
 				    	reg_modify_bits(PPE_FOE_CFG, ONLY_FWD_CPU, 4, 2);
 				    	
 				  	entry->ipv4_hnapt.udib1.state = INVALID;
 					entry->ipv4_hnapt.udib1.time_stamp = reg_read(FOE_TS) & 0xFF;
 					ppe_set_cache_ebl();
 					mod_timer(&hwnat_clear_entry_timer, jiffies + 3 * HZ);
-				/*
+				
 					printk("delete old entry: dip =%x\n", ntohl(dip));
 							
 				    	printk("old mac= %x:%x:%x:%x:%x:%x, dip=%x\n", 
@@ -4332,7 +4296,7 @@ void foe_clear_entry(struct neighbour *neigh)
 				    		entry->ipv4_hnapt.dmac_lo[0],
 				    		ntohl(dip));
 				    	printk("new mac= %x:%x:%x:%x:%x:%x, dip=%x\n", mac0, mac1, mac2, mac3, mac4, mac5, ntohl(dip));
-				*/
+
 				}
 			}
 		}
diff --git a/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h b/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h
index 687de201b..6e3ba7310 100644
--- a/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h
+++ b/trunk/linux-4.4.x/net/nat/hw_nat/ra_nat.h
@@ -1,54 +1,17 @@
-/******************************************************************************
- *
- * This file is provided under a dual license.  When you use or
- * distribute this software, you may choose to be licensed under
- * version 2 of the GNU General Public License ("GPLv2 License")
- * or BSD License.
- *
- * GPLv2 License
- *
- * Copyright(C) 2017 MediaTek Inc.
+/* Copyright  2016 MediaTek Inc.
+ * Author: Nelson Chang <nelson.chang@mediatek.com>
+ * Author: Carlos Huang <carlos.huang@mediatek.com>
+ * Author: Harry Huang <harry.huang@mediatek.com>
  *
  * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
+ * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
- * See http://www.gnu.org/licenses/gpl-2.0.html for more details.
- *
- * BSD LICENSE
- *
- * Copyright(C) 2017 MediaTek Inc. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in
- *    the documentation and/or other materials provided with the
- *    distribution.
- *  * Neither the name of the copyright holder nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- *****************************************************************************/
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
 #ifndef _RA_NAT_WANTED
 #define _RA_NAT_WANTED
 
@@ -59,13 +22,13 @@
 #define hwnat_vlan_tag_get(__skb)         ((__skb)->vlan_tci & ~VLAN_TAG_PRESENT)
 
 #if defined(CONFIG_RA_NAT_HW)
-extern void hwnat_magic_tag_set_zero(struct sk_buff *skb);
-extern void hwnat_check_magic_tag(struct sk_buff *skb);
-extern void hwnat_set_headroom_zero(struct sk_buff *skb);
-extern void hwnat_set_tailroom_zero(struct sk_buff *skb);
-extern void hwnat_copy_headroom(u8 *data, struct sk_buff *skb);
-extern void hwnat_copy_tailroom(u8 *data, int size, struct sk_buff *skb);
-extern void hwnat_setup_dma_ops(struct device *dev, bool coherent);
+void hwnat_magic_tag_set_zero(struct sk_buff *skb);
+void hwnat_check_magic_tag(struct sk_buff *skb);
+void hwnat_set_headroom_zero(struct sk_buff *skb);
+void hwnat_set_tailroom_zero(struct sk_buff *skb);
+void hwnat_copy_headroom(u8 *data, struct sk_buff *skb);
+void hwnat_copy_tailroom(u8 *data, int size, struct sk_buff *skb);
+
 #else
 
 static inline void hwnat_magic_tag_set_zero(struct sk_buff *skb)
@@ -226,23 +189,19 @@ defined(CONFIG_MT7610_AP_MESH)
 	MAX_IF_NUM
 };
 
-#define MAX_IF_NUM 64
 struct pdma_rx_desc_info4 {
 	u16 MAGIC_TAG_PROTECT;
 	uint32_t foe_entry_num:14;
 	uint32_t CRSN:5;
-	uint32_t SPORT:3;
-#if defined(CONFIG_MACH_LEOPARD)
-	uint32_t foe_entry_num_32:1;
-#else
-	uint32_t rsv:1;
-#endif
+	uint32_t SPORT:4;
 	uint32_t ALG:1;
 	uint16_t IF:8;
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 	u8 WDMAID;
 	uint16_t RXID:2;
 	uint16_t WCID:8;
 	uint16_t BSSID:6;
+#endif
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 	u16 SOURCE;
 	u16 DEST;
@@ -252,20 +211,16 @@ struct pdma_rx_desc_info4 {
 struct head_rx_descinfo4 {
 	uint32_t foe_entry_num:14;
 	uint32_t CRSN:5;
-	uint32_t SPORT:3;
-#if defined(CONFIG_MACH_LEOPARD)
-	uint32_t foe_entry_num_32:1;
-#else
-	uint32_t rsv:1;
-#endif
+	uint32_t SPORT:4;
 	uint32_t ALG:1;
 	uint32_t IF:8;
 	u16 MAGIC_TAG_PROTECT;
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 	u8 WDMAID;
 	uint16_t RXID:2;
 	uint16_t WCID:8;
 	uint16_t BSSID:6;
-
+#endif
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 	u16 SOURCE;
 	u16 DEST;
@@ -276,19 +231,16 @@ struct cb_rx_desc_info4 {
 	u16 MAGIC_TAG_PROTECT0;
 	uint32_t foe_entry_num:14;
 	uint32_t CRSN:5;
-	uint32_t SPORT:3;
-#if defined(CONFIG_MACH_LEOPARD)
-	uint32_t foe_entry_num_32:1;
-#else
-	uint32_t rsv:1;
-#endif
+	uint32_t SPORT:4;
 	uint32_t ALG:1;
 	uint32_t IF:8;
 	u16 MAGIC_TAG_PROTECT1;
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 	u8 WDMAID;
 	uint16_t RXID:2;
 	uint16_t WCID:8;
 	uint16_t BSSID:6;
+#endif
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 	u16 SOURCE;
 	u16 DEST;
@@ -336,21 +288,8 @@ struct cb_rx_desc_info4 {
 
 #define FOE_TAG_PROTECT(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->MAGIC_TAG_PROTECT)
-
-#define FOE_ENTRY_NUM_LSB(skb)  \
-	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num)
-
-#if defined(CONFIG_MACH_LEOPARD)
-#define FOE_ENTRY_NUM_MSB(skb)  \
-	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num_32)
-#define FOE_ENTRY_NUM(skb)  \
-	(((FOE_ENTRY_NUM_MSB(skb) & 0x1) << 14) | FOE_ENTRY_NUM_LSB(skb))
-#else
-#define FOE_ENTRY_NUM_MSB(skb)  \
-	(((struct head_rx_descinfo4 *)((skb)->head))->rsv)
 #define FOE_ENTRY_NUM(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num)
-#endif
 #define FOE_ALG(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->ALG)
 #define FOE_AI(skb)  \
@@ -359,19 +298,19 @@ struct cb_rx_desc_info4 {
 	(((struct head_rx_descinfo4 *)((skb)->head))->SPORT)
 #define FOE_MAGIC_TAG(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->IF)
-
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->RXID)
 #define FOE_WC_ID(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->BSSID)
-
+#endif
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 #define FOE_SOURCE(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->SOURCE)
 #define FOE_DEST(skb)	(((struct head_rx_descinfo4 *)((skb)->head))->DEST)
 #endif
 
-#define IS_SPACE_AVAILABLE_HEAD(skb)  \
+#define IS_SPACE_AVAILABLED_HEAD(skb)  \
 	((((skb_headroom(skb) >= FOE_INFO_LEN) ? 1 : 0)))
 #define IS_SPACE_AVAILABLE_HEAD(skb)  \
 	((((skb_headroom(skb) >= FOE_INFO_LEN) ? 1 : 0)))
@@ -379,20 +318,8 @@ struct cb_rx_desc_info4 {
 
 #define FOE_TAG_PROTECT_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->MAGIC_TAG_PROTECT)
-#define FOE_ENTRY_NUM_LSB_HEAD(skb)  \
-	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num)
-#if defined(CONFIG_MACH_LEOPARD)
-#define FOE_ENTRY_NUM_MSB_HEAD(skb)  \
-	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num_32)
-#define FOE_ENTRY_NUM_HEAD(skb)  \
-	(((FOE_ENTRY_NUM_MSB_HEAD(skb) & 0x1) << 14) | FOE_ENTRY_NUM_LSB_HEAD(skb))
-#else
-#define FOE_ENTRY_NUM_MSB_HEAD(skb)  \
-	(((struct head_rx_descinfo4 *)((skb)->head))->rsv)
 #define FOE_ENTRY_NUM_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->foe_entry_num)
-#endif
-
 #define FOE_ALG_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->ALG)
 #define FOE_AI_HEAD(skb)  \
@@ -402,6 +329,7 @@ struct cb_rx_desc_info4 {
 #define FOE_MAGIC_TAG_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->IF)
 
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID_HEAD(skb)  \
@@ -410,6 +338,7 @@ struct cb_rx_desc_info4 {
 	(((struct head_rx_descinfo4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->BSSID)
+#endif
 
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 #define FOE_SOURCE_HEAD(skb)  \
@@ -418,6 +347,7 @@ struct cb_rx_desc_info4 {
 	(((struct head_rx_descinfo4 *)((skb)->head))->DEST)
 #endif
 
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID_HEAD(skb)  \
@@ -426,6 +356,7 @@ struct cb_rx_desc_info4 {
 	(((struct head_rx_descinfo4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->BSSID)
+#endif
 
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 #define FOE_SOURCE_HEAD(skb)  \
@@ -433,7 +364,7 @@ struct cb_rx_desc_info4 {
 #define FOE_DEST_HEAD(skb)  \
 	(((struct head_rx_descinfo4 *)((skb)->head))->DEST)
 #endif
-#define IS_SPACE_AVAILABLE_TAIL(skb)  \
+#define IS_SPACE_AVAILABLED_TAIL(skb)  \
 	(((skb_tailroom(skb) >= FOE_INFO_LEN) ? 1 : 0))
 #define IS_SPACE_AVAILABLE_TAIL(skb)  \
 	(((skb_tailroom(skb) >= FOE_INFO_LEN) ? 1 : 0))
@@ -442,21 +373,8 @@ struct cb_rx_desc_info4 {
 
 #define FOE_TAG_PROTECT_TAIL(skb)  \
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->MAGIC_TAG_PROTECT)
-#define FOE_ENTRY_NUM_LSB_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->foe_entry_num)
-
-#if defined(CONFIG_MACH_LEOPARD)
-#define FOE_ENTRY_NUM_MSB_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->foe_entry_num_32)
-#define FOE_ENTRY_NUM_TAIL(skb)  \
-	(((FOE_ENTRY_NUM_MSB_TAIL(skb) & 0x1) << 14) | FOE_ENTRY_NUM_LSB_TAIL(skb))
-#else
-#define FOE_ENTRY_NUM_MSB_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->rsv)
 #define FOE_ENTRY_NUM_TAIL(skb)  \
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->foe_entry_num)
-#endif
-
 #define FOE_ALG_TAIL(skb)  \
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->ALG)
 #define FOE_AI_TAIL(skb)  \
@@ -473,14 +391,16 @@ struct cb_rx_desc_info4 {
 	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->DEST)
 #endif
 
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->WDMAID)
+	(((struct pdma_rx_desc_info4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->RXID)
+	(((struct pdma_rx_desc_info4 *)((skb)->head))->RXID)
 #define FOE_WC_ID_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->WCID)
+	(((struct pdma_rx_desc_info4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID_TAIL(skb)  \
-	(((struct pdma_rx_desc_info4 *)((long)((skb_end_pointer(skb)) - FOE_INFO_LEN)))->BSSID)
+	(((struct pdma_rx_desc_info4 *)((skb)->head))->BSSID)
+#endif
 
 /* change the position of skb_CB if necessary */
 #define CB_OFFSET		    40
@@ -506,6 +426,8 @@ struct cb_rx_desc_info4 {
 #define FOE_DEST_CB(skb)	(((struct cb_rx_desc_info4 *)((skb)->cb + CB_OFFSET))->DEST)
 #endif
 
+
+#if defined(CONFIG_ARCH_MT7622_WIFI_HW_NAT)
 #define FOE_WDMA_ID_CB(skb)  \
 	(((struct cb_rx_desc_info4 *)((skb)->head))->WDMAID)
 #define FOE_RX_ID_CB(skb)  \
@@ -514,6 +436,7 @@ struct cb_rx_desc_info4 {
 	(((struct cb_rx_desc_info4 *)((skb)->head))->WCID)
 #define FOE_BSS_ID_CB(skb)  \
 	(((struct cb_rx_desc_info4 *)((skb)->head))->BSSID)
+#endif
 
 #define IS_MAGIC_TAG_PROTECT_VALID_HEAD(skb)  \
 	(FOE_TAG_PROTECT_HEAD(skb) == TAG_PROTECT)
@@ -558,7 +481,7 @@ static inline void hwnat_set_l2tp_unhit(struct iphdr *iph, struct sk_buff *skb)
 #if defined(CONFIG_RA_HW_NAT_PPTP_L2TP)
 	/* only clear headeroom for TCP OR not L2TP packets */
 	if ((iph->protocol == 0x6) || (ntohs(udp_hdr(skb)->dest) != 1701)) {
-		if (IS_SPACE_AVAILABLE_HEAD(skb)) {
+		if (IS_SPACE_AVAILABLED_HEAD(skb)) {
 			FOE_MAGIC_TAG(skb) = 0;
 			FOE_AI(skb) = UN_HIT;
 		}
@@ -581,60 +504,53 @@ static inline void hwnat_clear_l2tp_fast_path(u32 l2tp_fast_path)
 #endif
 }
 
-/* #define CONFIG_HW_NAT_IPI */
-#if defined(CONFIG_HW_NAT_IPI)
-extern int debug_level;
-int get_rps_cpu(struct net_device *dev, struct sk_buff *skb,
-		struct rps_dev_flow **rflowp);
-uint32_t ppe_extif_rx_handler(struct sk_buff *skb);
-int hitbind_force_to_cpu_handler(struct sk_buff *skb, struct foe_entry *entry);
-extern unsigned int ipidbg[num_possible_cpus()][10];
-extern unsigned int ipidbg2[num_possible_cpus()][10];
-/* #define HNAT_IPI_RXQUEUE	1 */
+//#define CONFIG_HW_NAT_IPI
+#if defined (CONFIG_HW_NAT_IPI)
+//#define HNAT_IPI_RXQUEUE	1
 #define HNAT_IPI_DQ		1
 #define HNAT_IPI_HASH_NORMAL	0
 #define HNAT_IPI_HASH_VTAG		1
 #define HNAT_IPI_HASH_FROM_EXTIF	2
 #define HNAT_IPI_HASH_FROM_GMAC		4
 
-struct hnat_ipi_s {
-#if defined(HNAT_IPI_DQ)
-	struct sk_buff_head     skb_input_queue;
-	struct sk_buff_head     skb_process_queue;
-#elif defined(HNAT_IPI_RXQUEUE)
-	atomic_t rx_queue_num;
-	unsigned int rx_queue_ridx;
-	unsigned int rx_queue_widx;
-	struct sk_buff **rx_queue;
+typedef struct {
+#if defined (HNAT_IPI_DQ)
+	struct sk_buff_head     skbInputQueue;
+	struct sk_buff_head     skbProcessQueue;
+#elif defined (HNAT_IPI_RXQUEUE)
+	atomic_t RxQueueNum;
+	unsigned int RxQueueRIdx;
+	unsigned int RxQueueWIdx;
+	struct sk_buff** RxQueue;
 #else
-	/* unsigned int dummy0[0]; */
-	struct sk_buff_head     skb_ipi_queue;
-	/* unsigned int dummy1[8]; */
+	//unsigned int dummy0[0];
+	struct sk_buff_head     skbIpiQueue;
+	//unsigned int dummy1[8];
 #endif
 	unsigned long time_rec, recv_time;
 	unsigned int ipi_accum;
-	/*hwnat ipi use*/
-	spinlock_t      ipilock;
+	spinlock_t      ipilock;	
 	struct tasklet_struct smp_func_call_tsk;
-} ____cacheline_aligned_in_smp;
+} ____cacheline_aligned_in_smp hnat_ipi_s;
 
-struct hnat_ipi_stat {
-	unsigned long drop_pkt_num_from_extif;
-	unsigned long drop_pkt_num_from_ppehit;
+
+typedef struct {
+	unsigned long dropPktNum_from_extif;
+	unsigned long dropPktNum_from_ppehit;
 	unsigned int smp_call_cnt_from_extif;
 	unsigned int smp_call_cnt_from_ppehit;
 	atomic_t cpu_status;
-	/* atomic_t cpu_status_from_extif; */
-	/* atomic_t cpu_status_from_ppehit; */
-
-	/* atomic_t hook_status_from_extif; */
-	/* atomic_t hook_status_from_ppehit; */
-} ____cacheline_aligned_in_smp;
+	//atomic_t cpu_status_from_extif;
+	//atomic_t cpu_status_from_ppehit;
+	
+	//atomic_t hook_status_from_extif;
+	//atomic_t hook_status_from_ppehit;
+} ____cacheline_aligned_in_smp hnat_ipi_stat;
 
-#define cpu_status_from_extif	cpu_status
-#define cpu_status_from_ppehit	cpu_status
+#define cpu_status_from_extif 	cpu_status
+#define cpu_status_from_ppehit 	cpu_status
 
-struct hnat_ipi_cfg {
+typedef struct {
 	unsigned int enable_from_extif;
 	unsigned int enable_from_ppehit;
 	unsigned int queue_thresh_from_extif;
@@ -643,10 +559,9 @@ struct hnat_ipi_cfg {
 	unsigned int drop_pkt_from_ppehit;
 	unsigned int ipi_cnt_mod_from_extif;
 	unsigned int ipi_cnt_mod_from_ppehit;
-} ____cacheline_aligned_in_smp;
-
-int hnat_ipi_init(void);
-int hnat_ipi_de_init(void);
+} ____cacheline_aligned_in_smp hnat_ipi_cfg;
+int HnatIPIInit(void);
+int HnatIPIDeInit(void);
 #endif
 
 #endif
diff --git a/trunk/linux-4.4.x/net/netfilter/Kconfig b/trunk/linux-4.4.x/net/netfilter/Kconfig
index a1cccc8eb..7e5e0c93a 100644
--- a/trunk/linux-4.4.x/net/netfilter/Kconfig
+++ b/trunk/linux-4.4.x/net/netfilter/Kconfig
@@ -1,6 +1,10 @@
 menu "Core Netfilter Configuration"
 	depends on NET && INET && NETFILTER
 
+config NF_SHORTCUT_HOOK
+	bool "Netfilter Shortcut"
+	default n
+
 config NETFILTER_INGRESS
 	bool "Netfilter ingress support"
 	default y
@@ -114,14 +118,6 @@ config NF_CONNTRACK_EVENTS
 
 	  If unsure, say `N'.
 
-config NF_CONNTRACK_CHAIN_EVENTS
-	bool "Register multiple callbacks to ct events"
-	depends on NF_CONNTRACK_EVENTS
-	help
-	  Support multiple registrations.
-
-	  If unsure, say `N'.
-
 config NF_CONNTRACK_TIMEOUT
 	bool  'Connection tracking timeout'
 	depends on NETFILTER_ADVANCED
@@ -132,6 +128,14 @@ config NF_CONNTRACK_TIMEOUT
 
 	  If unsure, say `N'.
 
+config NF_CONNTRACK_CHAIN_EVENTS
+	bool "Register multiple callbacks to ct events"
+	depends on NF_CONNTRACK_EVENTS
+	help
+	  Support multiple registrations.
+
+	  If unsure, say `N'.
+
 config NF_CONNTRACK_TIMESTAMP
 	bool  'Connection tracking timestamping'
 	depends on NETFILTER_ADVANCED
@@ -144,10 +148,11 @@ config NF_CONNTRACK_TIMESTAMP
 	  If unsure, say `N'.
 
 config NF_CONNTRACK_LABELS
-	bool
+	bool "Connection tracking labels"
 	help
 	  This option enables support for assigning user-defined flag bits
-	  to connection tracking entries.  It selected by the connlabel match.
+	  to connection tracking entries.  It can be used with xtables connlabel
+	  match and the nftables ct expression.
 
 config NF_CT_PROTO_DCCP
 	tristate 'DCCP protocol connection tracking support'
@@ -183,6 +188,15 @@ config NF_CT_PROTO_UDPLITE
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config NF_CT_PROTO_ESP
+	tristate 'ESP protocol connection tracking support'
+	depends on NETFILTER_ADVANCED && BCM_KF_NETFILTER
+	help
+	  With this option enabled, the layer 3 ESP protocol 
+	  tracking will be able to do tracking on ESP connections
+	  
+	  To compile it as a module, choose M here.  If unsure, say N.
+
 config NF_CONNTRACK_AMANDA
 	tristate "Amanda backup protocol support"
 	depends on NETFILTER_ADVANCED
@@ -214,6 +228,7 @@ config NF_CONNTRACK_FTP
 
 config NF_CONNTRACK_H323
 	tristate "H.323 protocol support"
+	depends on IPV6 || IPV6=n
 	depends on NETFILTER_ADVANCED
 	help
 	  H.323 is a VoIP signalling protocol from ITU-T. As one of the most
@@ -302,6 +317,28 @@ config NF_CONNTRACK_PPTP
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config NF_CONNTRACK_QUAKE3
+	tristate "Quake3 protocol support"
+	depends on NETFILTER_ADVANCED
+	help
+	  Quake III Arena  connection tracking helper. This module allows for a
+	  stricter firewall rulebase if one only allows traffic to a master
+	  server. Connections to Quake III server IP addresses and ports returned
+	  by the master server will be tracked automatically.
+
+	  If you want to compile it as a module, say M here and read
+	  <file:Documentation/modules.txt>.  If unsure, say 'Y'.
+
+config NF_CONNTRACK_RTSP
+	tristate  "RTSP protocol support"
+	depends on NETFILTER_ADVANCED
+	help
+	  Support the RTSP protocol.  This allows UDP transports to be setup
+	  properly, including RTP and RDT.
+
+	  If you want to compile it as a module, say 'M' here and read
+	  Documentation/modules.txt.  If unsure, say 'Y'.
+
 config NF_CONNTRACK_SANE
 	tristate "SANE protocol support"
 	depends on NETFILTER_ADVANCED
@@ -327,6 +364,16 @@ config NF_CONNTRACK_SIP
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config NF_CONNTRACK_IPSEC
+	tristate "IPSEC protocol support"
+	depends on BCM_KF_NETFILTER
+	default m if NETFILTER_ADVANCED=n
+	help
+	  IPSec is used for for securing IP communications by authenticating and 
+	  encrypting each IP packet of a communication session
+	  
+	  To compile it as a module, choose M here.  If unsure, say N.
+
 config NF_CONNTRACK_TFTP
 	tristate "TFTP protocol support"
 	depends on NETFILTER_ADVANCED
@@ -338,6 +385,26 @@ config NF_CONNTRACK_TFTP
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+#BRCM begin
+config NF_DYNDSCP
+  tristate  "Dynamic DSCP Mangling support "
+  depends on NF_CONNTRACK && BCM_KF_NETFILTER
+  default n
+  help
+  	This option enables support for dynamic DSCP, i.e tos will be derived from 
+  	tos value of WAN packets of each connection.
+
+config NF_CONNTRACK_RTSP
+	tristate "RTSP protocol support"
+#	depends on NF_CONNTRACK && BCM_KF_NETFILTER
+	depends on NF_CONNTRACK
+	help
+	  RTSP (Real Time Streaming Protocol) support.
+
+	  To compile it as a module, choose M here.  If unsure, say N.
+
+#BRCM end
+
 config NF_CT_NETLINK
 	tristate 'Connection tracking netlink interface'
 	select NETFILTER_NETLINK
@@ -356,27 +423,27 @@ config NF_CT_NETLINK_TIMEOUT
 
 	  If unsure, say `N'.
 
-config NF_CT_NETLINK_HELPER
-	tristate 'Connection tracking helpers in user-space via Netlink'
-	select NETFILTER_NETLINK
-	depends on NF_CT_NETLINK
-	depends on NETFILTER_NETLINK_QUEUE
-	depends on NETFILTER_NETLINK_GLUE_CT
-	depends on NETFILTER_ADVANCED
-	help
-	  This option enables the user-space connection tracking helpers
-	  infrastructure.
-
-	  If unsure, say `N'.
-
-config NETFILTER_NETLINK_GLUE_CT
-	bool "NFQUEUE and NFLOG integration with Connection Tracking"
-	default n
-	depends on (NETFILTER_NETLINK_QUEUE || NETFILTER_NETLINK_LOG) && NF_CT_NETLINK
-	help
-	  If this option is enabled, NFQUEUE and NFLOG can include
-	  Connection Tracking information together with the packet is
-	  the enqueued via NFNETLINK.
+#config NF_CT_NETLINK_HELPER
+#	tristate 'Connection tracking helpers in user-space via Netlink'
+#	select NETFILTER_NETLINK
+#	depends on NF_CT_NETLINK
+#	depends on NETFILTER_NETLINK_QUEUE
+#	depends on NETFILTER_NETLINK_GLUE_CT
+#	depends on NETFILTER_ADVANCED
+#	help
+#	  This option enables the user-space connection tracking helpers
+#	  infrastructure.
+#
+#	  If unsure, say `N'.
+
+#config NETFILTER_NETLINK_GLUE_CT
+#	bool "NFQUEUE and NFLOG integration with Connection Tracking"
+#	default n
+#	depends on (NETFILTER_NETLINK_QUEUE || NETFILTER_NETLINK_LOG) && NF_CT_NETLINK
+#	help
+#	  If this option is enabled, NFQUEUE and NFLOG can include
+#	  Connection Tracking information together with the packet is
+#	  the enqueued via NFNETLINK.
 
 config NF_NAT
 	tristate
@@ -412,6 +479,11 @@ config NF_NAT_FTP
 	depends on NF_CONNTRACK && NF_NAT
 	default NF_NAT && NF_CONNTRACK_FTP
 
+config NF_NAT_RTSP
+	tristate
+	depends on BCM_KF_NETFILTER && IP_NF_IPTABLES && NF_CONNTRACK && NF_NAT
+	default NF_NAT && NF_CONNTRACK_RTSP
+	
 config NF_NAT_IRC
 	tristate
 	depends on NF_CONNTRACK && NF_NAT
@@ -442,6 +514,8 @@ endif # NF_CONNTRACK
 config NF_TABLES
 	select NETFILTER_NETLINK
 	tristate "Netfilter nf_tables support"
+#	depends on IP_NF_MANGLE
+#	depends on NETFILTER_ADVANCED
 	help
 	  nftables is the new packet classification framework that intends to
 	  replace the existing {ip,ip6,arp,eb}_tables infrastructure. It
@@ -820,6 +894,18 @@ config NETFILTER_XT_TARGET_LOG
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config NETFILTER_XT_TARGET_IMQ
+	tristate '"IMQ" target support'
+	depends on NETFILTER_XTABLES
+	depends on IP_NF_MANGLE || IP6_NF_MANGLE
+	select IMQ
+	default m if NETFILTER_ADVANCED=n
+	help
+	  This option adds a `IMQ' target which is used to specify if and
+	  to which imq device packets should get enqueued/dequeued.
+
+	  To compile it as a module, choose M here.  If unsure, say N.
+
 config NETFILTER_XT_TARGET_MARK
 	tristate '"MARK" target support'
 	depends on NETFILTER_ADVANCED
@@ -848,12 +934,12 @@ config NETFILTER_XT_TARGET_NETMAP
 	To compile it as a module, choose M here. If unsure, say N.
 
 config NETFILTER_XT_TARGET_FULLCONENAT
-  tristate '"FULLCONENAT" target support'
-  depends on NF_NAT
-  ---help---
-  Full Cone NAT
+	tristate '"FULLCONENAT" target support'
+	depends on NF_NAT
+	---help---
+	Full Cone NAT
 
-  To compile it as a module, choose M here. If unsure, say N.
+	To compile it as a module, choose M here. If unsure, say N.
 
 config NETFILTER_XT_TARGET_NFLOG
 	tristate '"NFLOG" target support'
@@ -970,6 +1056,7 @@ config NETFILTER_XT_TARGET_SECMARK
 
 config NETFILTER_XT_TARGET_TCPMSS
 	tristate '"TCPMSS" target support'
+	depends on IPV6 || IPV6=n
 	default m if NETFILTER_ADVANCED=n
 	---help---
 	  This option adds a `TCPMSS' target, which allows you to alter the
@@ -1002,6 +1089,16 @@ config NETFILTER_XT_TARGET_TCPOPTSTRIP
 	  This option adds a "TCPOPTSTRIP" target, which allows you to strip
 	  TCP options from TCP packets.
 
+config NETFILTER_XT_TARGET_SKIPLOG
+	tristate '"SKIPLOG" target support'
+	depends on NETFILTER_XTABLES && (IPV6 || IPV6=n) && BCM_KF_NETFILTER
+	---help---
+	  configuration like:
+
+	  iptables -A FORWARD -p tcp -j SKIPLOG
+
+	  To compile it as a module, choose M here.  If unsure, say N.
+
 # alphabetically ordered list of matches
 
 comment "Xtables matches"
@@ -1308,18 +1405,18 @@ config NETFILTER_XT_MATCH_NFACCT
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
-config NETFILTER_XT_MATCH_OSF
-	tristate '"osf" Passive OS fingerprint match'
-	depends on NETFILTER_ADVANCED && NETFILTER_NETLINK
-	help
-	  This option selects the Passive OS Fingerprinting match module
-	  that allows to passively match the remote operating system by
-	  analyzing incoming TCP SYN packets.
-
-	  Rules and loading software can be downloaded from
-	  http://www.ioremap.net/projects/osf
-
-	  To compile it as a module, choose M here.  If unsure, say N.
+#config NETFILTER_XT_MATCH_OSF
+#	tristate '"osf" Passive OS fingerprint match'
+#	depends on NETFILTER_ADVANCED && NETFILTER_NETLINK
+#	help
+#	  This option selects the Passive OS Fingerprinting match module
+#	  that allows to passively match the remote operating system by
+#	  analyzing incoming TCP SYN packets.
+#
+#	  Rules and loading software can be downloaded from
+#	  http://www.ioremap.net/projects/osf
+#
+#	  To compile it as a module, choose M here.  If unsure, say N.
 
 config NETFILTER_XT_MATCH_OWNER
 	tristate '"owner" match support'
@@ -1533,6 +1630,19 @@ config NETFILTER_XT_MATCH_TIME
 	  If you want to compile it as a module, say M here.
 	  If unsure, say N.
 
+config NETFILTER_XT_MATCH_LAYER7
+	tristate '"layer7" match support'
+	depends on NETFILTER_XTABLES
+	depends on NETFILTER_ADVANCED
+	depends on NF_CONNTRACK
+
+config NETFILTER_XT_MATCH_LAYER7_DEBUG
+	bool 'Layer 7 debugging output'
+	depends on NETFILTER_XT_MATCH_LAYER7
+	depends on SUPPORT_OPENWRT
+	help
+	  Say Y to get lots of debugging output.
+         
 config NETFILTER_XT_MATCH_U32
 	tristate '"u32" match support'
 	depends on NETFILTER_ADVANCED
@@ -1547,12 +1657,47 @@ config NETFILTER_XT_MATCH_U32
 	  Details and examples are in the kernel module source.
 
 config NETFILTER_XT_MATCH_WEBSTR
-        tristate "WEBSTR match support"
-        depends on IP_NF_FILTER
-        help
-          This option allows to match string in http web header
-          To compile it as a module, choose M here.  If unsure, say N.
+	tristate  '"webstr" match support'
+	depends on NETFILTER_XTABLES
+	help
+	  This option adds a `webstr' match, which allows you to look for
+	  pattern matchings in http stream.
+
+	  To compile it as a module, choose M here.  If unsure, say N.
 
+config NETFILTER_XT_MATCH_CONDITION
+	tristate  '"condition" match support'
+	depends on NETFILTER_XTABLES
+	help
+	  This option allows you to match firewall rules against condition
+	  variables stored in the /proc/net/nf_condition directory.
+
+	  N.B.: older versions used /proc/net/ipt_condition. You can
+	  reenable it with "compat_dir_name".
+
+	  If you want to compile it as a module, say M here and read
+	  Documentation/modules.txt.  If unsure, say `N'.
+
+config NETFILTER_XT_MATCH_GEOIP
+	tristate  '"geoip" match support'
+	depends on NETFILTER_XTABLES
+	help
+	  This option allows you to match a packet by its source or
+	  destination country.  Basically, you need a country's
+	  database containing all subnets and associated countries.
+
+	  For the complete procedure and understanding, read :
+	  http://people.netfilter.org/acidfu/geoip/howto/geoip-HOWTO.html
+
+	  If you want to compile it as a module, say M here and read
+	  <file:Documentation/modules.txt>.  The module will be
+	  called `ipt_geoip'.  If unsure, say `N'.
+
+config NETFILTER_XT_MATCH_ETHPORT
+	tristate '"Ethernet port for incoming packets" match support'
+	depends on NETFILTER_XTABLES && (IP6_NF_IPTABLES || IP6_NF_IPTABLES=n)
+	help
+	  This option adds a `ethport' match.
 
 endif # NETFILTER_XTABLES
 
@@ -1561,3 +1706,5 @@ endmenu
 source "net/netfilter/ipset/Kconfig"
 
 source "net/netfilter/ipvs/Kconfig"
+
+#source "net/netfilter/fltr/Kconfig"
diff --git a/trunk/linux-4.4.x/net/netfilter/Makefile b/trunk/linux-4.4.x/net/netfilter/Makefile
index 2af169310..c4a7a53c2 100644
--- a/trunk/linux-4.4.x/net/netfilter/Makefile
+++ b/trunk/linux-4.4.x/net/netfilter/Makefile
@@ -8,6 +8,12 @@ nf_conntrack-$(CONFIG_NF_CONNTRACK_LABELS) += nf_conntrack_labels.o
 
 obj-$(CONFIG_NETFILTER) = netfilter.o
 
+ifeq ($(CONFIG_NF_SHORTCUT_HOOK),y)
+obj-y += nf_shortcut_hook.o
+obj-m += nf_sc.o
+nf_sc-objs := nf_shortcut.o
+endif
+
 obj-$(CONFIG_NETFILTER_NETLINK) += nfnetlink.o
 obj-$(CONFIG_NETFILTER_NETLINK_ACCT) += nfnetlink_acct.o
 obj-$(CONFIG_NETFILTER_NETLINK_QUEUE) += nfnetlink_queue.o
@@ -21,6 +27,9 @@ obj-$(CONFIG_NF_CT_PROTO_DCCP) += nf_conntrack_proto_dccp.o
 obj-$(CONFIG_NF_CT_PROTO_GRE) += nf_conntrack_proto_gre.o
 obj-$(CONFIG_NF_CT_PROTO_SCTP) += nf_conntrack_proto_sctp.o
 obj-$(CONFIG_NF_CT_PROTO_UDPLITE) += nf_conntrack_proto_udplite.o
+ifdef BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
+obj-$(CONFIG_NF_CT_PROTO_ESP) += nf_conntrack_proto_esp.o
+endif #BCM_KF
 
 # netlink interface for nf_conntrack
 obj-$(CONFIG_NF_CT_NETLINK) += nf_conntrack_netlink.o
@@ -38,9 +47,17 @@ obj-$(CONFIG_NF_CONNTRACK_BROADCAST) += nf_conntrack_broadcast.o
 obj-$(CONFIG_NF_CONNTRACK_NETBIOS_NS) += nf_conntrack_netbios_ns.o
 obj-$(CONFIG_NF_CONNTRACK_SNMP) += nf_conntrack_snmp.o
 obj-$(CONFIG_NF_CONNTRACK_PPTP) += nf_conntrack_pptp.o
+obj-$(CONFIG_NF_CONNTRACK_QUAKE3) += nf_conntrack_quake3.o
+obj-$(CONFIG_NF_CONNTRACK_RTSP) += nf_conntrack_rtsp.o
+
 obj-$(CONFIG_NF_CONNTRACK_SANE) += nf_conntrack_sane.o
 obj-$(CONFIG_NF_CONNTRACK_SIP) += nf_conntrack_sip.o
 obj-$(CONFIG_NF_CONNTRACK_TFTP) += nf_conntrack_tftp.o
+ifdef BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
+obj-$(CONFIG_NF_CONNTRACK_RTSP) += nf_conntrack_rtsp.o
+obj-$(CONFIG_NF_DYNDSCP) += nf_dyndscp.o
+obj-$(CONFIG_NF_CONNTRACK_IPSEC) += nf_conntrack_ipsec.o
+endif #BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
 
 nf_nat-y	:= nf_nat_core.o nf_nat_proto_unknown.o nf_nat_proto_common.o \
 		   nf_nat_proto_udp.o nf_nat_proto_tcp.o nf_nat_helper.o
@@ -62,6 +79,9 @@ obj-$(CONFIG_NF_NAT_FTP) += nf_nat_ftp.o
 obj-$(CONFIG_NF_NAT_IRC) += nf_nat_irc.o
 obj-$(CONFIG_NF_NAT_SIP) += nf_nat_sip.o
 obj-$(CONFIG_NF_NAT_TFTP) += nf_nat_tftp.o
+ifdef BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
+obj-$(CONFIG_NF_NAT_RTSP) += nf_nat_rtsp.o
+endif #BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
 
 # SYNPROXY
 obj-$(CONFIG_NETFILTER_SYNPROXY) += nf_synproxy_core.o
@@ -117,6 +137,7 @@ obj-$(CONFIG_NETFILTER_XT_TARGET_DSCP) += xt_DSCP.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_FLOWOFFLOAD) += xt_FLOWOFFLOAD.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_HL) += xt_HL.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_HMARK) += xt_HMARK.o
+obj-$(CONFIG_NETFILTER_XT_TARGET_IMQ) += xt_IMQ.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_LED) += xt_LED.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_LOG) += xt_LOG.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_NETMAP) += xt_NETMAP.o
@@ -132,6 +153,9 @@ obj-$(CONFIG_NETFILTER_XT_TARGET_TEE) += xt_TEE.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_TRACE) += xt_TRACE.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_IDLETIMER) += xt_IDLETIMER.o
 obj-$(CONFIG_NETFILTER_XT_TARGET_FULLCONENAT) += xt_FULLCONENAT.o
+ifdef BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
+obj-$(CONFIG_NETFILTER_XT_TARGET_SKIPLOG) += xt_SKIPLOG.o
+endif #BCM_KF # defined(CONFIG_BCM_KF_NETFILTER)
 
 # matches
 obj-$(CONFIG_NETFILTER_XT_MATCH_ADDRTYPE) += xt_addrtype.o
@@ -179,11 +203,18 @@ obj-$(CONFIG_NETFILTER_XT_MATCH_STATISTIC) += xt_statistic.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_STRING) += xt_string.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_TCPMSS) += xt_tcpmss.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_TIME) += xt_time.o
+obj-$(CONFIG_NETFILTER_XT_MATCH_LAYER7) += xt_layer7.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_U32) += xt_u32.o
+obj-$(CONFIG_NETFILTER_XT_MATCH_CONDITION) += xt_condition.o
+obj-$(CONFIG_NETFILTER_XT_MATCH_GEOIP) += xt_geoip.o
 obj-$(CONFIG_NETFILTER_XT_MATCH_WEBSTR) += xt_webstr.o
+obj-$(CONFIG_NETFILTER_XT_MATCH_ETHPORT) += xt_ethport.o
 
 # ipset
 obj-$(CONFIG_IP_SET) += ipset/
 
 # IPVS
 obj-$(CONFIG_IP_VS) += ipvs/
+
+# ASUS Net Filter
+obj-$(CONFIG_NETFILTER_ASUS_FILTER) += fltr/
diff --git a/trunk/linux-4.4.x/net/netfilter/core.c b/trunk/linux-4.4.x/net/netfilter/core.c
index ec99e9c2b..d4b343eb5 100644
--- a/trunk/linux-4.4.x/net/netfilter/core.c
+++ b/trunk/linux-4.4.x/net/netfilter/core.c
@@ -311,10 +311,18 @@ next_hook:
 		ret = NF_DROP_GETERR(verdict);
 		if (ret == 0)
 			ret = -EPERM;
-	} else if ((verdict & NF_VERDICT_MASK) == NF_QUEUE) {
+	} else if ((verdict & NF_VERDICT_MASK) == NF_QUEUE ||
+		   (verdict & NF_VERDICT_MASK) == NF_IMQ_QUEUE) {
 		int err = nf_queue(skb, elem, state,
-				   verdict >> NF_VERDICT_QBITS);
+				   verdict);
 		if (err < 0) {
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+			/* IMQ Bypass */
+			if (err == -ECANCELED && skb->imq_flags == 0) {
+				goto next_hook;
+			}
+#endif
+
 			if (err == -ESRCH &&
 			   (verdict & NF_VERDICT_FLAG_QUEUE_BYPASS))
 				goto next_hook;
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_core.c b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_core.c
index 101e58eb9..008005bbc 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_core.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_core.c
@@ -1711,6 +1711,9 @@ int nf_conntrack_init_start(void)
 		 * we use the old value of 8 to avoid reducing the max.
 		 * entries. */
 		max_factor = 4;
+#if defined(CONFIG_NETFILTER_XT_TARGET_FULLCONENAT) || defined(CONFIG_BCM_KF_NETFILTER)
+		nf_conntrack_htable_size = 16384;
+#endif
 	}
 	nf_conntrack_max = max_factor * nf_conntrack_htable_size;
 
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_expect.c b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_expect.c
index 5479d11e4..a91f8bd51 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_expect.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_expect.c
@@ -647,7 +647,7 @@ int nf_conntrack_expect_init(void)
 		if (!nf_ct_expect_hsize)
 			nf_ct_expect_hsize = 1;
 	}
-	nf_ct_expect_max = nf_ct_expect_hsize * 1024;
+	nf_ct_expect_max = nf_ct_expect_hsize * 4;
 	nf_ct_expect_cachep = kmem_cache_create("nf_conntrack_expect",
 				sizeof(struct nf_conntrack_expect),
 				0, 0, NULL);
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_netlink.c b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_netlink.c
index 754658b3b..102597ea0 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_netlink.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_netlink.c
@@ -639,7 +639,7 @@ ctnetlink_nlmsg_size(const struct nf_conn *ct)
 #ifdef CONFIG_NF_CONNTRACK_EVENTS
 #ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
 static int ctnetlink_conntrack_event(struct notifier_block *this,
-                           unsigned long events, void *ptr)
+				     unsigned long events, void *ptr)
 #else
 static int
 ctnetlink_conntrack_event(unsigned int events, struct nf_ct_event *item)
@@ -651,7 +651,7 @@ ctnetlink_conntrack_event(unsigned int events, struct nf_ct_event *item)
 	struct nfgenmsg *nfmsg;
 	struct nlattr *nest_parms;
 #ifdef CONFIG_NF_CONNTRACK_CHAIN_EVENTS
-	struct nf_ct_event *item = (struct nf_ct_event *)ptr;
+	struct nf_ct_event *item = ptr;
 #endif
 	struct nf_conn *ct = item->ct;
 	struct sk_buff *skb;
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_proto_tcp.c b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_proto_tcp.c
index ad11afc68..7714f5835 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_proto_tcp.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_proto_tcp.c
@@ -87,7 +87,7 @@ static const char *const tcp_conntrack_names[] = {
 static unsigned int tcp_timeouts[TCP_CONNTRACK_TIMEOUT_MAX] __read_mostly = {
 	[TCP_CONNTRACK_SYN_SENT]	= 2 MINS,
 	[TCP_CONNTRACK_SYN_RECV]	= 60 SECS,
-	[TCP_CONNTRACK_ESTABLISHED]	= 5 DAYS,
+	[TCP_CONNTRACK_ESTABLISHED]	= 20 MINS,
 	[TCP_CONNTRACK_FIN_WAIT]	= 2 MINS,
 	[TCP_CONNTRACK_CLOSE_WAIT]	= 60 SECS,
 	[TCP_CONNTRACK_LAST_ACK]	= 30 SECS,
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_quake3.c b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_quake3.c
new file mode 100644
index 000000000..265c6d3b2
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_quake3.c
@@ -0,0 +1,200 @@
+/* Quake3 extension for IP connection tracking
+ * (C) 2002 by Filip Sneppe <filip.sneppe@cronos.be>
+ * (C) 2005 by Harald Welte <laforge@netfilter.org>
+ * based on nf_conntrack_ftp.c and nf_conntrack_tftp.c
+ *
+ * nf_conntrack_quake3.c v0.04 2002-08-31
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ *
+ *      Module load syntax:
+ *      insmod nf_conntrack_quake3.o ports=port1,port2,...port<MAX_PORTS>
+ *
+ *      please give the ports of all Quake3 master servers You wish to
+ *      connect to. If you don't specify ports, the default will be UDP
+ *      port 27950.
+ *
+ *      Thanks to the Ethereal folks for their analysis of the Quake3 protocol.
+ */
+
+#include <linux/module.h>
+#include <linux/ip.h>
+#include <linux/udp.h>
+
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_tuple.h>
+#include <net/netfilter/nf_conntrack_expect.h>
+#include <net/netfilter/nf_conntrack_helper.h>
+#include <linux/netfilter/nf_conntrack_quake3.h>
+
+MODULE_AUTHOR("Filip Sneppe <filip.sneppe@cronos.be>");
+MODULE_DESCRIPTION("Netfilter connection tracking module for Quake III Arena");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("ip_conntrack_quake3");
+
+unsigned int (*nf_nat_quake3_hook)(struct sk_buff *skb,
+				   enum ip_conntrack_info ctinfo,
+				   struct nf_conntrack_expect *exp)
+				   __read_mostly;
+EXPORT_SYMBOL_GPL(nf_nat_quake3_hook);
+
+
+#define MAX_PORTS 8
+static int ports[MAX_PORTS];
+static int ports_c = 0;
+module_param_array(ports, int, &ports_c, 0400);
+MODULE_PARM_DESC(ports, "port numbers of Quake III master servers");
+
+static char quake3_buffer[65536];
+static DEFINE_SPINLOCK(quake3_buffer_lock);
+
+/* Quake3 master server reply will add > 100 expectations per reply packet; when
+   doing lots of printk's, klogd may not be able to read /proc/kmsg fast enough */
+
+struct quake3_search quake3s_conntrack = { "****", "getserversResponse", sizeof("getserversResponse") - 1 };
+
+static int quake3_help(struct sk_buff *skb,
+	unsigned int protoff,
+	struct nf_conn *ct,
+	enum ip_conntrack_info ctinfo)
+{
+	struct udphdr _udph, *uh;
+	struct nf_conntrack_expect *exp;
+	void *data, *qb_ptr;
+	int dir = CTINFO2DIR(ctinfo);
+	int i, dataoff;
+	int ret = NF_ACCEPT;
+	typeof(nf_nat_quake3_hook) nf_nat_quake3;
+
+	/* Until there's been traffic both ways, don't look in packets. note:
+	 * it's UDP ! */
+	if (ctinfo != IP_CT_ESTABLISHED
+	    && ctinfo != IP_CT_IS_REPLY) {
+	        pr_debug("nf_conntrack_quake3: not ok ! Conntrackinfo = %u\n",
+			ctinfo);
+	        return NF_ACCEPT;
+	} else {
+		pr_debug("nf_conntrack_quake3: it's ok ! Conntrackinfo = %u\n",
+			ctinfo);
+	}
+
+	/* Valid UDP header? */
+	uh = skb_header_pointer(skb, protoff, sizeof(_udph), &_udph);
+	if (!uh)
+		return NF_ACCEPT;
+
+	/* Any data? */
+	dataoff = protoff + sizeof(struct udphdr);
+	if (dataoff >= skb->len)
+		return NF_ACCEPT;
+
+	spin_lock_bh(&quake3_buffer_lock);
+	qb_ptr = skb_header_pointer(skb, dataoff,
+				    skb->len - dataoff, quake3_buffer);
+	BUG_ON(qb_ptr == NULL);
+	data = qb_ptr;
+
+	if (strnicmp(data + 4, quake3s_conntrack.pattern,
+		     quake3s_conntrack.plen) == 0) {
+		for(i=23;    /* 4 bytes filler, 18 bytes "getserversResponse",
+				1 byte "\" */
+		    i+6 < ntohs(uh->len);
+		    i+=7) {
+			u_int32_t *ip = data+i;
+			u_int16_t *port = data+i+4;
+#if 0
+			pr_debug("nf_conntrack_quake3: adding server at offset "
+			       "%u/%u %u.%u.%u.%u:%u\n", i, ntohs(uh->len),
+			       NIPQUAD(*ip), ntohs(*port));
+#endif
+
+			exp = nf_ct_expect_alloc(ct);
+			if (!exp) {
+				ret = NF_DROP;
+				goto out;
+			}
+
+			memset(exp, 0, sizeof(*exp));
+
+			exp->tuple.src.u3.ip = ct->tuplehash[!dir].tuple.src.u3.ip;
+			exp->tuple.dst.u3.ip = *ip;
+			exp->tuple.dst.u.udp.port = *port;
+			exp->tuple.dst.protonum = IPPROTO_UDP;
+
+			exp->mask.src.u3.ip = 0xffffffff;
+
+			nf_nat_quake3 = rcu_dereference(nf_nat_quake3_hook);
+			if (nf_nat_quake3 && ct->status & IPS_NAT_MASK)
+				ret = nf_nat_quake3(skb, ctinfo, exp);
+			else if (nf_ct_expect_related(exp) != 0)
+				ret = NF_DROP;
+			nf_ct_expect_put(exp);
+			goto out;
+		}
+	}
+
+out:
+	spin_unlock_bh(&quake3_buffer_lock);
+
+	return ret;
+}
+
+static struct nf_conntrack_helper quake3[MAX_PORTS] __read_mostly;
+static char quake3_names[MAX_PORTS][sizeof("quake3-65535")] __read_mostly;
+
+static const struct nf_conntrack_expect_policy quake_exp_policy = {
+	.timeout	= 120,
+};
+
+static void fini(void)
+{
+	int i;
+
+	for(i = 0; i < ports_c; i++)
+			nf_conntrack_helper_unregister(&quake3[i]);
+}
+
+static int __init init(void)
+{
+	int i, ret;
+	char *tmpname;
+
+	if (ports_c == 0)
+		ports[ports_c++] = QUAKE3_MASTER_PORT;
+
+	for(i = 0; i < ports_c; i++) {
+		/* Create helper structure */
+		memset(&quake3[i], 0, sizeof(struct nf_conntrack_helper));
+		quake3[i].tuple.src.l3num = AF_INET;
+
+		quake3[i].tuple.dst.protonum = IPPROTO_UDP;
+		quake3[i].tuple.src.u.udp.port = htons(ports[i]);
+		quake3[i].help = quake3_help;
+		quake3[i].me = THIS_MODULE;
+		quake3[i].expect_policy = &quake_exp_policy;
+
+		tmpname = &quake3_names[i][0];
+		if (ports[i] == QUAKE3_MASTER_PORT)
+			sprintf(tmpname, "quake3");
+		else
+			sprintf(tmpname, "quake3-%d", i);
+		quake3[i].name = tmpname;
+
+		ret = nf_conntrack_helper_register(&quake3[i]);
+		if(ret) {
+			printk(KERN_ERR "nf_ct_quake: failed to register"
+			       " helper for pf: %u port: %u\n",
+				quake3[i].tuple.src.l3num, ports[i]);
+			fini();
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_rtsp.c b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_rtsp.c
new file mode 100644
index 000000000..269dff7ff
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_rtsp.c
@@ -0,0 +1,576 @@
+/*
+ * RTSP extension for IP connection tracking
+ * (C) 2003 by Tom Marshall <tmarshall at real.com>
+ *
+ * 2005-02-13: Harald Welte <laforge at netfilter.org>
+ * 	- port to 2.6
+ * 	- update to recent post-2.6.11 api changes
+ * 2006-09-14: Steven Van Acker <deepstar at singularity.be>
+ *	- removed calls to NAT code from conntrack helper: NAT no longer needed to use rtsp-conntrack
+ * 2007-04-18: Michael Guntsche <mike at it-loops.com>
+ * 			- Port to new NF API
+ * 2013-03-04: Il'inykh Sergey <sergeyi at inango-sw.com>. Inango Systems Ltd
+ *	- fixed rtcp nat mapping and other port mapping fixes
+ *	- simple TEARDOWN request handling
+ *	- codestyle fixes and other less significant bug fixes 
+ *
+ * based on ip_conntrack_irc.c
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ *
+ * Module load syntax:
+ *   insmod nf_conntrack_rtsp.o ports=port1,port2,...port<MAX_PORTS>
+ *                              max_outstanding=n setup_timeout=secs
+ *
+ * If no ports are specified, the default will be port 554.
+ *
+ * With max_outstanding you can define the maximum number of not yet
+ * answered SETUP requests per RTSP session (default 8).
+ * With setup_timeout you can specify how long the system waits for
+ * an expected data channel (default 300 seconds).
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/netfilter.h>
+#include <linux/ip.h>
+#include <linux/inet.h>
+#include <net/tcp.h>
+
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_expect.h>
+#include <net/netfilter/nf_conntrack_helper.h>
+#include <linux/netfilter/nf_conntrack_rtsp.h>
+
+#define NF_NEED_STRNCASECMP
+#define NF_NEED_STRTOU16
+#define NF_NEED_STRTOU32
+#define NF_NEED_NEXTLINE
+#include <linux/netfilter_helpers.h>
+#define NF_NEED_MIME_NEXTLINE
+#include <linux/netfilter_mime.h>
+
+#include <linux/ctype.h>
+
+#define MAX_PORTS 8
+static int ports[MAX_PORTS];
+static int num_ports = 0;
+static int max_outstanding = 8;
+static unsigned int setup_timeout = 300;
+
+MODULE_AUTHOR("Tom Marshall <tmarshall at real.com>");
+MODULE_DESCRIPTION("RTSP connection tracking module");
+MODULE_LICENSE("GPL");
+module_param_array(ports, int, &num_ports, 0400);
+MODULE_PARM_DESC(ports, "port numbers of RTSP servers");
+module_param(max_outstanding, int, 0400);
+MODULE_PARM_DESC(max_outstanding, "max number of outstanding SETUP requests per RTSP session");
+module_param(setup_timeout, int, 0400);
+MODULE_PARM_DESC(setup_timeout, "timeout on for unestablished data channels");
+
+static char *rtsp_buffer;
+static DEFINE_SPINLOCK(rtsp_buffer_lock);
+
+static struct nf_conntrack_expect_policy rtsp_exp_policy;
+
+unsigned int (*nf_nat_rtsp_hook)(struct sk_buff *skb,
+				 enum ip_conntrack_info ctinfo,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+				 unsigned int protoff,
+#endif
+				 unsigned int matchoff, unsigned int matchlen,
+				 struct ip_ct_rtsp_expect* prtspexp,
+				 struct nf_conntrack_expect *rtp_exp,
+				 struct nf_conntrack_expect *rtcp_exp);
+
+EXPORT_SYMBOL_GPL(nf_nat_rtsp_hook);
+
+/*
+ * Max mappings we will allow for one RTSP connection (for RTP, the number
+ * of allocated ports is twice this value).  Note that SMIL burns a lot of
+ * ports so keep this reasonably high.  If this is too low, you will see a
+ * lot of "no free client map entries" messages.
+ */
+#define MAX_PORT_MAPS 16
+
+/*** default port list was here in the masq code: 554, 3030, 4040 ***/
+
+#define SKIP_WSPACE(ptr,len,off) while(off < len && isspace(*(ptr+off))) { off++; }
+
+/*
+ * Parse an RTSP packet.
+ *
+ * Returns zero if parsing failed.
+ *
+ * Parameters:
+ *  IN      ptcp        tcp data pointer
+ *  IN      tcplen      tcp data len
+ *  IN/OUT  ptcpoff     points to current tcp offset
+ *  OUT     phdrsoff    set to offset of rtsp headers
+ *  OUT     phdrslen    set to length of rtsp headers
+ *  OUT     pcseqoff    set to offset of CSeq header
+ *  OUT     pcseqlen    set to length of CSeq header
+ */
+static int
+rtsp_parse_message(char* ptcp, uint tcplen, uint* ptcpoff,
+		   uint* phdrsoff, uint* phdrslen,
+		   uint* pcseqoff, uint* pcseqlen,
+		   uint* transoff, uint* translen)
+{
+	uint	entitylen = 0;
+	uint	lineoff;
+	uint	linelen;
+	
+	if (!nf_nextline(ptcp, tcplen, ptcpoff, &lineoff, &linelen))
+		return 0;
+	
+	*phdrsoff = *ptcpoff;
+	while (nf_mime_nextline(ptcp, tcplen, ptcpoff, &lineoff, &linelen)) {
+		if (linelen == 0) {
+			if (entitylen > 0)
+				*ptcpoff += min(entitylen, tcplen - *ptcpoff);
+			break;
+		}
+		if (lineoff+linelen > tcplen) {
+			pr_info("!! overrun !!\n");
+			break;
+		}
+
+		if (nf_strncasecmp(ptcp+lineoff, "CSeq:", 5) == 0) {
+			*pcseqoff = lineoff;
+			*pcseqlen = linelen;
+		} 
+
+		if (nf_strncasecmp(ptcp+lineoff, "Transport:", 10) == 0) {
+			*transoff = lineoff;
+			*translen = linelen;
+		}
+		
+		if (nf_strncasecmp(ptcp+lineoff, "Content-Length:", 15) == 0) {
+			uint off = lineoff+15;
+			SKIP_WSPACE(ptcp+lineoff, linelen, off);
+			nf_strtou32(ptcp+off, &entitylen);
+		}
+	}
+	*phdrslen = (*ptcpoff) - (*phdrsoff);
+	
+	return 1;
+}
+
+/*
+ * Find lo/hi client ports (if any) in transport header
+ * In:
+ *   ptcp, tcplen = packet
+ *   tranoff, tranlen = buffer to search
+ *
+ * Out:
+ *   pport_lo, pport_hi = lo/hi ports (host endian)
+ *
+ * Returns nonzero if any client ports found
+ *
+ * Note: it is valid (and expected) for the client to request multiple
+ * transports, so we need to parse the entire line.
+ */
+static int
+rtsp_parse_transport(char* ptran, uint tranlen,
+		     struct ip_ct_rtsp_expect* prtspexp)
+{
+	int  rc = 0;
+	uint off = 0;
+	
+	if (tranlen < 10 || !iseol(ptran[tranlen-1]) ||
+	    nf_strncasecmp(ptran, "Transport:", 10) != 0) {
+		pr_info("sanity check failed\n");
+		return 0;
+	}
+	
+	pr_debug("tran='%.*s'\n", (int)tranlen, ptran);
+	off += 10;
+	SKIP_WSPACE(ptran, tranlen, off);
+	
+	/* Transport: tran;field;field=val,tran;field;field=val,... */
+	while (off < tranlen) {
+		const char* pparamend;
+		uint        nextparamoff;
+		
+		pparamend = memchr(ptran+off, ',', tranlen-off);
+		pparamend = (pparamend == NULL) ? ptran+tranlen : pparamend+1;
+		nextparamoff = pparamend-ptran;
+		
+		while (off < nextparamoff) {
+			const char* pfieldend;
+			uint        nextfieldoff;
+			
+			pfieldend = memchr(ptran+off, ';', nextparamoff-off);
+			nextfieldoff = (pfieldend == NULL) ? nextparamoff : pfieldend-ptran+1;
+		   
+			if (strncmp(ptran+off, "client_port=", 12) == 0) {
+				u_int16_t   port;
+				uint        numlen;
+
+				off += 12;
+				numlen = nf_strtou16(ptran+off, &port);
+				off += numlen;
+				if (prtspexp->loport != 0 && prtspexp->loport != port)
+					pr_debug("multiple ports found, port %hu ignored\n", port);
+				else {
+					pr_debug("lo port found : %hu\n", port);
+					prtspexp->loport = prtspexp->hiport = port;
+					if (ptran[off] == '-') {
+						off++;
+						numlen = nf_strtou16(ptran+off, &port);
+						off += numlen;
+						prtspexp->pbtype = pb_range;
+						prtspexp->hiport = port;
+						
+						// If we have a range, assume rtp:
+						// loport must be even, hiport must be loport+1
+						if ((prtspexp->loport & 0x0001) != 0 ||
+						    prtspexp->hiport != prtspexp->loport+1) {
+							pr_debug("incorrect range: %hu-%hu, correcting\n",
+							       prtspexp->loport, prtspexp->hiport);
+							prtspexp->loport &= 0xfffe;
+							prtspexp->hiport = prtspexp->loport+1;
+						}
+					} else if (ptran[off] == '/') {
+						off++;
+						numlen = nf_strtou16(ptran+off, &port);
+						off += numlen;
+						prtspexp->pbtype = pb_discon;
+						prtspexp->hiport = port;
+					}
+					rc = 1;
+				}
+			}
+			
+			/*
+			 * Note we don't look for the destination parameter here.
+			 * If we are using NAT, the NAT module will handle it.  If not,
+			 * and the client is sending packets elsewhere, the expectation
+			 * will quietly time out.
+			 */
+			
+			off = nextfieldoff;
+		}
+		
+		off = nextparamoff;
+	}
+	
+	return rc;
+}
+
+
+/*** conntrack functions ***/
+
+/* outbound packet: client->server */
+
+static inline int
+help_out(struct sk_buff *skb, unsigned char *rb_ptr, unsigned int datalen,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	 struct nf_conn *ct, enum ip_conntrack_info ctinfo,
+	 unsigned int protoff)
+#else
+	 struct nf_conn *ct, enum ip_conntrack_info ctinfo)
+#endif
+{
+	struct ip_ct_rtsp_expect expinfo;
+	
+	int dir = CTINFO2DIR(ctinfo);   /* = IP_CT_DIR_ORIGINAL */
+	//struct  tcphdr* tcph = (void*)iph + iph->ihl * 4;
+	//uint    tcplen = pktlen - iph->ihl * 4;
+	char*   pdata = rb_ptr;
+	//uint    datalen = tcplen - tcph->doff * 4;
+	uint    dataoff = 0;
+	int ret = NF_ACCEPT;
+	
+	struct nf_conntrack_expect *rtp_exp;
+	struct nf_conntrack_expect *rtcp_exp = NULL;
+	
+	__be16 be_loport;
+	__be16 be_hiport;
+	
+	typeof(nf_nat_rtsp_hook) nf_nat_rtsp;
+
+	memset(&expinfo, 0, sizeof(expinfo));
+	
+	while (dataoff < datalen) {
+		uint cmdoff = dataoff;
+		uint hdrsoff = 0;
+		uint hdrslen = 0;
+		uint cseqoff = 0;
+		uint cseqlen = 0;
+		uint transoff = 0;
+		uint translen = 0;
+		uint off;
+		
+		if (!rtsp_parse_message(pdata, datalen, &dataoff,
+					&hdrsoff, &hdrslen,
+					&cseqoff, &cseqlen,
+					&transoff, &translen))
+			break;      /* not a valid message */
+
+		if (strncmp(pdata+cmdoff, "TEARDOWN ", 9) == 0) {
+			pr_debug("teardown handled\n");
+			nf_ct_remove_expectations(ct); /* FIXME must be session id aware */
+			break;
+		}
+
+		if (strncmp(pdata+cmdoff, "SETUP ", 6) != 0)
+			continue;   /* not a SETUP message */
+
+		pr_debug("found a setup message\n");
+
+		off = 0;
+		if(translen)
+			rtsp_parse_transport(pdata+transoff, translen, &expinfo);
+
+		if (expinfo.loport == 0) {
+			pr_debug("no udp transports found\n");
+			continue;   /* no udp transports found */
+		}
+
+		pr_debug("udp transport found, ports=(%d,%hu,%hu)\n",
+			 (int)expinfo.pbtype, expinfo.loport, expinfo.hiport);
+
+
+		be_loport = htons(expinfo.loport);
+
+		rtp_exp = nf_ct_expect_alloc(ct);
+		if (rtp_exp == NULL) {
+			ret = NF_DROP;
+			goto out;
+		}
+
+		nf_ct_expect_init(rtp_exp, NF_CT_EXPECT_CLASS_DEFAULT,
+				  nf_ct_l3num(ct),
+				  &ct->tuplehash[!dir].tuple.src.u3,
+				  &ct->tuplehash[!dir].tuple.dst.u3,
+				  IPPROTO_UDP, NULL, &be_loport);
+
+		rtp_exp->flags = 0;
+
+		if (expinfo.pbtype == pb_range) {
+			pr_debug("setup expectation for rtcp\n");
+
+			be_hiport = htons(expinfo.hiport);
+			rtcp_exp = nf_ct_expect_alloc(ct);
+			if (rtcp_exp == NULL) {
+				ret = NF_DROP;
+				goto out1;
+			}
+
+			nf_ct_expect_init(rtcp_exp, NF_CT_EXPECT_CLASS_DEFAULT,
+					  nf_ct_l3num(ct),
+					  &ct->tuplehash[!dir].tuple.src.u3,
+					  &ct->tuplehash[!dir].tuple.dst.u3,
+					  IPPROTO_UDP, NULL, &be_hiport);
+
+			rtcp_exp->flags = 0;
+
+			pr_debug("expect_related %pI4:%u-%u-%pI4:%u-%u\n",
+				   &rtp_exp->tuple.src.u3.ip,
+				   ntohs(rtp_exp->tuple.src.u.udp.port),
+				   ntohs(rtcp_exp->tuple.src.u.udp.port),
+				   &rtp_exp->tuple.dst.u3.ip,
+				   ntohs(rtp_exp->tuple.dst.u.udp.port),
+				   ntohs(rtcp_exp->tuple.dst.u.udp.port));
+		} else {
+			pr_debug("expect_related %pI4:%u-%pI4:%u\n",
+					&rtp_exp->tuple.src.u3.ip,
+					ntohs(rtp_exp->tuple.src.u.udp.port),
+					&rtp_exp->tuple.dst.u3.ip,
+					ntohs(rtp_exp->tuple.dst.u.udp.port));
+		}
+
+		nf_nat_rtsp = rcu_dereference(nf_nat_rtsp_hook);
+		if (nf_nat_rtsp && ct->status & IPS_NAT_MASK)
+			/* pass the request off to the nat helper */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+			ret = nf_nat_rtsp(skb, ctinfo, protoff, hdrsoff, hdrslen,
+					  &expinfo, rtp_exp, rtcp_exp);
+#else
+			ret = nf_nat_rtsp(skb, ctinfo, hdrsoff, hdrslen,
+					  &expinfo, rtp_exp, rtcp_exp);
+#endif
+		else {
+			if (nf_ct_expect_related(rtp_exp) == 0) {
+				if (rtcp_exp && nf_ct_expect_related(rtcp_exp) != 0) {
+					nf_ct_unexpect_related(rtp_exp);
+					pr_info("nf_conntrack_expect_related failed for rtcp\n");
+					ret = NF_DROP;
+				}
+			} else {
+				pr_info("nf_conntrack_expect_related failed for rtp\n");
+				ret = NF_DROP;
+			}
+		}
+		if (rtcp_exp) {
+			nf_ct_expect_put(rtcp_exp);
+		}
+out1:
+		nf_ct_expect_put(rtp_exp);
+		goto out;
+	}
+out:
+
+	return ret;
+}
+
+
+static inline int
+help_in(struct sk_buff *skb, size_t pktlen,
+	struct nf_conn* ct, enum ip_conntrack_info ctinfo)
+{
+	return NF_ACCEPT;
+}
+
+static int help(struct sk_buff *skb, unsigned int protoff,
+		struct nf_conn *ct, enum ip_conntrack_info ctinfo) 
+{
+	struct tcphdr _tcph, *th;
+	unsigned int dataoff, datalen;
+	char *rb_ptr;
+	int ret = NF_DROP;
+
+	/* Until there's been traffic both ways, don't look in packets. */
+	if (ctinfo != IP_CT_ESTABLISHED && 
+	    ctinfo != IP_CT_ESTABLISHED + IP_CT_IS_REPLY) {
+		pr_debug("conntrackinfo = %u\n", ctinfo);
+		return NF_ACCEPT;
+	} 
+
+	/* Not whole TCP header? */
+	th = skb_header_pointer(skb, protoff, sizeof(_tcph), &_tcph);
+
+	if (!th)
+		return NF_ACCEPT;
+   
+	/* No data ? */
+	dataoff = protoff + th->doff*4;
+	datalen = skb->len - dataoff;
+	if (dataoff >= skb->len)
+		return NF_ACCEPT;
+
+	spin_lock_bh(&rtsp_buffer_lock);
+	rb_ptr = skb_header_pointer(skb, dataoff,
+				    skb->len - dataoff, rtsp_buffer);
+	BUG_ON(rb_ptr == NULL);
+
+#if 0
+	/* Checksum invalid?  Ignore. */
+	/* FIXME: Source route IP option packets --RR */
+	if (tcp_v4_check(tcph, tcplen, iph->saddr, iph->daddr,
+			 csum_partial((char*)tcph, tcplen, 0)))
+	{
+		DEBUGP("bad csum: %p %u %u.%u.%u.%u %u.%u.%u.%u\n",
+		       tcph, tcplen, NIPQUAD(iph->saddr), NIPQUAD(iph->daddr));
+		return NF_ACCEPT;
+	}
+#endif
+
+	switch (CTINFO2DIR(ctinfo)) {
+	case IP_CT_DIR_ORIGINAL:
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+		ret = help_out(skb, rb_ptr, datalen, ct, ctinfo, protoff);
+#else
+		ret = help_out(skb, rb_ptr, datalen, ct, ctinfo);
+#endif
+		break;
+	case IP_CT_DIR_REPLY:
+		pr_debug("IP_CT_DIR_REPLY\n");
+		/* inbound packet: server->client */
+		ret = NF_ACCEPT;
+		break;
+	}
+
+	spin_unlock_bh(&rtsp_buffer_lock);
+
+	return ret;
+}
+
+static struct nf_conntrack_helper rtsp_helpers[MAX_PORTS];
+static char rtsp_names[MAX_PORTS][10];
+
+/* This function is intentionally _NOT_ defined as __exit */
+static void
+fini(void)
+{
+	int i;
+	for (i = 0; i < num_ports; i++) {
+		pr_debug("unregistering port %d\n", ports[i]);
+		nf_conntrack_helper_unregister(&rtsp_helpers[i]);
+	}
+	kfree(rtsp_buffer);
+}
+
+static int __init
+init(void)
+{
+	int i, ret;
+	struct nf_conntrack_helper *hlpr;
+	char *tmpname;
+
+	printk("nf_conntrack_rtsp v" IP_NF_RTSP_VERSION " loading\n");
+
+	if (max_outstanding < 1) {
+		printk("nf_conntrack_rtsp: max_outstanding must be a positive integer\n");
+		return -EBUSY;
+	}
+	if (setup_timeout < 0) {
+		printk("nf_conntrack_rtsp: setup_timeout must be a positive integer\n");
+		return -EBUSY;
+	}
+
+	rtsp_exp_policy.max_expected = max_outstanding;
+	rtsp_exp_policy.timeout = setup_timeout;
+	
+	rtsp_buffer = kmalloc(65536, GFP_KERNEL);
+	if (!rtsp_buffer) 
+		return -ENOMEM;
+
+	/* If no port given, default to standard rtsp port */
+	if (ports[0] == 0) {
+		ports[0] = RTSP_PORT;
+		num_ports = 1;
+	}
+
+	for (i = 0; (i < MAX_PORTS) && ports[i]; i++) {
+		hlpr = &rtsp_helpers[i];
+		memset(hlpr, 0, sizeof(struct nf_conntrack_helper));
+		hlpr->tuple.src.l3num = AF_INET;
+		hlpr->tuple.src.u.tcp.port = htons(ports[i]);
+		hlpr->tuple.dst.protonum = IPPROTO_TCP;
+		hlpr->expect_policy = &rtsp_exp_policy;
+		hlpr->me = THIS_MODULE;
+		hlpr->help = help;
+
+		tmpname = &rtsp_names[i][0];
+		if (ports[i] == RTSP_PORT) {
+			sprintf(tmpname, "rtsp");
+		} else {
+			sprintf(tmpname, "rtsp-%d", i);
+		}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
+		strlcpy(hlpr->name, tmpname, sizeof(hlpr->name));
+#else
+		hlpr->name = tmpname;
+#endif
+		pr_debug("port #%d: %d\n", i, ports[i]);
+
+		ret = nf_conntrack_helper_register(hlpr);
+
+		if (ret) {
+			printk("nf_conntrack_rtsp: ERROR registering port %d\n", ports[i]);
+			fini();
+			return -EBUSY;
+		}
+	}
+	return 0;
+}
+
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_standalone.c b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_standalone.c
index 5f9c19f24..4ad91ff45 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_conntrack_standalone.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_conntrack_standalone.c
@@ -514,7 +514,7 @@ static struct ctl_table nf_ct_sysctl_table[] = {
 		.procname       = "nf_conntrack_buckets",
 		.data           = &init_net.ct.htable_size,
 		.maxlen         = sizeof(unsigned int),
-		.mode           = 0644,
+		.mode           = 0444,
 		.proc_handler   = proc_dointvec,
 	},
 	{
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_internals.h b/trunk/linux-4.4.x/net/netfilter/nf_internals.h
index 065522564..19797bc19 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_internals.h
+++ b/trunk/linux-4.4.x/net/netfilter/nf_internals.h
@@ -18,7 +18,7 @@ unsigned int nf_iterate(struct list_head *head, struct sk_buff *skb,
 
 /* nf_queue.c */
 int nf_queue(struct sk_buff *skb, struct nf_hook_ops *elem,
-	     struct nf_hook_state *state, unsigned int queuenum);
+	     struct nf_hook_state *state, unsigned int verdict);
 void nf_queue_nf_hook_drop(struct net *net, struct nf_hook_ops *ops);
 int __init netfilter_queue_init(void);
 
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_nat_core.c b/trunk/linux-4.4.x/net/netfilter/nf_nat_core.c
index 3c9ebfe82..40fcc27e8 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_nat_core.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_nat_core.c
@@ -165,9 +165,11 @@ static int in_range(const struct nf_nat_l3proto *l3proto,
 	    !l3proto->in_range(tuple, range))
 		return 0;
 
+	if (range->flags & NF_NAT_RANGE_PROTO_PSID)
+		return l4proto->in_range(tuple, NF_NAT_MANIP_SRC, range);
+
 	if (!(range->flags & NF_NAT_RANGE_PROTO_SPECIFIED) ||
-	    l4proto->in_range(tuple, NF_NAT_MANIP_SRC,
-			      &range->min_proto, &range->max_proto))
+	    l4proto->in_range(tuple, NF_NAT_MANIP_SRC, range))
 		return 1;
 
 	return 0;
@@ -348,10 +350,12 @@ get_unique_tuple(struct nf_conntrack_tuple *tuple,
 
 	/* Only bother mapping if it's not already in range and unique */
 	if (!(range->flags & NF_NAT_RANGE_PROTO_RANDOM_ALL)) {
-		if (range->flags & NF_NAT_RANGE_PROTO_SPECIFIED) {
-			if (l4proto->in_range(tuple, maniptype,
-					      &range->min_proto,
-					      &range->max_proto) &&
+		if (range->flags & NF_NAT_RANGE_PROTO_PSID) {
+			if (l4proto->in_range(tuple, maniptype, range) &&
+			    !nf_nat_used_tuple(tuple, ct))
+				goto out;
+		} else if (range->flags & NF_NAT_RANGE_PROTO_SPECIFIED) {
+			if (l4proto->in_range(tuple, maniptype, range) &&
 			    (range->min_proto.all == range->max_proto.all ||
 			     !nf_nat_used_tuple(tuple, ct)))
 				goto out;
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_nat_proto_common.c b/trunk/linux-4.4.x/net/netfilter/nf_nat_proto_common.c
index 7d7466dbf..4a1f7a57e 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_nat_proto_common.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_nat_proto_common.c
@@ -19,9 +19,10 @@
 
 bool nf_nat_l4proto_in_range(const struct nf_conntrack_tuple *tuple,
 			     enum nf_nat_manip_type maniptype,
-			     const union nf_conntrack_man_proto *min,
-			     const union nf_conntrack_man_proto *max)
+			     const struct nf_nat_range *range)
 {
+	const union nf_conntrack_man_proto *min = &range->min_proto;
+	const union nf_conntrack_man_proto *max = &range->max_proto;
 	__be16 port;
 
 	if (maniptype == NF_NAT_MANIP_SRC)
@@ -29,6 +30,17 @@ bool nf_nat_l4proto_in_range(const struct nf_conntrack_tuple *tuple,
 	else
 		port = tuple->dst.u.all;
 
+	if (range->flags & NF_NAT_RANGE_PROTO_PSID) {
+		unsigned int a = range->min_proto.psid.offset;
+		unsigned int k = range->min_proto.psid.length;
+		unsigned int m = 16 - a - k;
+		u_int16_t psid = range->max_proto.psid.id;
+		u_int16_t id = ntohs(port);
+
+		return (a == 0 || (id >> (16 - a))) &&
+		       !(((id >> m) ^ psid) & ~(~0U << k));
+	}
+
 	return ntohs(port) >= ntohs(min->all) &&
 	       ntohs(port) <= ntohs(max->all);
 }
@@ -50,6 +62,39 @@ void nf_nat_l4proto_unique_tuple(const struct nf_nat_l3proto *l3proto,
 	else
 		portptr = &tuple->dst.u.all;
 
+	if (range->flags & NF_NAT_RANGE_PROTO_PSID) {
+		unsigned int a = range->min_proto.psid.offset;
+		unsigned int k = range->min_proto.psid.length;
+		unsigned int m = 16 - a - k;
+		u_int16_t psid = range->max_proto.psid.id << m;
+
+		range_size = (1 << (16 - k)) - (!!a << m);
+		if (range_size == 0)
+			return;
+
+		if (range->flags & NF_NAT_RANGE_PROTO_RANDOM) {
+			off = l3proto->secure_port(tuple, maniptype == NF_NAT_MANIP_SRC
+							  ? tuple->dst.u.all
+							  : tuple->src.u.all);
+		} else if (range->flags & NF_NAT_RANGE_PROTO_RANDOM_FULLY) {
+			off = prandom_u32();
+		} else {
+			off = *rover;
+		}
+
+		for (i = 0; ; ++off) {
+			unsigned int n = off % range_size;
+			*portptr = htons((((n >> m) + !!a) << (16 - a)) |
+					 psid | (n & ~(~0U << m)));
+			if (++i != range_size && nf_nat_used_tuple(tuple, ct))
+				continue;
+			if (!(range->flags & NF_NAT_RANGE_PROTO_RANDOM_ALL))
+				*rover = off;
+			return;
+		}
+		return;
+	}
+
 	/* If no range specified... */
 	if (!(range->flags & NF_NAT_RANGE_PROTO_SPECIFIED)) {
 		/* If it's dst rewrite, can't change port */
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_nat_proto_unknown.c b/trunk/linux-4.4.x/net/netfilter/nf_nat_proto_unknown.c
index 6e494d584..8e39058ca 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_nat_proto_unknown.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_nat_proto_unknown.c
@@ -19,8 +19,7 @@
 
 static bool unknown_in_range(const struct nf_conntrack_tuple *tuple,
 			     enum nf_nat_manip_type manip_type,
-			     const union nf_conntrack_man_proto *min,
-			     const union nf_conntrack_man_proto *max)
+			     const struct nf_nat_range *range)
 {
 	return true;
 }
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_queue.c b/trunk/linux-4.4.x/net/netfilter/nf_queue.c
index b19ad20a7..298334ca3 100644
--- a/trunk/linux-4.4.x/net/netfilter/nf_queue.c
+++ b/trunk/linux-4.4.x/net/netfilter/nf_queue.c
@@ -27,6 +27,23 @@
  * receives, no matter what.
  */
 
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+static const struct nf_queue_handler __rcu *queue_imq_handler __read_mostly;
+
+void nf_register_queue_imq_handler(const struct nf_queue_handler *qh)
+{
+	rcu_assign_pointer(queue_imq_handler, qh);
+}
+EXPORT_SYMBOL_GPL(nf_register_queue_imq_handler);
+
+void nf_unregister_queue_imq_handler(void)
+{
+	RCU_INIT_POINTER(queue_imq_handler, NULL);
+	synchronize_rcu();
+}
+EXPORT_SYMBOL_GPL(nf_unregister_queue_imq_handler);
+#endif
+
 /* return EBUSY when somebody else is registered, return EEXIST if the
  * same handler is registered, return 0 in case of success. */
 void nf_register_queue_handler(struct net *net, const struct nf_queue_handler *qh)
@@ -114,16 +131,26 @@ void nf_queue_nf_hook_drop(struct net *net, struct nf_hook_ops *ops)
 int nf_queue(struct sk_buff *skb,
 	     struct nf_hook_ops *elem,
 	     struct nf_hook_state *state,
-	     unsigned int queuenum)
+	     unsigned int verdict)
 {
 	int status = -ENOENT;
 	struct nf_queue_entry *entry = NULL;
 	const struct nf_afinfo *afinfo;
 	const struct nf_queue_handler *qh;
 	struct net *net = state->net;
+	unsigned int queuetype = verdict & NF_VERDICT_MASK;
+	unsigned int queuenum  = verdict >> NF_VERDICT_QBITS;
 
 	/* QUEUE == DROP if no one is waiting, to be safe. */
-	qh = rcu_dereference(net->nf.queue_handler);
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	if (queuetype == NF_IMQ_QUEUE) {
+		qh = rcu_dereference(queue_imq_handler);
+	} else
+#endif
+	{
+		qh = rcu_dereference(net->nf.queue_handler);
+	}
+
 	if (!qh) {
 		status = -ESRCH;
 		goto err;
@@ -198,9 +225,17 @@ void nf_reinject(struct nf_queue_entry *entry, unsigned int verdict)
 		local_bh_enable();
 		break;
 	case NF_QUEUE:
+	case NF_IMQ_QUEUE:
 		err = nf_queue(skb, elem, &entry->state,
-			       verdict >> NF_VERDICT_QBITS);
+			       verdict);
 		if (err < 0) {
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+			/* IMQ Bypass */
+			if (err == -ECANCELED && skb->imq_flags == 0) {
+				goto next_hook;
+			}
+#endif
+
 			if (err == -ESRCH &&
 			   (verdict & NF_VERDICT_FLAG_QUEUE_BYPASS))
 				goto next_hook;
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_shortcut.c b/trunk/linux-4.4.x/net/netfilter/nf_shortcut.c
new file mode 100644
index 000000000..0aa67f4d2
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/nf_shortcut.c
@@ -0,0 +1,177 @@
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+
+#include <linux/inetdevice.h>
+#include <linux/tcp.h>
+#include <linux/ip.h>
+#include <net/tcp.h>
+#include <net/ip.h>
+
+extern int (*smb_nf_local_in_hook)(struct sk_buff *skb);
+extern int (*smb_nf_pre_routing_hook)(struct sk_buff *skb);
+extern int (*smb_nf_local_out_hook)(struct sk_buff *skb);
+extern int (*smb_nf_post_routing_hook)(struct sk_buff *skb);
+
+struct net_device *lan_int = NULL;
+struct in_ifaddr *lan_ifa = NULL;
+
+
+int mtk_smb_nf_local_in_hook(struct sk_buff *skb)
+{
+	struct iphdr *iph = ip_hdr(skb);
+
+	if (skb->protocol == htons(ETH_P_IP)) {
+		struct iphdr *iph = ip_hdr(skb);
+			
+		if (iph->protocol == IPPROTO_TCP) {
+			struct tcphdr *th = tcp_hdr(skb);
+			unsigned short sport, dport;
+
+			th = tcp_hdr(skb);
+			th = (struct tcphdr *)(((unsigned char *)iph) + iph->ihl*4);
+
+			if ((iph->daddr == lan_ifa->ifa_local) 
+				&& ((th->dest == 0xbd01) || (th->dest == 0x8900) 
+				|| (th->dest == 0x8a00) || (th->dest == 0x8b00)))
+				return 1;
+			else
+				return 0;
+		}
+
+	}
+	
+	return 0;
+}
+
+int mtk_smb_nf_pre_routing_hook(struct sk_buff *skb)
+{
+	struct iphdr *iph = ip_hdr(skb);
+
+	if (skb->protocol == htons(ETH_P_IP)) {
+		struct iphdr *iph = ip_hdr(skb);
+			
+		if (iph->protocol == IPPROTO_TCP) {
+			struct tcphdr *th = tcp_hdr(skb);
+			unsigned short sport, dport;
+
+			th = tcp_hdr(skb);
+			th = (struct tcphdr *)(((unsigned char *)iph) + iph->ihl*4);
+			if ((iph->daddr == lan_ifa->ifa_local) 
+				&& ((th->dest == 0xbd01) || (th->dest == 0x8900) 
+				|| (th->dest == 0x8a00) || (th->dest == 0x8b00)))
+				return 1;
+			else
+				return 0;
+		}
+
+	}	
+
+	return 0;
+}
+
+int mtk_smb_nf_local_out_hook(struct sk_buff *skb)
+{
+	struct iphdr *iph = ip_hdr(skb);
+
+	if (iph->protocol == IPPROTO_TCP) {
+		struct tcphdr *th = tcp_hdr(skb);
+
+		th = tcp_hdr(skb);
+		th = (struct tcphdr *)(((unsigned char *)iph) + iph->ihl*4);
+
+		if ((iph->saddr == lan_ifa->ifa_local)
+			&& ((th->source == 0xbd01) || (th->source == 0x8900) 
+			|| (th->source == 0x8a00) || (th->source == 0x8b00)))
+			return 1;
+		else
+			return 0;
+	}
+
+	return 0;
+}
+
+int mtk_smb_nf_post_routing_hook(struct sk_buff *skb)
+{
+	struct iphdr *iph = ip_hdr(skb);
+
+	if (skb->protocol == htons(ETH_P_IP)) {
+		struct iphdr *iph = ip_hdr(skb);
+			
+		if (iph->protocol == IPPROTO_TCP) {
+			struct tcphdr *th = tcp_hdr(skb);
+
+			th = tcp_hdr(skb);
+			th = (struct tcphdr *)(((unsigned char *)iph) + iph->ihl*4);
+
+			if ((iph->saddr == lan_ifa->ifa_local)
+				&& ((th->source == 0xbd01) || (th->source == 0x8900) 
+				|| (th->source == 0x8a00) || (th->source == 0x8b00)))
+				return 1;
+			else
+				return 0;
+		}
+
+	}	
+
+	return 0;
+}
+
+int __init mtk_smb_hook_init(void)
+{
+	struct in_device *in_dev;
+	struct in_ifaddr **ifap = NULL;
+	struct in_ifaddr *ifa = NULL;
+
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,35)
+	lan_int = dev_get_by_name_rcu(&init_net, "br0");
+#else
+	lan_int = __dev_get_by_name("br0");
+#endif
+	if (lan_int)
+		in_dev = __in_dev_get_rtnl(lan_int);
+	else
+		return 0;
+
+	if (in_dev) {
+		for (ifap = &in_dev->ifa_list; (ifa = *ifap) != NULL;
+		     ifap = &ifa->ifa_next) {
+			if (!strcmp("br0", ifa->ifa_label))
+			{
+				lan_ifa = ifa;
+				break; /* found */
+			}
+		}
+	}
+	else
+		return 0;
+
+	if (lan_ifa) {
+		smb_nf_local_in_hook = mtk_smb_nf_local_in_hook;
+		smb_nf_pre_routing_hook = mtk_smb_nf_pre_routing_hook;
+		smb_nf_local_out_hook = mtk_smb_nf_local_out_hook;
+		smb_nf_post_routing_hook = mtk_smb_nf_post_routing_hook;
+	}
+
+	//printk("Samba Netfilter Hook Enabled\n");
+
+	return 0;
+}
+
+void mtk_smb_hook_cleanup(void)
+{
+	lan_int = NULL;
+	lan_ifa = NULL;
+	smb_nf_local_in_hook = NULL;
+	smb_nf_pre_routing_hook = NULL;
+	smb_nf_local_out_hook = NULL;
+	smb_nf_post_routing_hook = NULL;
+
+	return;
+}
+
+module_init(mtk_smb_hook_init);
+module_exit(mtk_smb_hook_cleanup);
+
+MODULE_LICENSE("GPL");
diff --git a/trunk/linux-4.4.x/net/netfilter/nf_shortcut_hook.c b/trunk/linux-4.4.x/net/netfilter/nf_shortcut_hook.c
new file mode 100644
index 000000000..617139c11
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/nf_shortcut_hook.c
@@ -0,0 +1,17 @@
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/skbuff.h>
+
+
+int (*smb_nf_local_in_hook)(struct sk_buff *skb) = NULL;
+int (*smb_nf_pre_routing_hook)(struct sk_buff *skb) = NULL;
+int (*smb_nf_local_out_hook)(struct sk_buff *skb) = NULL;
+int (*smb_nf_post_routing_hook)(struct sk_buff *skb) = NULL;
+EXPORT_SYMBOL(smb_nf_local_in_hook);
+EXPORT_SYMBOL(smb_nf_pre_routing_hook);
+EXPORT_SYMBOL(smb_nf_local_out_hook);
+EXPORT_SYMBOL(smb_nf_post_routing_hook);
+
+
diff --git a/trunk/linux-4.4.x/net/netfilter/xt_IMQ.c b/trunk/linux-4.4.x/net/netfilter/xt_IMQ.c
new file mode 100644
index 000000000..f9c581708
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/xt_IMQ.c
@@ -0,0 +1,72 @@
+/*
+ * This target marks packets to be enqueued to an imq device
+ */
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/netfilter/x_tables.h>
+#include <linux/netfilter/xt_IMQ.h>
+#include <linux/imq.h>
+
+static unsigned int imq_target(struct sk_buff *pskb,
+				const struct xt_action_param *par)
+{
+	const struct xt_imq_info *mr = par->targinfo;
+
+	pskb->imq_flags = (mr->todev & IMQ_F_IFMASK) | IMQ_F_ENQUEUE;
+
+	return XT_CONTINUE;
+}
+
+static int imq_checkentry(const struct xt_tgchk_param *par)
+{
+	struct xt_imq_info *mr = par->targinfo;
+
+	if (mr->todev > IMQ_MAX_DEVS - 1) {
+		pr_warn("IMQ: invalid device specified, highest is %u\n",
+			IMQ_MAX_DEVS - 1);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static struct xt_target xt_imq_reg[] __read_mostly = {
+	{
+		.name           = "IMQ",
+		.family		= AF_INET,
+		.checkentry     = imq_checkentry,
+		.target         = imq_target,
+		.targetsize	= sizeof(struct xt_imq_info),
+		.table		= "mangle",
+		.me             = THIS_MODULE
+	},
+	{
+		.name           = "IMQ",
+		.family		= AF_INET6,
+		.checkentry     = imq_checkentry,
+		.target         = imq_target,
+		.targetsize	= sizeof(struct xt_imq_info),
+		.table		= "mangle",
+		.me             = THIS_MODULE
+	},
+};
+
+static int __init imq_init(void)
+{
+	return xt_register_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
+}
+
+static void __exit imq_fini(void)
+{
+	xt_unregister_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
+}
+
+module_init(imq_init);
+module_exit(imq_fini);
+
+MODULE_AUTHOR("https://github.com/imq/linuximq");
+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See https://github.com/imq/linuximq/wiki for more information.");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("ipt_IMQ");
+MODULE_ALIAS("ip6t_IMQ");
+
diff --git a/trunk/linux-4.4.x/net/netfilter/xt_condition.c b/trunk/linux-4.4.x/net/netfilter/xt_condition.c
new file mode 100644
index 000000000..be75f41ae
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/xt_condition.c
@@ -0,0 +1,241 @@
+/*
+ *	"condition" match extension for Xtables
+ *
+ *	Description: This module allows firewall rules to match using
+ *	condition variables available through procfs.
+ *
+ *	Authors:
+ *	Stephane Ouellette <ouellettes [at] videotron ca>, 2002-10-22
+ *	Massimiliano Hofer <max [at] nucleus it>, 2006-05-15
+ *
+ *	This program is free software; you can redistribute it and/or modify it
+ *	under the terms of the GNU General Public License; either version 2
+ *	or 3 of the License, as published by the Free Software Foundation.
+ */
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <linux/spinlock.h>
+#include <linux/string.h>
+#include <linux/version.h>
+#include <linux/netfilter/x_tables.h>
+#include <asm/uaccess.h>
+#include <linux/netfilter/xt_condition.h>
+#include <linux/netfilter/compat_xtables.h>
+
+#ifndef CONFIG_PROC_FS
+#	error "proc file system support is required for this module"
+#endif
+
+/* Defaults, these can be overridden on the module command-line. */
+static unsigned int condition_list_perms = S_IRUGO | S_IWUSR;
+static unsigned int condition_uid_perms = 0;
+static unsigned int condition_gid_perms = 0;
+
+MODULE_AUTHOR("Stephane Ouellette <ouellettes@videotron.ca>");
+MODULE_AUTHOR("Massimiliano Hofer <max@nucleus.it>");
+MODULE_AUTHOR("Jan Engelhardt ");
+MODULE_DESCRIPTION("Allows rules to match against condition variables");
+MODULE_LICENSE("GPL");
+module_param(condition_list_perms, uint, S_IRUSR | S_IWUSR);
+MODULE_PARM_DESC(condition_list_perms, "permissions on /proc/net/nf_condition/* files");
+module_param(condition_uid_perms, uint, S_IRUSR | S_IWUSR);
+MODULE_PARM_DESC(condition_uid_perms, "user owner of /proc/net/nf_condition/* files");
+module_param(condition_gid_perms, uint, S_IRUSR | S_IWUSR);
+MODULE_PARM_DESC(condition_gid_perms, "group owner of /proc/net/nf_condition/* files");
+MODULE_ALIAS("ipt_condition");
+MODULE_ALIAS("ip6t_condition");
+
+struct condition_variable {
+	struct list_head list;
+	struct proc_dir_entry *status_proc;
+	unsigned int refcount;
+	bool enabled;
+	char name[sizeof(((struct xt_condition_mtinfo *)NULL)->name)];
+};
+
+/* proc_lock is a user context only semaphore used for write access */
+/*           to the conditions' list.                               */
+static DEFINE_MUTEX(proc_lock);
+
+static LIST_HEAD(conditions_list);
+static struct proc_dir_entry *proc_net_condition;
+
+static int condition_proc_show(struct seq_file *m, void *data)
+{
+	const struct condition_variable *var = m->private;
+
+	seq_printf(m, var->enabled ? "1\n" : "0\n");
+	return 0;
+}
+
+static int condition_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, condition_proc_show, PDE_DATA(inode));
+}
+
+static ssize_t
+condition_proc_write(struct file *file, const char __user *buffer,
+                     size_t length, loff_t *loff)
+{
+	struct condition_variable *var = PDE_DATA(file_inode(file));
+	char newval;
+
+	if (length > 0) {
+		if (get_user(newval, buffer) != 0)
+			return -EFAULT;
+		/* Match only on the first character */
+		switch (newval) {
+		case '0':
+			var->enabled = false;
+			break;
+		case '1':
+			var->enabled = true;
+			break;
+		}
+	}
+	return length;
+}
+
+static const struct file_operations condition_proc_fops = {
+	.open    = condition_proc_open,
+	.read    = seq_read,
+	.llseek  = seq_lseek,
+	.write   = condition_proc_write,
+	.release = single_release,
+};
+
+static bool
+condition_mt(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct xt_condition_mtinfo *info = par->matchinfo;
+	const struct condition_variable *var   = info->condvar;
+
+	return var->enabled ^ info->invert;
+}
+
+static int condition_mt_check(const struct xt_mtchk_param *par)
+{
+	struct xt_condition_mtinfo *info = par->matchinfo;
+	struct condition_variable *var;
+
+	/* Forbid certain names */
+	if (*info->name == '\0' || *info->name == '.' ||
+	    info->name[sizeof(info->name)-1] != '\0' ||
+	    memchr(info->name, '/', sizeof(info->name)) != NULL) {
+		printk(KERN_INFO KBUILD_MODNAME ": name not allowed or too "
+		       "long: \"%.*s\"\n", (unsigned int)sizeof(info->name),
+		       info->name);
+		return -EINVAL;
+	}
+	/*
+	 * Let's acquire the lock, check for the condition and add it
+	 * or increase the reference counter.
+	 */
+	mutex_lock(&proc_lock);
+	list_for_each_entry(var, &conditions_list, list) {
+		if (strcmp(info->name, var->name) == 0) {
+			var->refcount++;
+			mutex_unlock(&proc_lock);
+			info->condvar = var;
+			return 0;
+		}
+	}
+
+	/* At this point, we need to allocate a new condition variable. */
+	var = kmalloc(sizeof(struct condition_variable), GFP_KERNEL);
+	if (var == NULL) {
+		mutex_unlock(&proc_lock);
+		return -ENOMEM;
+	}
+
+	memcpy(var->name, info->name, sizeof(info->name));
+	/* Create the condition variable's proc file entry. */
+	var->status_proc = proc_create_data(info->name, condition_list_perms,
+	                   proc_net_condition, &condition_proc_fops, var);
+	if (var->status_proc == NULL) {
+		kfree(var);
+		mutex_unlock(&proc_lock);
+		return -ENOMEM;
+	}
+
+	proc_set_user(var->status_proc,
+	              make_kuid(&init_user_ns, condition_uid_perms),
+	              make_kgid(&init_user_ns, condition_gid_perms));
+	var->refcount = 1;
+	var->enabled  = false;
+	wmb();
+	list_add(&var->list, &conditions_list);
+	mutex_unlock(&proc_lock);
+	info->condvar = var;
+	return 0;
+}
+
+static void condition_mt_destroy(const struct xt_mtdtor_param *par)
+{
+	const struct xt_condition_mtinfo *info = par->matchinfo;
+	struct condition_variable *var = info->condvar;
+
+	mutex_lock(&proc_lock);
+	if (--var->refcount == 0) {
+		list_del(&var->list);
+		proc_remove(var->status_proc);
+		mutex_unlock(&proc_lock);
+		kfree(var);
+		return;
+	}
+	mutex_unlock(&proc_lock);
+}
+
+static struct xt_match condition_mt_reg[] __read_mostly = {
+	{
+		.name       = "condition",
+		.revision   = 1,
+		.family     = NFPROTO_IPV4,
+		.matchsize  = sizeof(struct xt_condition_mtinfo),
+		.match      = condition_mt,
+		.checkentry = condition_mt_check,
+		.destroy    = condition_mt_destroy,
+		.me         = THIS_MODULE,
+	},
+	{
+		.name       = "condition",
+		.revision   = 1,
+		.family     = NFPROTO_IPV6,
+		.matchsize  = sizeof(struct xt_condition_mtinfo),
+		.match      = condition_mt,
+		.checkentry = condition_mt_check,
+		.destroy    = condition_mt_destroy,
+		.me         = THIS_MODULE,
+	},
+};
+
+static const char *const dir_name = "nf_condition";
+
+static int __init condition_mt_init(void)
+{
+	int ret;
+
+	mutex_init(&proc_lock);
+	proc_net_condition = proc_mkdir(dir_name, init_net.proc_net);
+	if (proc_net_condition == NULL)
+		return -EACCES;
+
+	ret = xt_register_matches(condition_mt_reg, ARRAY_SIZE(condition_mt_reg));
+	if (ret < 0) {
+		remove_proc_entry(dir_name, init_net.proc_net);
+		return ret;
+	}
+
+	return 0;
+}
+
+static void __exit condition_mt_exit(void)
+{
+	xt_unregister_matches(condition_mt_reg, ARRAY_SIZE(condition_mt_reg));
+	remove_proc_entry(dir_name, init_net.proc_net);
+}
+
+module_init(condition_mt_init);
+module_exit(condition_mt_exit);
diff --git a/trunk/linux-4.4.x/net/netfilter/xt_connmark.c b/trunk/linux-4.4.x/net/netfilter/xt_connmark.c
index 69f78e96f..31a7ccfa5 100644
--- a/trunk/linux-4.4.x/net/netfilter/xt_connmark.c
+++ b/trunk/linux-4.4.x/net/netfilter/xt_connmark.c
@@ -55,6 +55,15 @@ connmark_tg(struct sk_buff *skb, const struct xt_action_param *par)
 			nf_conntrack_event_cache(IPCT_MARK, ct);
 		}
 		break;
+	case XT_CONNMARK_SET_RETURN:
+		// Set connmark and mark, apply mask to mark, do XT_RETURN	- zzz
+		newmark = ct->mark = info->ctmark;
+		newmark &= info->ctmask;
+		if (newmark != skb->mark) {
+			skb->mark = newmark;
+		}
+		//return XT_RETURN;	// set return here will cause traffic blocked !?
+		break;
 	case XT_CONNMARK_SAVE:
 		newmark = (ct->mark & ~info->ctmask) ^
 		          (skb->mark & info->nfmask);
diff --git a/trunk/linux-4.4.x/net/netfilter/xt_ethport.c b/trunk/linux-4.4.x/net/netfilter/xt_ethport.c
new file mode 100644
index 000000000..8c4a8ddd6
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/xt_ethport.c
@@ -0,0 +1,84 @@
+/*
+ * IP tables module for matching the value of the incoming ether port
+ * for Ralink SoC platform.
+ *
+ * (C) 2009 by Y.Y. Huang <yy_huang@ralinktech.com.tw>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+
+#include <linux/netfilter/xt_ethport.h>
+#include <linux/netfilter/x_tables.h>
+
+MODULE_AUTHOR("Y.Y. Huang <yy_huang@ralinktech.com.tw>");
+MODULE_DESCRIPTION("x_tables Ra SoC Ethernet incoming port matching module");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("ipt_ethport");
+MODULE_ALIAS("ip6t_ethport");
+
+static bool match(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct xt_ethport_info *info = par->matchinfo;
+	u_int8_t portnum = skb->priority;
+
+	return (portnum == info->portnum) ^ !!info->invert;
+}
+
+static bool match6(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct xt_ethport_info *info = par->matchinfo;
+	u_int8_t portnum = skb->priority;
+
+	return (portnum == info->portnum) ^ !!info->invert;
+}
+
+static int checkentry(const struct xt_mtchk_param *par)
+{
+	const u_int8_t portnum = ((struct xt_ethport_info *)(par->matchinfo))->portnum;
+
+	if (portnum > XT_ETHPORT_MAX) {
+		printk(KERN_ERR "xt_ethport: port number %x is out of range(%x)\n", portnum, XT_ETHPORT_MAX);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static struct xt_match xt_ethport_match[] = {
+	{
+		.name		= "ethport",
+		.family		= AF_INET,
+		.checkentry	= checkentry,
+		.match		= match,
+		.matchsize	= sizeof(struct xt_ethport_info),
+		.me		= THIS_MODULE,
+	},
+	{
+		.name		= "ethport",
+		.family		= AF_INET6,
+		.checkentry	= checkentry,
+		.match		= match6,
+		.matchsize	= sizeof(struct xt_ethport_info),
+		.me		= THIS_MODULE,
+	},
+};
+
+static int __init xt_ethport_match_init(void)
+{
+	return xt_register_matches(xt_ethport_match, ARRAY_SIZE(xt_ethport_match));
+}
+
+static void __exit xt_ethport_match_fini(void)
+{
+	xt_unregister_matches(xt_ethport_match, ARRAY_SIZE(xt_ethport_match));
+}
+
+module_init(xt_ethport_match_init);
+module_exit(xt_ethport_match_fini);
diff --git a/trunk/linux-4.4.x/net/netfilter/xt_geoip.c b/trunk/linux-4.4.x/net/netfilter/xt_geoip.c
new file mode 100644
index 000000000..a545e9049
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/xt_geoip.c
@@ -0,0 +1,371 @@
+/* iptables kernel module for the geoip match
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * Copyright (c) 2004, 2005, 2006, 2007, 2008
+ * Samuel Jean & Nicolas Bouliane
+ */
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/rcupdate.h>
+#include <linux/skbuff.h>
+#include <linux/version.h>
+#include <linux/vmalloc.h>
+#include <linux/netfilter/x_tables.h>
+#include <asm/atomic.h>
+#include <asm/uaccess.h>
+#include <linux/netfilter/xt_geoip.h>
+#include <linux/netfilter/compat_xtables.h>
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Nicolas Bouliane");
+MODULE_AUTHOR("Samuel Jean");
+MODULE_DESCRIPTION("xtables module for geoip match");
+MODULE_ALIAS("ip6t_geoip");
+MODULE_ALIAS("ipt_geoip");
+
+enum geoip_proto {
+	GEOIPROTO_IPV6,
+	GEOIPROTO_IPV4,
+	__GEOIPROTO_MAX,
+};
+
+/**
+ * @list:	anchor point for geoip_head
+ * @subnets:	packed ordered list of ranges (either v6 or v4)
+ * @count:	number of ranges
+ * @cc:		country code
+ */
+struct geoip_country_kernel {
+	struct list_head list;
+	void *subnets;
+	atomic_t ref;
+	unsigned int count;
+	unsigned short cc;
+};
+
+static struct list_head geoip_head[__GEOIPROTO_MAX];
+static DEFINE_SPINLOCK(geoip_lock);
+
+static const enum geoip_proto nfp2geo[] = {
+	[NFPROTO_IPV6] = GEOIPROTO_IPV6,
+	[NFPROTO_IPV4] = GEOIPROTO_IPV4,
+};
+static const size_t geoproto_size[] = {
+	[GEOIPROTO_IPV6] = sizeof(struct geoip_subnet6),
+	[GEOIPROTO_IPV4] = sizeof(struct geoip_subnet4),
+};
+
+static struct geoip_country_kernel *
+geoip_add_node(const struct geoip_country_user __user *umem_ptr,
+               enum geoip_proto proto)
+{
+	struct geoip_country_user umem;
+	struct geoip_country_kernel *p;
+	size_t size;
+	void *subnet;
+	int ret;
+
+	if (copy_from_user(&umem, umem_ptr, sizeof(umem)) != 0)
+		return ERR_PTR(-EFAULT);
+
+	p = kmalloc(sizeof(struct geoip_country_kernel), GFP_KERNEL);
+	if (p == NULL)
+		return ERR_PTR(-ENOMEM);
+
+	p->count   = umem.count;
+	p->cc      = umem.cc;
+	size = p->count * geoproto_size[proto];
+	if (size == 0) {
+		/*
+		 * Believe it or not, vmalloc prints a warning to dmesg for
+		 * zero-sized allocations :-/
+		 */
+		subnet = NULL;
+	} else {
+		subnet = vmalloc(size);
+		if (subnet == NULL) {
+			ret = -ENOMEM;
+			goto free_p;
+		}
+	}
+	if (copy_from_user(subnet,
+	    (const void __user *)(unsigned long)umem.subnets, size) != 0) {
+		ret = -EFAULT;
+		goto free_s;
+	}
+
+	p->subnets = subnet;
+	atomic_set(&p->ref, 1);
+	INIT_LIST_HEAD(&p->list);
+
+	spin_lock(&geoip_lock);
+	list_add_tail_rcu(&p->list, &geoip_head[proto]);
+	spin_unlock(&geoip_lock);
+
+	return p;
+
+ free_s:
+	vfree(subnet);
+ free_p:
+	kfree(p);
+	return ERR_PTR(ret);
+}
+
+static void geoip_try_remove_node(struct geoip_country_kernel *p)
+{
+	spin_lock(&geoip_lock);
+	if (!atomic_dec_and_test(&p->ref)) {
+		spin_unlock(&geoip_lock);
+		return;
+	}
+
+	/* So now am unlinked or the only one alive, right ?
+	 * What are you waiting ? Free up some memory!
+	 */
+	list_del_rcu(&p->list);
+	spin_unlock(&geoip_lock);
+
+	synchronize_rcu();
+	vfree(p->subnets);
+	kfree(p);
+}
+
+static struct geoip_country_kernel *find_node(unsigned short cc,
+    enum geoip_proto proto)
+{
+	struct geoip_country_kernel *p;
+	spin_lock(&geoip_lock);
+
+	list_for_each_entry_rcu(p, &geoip_head[proto], list)
+		if (p->cc == cc) {
+			atomic_inc(&p->ref);
+			spin_unlock(&geoip_lock);
+			return p;
+		}
+
+	spin_unlock(&geoip_lock);
+	return NULL;
+}
+
+static inline int
+ipv6_cmp(const struct in6_addr *p, const struct in6_addr *q)
+{
+	unsigned int i;
+
+	for (i = 0; i < 4; ++i) {
+		if (p->s6_addr32[i] < q->s6_addr32[i])
+			return -1;
+		else if (p->s6_addr32[i] > q->s6_addr32[i])
+			return 1;
+	}
+
+	return 0;
+}
+
+static bool geoip_bsearch6(const struct geoip_subnet6 *range,
+    const struct in6_addr *addr, int lo, int hi)
+{
+	int mid;
+
+	while (true) {
+		if (hi <= lo)
+			return false;
+		mid = (lo + hi) / 2;
+		if (ipv6_cmp(&range[mid].begin, addr) <= 0 &&
+		    ipv6_cmp(addr, &range[mid].end) <= 0)
+			return true;
+		if (ipv6_cmp(&range[mid].begin, addr) > 0)
+			hi = mid;
+		else if (ipv6_cmp(&range[mid].end, addr) < 0)
+			lo = mid + 1;
+		else
+			break;
+	}
+
+	WARN_ON(true);
+	return false;
+}
+
+static bool
+xt_geoip_mt6(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct xt_geoip_match_info *info = par->matchinfo;
+	const struct geoip_country_kernel *node;
+	const struct ipv6hdr *iph = ipv6_hdr(skb);
+	unsigned int i;
+	struct in6_addr ip;
+
+	memcpy(&ip, (info->flags & XT_GEOIP_SRC) ? &iph->saddr : &iph->daddr,
+	       sizeof(ip));
+	for (i = 0; i < 4; ++i)
+		ip.s6_addr32[i] = ntohl(ip.s6_addr32[i]);
+
+	rcu_read_lock();
+	for (i = 0; i < info->count; i++) {
+		if ((node = info->mem[i].kernel) == NULL) {
+			printk(KERN_ERR "xt_geoip: what the hell ?? '%c%c' isn't loaded into memory... skip it!\n",
+					COUNTRY(info->cc[i]));
+			continue;
+		}
+		if (geoip_bsearch6(node->subnets, &ip, 0, node->count)) {
+			rcu_read_unlock();
+			return !(info->flags & XT_GEOIP_INV);
+		}
+	}
+
+	rcu_read_unlock();
+	return info->flags & XT_GEOIP_INV;
+}
+
+static bool geoip_bsearch4(const struct geoip_subnet4 *range,
+    uint32_t addr, int lo, int hi)
+{
+	int mid;
+
+	while (true) {
+		if (hi <= lo)
+			return false;
+		mid = (lo + hi) / 2;
+		if (range[mid].begin <= addr && addr <= range[mid].end)
+			return true;
+		if (range[mid].begin > addr)
+			hi = mid;
+		else if (range[mid].end < addr)
+			lo = mid + 1;
+		else
+			break;
+	}
+
+	WARN_ON(true);
+	return false;
+}
+
+static bool
+xt_geoip_mt4(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct xt_geoip_match_info *info = par->matchinfo;
+	const struct geoip_country_kernel *node;
+	const struct iphdr *iph = ip_hdr(skb);
+	unsigned int i;
+	uint32_t ip;
+
+	ip = ntohl((info->flags & XT_GEOIP_SRC) ? iph->saddr : iph->daddr);
+	rcu_read_lock();
+	for (i = 0; i < info->count; i++) {
+		if ((node = info->mem[i].kernel) == NULL) {
+			printk(KERN_ERR "xt_geoip: what the hell ?? '%c%c' isn't loaded into memory... skip it!\n",
+					COUNTRY(info->cc[i]));
+			continue;
+		}
+		if (geoip_bsearch4(node->subnets, ip, 0, node->count)) {
+			rcu_read_unlock();
+			return !(info->flags & XT_GEOIP_INV);
+		}
+	}
+
+	rcu_read_unlock();
+	return info->flags & XT_GEOIP_INV;
+}
+
+static int xt_geoip_mt_checkentry(const struct xt_mtchk_param *par)
+{
+	struct xt_geoip_match_info *info = par->matchinfo;
+	struct geoip_country_kernel *node;
+	unsigned int i;
+
+	for (i = 0; i < info->count; i++) {
+		node = find_node(info->cc[i], nfp2geo[par->family]);
+		if (node == NULL) {
+			node = geoip_add_node((const void __user *)(unsigned long)info->mem[i].user,
+			       nfp2geo[par->family]);
+			if (IS_ERR(node)) {
+				printk(KERN_ERR
+						"xt_geoip: unable to load '%c%c' into memory: %ld\n",
+						COUNTRY(info->cc[i]), PTR_ERR(node));
+				return PTR_ERR(node);
+			}
+		}
+
+		/* Overwrite the now-useless pointer info->mem[i] with
+		 * a pointer to the node's kernelspace structure.
+		 * This avoids searching for a node in the match() and
+		 * destroy() functions.
+		 */
+		info->mem[i].kernel = node;
+	}
+
+	return 0;
+}
+
+static void xt_geoip_mt_destroy(const struct xt_mtdtor_param *par)
+{
+	struct xt_geoip_match_info *info = par->matchinfo;
+	struct geoip_country_kernel *node;
+	unsigned int i;
+
+	/* This entry has been removed from the table so
+	 * decrease the refcount of all countries it is
+	 * using.
+	 */
+
+	for (i = 0; i < info->count; i++)
+		if ((node = info->mem[i].kernel) != NULL) {
+			/* Free up some memory if that node isn't used
+			 * anymore. */
+			geoip_try_remove_node(node);
+		}
+		else
+			/* Something strange happened. There's no memory allocated for this
+			 * country.  Please send this bug to the mailing list. */
+			printk(KERN_ERR
+					"xt_geoip: What happened peejix ? What happened acidfu ?\n"
+					"xt_geoip: please report this bug to the maintainers\n");
+}
+
+static struct xt_match xt_geoip_match[] __read_mostly = {
+	{
+		.name       = "geoip",
+		.revision   = 1,
+		.family     = NFPROTO_IPV6,
+		.match      = xt_geoip_mt6,
+		.checkentry = xt_geoip_mt_checkentry,
+		.destroy    = xt_geoip_mt_destroy,
+		.matchsize  = sizeof(struct xt_geoip_match_info),
+		.me         = THIS_MODULE,
+	},
+	{
+		.name       = "geoip",
+		.revision   = 1,
+		.family     = NFPROTO_IPV4,
+		.match      = xt_geoip_mt4,
+		.checkentry = xt_geoip_mt_checkentry,
+		.destroy    = xt_geoip_mt_destroy,
+		.matchsize  = sizeof(struct xt_geoip_match_info),
+		.me         = THIS_MODULE,
+	},
+};
+
+static int __init xt_geoip_mt_init(void)
+{
+	unsigned int i;
+
+	for (i = 0; i < ARRAY_SIZE(geoip_head); ++i)
+		INIT_LIST_HEAD(&geoip_head[i]);
+	return xt_register_matches(xt_geoip_match, ARRAY_SIZE(xt_geoip_match));
+}
+
+static void __exit xt_geoip_mt_fini(void)
+{
+	xt_unregister_matches(xt_geoip_match, ARRAY_SIZE(xt_geoip_match));
+}
+
+module_init(xt_geoip_mt_init);
+module_exit(xt_geoip_mt_fini);
diff --git a/trunk/linux-4.4.x/net/netfilter/xt_layer7.c b/trunk/linux-4.4.x/net/netfilter/xt_layer7.c
new file mode 100644
index 000000000..b10ddd6f7
--- /dev/null
+++ b/trunk/linux-4.4.x/net/netfilter/xt_layer7.c
@@ -0,0 +1,705 @@
+/*
+Kernel module to match application layer (OSI layer 7) data in connections.
+
+http://l7-filter.sf.net
+
+(C) 2003-2009 Matthew Strait and Ethan Sommer.
+
+This program is free software; you can redistribute it and/or
+modify it under the terms of the GNU General Public License
+  as published by the Free Software Foundation; either version
+  2 of the License, or (at your option) any later version.
+  http://www.gnu.org/licenses/gpl.txt
+
+  Based on ipt_string.c (C) 2000 Emmanuel Roger <winfield@freegates.be>,
+  xt_helper.c (C) 2002 Harald Welte and cls_layer7.c (C) 2003 Matthew Strait,
+  Ethan Sommer, Justin Levandoski.
+*/
+
+#include <linux/spinlock.h>
+#include <linux/version.h>
+#include <net/ip.h>
+#include <net/tcp.h>
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/netfilter.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 27)
+#include <net/netfilter/nf_conntrack_extend.h>
+#include <net/netfilter/nf_conntrack_acct.h>
+#endif
+#include <linux/netfilter/x_tables.h>
+#include <linux/netfilter/xt_layer7.h>
+#include <linux/ctype.h>
+#include <linux/proc_fs.h>
+
+#include "regexp/regexp.c"
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Matthew Strait <quadong@users.sf.net>, Ethan Sommer <sommere@users.sf.net>");
+MODULE_DESCRIPTION("iptables application layer match module");
+MODULE_ALIAS("ipt_layer7");
+MODULE_VERSION("2.21");
+
+static int maxdatalen = 2048; // this is the default
+module_param(maxdatalen, int, 0444);
+MODULE_PARM_DESC(maxdatalen, "maximum bytes of data looked at by l7-filter");
+#ifdef CONFIG_NETFILTER_XT_MATCH_LAYER7_DEBUG
+        #define DPRINTK(format,args...) printk(format,##args)
+#else
+        #define DPRINTK(format,args...)
+#endif
+
+/* Number of packets whose data we look at.
+This can be modified through /proc/net/layer7_numpackets */
+static int num_packets = 10;
+
+static struct pattern_cache {
+        char * regex_string;
+        regexp * pattern;
+        struct pattern_cache * next;
+} * first_pattern_cache = NULL;
+
+DEFINE_SPINLOCK(l7_lock);
+
+static int total_acct_packets(struct nf_conn *ct)
+{
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 26)
+        BUG_ON(ct == NULL);
+        return (ct->counters[IP_CT_DIR_ORIGINAL].packets + ct->counters[IP_CT_DIR_REPLY].packets);
+#else
+        struct nf_conn_counter *acct;
+
+        BUG_ON(ct == NULL);
+        acct = nf_conn_acct_find(ct);
+        if (!acct)
+                return 0;
+        return (atomic64_read(&acct[IP_CT_DIR_ORIGINAL].packets) + atomic64_read(&acct[IP_CT_DIR_REPLY].packets));
+#endif
+}
+
+#ifdef CONFIG_IP_NF_MATCH_LAYER7_DEBUG
+/* Converts an unfriendly string into a friendly one by
+replacing unprintables with periods and all whitespace with " ". */
+static char * friendly_print(unsigned char * s)
+{
+        char * f = kmalloc(strlen(s) + 1, GFP_ATOMIC);
+        int i;
+
+        if(!f) {
+                if (net_ratelimit())
+                        printk(KERN_ERR "layer7: out of memory in "
+                                        "friendly_print, bailing.\n");
+                return NULL;
+        }
+
+        for(i = 0; i < strlen(s); i++){
+                if(isprint(s[i]) && s[i] < 128) f[i] = s[i];
+                else if(isspace(s[i]))          f[i] = ' ';
+                else                            f[i] = '.';
+        }
+        f[i] = '\0';
+        return f;
+}
+
+static char dec2hex(int i)
+{
+        switch (i) {
+                case 0 ... 9:
+                        return (i + '0');
+                        break;
+                case 10 ... 15:
+                        return (i - 10 + 'a');
+                        break;
+                default:
+                        if (net_ratelimit())
+                                printk("layer7: Problem in dec2hex\n");
+                        return '\0';
+        }
+}
+
+static char * hex_print(unsigned char * s)
+{
+        char * g = kmalloc(strlen(s)*3 + 1, GFP_ATOMIC);
+        int i;
+
+        if(!g) {
+               if (net_ratelimit())
+                        printk(KERN_ERR "layer7: out of memory in hex_print, "
+                                        "bailing.\n");
+               return NULL;
+        }
+
+        for(i = 0; i < strlen(s); i++) {
+                g[i*3    ] = dec2hex(s[i]/16);
+                g[i*3 + 1] = dec2hex(s[i]%16);
+                g[i*3 + 2] = ' ';
+        }
+        g[i*3] = '\0';
+
+        return g;
+}
+#endif // DEBUG
+
+/* Use instead of regcomp.  As we expect to be seeing the same regexps over and
+over again, it make sense to cache the results. */
+static regexp * compile_and_cache(const char * regex_string,
+                                  const char * protocol)
+{
+        struct pattern_cache * node               = first_pattern_cache;
+        struct pattern_cache * last_pattern_cache = first_pattern_cache;
+        struct pattern_cache * tmp;
+        unsigned int len;
+
+        while (node != NULL) {
+                if (!strcmp(node->regex_string, regex_string))
+                return node->pattern;
+
+                last_pattern_cache = node;/* points at the last non-NULL node */
+                node = node->next;
+        }
+
+        /* If we reach the end of the list, then we have not yet cached
+           the pattern for this regex. Let's do that now.
+           Be paranoid about running out of memory to avoid list corruption. */
+        tmp = kmalloc(sizeof(struct pattern_cache), GFP_ATOMIC);
+
+        if(!tmp) {
+                if (net_ratelimit())
+                        printk(KERN_ERR "layer7: out of memory in "
+                                        "compile_and_cache, bailing.\n");
+                return NULL;
+        }
+
+        tmp->regex_string  = kmalloc(strlen(regex_string) + 1, GFP_ATOMIC);
+        tmp->pattern       = kmalloc(sizeof(struct regexp),    GFP_ATOMIC);
+        tmp->next = NULL;
+
+        if(!tmp->regex_string || !tmp->pattern) {
+                if (net_ratelimit())
+                        printk(KERN_ERR "layer7: out of memory in "
+                                        "compile_and_cache, bailing.\n");
+                kfree(tmp->regex_string);
+                kfree(tmp->pattern);
+                kfree(tmp);
+                return NULL;
+        }
+
+        /* Ok.  The new node is all ready now. */
+        node = tmp;
+
+        if(first_pattern_cache == NULL) /* list is empty */
+                first_pattern_cache = node; /* make node the beginning */
+        else
+                last_pattern_cache->next = node; /* attach node to the end */
+
+        /* copy the string and compile the regex */
+        len = strlen(regex_string);
+        DPRINTK("About to compile this: \"%s\"\n", regex_string);
+        node->pattern = regcomp((char *)regex_string, &len);
+        if ( !node->pattern ) {
+                if (net_ratelimit())
+                        printk(KERN_ERR "layer7: Error compiling regexp "
+                                        "\"%s\" (%s)\n",
+                                        regex_string, protocol);
+                /* pattern is now cached as NULL, so we won't try again. */
+        }
+
+        strcpy(node->regex_string, regex_string);
+        return node->pattern;
+}
+
+static int can_handle(const struct sk_buff *skb)
+{
+        if(!ip_hdr(skb)) /* not IP */
+                return 0;
+        if(ip_hdr(skb)->protocol != IPPROTO_TCP &&
+           ip_hdr(skb)->protocol != IPPROTO_UDP &&
+           ip_hdr(skb)->protocol != IPPROTO_ICMP)
+                return 0;
+        return 1;
+}
+
+/* Returns offset the into the skb->data that the application data starts */
+static int app_data_offset(const struct sk_buff *skb)
+{
+        /* In case we are ported somewhere (ebtables?) where ip_hdr(skb)
+        isn't set, this can be gotten from 4*(skb->data[0] & 0x0f) as well. */
+        int ip_hl = 4*ip_hdr(skb)->ihl;
+
+        if( ip_hdr(skb)->protocol == IPPROTO_TCP ) {
+                /* 12 == offset into TCP header for the header length field.
+                Can't get this with skb->h.th->doff because the tcphdr
+                struct doesn't get set when routing (this is confirmed to be
+                true in Netfilter as well as QoS.) */
+                int tcp_hl = 4*(skb->data[ip_hl + 12] >> 4);
+
+                return ip_hl + tcp_hl;
+        } else if( ip_hdr(skb)->protocol == IPPROTO_UDP  ) {
+                return ip_hl + 8; /* UDP header is always 8 bytes */
+        } else if( ip_hdr(skb)->protocol == IPPROTO_ICMP ) {
+                return ip_hl + 8; /* ICMP header is 8 bytes */
+        } else {
+                if (net_ratelimit())
+                        printk(KERN_ERR "layer7: tried to handle unknown "
+                                        "protocol!\n");
+                return ip_hl + 8; /* something reasonable */
+        }
+}
+
+/* handles whether there's a match when we aren't appending data anymore */
+static int match_no_append(struct nf_conn * conntrack,
+                           struct nf_conn * master_conntrack,
+                           enum ip_conntrack_info ctinfo,
+                           enum ip_conntrack_info master_ctinfo,
+                           const struct xt_layer7_info * info)
+{
+        /* If we're in here, throw the app data away */
+        if(master_conntrack->layer7.app_data != NULL) {
+
+        #ifdef CONFIG_IP_NF_MATCH_LAYER7_DEBUG
+                if(!master_conntrack->layer7.app_proto) {
+                        char * f =
+                          friendly_print(master_conntrack->layer7.app_data);
+                        char * g =
+                          hex_print(master_conntrack->layer7.app_data);
+                        DPRINTK("\nl7-filter gave up after %d bytes "
+                                "(%d packets):\n%s\n",
+                                strlen(f), total_acct_packets(master_conntrack), f);
+                        kfree(f);
+                        DPRINTK("In hex: %s\n", g);
+                        kfree(g);
+                }
+        #endif
+
+                kfree(master_conntrack->layer7.app_data);
+                master_conntrack->layer7.app_data = NULL; /* don't free again */
+        }
+
+        if(master_conntrack->layer7.app_proto){
+                /* Here child connections set their .app_proto (for /proc) */
+                if(!conntrack->layer7.app_proto) {
+                        conntrack->layer7.app_proto =
+                          kmalloc(strlen(master_conntrack->layer7.app_proto)+1,
+                            GFP_ATOMIC);
+                        if(!conntrack->layer7.app_proto){
+                                if (net_ratelimit())
+                                        printk(KERN_ERR "layer7: out of memory "
+                                                        "in match_no_append, "
+                                                        "bailing.\n");
+                                return 1;
+                        }
+                        strcpy(conntrack->layer7.app_proto,
+                                master_conntrack->layer7.app_proto);
+                }
+
+                return (!strcmp(master_conntrack->layer7.app_proto,
+                                info->protocol));
+        }
+        else {
+                /* If not classified, set to "unknown" to distinguish from
+                connections that are still being tested. */
+                master_conntrack->layer7.app_proto =
+                        kmalloc(strlen("unknown")+1, GFP_ATOMIC);
+                if(!master_conntrack->layer7.app_proto){
+                        if (net_ratelimit())
+                                printk(KERN_ERR "layer7: out of memory in "
+                                                "match_no_append, bailing.\n");
+                        return 1;
+                }
+                strcpy(master_conntrack->layer7.app_proto, "unknown");
+                return 0;
+        }
+}
+
+/* add the new app data to the conntrack.  Return number of bytes added. */
+static int add_datastr(char *target, int offset, char *app_data, int len)
+{
+        int length = 0, i;
+        if (!target) return 0;
+
+        /* Strip nulls. Make everything lower case (our regex lib doesn't
+        do case insensitivity).  Add it to the end of the current data. */
+        for(i = 0; i < maxdatalen-offset-1 && i < len; i++) {
+                if(app_data[i] != '\0') {
+                        /* the kernel version of tolower mungs 'upper ascii' */
+                        target[length+offset] =
+                                isascii(app_data[i])?
+                                        tolower(app_data[i]) : app_data[i];
+                        length++;
+                }
+        }
+        target[length+offset] = '\0';
+
+        return length;
+}
+
+/* add the new app data to the conntrack.  Return number of bytes added. */
+static int add_data(struct nf_conn * master_conntrack,
+                    char * app_data, int appdatalen)
+{
+        int length;
+
+        length = add_datastr(master_conntrack->layer7.app_data, master_conntrack->layer7.app_data_len, app_data, appdatalen);
+        master_conntrack->layer7.app_data_len += length;
+
+        return length;
+}
+
+/* taken from drivers/video/modedb.c */
+static int my_atoi(const char *s)
+{
+        int val = 0;
+
+        for (;; s++) {
+                switch (*s) {
+                        case '0'...'9':
+                        val = 10*val+(*s-'0');
+                        break;
+                default:
+                        return val;
+                }
+        }
+}
+
+/* write out num_packets to userland. */
+
+static ssize_t
+layer7_read_proc(struct file *file, char __user *buf,
+                  size_t size, loff_t *ppos)
+{
+        if(num_packets > 99 && net_ratelimit())
+                printk(KERN_ERR "layer7: NOT REACHED. num_packets too big\n");
+        char page[4];
+       
+        page[0] = num_packets/10 + '0';
+        page[1] = num_packets%10 + '0';
+        page[2] = '\n';
+        page[3] = '\0';
+
+        return simple_read_from_buffer(buf, size, ppos, page,
+                                        sizeof(page));
+}
+
+/* Read in num_packets from userland */
+static ssize_t layer7_write_proc(struct file* file, const char __user * buffer,
+                             size_t count, loff_t *ppos)
+{
+        char * foo = kmalloc(count, GFP_ATOMIC);
+
+        if(!foo){
+                if (net_ratelimit())
+                        printk(KERN_ERR "layer7: out of memory, bailing. "
+                                        "num_packets unchanged.\n");
+                return count;
+        }
+
+        if(copy_from_user(foo, buffer, count)) {
+                return -EFAULT;
+        }
+
+
+        num_packets = my_atoi(foo);
+        kfree (foo);
+
+        /* This has an arbitrary limit to make the math easier. I'm lazy.
+        But anyway, 99 is a LOT! If you want more, you're doing it wrong! */
+        if(num_packets > 99) {
+                printk(KERN_WARNING "layer7: num_packets can't be > 99.\n");
+                num_packets = 99;
+        } else if(num_packets < 1) {
+                printk(KERN_WARNING "layer7: num_packets can't be < 1.\n");
+                num_packets = 1;
+        }
+
+        return count;
+}
+
+static bool
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 35)
+match(const struct sk_buff *skbin, struct xt_action_param *par)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
+match(const struct sk_buff *skbin, const struct xt_match_param *par)
+#else
+match(const struct sk_buff *skbin,
+      const struct net_device *in,
+      const struct net_device *out,
+      const struct xt_match *match,
+      const void *matchinfo,
+      int offset,
+      unsigned int protoff,
+      bool *hotdrop)
+#endif
+{
+        /* sidestep const without getting a compiler warning... */
+        struct sk_buff * skb = (struct sk_buff *)skbin;
+
+        const struct xt_layer7_info * info =
+        #if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
+                par->matchinfo;
+        #else
+                matchinfo;
+        #endif
+
+        enum ip_conntrack_info master_ctinfo, ctinfo;
+        struct nf_conn *master_conntrack, *conntrack;
+        unsigned char *app_data, *tmp_data;
+        unsigned int pattern_result, appdatalen;
+        regexp * comppattern;
+
+        /* Be paranoid/incompetent - lock the entire match function. */
+        spin_lock_bh(&l7_lock);
+
+        if(!can_handle(skb)){
+                DPRINTK("layer7: This is some protocol I can't handle.\n");
+                spin_unlock_bh(&l7_lock);
+                return info->invert;
+        }
+
+        /* Treat parent & all its children together as one connection, except
+        for the purpose of setting conntrack->layer7.app_proto in the actual
+        connection. This makes /proc/net/ip_conntrack more satisfying. */
+        if(!(conntrack = nf_ct_get(skb, &ctinfo)) ||
+           !(master_conntrack=nf_ct_get(skb,&master_ctinfo))){
+                DPRINTK("layer7: couldn't get conntrack.\n");
+                spin_unlock_bh(&l7_lock);
+                return info->invert;
+        }
+
+        /* Try to get a master conntrack (and its master etc) for FTP, etc. */
+        while (master_ct(master_conntrack) != NULL)
+                master_conntrack = master_ct(master_conntrack);
+
+        /* if we've classified it or seen too many packets */
+        if(!info->pkt && (total_acct_packets(master_conntrack) > num_packets ||
+           master_conntrack->layer7.app_proto)) {
+
+                pattern_result = match_no_append(conntrack, master_conntrack,
+                                                 ctinfo, master_ctinfo, info);
+
+                /* skb->cb[0] == seen. Don't do things twice if there are
+                multiple l7 rules. I'm not sure that using cb for this purpose
+                is correct, even though it says "put your private variables
+                there". But it doesn't look like it is being used for anything
+                else in the skbs that make it here. */
+                skb->cb[0] = 1; /* marking it seen here's probably irrelevant */
+
+                spin_unlock_bh(&l7_lock);
+                return (pattern_result ^ info->invert);
+        }
+
+        if(skb_is_nonlinear(skb)){
+                if(skb_linearize(skb) != 0){
+                        if (net_ratelimit())
+                                printk(KERN_ERR "layer7: failed to linearize "
+                                                "packet, bailing.\n");
+                        spin_unlock_bh(&l7_lock);
+                        return info->invert;
+                }
+        }
+
+        /* now that the skb is linearized, it's safe to set these. */
+        app_data = skb->data + app_data_offset(skb);
+        appdatalen = skb_tail_pointer(skb) - app_data;
+
+        /* the return value gets checked later, when we're ready to use it */
+        comppattern = compile_and_cache(info->pattern, info->protocol);
+
+        if (info->pkt) {
+                tmp_data = kmalloc(maxdatalen, GFP_ATOMIC);
+                if(!tmp_data){
+                        if (net_ratelimit())
+                                printk(KERN_ERR "layer7: out of memory in match, bailing.\n");
+                        return info->invert;
+                }
+
+                tmp_data[0] = '\0';
+                add_datastr(tmp_data, 0, app_data, appdatalen);
+                pattern_result = ((comppattern && regexec(comppattern, tmp_data)) ? 1 : 0);
+
+                kfree(tmp_data);
+                tmp_data = NULL;
+                spin_unlock_bh(&l7_lock);
+
+                return (pattern_result ^ info->invert);
+        }
+
+        /* On the first packet of a connection, allocate space for app data */
+        if(total_acct_packets(master_conntrack) == 1 && !skb->cb[0] &&
+           !master_conntrack->layer7.app_data){
+                master_conntrack->layer7.app_data =
+                        kmalloc(maxdatalen, GFP_ATOMIC);
+                if(!master_conntrack->layer7.app_data){
+                        if (net_ratelimit())
+                                printk(KERN_ERR "layer7: out of memory in "
+                                                "match, bailing.\n");
+                        spin_unlock_bh(&l7_lock);
+                        return info->invert;
+                }
+
+                master_conntrack->layer7.app_data[0] = '\0';
+        }
+
+        /* Can be here, but unallocated, if numpackets is increased near
+        the beginning of a connection */
+        if(master_conntrack->layer7.app_data == NULL){
+                spin_unlock_bh(&l7_lock);
+                return info->invert; /* unmatched */
+        }
+
+        if(!skb->cb[0]){
+                int newbytes;
+                newbytes = add_data(master_conntrack, app_data, appdatalen);
+
+                if(newbytes == 0) { /* didn't add any data */
+                        skb->cb[0] = 1;
+                        /* Didn't match before, not going to match now */
+                        spin_unlock_bh(&l7_lock);
+                        return info->invert;
+                }
+        }
+
+        /* If looking for "unknown", then never match.  "Unknown" means that
+        we've given up; we're still trying with these packets. */
+        if(!strcmp(info->protocol, "unknown")) {
+                pattern_result = 0;
+        /* If looking for "unset", then always match. "Unset" means that we
+        haven't yet classified the connection. */
+        } else if(!strcmp(info->protocol, "unset")) {
+                pattern_result = 2;
+                DPRINTK("layer7: matched unset: not yet classified "
+                        "(%d/%d packets)\n",
+                        total_acct_packets(master_conntrack), num_packets);
+        /* If the regexp failed to compile, don't bother running it */
+        } else if(comppattern &&
+                  regexec(comppattern, master_conntrack->layer7.app_data)){
+                DPRINTK("layer7: matched %s\n", info->protocol);
+                pattern_result = 1;
+        } else pattern_result = 0;
+
+        if(pattern_result == 1) {
+                master_conntrack->layer7.app_proto =
+                        kmalloc(strlen(info->protocol)+1, GFP_ATOMIC);
+                if(!master_conntrack->layer7.app_proto){
+                        if (net_ratelimit())
+                                printk(KERN_ERR "layer7: out of memory in "
+                                                "match, bailing.\n");
+                        spin_unlock_bh(&l7_lock);
+                        return (pattern_result ^ info->invert);
+                }
+                strcpy(master_conntrack->layer7.app_proto, info->protocol);
+        } else if(pattern_result > 1) { /* cleanup from "unset" */
+                pattern_result = 1;
+        }
+
+        /* mark the packet seen */
+        skb->cb[0] = 1;
+
+        spin_unlock_bh(&l7_lock);
+        return (pattern_result ^ info->invert);
+}
+
+// load nf_conntrack_ipv4
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 35)
+static int
+#else
+static bool
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
+check(const struct xt_mtchk_param *par)
+{
+        if (nf_ct_l3proto_try_module_get(par->match->family) < 0) {
+                printk(KERN_WARNING "can't load conntrack support for "
+                                    "proto=%d\n", par->match->family);
+#else
+check(const char *tablename, const void *inf,
+                 const struct xt_match *match, void *matchinfo,
+                 unsigned int hook_mask)
+{
+        if (nf_ct_l3proto_try_module_get(match->family) < 0) {
+                printk(KERN_WARNING "can't load conntrack support for "
+                                    "proto=%d\n", match->family);
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 35)
+                return -EINVAL;
+        }
+        return 0;
+#else
+                return 0;
+        }
+        return 1;
+#endif
+}
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
+        static void destroy(const struct xt_mtdtor_param *par)
+        {
+                nf_ct_l3proto_module_put(par->match->family);
+        }
+#else
+        static void destroy(const struct xt_match *match, void *matchinfo)
+        {
+                nf_ct_l3proto_module_put(match->family);
+        }
+#endif
+
+static struct xt_match xt_layer7_match[] __read_mostly = {
+{
+        .name           = "layer7",
+        .family         = AF_INET,
+        .checkentry     = check,
+        .match          = match,
+        .destroy        = destroy,
+        .matchsize      = sizeof(struct xt_layer7_info),
+        .me             = THIS_MODULE
+}
+};
+
+static const struct file_operations fops = {
+        .read = layer7_read_proc,
+        .write = layer7_write_proc,
+        .llseek = default_llseek,
+};
+
+static void layer7_cleanup_proc(void)
+{
+        remove_proc_entry("layer7_numpackets", init_net.proc_net);
+}
+
+/* register the proc file */
+static void layer7_init_proc(void)
+{
+        proc_create("layer7_numpackets", 0644, init_net.proc_net, &fops);
+}
+
+static int __init xt_layer7_init(void)
+{
+        need_conntrack();
+
+        layer7_init_proc();
+        if(maxdatalen < 1) {
+                printk(KERN_WARNING "layer7: maxdatalen can't be < 1, "
+                        "using 1\n");
+                maxdatalen = 1;
+        }
+        /* This is not a hard limit.  It's just here to prevent people from
+        bringing their slow machines to a grinding halt. */
+        else if(maxdatalen > 65536) {
+                printk(KERN_WARNING "layer7: maxdatalen can't be > 65536, "
+                        "using 65536\n");
+                maxdatalen = 65536;
+        }
+        return xt_register_matches(xt_layer7_match,
+                                   ARRAY_SIZE(xt_layer7_match));
+}
+
+static void __exit xt_layer7_fini(void)
+{
+        layer7_cleanup_proc();
+        xt_unregister_matches(xt_layer7_match, ARRAY_SIZE(xt_layer7_match));
+}
+
+module_init(xt_layer7_init);
+module_exit(xt_layer7_fini);
\ No newline at end of file
diff --git a/trunk/linux-4.4.x/net/netfilter/xt_mac.c b/trunk/linux-4.4.x/net/netfilter/xt_mac.c
index d5b4fd4f9..0e8332b5e 100644
--- a/trunk/linux-4.4.x/net/netfilter/xt_mac.c
+++ b/trunk/linux-4.4.x/net/netfilter/xt_mac.c
@@ -47,8 +47,10 @@ static struct xt_match mac_mt_reg __read_mostly = {
 	.family    = NFPROTO_UNSPEC,
 	.match     = mac_mt,
 	.matchsize = sizeof(struct xt_mac_info),
+	// NOTE: bandwidth limtier and traditional qos need NF_INET_LOCAL_OUT for non-imq models, DON"T remove it!
 	.hooks     = (1 << NF_INET_PRE_ROUTING) | (1 << NF_INET_LOCAL_IN) |
-	             (1 << NF_INET_FORWARD),
+	             (1 << NF_INET_FORWARD) | (1 << NF_INET_POST_ROUTING) |
+	             (1 << NF_INET_LOCAL_OUT),
 	.me        = THIS_MODULE,
 };
 
diff --git a/trunk/linux-4.4.x/net/netfilter/xt_webstr.c b/trunk/linux-4.4.x/net/netfilter/xt_webstr.c
index cdbd0dbde..4a8250b0d 100644
--- a/trunk/linux-4.4.x/net/netfilter/xt_webstr.c
+++ b/trunk/linux-4.4.x/net/netfilter/xt_webstr.c
@@ -15,21 +15,12 @@
  * 		alongside the existing linear search based on memcmp().
  * 		Also a quick check to decide which method to use on a per
  * 		packet basis.
- * Download location
- *               http://svn.dd-wrt.com:8000/browser//src/linux/xscale/linux-2.6.34.6/net/ipv4/netfilter
  */
 
 /* Kernel module to match a http header string into a packet.
  *
- * Copyright (C) 2009 - 2010, CyberTAN Corporation
- *
+ * Copyright (C) 2003, CyberTAN Corporation
  * All Rights Reserved.
- * You can redistribute it and/or modify it under the terms of the GPL v2
- *
- * THIS SOFTWARE IS OFFERED "AS IS", AND CYBERTAN GRANTS NO WARRANTIES OF ANY
- * KIND, EXPRESS OR IMPLIED, BY STATUTE, COMMUNICATION OR OTHERWISE. CYBERTAN
- * SPECIFICALLY DISCLAIMS ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS
- * FOR A SPECIFIC PURPOSE OR NON INFRINGEMENT CONCERNING THIS SOFTWARE.
  *
  * Description:
  *   This is kernel module for web content inspection. It was derived from
@@ -37,38 +28,46 @@
  *
  *   The module follows the Netfilter framework, called extended packet
  *   matching modules.
- * Restriction:
- *            Can not search https headers, higly recomended to use  tinyproxy server to block contents
- ******************************************************************************************************
- Includes Intel Corporation's changes/modifications dated: 02.11.2011
- Changed/modified portions :
- * -  X-tables API adapted for kernel 2.6.39
- * - added, improved Debug prints
- * - Kernel warning /complains of a too big stack size in the xt_webstr_match() function fixed
- * - copy from packet sk_buff removed, search is done directly in the tcp payload (optimization)
- * Copyright  2011-2014, Intel Corporation.
- ******************************************************************************************************
-
  */
 
-
+/* Linux Kernel 2.6 Port ( 2.4 ipt-> 2.6 xt)
+ * Copyright (C) 2008, Ralink Technology Corporation.
+ * All Rights Reserved.
+ */
 
 #include <linux/module.h>
 #include <linux/skbuff.h>
+#include <linux/netfilter/x_tables.h>
 #include <linux/ip.h>
+#include <linux/ipv6.h>
 #include <linux/tcp.h>
+#include <net/sock.h>
 
-#include <linux/netfilter/x_tables.h>
-#include <linux/netfilter_ipv4/ip_tables.h>
-#include <linux/netfilter_ipv6/ip6_tables.h>
-#include <linux/netfilter/xt_webstr.h>
+#define BM_MAX_NLEN 256
+#define BM_MAX_HLEN 1024
+
+#define BLK_JAVA        0x01
+#define BLK_ACTIVE      0x02
+#define BLK_COOKIE      0x04
+#define BLK_PROXY       0x08
+
+typedef char *(*proc_ipt_search) (char *, char *, int, int);
+
+struct ipt_webstr_info {
+    char string[BM_MAX_NLEN];
+    u_int16_t invert;
+    u_int16_t len;
+    u_int8_t type;
+};
+
+enum xt_webstr_type
+{
+    IPT_WEBSTR_HOST,
+    IPT_WEBSTR_URL,
+    IPT_WEBSTR_CONTENT
+};
 
-MODULE_LICENSE("GPL");
-MODULE_AUTHOR("Gianni Tedesco <gianni@ecsc.co.uk>");
-MODULE_ALIAS("ip6t_webstr");
-MODULE_ALIAS("ipt_webstr");
 
-//MODULE_DESCRIPTION("Xtables: match --url or --host parameter in http header IPv4");
 #define	isdigit(x) ((x) >= '0' && (x) <= '9')
 #define	isupper(x) (((unsigned)(x) >= 'A') && ((unsigned)(x) <= 'Z'))
 #define	islower(x) (((unsigned)(x) >= 'a') && ((unsigned)(x) <= 'z'))
@@ -87,10 +86,7 @@ MODULE_ALIAS("ipt_webstr");
 	word[(next=strstr(next, delim)) ? strstr(word, delim) - word : sizeof(word) - 1] = '\0', \
 	next = next ? next + sizeof(delim) - 1 : NULL)
 
-#define URLSIZE 	1024
-#define WORDSIZE 	256
-#define HOSTSIZE 	256
-
+#define BUFSIZE 	1024
 
 /* Flags for get_http_info() */
 #define HTTP_HOST	0x01
@@ -98,22 +94,33 @@ MODULE_ALIAS("ipt_webstr");
 /* Flags for mangle_http_header() */
 #define HTTP_COOKIE	0x04
 
-//#define DEBUG
-#ifdef DEBUG
-#define DEBUGP printk
-#define PRINTK_LEVEL KERN_CRIT
+#if 0
+#define SPARQ_LOG       printk
 #else
-#define PRINTK_LEVEL
-#define DEBUGP( PRINTK_LEVEL, format, args...)
+#define SPARQ_LOG(format, args...)
 #endif
 
 typedef struct httpinfo {
-    char  host[HOSTSIZE];
+    char host[BUFSIZE + 1];
     int hostlen;
-    char  url[URLSIZE];
+    char url[BUFSIZE + 1];
     int urllen;
 } httpinfo_t;
-static httpinfo_t htinfo;
+
+httpinfo_t htinfo;
+
+static int strnicmp(const char *cs, const char *ct, size_t count)
+{
+	register signed char __res = 0;
+
+	while (count) {
+		if ((__res = toupper(*cs) - toupper(*ct++)) != 0 || !*cs++) {
+			break;
+		}
+		count--;
+	}
+	return __res;
+}
 
 /* Return 1 for match, 0 for accept, -1 for partial. */
 static int find_pattern2(const char *data, size_t dlen,
@@ -126,14 +133,14 @@ static int find_pattern2(const char *data, size_t dlen,
     int state = 0;
     *numoff = *numlen = 0;
 
-    DEBUGP( PRINTK_LEVEL "%s: pattern = '%s', dlen = %u\n",__FUNCTION__, pattern, dlen);
+    SPARQ_LOG("%s: pattern = '%s', dlen = %u\n",__FUNCTION__, pattern, dlen);
     if (dlen == 0)
 	return 0;
 
     if (dlen <= plen) {	/* Short packet: try for partial? */
-	if (strncasecmp(data, pattern, dlen) == 0)
+	if (strnicmp(data, pattern, dlen) == 0)
 	    return -1;
-	else 
+	else
 	    return 0;
     }
     for (i = 0; i <= (dlen - plen); i++) {
@@ -166,25 +173,31 @@ static int find_pattern2(const char *data, size_t dlen,
     return 0;
 }
 
-static int mangle_http_header(int flags, unsigned char *data, unsigned int datalen)
+#if 0
+static int mangle_http_header(const struct sk_buff *skb, int flags)
 {
+    struct iphdr *iph = (skb)->nh.iph;
+    struct tcphdr *tcph = (void *)iph + iph->ihl*4;
+    unsigned char *data = (void *)tcph + tcph->doff*4;
+    unsigned int datalen = (skb)->len - (iph->ihl*4) - (tcph->doff*4);
+
     int found, offset, len;
     int ret = 0;
 
 
-    DEBUGP( PRINTK_LEVEL "%s: seq=%u\n", __FUNCTION__, ntohl(tcph->seq));
+    SPARQ_LOG("%s: seq=%u\n", __FUNCTION__, ntohl(tcph->seq));
 
     /* Basic checking, is it HTTP packet? */
     if (datalen < 10)
 	return ret;	/* Not enough length, ignore it */
     if (memcmp(data, "GET ", sizeof("GET ") - 1) != 0 &&
         memcmp(data, "POST ", sizeof("POST ") - 1) != 0 &&
-        memcmp(data, "HEAD ", sizeof("HEAD ") - 1) != 0)
+        memcmp(data, "HEAD ", sizeof("HEAD ") - 1) != 0) //zg add 2006.09.28 for cdrouter3.3 item 186(cdrouter_urlfilter_15)
 	return ret;	/* Pass it */
 
     /* COOKIE modification */
     if (flags & HTTP_COOKIE) {
-	found = find_pattern2(data, datalen, "Cookie: ", 
+	found = find_pattern2(data, datalen, "Cookie: ",
 		sizeof("Cookie: ")-1, '\r', &offset, &len);
 	if (found) {
 	    char c;
@@ -199,197 +212,352 @@ static int mangle_http_header(int flags, unsigned char *data, unsigned int datal
 
     return ret;
 }
+#endif
 
-static int get_http_info(int flags, httpinfo_t *info, const unsigned char *data, unsigned int datalen)
+static int get_http_info(const struct sk_buff *skb, int flags, httpinfo_t *info)
 {
+    struct iphdr *iph = ip_hdr(skb);
+    struct tcphdr *tcph = (void *)iph + iph->ihl*4;
+    unsigned char *data = (void *)tcph + tcph->doff*4;
+    unsigned int datalen = (skb)->len - (iph->ihl*4) - (tcph->doff*4);
+
     int found, offset;
     int hostlen, pathlen;
     int ret = 0;
 
+
+    SPARQ_LOG("%s: seq=%u\n", __FUNCTION__, ntohl(tcph->seq));
+
     /* Basic checking, is it HTTP packet? */
     if (datalen < 10)
-    {
-        #ifdef DEBUG
-            DEBUGP( PRINTK_LEVEL "%s: Error ?SYN? datalen <10 datalen=%d\n", __FUNCTION__ ,datalen);
-        #endif
 	return ret;	/* Not enough length, ignore it */
-    }
     if (memcmp(data, "GET ", sizeof("GET ") - 1) != 0 &&
         memcmp(data, "POST ", sizeof("POST ") - 1) != 0 &&
-        memcmp(data, "HEAD ", sizeof("HEAD ") - 1) != 0)
-    {
-        #ifdef DEBUG
-            DEBUGP( PRINTK_LEVEL "%s: Error no GET/POST clause\n", __FUNCTION__ );
-        #endif
-	    return ret;	/* Pass it */
-    }
+        memcmp(data, "HEAD ", sizeof("HEAD ") - 1) != 0) //zg add 2006.09.28 for cdrouter3.3 item 186(cdrouter_urlfilter_15)
+	return ret;	/* Pass it */
+
     if (!(flags & (HTTP_HOST | HTTP_URL)))
-    {
-        #ifdef DEBUG
-            DEBUGP( PRINTK_LEVEL "%s: Error nor HOST nor URL match\n", __FUNCTION__ );
-        #endif
-	    return ret;
-    }
+	return ret;
 
-    if ( flags & HTTP_HOST )  /* it is always true because MATCH parameter parser adds HTTP__HOST when HTTP_URL is specified */ 
-    {
-        /* find the 'Host: ' value */
-         found = find_pattern2(data, datalen, "Host: ", 
-        	    sizeof("Host: ") - 1, '\r', &offset, &hostlen);
-        #ifdef DEBUG
-        if (found )
-            DEBUGP( PRINTK_LEVEL "Host found at offset=%d, with hostlen=%d\n", offset, hostlen);
-        #endif
-
-        if (!found || !hostlen)
-        	return ret;
-
-        ret++;	/* Host found, increase the return value */
-		hostlen = (hostlen < HOSTSIZE) ? hostlen : HOSTSIZE;
-        strncpy(info->host, data + offset, hostlen);
-		 *(info->host + hostlen) = 0;		/* null-terminated */
-        info->hostlen = hostlen;
-        DEBUGP( PRINTK_LEVEL "HOST=%s, hostlen=%d\n", info->host, info->hostlen);
-    }
+    /* find the 'Host: ' value */
+    found = find_pattern2(data, datalen, "Host: ",
+	    sizeof("Host: ") - 1, '\r', &offset, &hostlen);
+    SPARQ_LOG("Host found=%d\n", found);
+
+    if (!found || !hostlen)
+	return ret;
+
+    ret++;	/* Host found, increase the return value */
+    hostlen = (hostlen < BUFSIZE) ? hostlen : BUFSIZE;
+    strncpy(info->host, data + offset, hostlen);
+    *(info->host + hostlen) = 0;		/* null-terminated */
+    info->hostlen = hostlen;
+    SPARQ_LOG("HOST=%s, hostlen=%d\n", info->host, info->hostlen);
 
     if (!(flags & HTTP_URL))
 	return ret;
 
-    /* find the ['GET ' | 'POST ' | 'HEAD'] parameter value, i.e find url */
+    /* find the 'GET ' or 'POST ' or 'HEAD ' value */
     found = find_pattern2(data, datalen, "GET ",
 	    sizeof("GET ") - 1, '\r', &offset, &pathlen);
-    DEBUGP( PRINTK_LEVEL "HTTP GET found=%d\n", found);
     if (!found)
 	found = find_pattern2(data, datalen, "POST ",
 		sizeof("POST ") - 1, '\r', &offset, &pathlen);
-    if (!found) 
-        found = find_pattern2(data, datalen, "HEAD ", 
-                sizeof("HEAD ") - 1, '\r', &offset, &pathlen);      
-    DEBUGP( PRINTK_LEVEL "HTTP POST found=%d\n", found);
-
-    if (!found || (pathlen -= (sizeof(" HTTP/x.x") - 1)) <= 0) /* ignore this field */
-	   return ret;
-    DEBUGP( PRINTK_LEVEL " pathlen - (sizeof(' HTTP/x.x') %d\n", pathlen - (sizeof(" HTTP/x.x") - 1));
-
-    ret++;	/* GET/POST found, increase the return value */
-    pathlen = ((pathlen + hostlen) < URLSIZE) ? pathlen : URLSIZE - hostlen;
-	DEBUGP( PRINTK_LEVEL " Make url start from host hostlen %d\n", hostlen);
-	strncpy(info->url, info->host, hostlen);
-	
-	
+    /******* zg add 2006.09.28 for cdrouter3.3 item 186(cdrouter_urlfilter_15) ******/
+    if (!found)
+        found = find_pattern2(data, datalen, "HEAD ",
+                sizeof("HEAD ") - 1, '\r', &offset, &pathlen);
+    /************************* zg end 2006.09.28 ****************************/
+    SPARQ_LOG("GET/POST found=%d\n", found);
+
+    if (!found || (pathlen -= (sizeof(" HTTP/x.x") - 1)) <= 0)/* ignor this field */
+	return ret;
+
+    ret++;	/* GET/POST/HEAD found, increase the return value */
+    pathlen = ((pathlen + hostlen) < BUFSIZE) ? pathlen : BUFSIZE - hostlen;
+    strncpy(info->url, info->host, hostlen);
     strncpy(info->url + hostlen, data + offset, pathlen);
     *(info->url + hostlen + pathlen) = 0;	/* null-terminated */
-	/* in a regular http reguest, host is after url */
-    DEBUGP( PRINTK_LEVEL " Append Url  to host sits at address of %p, offset=%d from tcp payload to \n", data + offset, offset);
     info->urllen = hostlen + pathlen;
-    DEBUGP( PRINTK_LEVEL "URL=%s, urllen=%d\n", info->url, info->urllen);
+    SPARQ_LOG("URL=%s, urllen=%d\n", info->url, info->urllen);
+
+    return ret;
+}
+
+static int get_http_info6(const struct sk_buff *skb, int flags, httpinfo_t *info)
+{
+    struct ipv6hdr *ip6h = ipv6_hdr(skb);
+    struct tcphdr *tcph = tcp_hdr(skb);
+    unsigned char *data = (void *)tcph + tcph->doff*4;
+    unsigned int datalen = ntohs(ip6h->payload_len);
+
+    int found, offset;
+    int hostlen, pathlen;
+    int ret = 0;
+
+
+    SPARQ_LOG("%s: seq=%u\n", __FUNCTION__, ntohl(tcph->seq));
+
+    /* Basic checking, is it HTTP packet? */
+    if (datalen < 10)
+	return ret;	/* Not enough length, ignore it */
+    if (memcmp(data, "GET ", sizeof("GET ") - 1) != 0 &&
+        memcmp(data, "POST ", sizeof("POST ") - 1) != 0 &&
+        memcmp(data, "HEAD ", sizeof("HEAD ") - 1) != 0) //zg add 2006.09.28 for cdrouter3.3 item 186(cdrouter_urlfilter_15)
+	return ret;	/* Pass it */
+
+    if (!(flags & (HTTP_HOST | HTTP_URL)))
+	return ret;
+
+    /* find the 'Host: ' value */
+    found = find_pattern2(data, datalen, "Host: ",
+	    sizeof("Host: ") - 1, '\r', &offset, &hostlen);
+    SPARQ_LOG("Host found=%d\n", found);
+
+    if (!found || !hostlen)
+	return ret;
+
+    ret++;	/* Host found, increase the return value */
+    hostlen = (hostlen < BUFSIZE) ? hostlen : BUFSIZE;
+    strncpy(info->host, data + offset, hostlen);
+    *(info->host + hostlen) = 0;		/* null-terminated */
+    info->hostlen = hostlen;
+    SPARQ_LOG("HOST=%s, hostlen=%d\n", info->host, info->hostlen);
+
+    if (!(flags & HTTP_URL))
+	return ret;
+
+    /* find the 'GET ' or 'POST ' or 'HEAD ' value */
+    found = find_pattern2(data, datalen, "GET ",
+	    sizeof("GET ") - 1, '\r', &offset, &pathlen);
+    if (!found)
+	found = find_pattern2(data, datalen, "POST ",
+		sizeof("POST ") - 1, '\r', &offset, &pathlen);
+    /******* zg add 2006.09.28 for cdrouter3.3 item 186(cdrouter_urlfilter_15) ******/
+    if (!found)
+        found = find_pattern2(data, datalen, "HEAD ",
+                sizeof("HEAD ") - 1, '\r', &offset, &pathlen);
+    /************************* zg end 2006.09.28 ****************************/
+    SPARQ_LOG("GET/POST found=%d\n", found);
+
+    if (!found || (pathlen -= (sizeof(" HTTP/x.x") - 1)) <= 0)/* ignor this field */
+	return ret;
+
+    ret++;	/* GET/POST/HEAD found, increase the return value */
+    pathlen = ((pathlen + hostlen) < BUFSIZE) ? pathlen : BUFSIZE - hostlen;
+    strncpy(info->url, info->host, hostlen);
+    strncpy(info->url + hostlen, data + offset, pathlen);
+    *(info->url + hostlen + pathlen) = 0;	/* null-terminated */
+    info->urllen = hostlen + pathlen;
+    SPARQ_LOG("URL=%s, urllen=%d\n", info->url, info->urllen);
 
     return ret;
 }
 
 /* Linear string search based on memcmp() */
-static char *search_linear (char *needle, char *haystack, int needle_len, int haystack_len) 
+static char *search_linear (char *needle, char *haystack, int needle_len, int haystack_len)
 {
 	char *k = haystack + (haystack_len-needle_len);
 	char *t = haystack;
-	
-	DEBUGP( PRINTK_LEVEL "%s: haystack=%s, needle=%s\n", __FUNCTION__, t, needle);
+
+	SPARQ_LOG("%s: haystack=%s, needle=%s\n", __FUNCTION__, t, needle);
 	for(; t <= k; t++) {
-		DEBUGP( PRINTK_LEVEL "%s: haystack=%s, needle=%s\n", __FUNCTION__, t, needle);
-		if (strncasecmp(t, needle, needle_len) == 0) return t;
+		//SPARQ_LOG("%s: haystack=%s, needle=%s\n", __FUNCTION__, t, needle);
+		if (strnicmp(t, needle, needle_len) == 0) return t;
 		//if ( memcmp(t, needle, needle_len) == 0 ) return t;
 	}
 
 	return NULL;
 }
 
-#define TOKEN   "<&nbsp;>" 
 
-static bool xt_webstr_match(const struct sk_buff *skb,  struct xt_action_param *par)
+static bool match(const struct sk_buff *skb, struct xt_action_param *par)
 {
-	const struct xt_webstr_info *info = par->matchinfo;
-	unsigned char *data;
-	unsigned int datalen;
-	struct tcphdr *tcph;
+	const struct ipt_webstr_info *info = par->matchinfo;
+	struct iphdr *ip = ip_hdr(skb);
+	proc_ipt_search search=search_linear;
+
+	char token[] = "<&nbsp;>";
 	char *wordlist = (char *)&info->string;
+//	httpinfo_t htinfo;
 	int flags = 0;
 	int found = 0;
 	long int opt = 0;
 
-	if (info->len < 1)
+
+	if (!ip || info->len < 1)
 	    return 0;
 
-	if (par->family == NFPROTO_IPV4) {
-		struct iphdr *iph = ip_hdr(skb);
-		if (!iph) {
-			return 0;
+	SPARQ_LOG("\n************************************************\n"
+		"%s: type=%s\n", __FUNCTION__, (info->type == IPT_WEBSTR_URL)
+		? "IPT_WEBSTR_URL"  : (info->type == IPT_WEBSTR_HOST)
+		? "IPT_WEBSTR_HOST" : "IPT_WEBSTR_CONTENT" );
+
+	/* Determine the flags value for get_http_info(), and mangle packet
+	 * if needed. */
+	switch(info->type)
+	{
+	    case IPT_WEBSTR_URL:	/* fall through */
+		flags |= HTTP_URL;
+
+	    case IPT_WEBSTR_HOST:
+		flags |= HTTP_HOST;
+		break;
+
+	    case IPT_WEBSTR_CONTENT:
+		opt = simple_strtol(wordlist, (char **)NULL, 10);
+		SPARQ_LOG("%s: string=%s, opt=%#lx\n", __FUNCTION__, wordlist, opt);
+
+		if (opt & (BLK_JAVA | BLK_ACTIVE | BLK_PROXY))
+		    flags |= HTTP_URL;
+		if (opt & BLK_PROXY)
+		    flags |= HTTP_HOST;
+#if 0
+		// Could we modify the packet payload in a "match" module?  --YY@Ralink
+		if (opt & BLK_COOKIE)
+		    mangle_http_header(skb, HTTP_COOKIE);
+#endif
+		break;
+
+	    default:
+		printk("%s: Sorry! Cannot find this match option.\n", __FILE__);
+		return 0;
+	}
+
+	/* Get the http header info */
+	if (get_http_info(skb, flags, &htinfo) < 1)
+	    return 0;
+
+	/* Check if the http header content contains the forbidden keyword */
+	if (info->type == IPT_WEBSTR_HOST || info->type == IPT_WEBSTR_URL) {
+	    int nlen = 0, hlen = 0;
+	    char needle[BUFSIZE], *haystack = NULL;
+	    char *next;
+
+	    if (info->type == IPT_WEBSTR_HOST) {
+		haystack = htinfo.host;
+		hlen = htinfo.hostlen;
+	    }
+	    else {
+		haystack = htinfo.url;
+		hlen = htinfo.urllen;
+	    }
+	    split(needle, wordlist, next, token) {
+		nlen = strlen(needle);
+		SPARQ_LOG("keyword=%s, nlen=%d, hlen=%d\n", needle, nlen, hlen);
+		if (!nlen || !hlen || nlen > hlen) continue;
+		if (search(needle, haystack, nlen, hlen) != NULL) {
+		    found = 1;
+		    break;
 		}
-		tcph = (void *)iph + iph->ihl*4;
-		data = (void *)tcph + tcph->doff*4;
-		datalen = (skb)->len - (iph->ihl*4) - (tcph->doff*4);
+	    }
 	}
-#if IS_ENABLED(CONFIG_IPV6)
-	else if (par->family == NFPROTO_IPV6) {
-		struct ipv6hdr *iph = ipv6_hdr(skb);
-		if (!iph) {
-			return 0;
+	else {		/* IPT_WEBSTR_CONTENT */
+	    int vicelen;
+
+	    if (opt & BLK_JAVA) {
+		vicelen = sizeof(".js") - 1;
+		if (strnicmp(htinfo.url + htinfo.urllen - vicelen, ".js", vicelen) == 0) {
+		    SPARQ_LOG("%s: MATCH....java\n", __FUNCTION__);
+		    found = 1;
+		    goto match_ret;
+		}
+		vicelen = sizeof(".class") - 1;
+		if (strnicmp(htinfo.url + htinfo.urllen - vicelen, ".class", vicelen) == 0) {
+		    SPARQ_LOG("%s: MATCH....java\n", __FUNCTION__);
+		    found = 1;
+		    goto match_ret;
 		}
-		tcph = (void *)iph + sizeof(struct ipv6hdr);
-		data = (void *)tcph + tcph->doff*4;
-		datalen = (skb)->len - sizeof(struct ipv6hdr) - (tcph->doff*4);
+	    }
+	    if (opt & BLK_ACTIVE){
+		vicelen = sizeof(".ocx") - 1;
+		if (strnicmp(htinfo.url + htinfo.urllen - vicelen, ".ocx", vicelen) == 0) {
+		    SPARQ_LOG("%s: MATCH....activex\n", __FUNCTION__);
+		    found = 1;
+		    goto match_ret;
+		}
+		vicelen = sizeof(".cab") - 1;
+		if (strnicmp(htinfo.url + htinfo.urllen - vicelen, ".cab", vicelen) == 0) {
+		    SPARQ_LOG("%s: MATCH....activex\n", __FUNCTION__);
+		    found = 1;
+		    goto match_ret;
+		}
+	    }
+	    if (opt & BLK_PROXY){
+		if (strnicmp(htinfo.url + htinfo.hostlen, "http://", sizeof("http://") - 1) == 0) {
+		    SPARQ_LOG("%s: MATCH....proxy\n", __FUNCTION__);
+		    found = 1;
+		    goto match_ret;
+		}
+	    }
 	}
-#endif
-	else
-		return 0;
 
-	DEBUGP( PRINTK_LEVEL "\n************************************************\n"
-		"%s: type=%s\n", __FUNCTION__, (info->type == XT_WEBSTR_URL) 
-		? "XT_WEBSTR_URL"  : (info->type == XT_WEBSTR_HOST) 
-		? "XT_WEBSTR_HOST" : "XT_WEBSTR_CONTENT" );
-	
-	/* Determine the flags value for get_http_info(), and mangle packet 
+match_ret:
+	SPARQ_LOG("%s: Verdict =======> %s \n",__FUNCTION__
+		, found ? "DROP" : "ACCEPT");
+
+	return (found ^ info->invert);
+}
+
+static bool match6(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct ipt_webstr_info *info = par->matchinfo;
+	struct ipv6hdr *ip6 = ipv6_hdr(skb);
+	proc_ipt_search search=search_linear;
+
+	char token[] = "<&nbsp;>";
+	char *wordlist = (char *)&info->string;
+//	httpinfo_t htinfo;
+	int flags = 0;
+	int found = 0;
+	long int opt = 0;
+
+
+	if (!ip6 || info->len < 1)
+	    return 0;
+
+	SPARQ_LOG("\n************************************************\n"
+		"%s: type=%s\n", __FUNCTION__, (info->type == IPT_WEBSTR_URL)
+		? "IPT_WEBSTR_URL"  : (info->type == IPT_WEBSTR_HOST)
+		? "IPT_WEBSTR_HOST" : "IPT_WEBSTR_CONTENT" );
+
+	/* Determine the flags value for get_http_info(), and mangle packet
 	 * if needed. */
 	switch(info->type)
 	{
-	    case XT_WEBSTR_URL:
+	    case IPT_WEBSTR_URL:	/* fall through */
 		flags |= HTTP_URL;
-       /* add both flags because we construct url from host name first, then url
-       adds HTTP__HOST when HTTP_URL is specified */
-	    case XT_WEBSTR_HOST:
+
+	    case IPT_WEBSTR_HOST:
 		flags |= HTTP_HOST;
 		break;
 
-	    case XT_WEBSTR_CONTENT:
+	    case IPT_WEBSTR_CONTENT:
 		opt = simple_strtol(wordlist, (char **)NULL, 10);
-		DEBUGP( PRINTK_LEVEL "%s: string=%s, opt=%#lx\n", __FUNCTION__, wordlist, opt);
+		SPARQ_LOG("%s: string=%s, opt=%#lx\n", __FUNCTION__, wordlist, opt);
 
 		if (opt & (BLK_JAVA | BLK_ACTIVE | BLK_PROXY))
 		    flags |= HTTP_URL;
 		if (opt & BLK_PROXY)
 		    flags |= HTTP_HOST;
-		if (opt & BLK_COOKIE)
-		    mangle_http_header(HTTP_COOKIE, data, datalen);
 		break;
 
 	    default:
-		printk( KERN_ERR "%s: Sorry! Cannot find  match type.\n", __FILE__);
+		printk("%s: Sorry! Cannot find this match option.\n", __FILE__);
 		return 0;
 	}
 
 	/* Get the http header info */
-
-    DEBUGP( PRINTK_LEVEL "%s:, skb->len=%d, datalen=%d seq=%u\n", __FUNCTION__,skb->len, datalen, ntohl(tcph->seq));
-	if (get_http_info(flags, &htinfo, data, datalen) < 1)
+	if (get_http_info6(skb, flags, &htinfo) < 1)
 	    return 0;
 
 	/* Check if the http header content contains the forbidden keyword */
-	if (info->type == XT_WEBSTR_HOST || info->type == XT_WEBSTR_URL) {
+	if (info->type == IPT_WEBSTR_HOST || info->type == IPT_WEBSTR_URL) {
 	    int nlen = 0, hlen = 0;
-	    char needle[WORDSIZE], *haystack = NULL;
+	    char needle[BUFSIZE], *haystack = NULL;
 	    char *next;
-	    char *chtemp;
 
-	    if (info->type == XT_WEBSTR_HOST) {
+	    if (info->type == IPT_WEBSTR_HOST) {
 		haystack = htinfo.host;
 		hlen = htinfo.hostlen;
 	    }
@@ -397,54 +565,50 @@ static bool xt_webstr_match(const struct sk_buff *skb,  struct xt_action_param *
 		haystack = htinfo.url;
 		hlen = htinfo.urllen;
 	    }
-	    split(needle, wordlist, next, TOKEN) {
-	        /* Don't include '://' as part of the word being searched for */
-	        chtemp = strstr(needle, "://");
-	        if (NULL != chtemp)
-	            strcpy(needle, chtemp + 3);
+	    split(needle, wordlist, next, token) {
 		nlen = strlen(needle);
-		DEBUGP( PRINTK_LEVEL "keyword=%s, nlen=%d, hlen=%d\n", needle, nlen, hlen);
+		SPARQ_LOG("keyword=%s, nlen=%d, hlen=%d\n", needle, nlen, hlen);
 		if (!nlen || !hlen || nlen > hlen) continue;
-		if (search_linear(needle, haystack, nlen, hlen) != NULL) {
+		if (search(needle, haystack, nlen, hlen) != NULL) {
 		    found = 1;
 		    break;
 		}
 	    }
 	}
-	else {		/* XT_WEBSTR_CONTENT */
+	else {		/* IPT_WEBSTR_CONTENT */
 	    int vicelen;
 
 	    if (opt & BLK_JAVA) {
 		vicelen = sizeof(".js") - 1;
-		if (strncasecmp(htinfo.url + htinfo.urllen - vicelen, ".js", vicelen) == 0) {
-		    DEBUGP( PRINTK_LEVEL "%s: MATCH....java\n", __FUNCTION__);
+		if (strnicmp(htinfo.url + htinfo.urllen - vicelen, ".js", vicelen) == 0) {
+		    SPARQ_LOG("%s: MATCH....java\n", __FUNCTION__);
 		    found = 1;
 		    goto match_ret;
 		}
 		vicelen = sizeof(".class") - 1;
-		if (strncasecmp(htinfo.url + htinfo.urllen - vicelen, ".class", vicelen) == 0) {
-		    DEBUGP( PRINTK_LEVEL "%s: MATCH....java\n", __FUNCTION__);
+		if (strnicmp(htinfo.url + htinfo.urllen - vicelen, ".class", vicelen) == 0) {
+		    SPARQ_LOG("%s: MATCH....java\n", __FUNCTION__);
 		    found = 1;
 		    goto match_ret;
 		}
 	    }
 	    if (opt & BLK_ACTIVE){
 		vicelen = sizeof(".ocx") - 1;
-		if (strncasecmp(htinfo.url + htinfo.urllen - vicelen, ".ocx", vicelen) == 0) {
-		    DEBUGP( PRINTK_LEVEL "%s: MATCH....activex\n", __FUNCTION__);
+		if (strnicmp(htinfo.url + htinfo.urllen - vicelen, ".ocx", vicelen) == 0) {
+		    SPARQ_LOG("%s: MATCH....activex\n", __FUNCTION__);
 		    found = 1;
 		    goto match_ret;
 		}
 		vicelen = sizeof(".cab") - 1;
-		if (strncasecmp(htinfo.url + htinfo.urllen - vicelen, ".cab", vicelen) == 0) {
-		    DEBUGP( PRINTK_LEVEL "%s: MATCH....activex\n", __FUNCTION__);
+		if (strnicmp(htinfo.url + htinfo.urllen - vicelen, ".cab", vicelen) == 0) {
+		    SPARQ_LOG("%s: MATCH....activex\n", __FUNCTION__);
 		    found = 1;
 		    goto match_ret;
 		}
 	    }
 	    if (opt & BLK_PROXY){
-		if (strncasecmp(htinfo.url + htinfo.hostlen, "http://", sizeof("http://") - 1) == 0) {
-		    DEBUGP( PRINTK_LEVEL "%s: MATCH....proxy\n", __FUNCTION__);
+		if (strnicmp(htinfo.url + htinfo.hostlen, "http://", sizeof("http://") - 1) == 0) {
+		    SPARQ_LOG("%s: MATCH....proxy\n", __FUNCTION__);
 		    found = 1;
 		    goto match_ret;
 		}
@@ -452,42 +616,50 @@ static bool xt_webstr_match(const struct sk_buff *skb,  struct xt_action_param *
 	}
 
 match_ret:
-	DEBUGP( PRINTK_LEVEL "%s: Verdict =======> %s \n",__FUNCTION__
-		, found ? "MATCH FOUND" : "MATCH NOT FOUND");
+	SPARQ_LOG("%s: Verdict =======> %s \n",__FUNCTION__
+		, found ? "DROP" : "ACCEPT");
 
 	return (found ^ info->invert);
 }
 
+static int checkentry(const struct xt_mtchk_param *par)
+{
+#if 0
+       if (matchsize != IPT_ALIGN(sizeof(struct ipt_webstr_info)))
+               return 0;
+#endif
+       return 0;
+}
 
-static struct xt_match webstr_match[] __read_mostly = {
+static struct xt_match xt_webstr_match[] = {
 	{
-		.name		= "webstr",
-		.family		= NFPROTO_IPV4,
-		.match		= xt_webstr_match,
-		.matchsize      = sizeof(struct xt_webstr_info),
-		.me		= THIS_MODULE,
+	.name		= "webstr",
+	.family		= AF_INET,
+	.match		= match,
+	.checkentry	= checkentry,
+	.matchsize	= sizeof(struct ipt_webstr_info),
+	.me		= THIS_MODULE
 	},
-#if IS_ENABLED(CONFIG_IPV6)
 	{
-		.name		= "webstr",
-		.family		= NFPROTO_IPV6,
-		.match		= xt_webstr_match,
-		.matchsize      = sizeof(struct xt_webstr_info),
-		.me		= THIS_MODULE,
-	}
-#endif
-};
+	.name		= "webstr",
+	.family		= AF_INET6,
+	.match		= match6,
+	.checkentry	= checkentry,
+	.matchsize	= sizeof(struct ipt_webstr_info),
+	.me		= THIS_MODULE
+	},
 
+};
 
-static int __init xt_webstr_init(void)
+static int __init init(void)
 {
-	return xt_register_matches(webstr_match, ARRAY_SIZE(webstr_match));
+	return xt_register_matches(xt_webstr_match, ARRAY_SIZE(xt_webstr_match));
 }
 
-static void __exit xt_webstr_fini(void)
+static void __exit fini(void)
 {
-	xt_unregister_matches(webstr_match, ARRAY_SIZE(webstr_match));
+	xt_unregister_matches(xt_webstr_match, ARRAY_SIZE(xt_webstr_match));
 }
 
-module_init(xt_webstr_init);
-module_exit(xt_webstr_fini);
+module_init(init);
+module_exit(fini);
diff --git a/trunk/linux-4.4.x/net/sched/cobalt_compat.h b/trunk/linux-4.4.x/net/sched/cobalt_compat.h
index b11eaa5fe..348af9c3d 100644
--- a/trunk/linux-4.4.x/net/sched/cobalt_compat.h
+++ b/trunk/linux-4.4.x/net/sched/cobalt_compat.h
@@ -125,14 +125,14 @@ static inline int skb_mac_offset(const struct sk_buff *skb)
 
 
 #if KERNEL_VERSION(4, 12, 0) > LINUX_VERSION_CODE
-static void *kvzalloc(size_t sz, gfp_t flags)
+/*static void *kvzalloc(size_t sz, gfp_t flags)
 {
 	void *ptr = kzalloc(sz, flags);
 
 	if (!ptr)
 		ptr = vzalloc(sz);
 	return ptr;
-}
+}*/
 #endif
 
 /* save the best till last
diff --git a/trunk/linux-4.4.x/net/sched/sch_generic.c b/trunk/linux-4.4.x/net/sched/sch_generic.c
index 622e5e98e..2332ac917 100644
--- a/trunk/linux-4.4.x/net/sched/sch_generic.c
+++ b/trunk/linux-4.4.x/net/sched/sch_generic.c
@@ -108,6 +108,14 @@ static struct sk_buff *dequeue_skb(struct Qdisc *q, bool *validate,
 	return skb;
 }
 
+struct sk_buff *qdisc_dequeue_skb(struct Qdisc *q, bool *validate)
+{
+	int packets;
+
+	return dequeue_skb(q, validate, &packets);
+}
+EXPORT_SYMBOL(qdisc_dequeue_skb);
+
 static inline int handle_dev_cpu_collision(struct sk_buff *skb,
 					   struct netdev_queue *dev_queue,
 					   struct Qdisc *q)
diff --git a/trunk/linux-4.4.x/net/swrt_fastpath/Makefile b/trunk/linux-4.4.x/net/swrt_fastpath/Makefile
new file mode 100644
index 000000000..ecdf1a5d0
--- /dev/null
+++ b/trunk/linux-4.4.x/net/swrt_fastpath/Makefile
@@ -0,0 +1,4 @@
+obj-y += fast_path.o
+ifeq ($(wildcard net/swrt_fastpath/fast_path.c),)
+fast_path-objs = fast_path.obj
+endif
diff --git a/trunk/linux-4.4.x/net/swrt_fastpath/fast_path.obj b/trunk/linux-4.4.x/net/swrt_fastpath/fast_path.obj
new file mode 100644
index 0000000000000000000000000000000000000000..fb4adc69bddea3fe2cf5d5df89d2d86a14e8c094
GIT binary patch
literal 6996
zcmd^DUu;`f8UJ#x?S(c_x68V)1$JHB%wz3c(xzQEEHG`l7SusuozzJM$8l~_tB&p2
zH=~m(VQm!~EUNQRp$YB5jC3o~Xu1JoLK};;f+m5)9{K<;sM;z(JQXA~K-0|cckVs*
z$!)8SXFlcJ?|k3+&hPtk&OPTk-`;!Rfxf;z(bOmX(vw6k-Yn9Wl-js5$jGQ{)uxJn
zD4i>-6kWlwfMaXX#MC;Ie+t4KJw@|_PN$>AA#@_+dZ^3)$MIG8&Q<vKs`33-jjvlZ
zp1EpVR*hec-&ry9Yp$AaWkq%`WF(hF`Ox<kHcK0Qk@NDMg(Z3NbZY1=8Iak9l)R|)
zN%V*1#X;Jj4#|&6aq)TDjlKnqowek`X^~%_Zac9P?M(cHNFv+moE+_R&Wy&Sn9j*>
z(re@ih1D;6Lq3z_*aw}dg@1K&3cFt}sr4l96Dv)gf;IgmB%Xe^<0aRFUjk<=?{`G;
zN}(a;LM30SiF|GA!GeF(d9cuEI1l;NdSTXc3dN#V_UZ-St2^HDlJBk&**x#+KS-1v
znJJaMX~(ZR#kvP$XQt5b^EJX@gp+I4y6@EL)uMZqE&MyBS~v*28^!V1n7hq^=dt?_
zRjbb2eDSDLs?_Fv7jqpnky!Sxoj2}GVetp$&1EPCL{6ru54a43V=Y71KO~srv|%34
zrbfX8FPxl7UrWcey96I1Q|V#&ux0O}$jqW8dlvg--{PR0f!}yGDL)GRpP^lgYr?g0
z;OjNa&&kUeU!Tp&`Q-`V3`%=>2yGb6K}(}$(6*qBqKTwWrG{RR&B+&JNS<nKPEJWW
zxldBf6&aVM<+$Vq2W1IyA;<m~B#u4DM3^sVfMdwbx=B{lzR|j1KTo}6!5%SM|L9n0
z;I%|PbIO({lZXv{)=>m8w-9fOdF)3Xe?T6?@(SX98S$S-j2lqrB-;9{BR@qBZ!V{v
zZDM9}Bqv`V31S)>fkNT+%Z3dpXA-WhQ>lz&rABi?`F-r|80G|HGOz~w7g#M|w&1S?
ze=Ydy)-;1yf;G7bzPZ+aNheV=t|jy5It4yYrW2@>h_(y%2aeMu*NAgDkMs51)$<@J
z{9qpQ(et!jbgi4HkuSdh=B?SBytPH-@~IPu=eYc8xhAhJm*wZnN9AYB)2P=ZYIy{;
zJd9c%!kQ*za&R-&-1PZX_~aU;)IK;F?t=+oUa9s9_Wh0aK-2o1+5_vehvj+fmz%Sx
z<RSP-V~rAN)@x8+f&LcMu`%*`C)W;g8yiVAb5`p7q=f<|Q&-wn$`NY~=5U<zC<nHi
z&T;?r$?o(fnM|e@cUy>WBj<~}(~5~~jLF!@FmaMii+w#em6^0sO^bWt30tidb`$JG
z+UHW46@^b*;HmvBvZrao2mFF^ZTkFUM>dK)e-3^WJ|=}VYg(u)*7-fPx3LcB2YV6g
z(ZV{luqG|6NegSz!kV<OCM~Q<3u~hGeG_|4x%xkNbkFj9WhNgS=XoCIO#KafJbVxQ
z8MN=BRnhwTaql!m)}XCL8$j!K<l3}v&z}38%z?cVdmVJ09qzb0>eNTKZrkSV*s=58
zy8?}TaUG`5R_3MeCUj!9xQ)l>{K6EtUk~_E-J34>1#zbu4RPz<Y^gF+75Bj}9el_w
zOqFKJg;}L9yS3@MxO3Cq)ch<*wr`_(+4a5SzI)x2-FlVq^g8B_2Q$>Y$Y}-uZ#rD6
z`D)FpMAbd;$SCa9JY1pE#w4x&R=wnVhQ5arnN_ObqK*U<F*dLmez8z4yX*w;1fXiC
z%U+-h6E_mWS3#*-39D%i_k1Bi(<-0O9}CtkKU*u`-Ls2qtezR_T&i%zu$*o_U*{TE
zj|F1*-QubRQ5(`NR_Ert3L>sleb3$Zm4~-B{6Z1-*g9^(2iVlS?=`Ny6}8q5jsh);
zEuZN2*|B*H8Dz@_L*h72MuTh~Lk8KnxlOX=HdDlWCn9f($h<mxWXtNK$QB&J2HA4g
zs^1NGD{)WYE$Z5=g(f@zm2R!daNHQb1^o#_X2kmqnZFOzfuMA2B@KSs7{3es*A3Z4
z{~bf_cG0mT(c0=d=~>vYFv&JDq2A_Kk3qJ|wx_TK2b4iJzLHI{RW*7V8($74+45;q
zgg<86BU?V(6VS8e?ufiawuhRF;2YrofMLPi_05RvMdU{#@`;FiDkA?NBL6TV|2QK5
zG9vTWiYCU#xHVCJPYd9b{}z$|9+CeYk@2IYOPoItk#7%WuH1UoJAGi!C?8{dY~y1)
zALD%N;A1Br_wuoekNf1hr%m0Pt3KuhM=uVK`r}f=q2nKu29BPx7o6b@?@?GlJtO(N
zI#lw-qsQ{I^M(2}G{tJ|@%((ltIM1>*YJEPRq_SDT3Ka0Qz(^10nPhGIKdSW{9MYb
zE2~kOtHGT*;^txK*UPv(z#28hYEyN@ggD9#&kK6$rU=8t<>eI`9z5zZ_PQAdrM7TP
zIOy`90XcGfAWf3v^=gvG@U=yb*J*_uhsGsxUcs1Sg|AT@$0JN70X_g8|9G$m65t0Z
zLthKWr$d=%1?{=kF&++}IPUmC@B}zd$T$Z1<|V)#aN2F59v_0E)Ps*xkJpWUV|dLN
zM;s60Ccsze5x>&&@B=YUrocFrUvT2b@JMqU$GY+ZPP_Qlz+VFV2<_Y;uh>2KRY@7f
z3$z2yA~<oE$YFn;<70sz)&r&Q=1-Y^Sr3&reuyxy1o$q_!{9XeHZ<_~njo(PxI;Y-
z6BQromWIsw>AEofIFchy0-S#0IPMNm20skW`4iM9gS=SpGWDqIQR;E{*T56t%}~$t
zCXQ?EB=z9BKA5WV-5=U1+*?C`;6C-J+tcKz+q2-z|13E3Z&Mx$?urEX1<15}I~>1E
z8OdEC-+}eSK1>WCFYwq-+)1H)kn+7EufZ;k@#CTXG&$Cz&2g*;iThu1?CTiiT|qw9
zeL<bM|F=+&_XDoQy8k+M{h=M+A8n^_God{%*^fvm#Kf?|t*YKnb1Lghx*d&naH%L4
za?P||3JQdGL%R{!z-JAqD$3!BW#|&?Lm5lLTdr$&IMjnFqA%L*Mq_-MYUntIf_S9Q
zqhULC^E`sU_d~{3Q8l0)G54Vv(*^%*Sw&iWB(&4@quoWrQu}=vI@9kG{N|veU+T5r
z<LDC`ub`r76ex<v@n_J;wclM>n5>!+Jhb1ZAew$J8~I|pcK!0+Ht~Gm4F*u^sqwxK
z$;8`&vyt^@9(b*~crT-G;yryGyr00%#G5ei5Na3i_Yu73fHwi1CLP~zp)m1|0B;mJ
z#)spzi}z>r&G;?>?``NbX}ou#F!2_Er}qo%Lp$!557A7#vlv)_PLsy_4-_WeMd0P2
zV|+N?x_H9?Gx5f8Hav@QO&V_qMkd}MlB6B+xGp-ryCZnN1KveC2ub7J8NquAc(1{R
zc(<Wxyf24%D4U{oc&3G-vSa^&2;MaA8rF+=ymK|)HzIgT*TH)vf>$>1__eI@9u4vE
z`Y1XJymHtl)A`Ot@O<E9FwXd#(2nu)y~dwtyg?|hg|`sFd(ObyWZ=CT!D|AKel+R$
zUWwpc03P29#+OFZ`Ti+__cXvhslmW8tmq0l^rP2p34-=T1Ksa@M7y;p2(eAP9Dzd8
zcpF1IzKf*G@S6#`>PZZ?J3>1>G{DVm5N$~J!0w-&PBoBlf5MJ+(WLG0dUa#t*f8wA
nfVrBq9l4>FBe+9XkQDD9#>qU0&v10E=*sXq+$kCavhMyD%3)cA

literal 0
HcmV?d00001

diff --git a/trunk/linux-4.4.x/net/xfrm/xfrm_input.c b/trunk/linux-4.4.x/net/xfrm/xfrm_input.c
index 1c4ad477c..e872c6e0b 100644
--- a/trunk/linux-4.4.x/net/xfrm/xfrm_input.c
+++ b/trunk/linux-4.4.x/net/xfrm/xfrm_input.c
@@ -294,6 +294,18 @@ int xfrm_input(struct sk_buff *skb, int nexthdr, __be32 spi, int encap_type)
 		skb_dst_force(skb);
 		dev_hold(skb->dev);
 
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+		if (family == AF_INET)
+		{
+			if (x->type->input(x, skb) == 1)
+			{
+				return 0;
+			}
+			else
+				goto drop;
+		}
+		else	
+#endif
 		nexthdr = x->type->input(x, skb);
 
 		if (nexthdr == -EINPROGRESS)
diff --git a/trunk/linux-4.4.x/net/xfrm/xfrm_output.c b/trunk/linux-4.4.x/net/xfrm/xfrm_output.c
index f17cbac0b..2c02ad09e 100644
--- a/trunk/linux-4.4.x/net/xfrm/xfrm_output.c
+++ b/trunk/linux-4.4.x/net/xfrm/xfrm_output.c
@@ -22,8 +22,11 @@
 #include <net/ra_nat.h>
 
 static int xfrm_output2(struct net *net, struct sock *sk, struct sk_buff *skb);
-
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+int xfrm_skb_check_space(struct sk_buff *skb)
+#else
 static int xfrm_skb_check_space(struct sk_buff *skb)
+#endif
 {
 	struct dst_entry *dst = skb_dst(skb);
 	int nhead = dst->header_len + LL_RESERVED_SPACE(dst->dev)
@@ -107,15 +110,27 @@ static int xfrm_output_one(struct sk_buff *skb, int err)
 		skb_dst_force(skb);
 
 		err = x->type->output(x, skb);
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+		if (skb->protocol == htons(ETH_P_IP))
+		{	
+			if (err == 1)
+				return err;
+		}		
+#endif	
 		if (err == -EINPROGRESS)
 			goto out;
 
 resume:
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+		if (skb->protocol == htons(ETH_P_IPV6))
+#else	
+		{
 		if (err) {
 			XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEPROTOERROR);
 			goto error_nolock;
 		}
-
+		}
+#endif
 		dst = skb_dst_pop(skb);
 		if (!dst) {
 			XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
@@ -159,7 +174,10 @@ int xfrm_output_resume(struct sk_buff *skb, int err)
 
 	if (err == -EINPROGRESS)
 		err = 0;
-
+#if defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)
+	if (skb->protocol = htons(ETH_P_IP))
+		return 0;
+#endif	
 out:
 	return err;
 }
diff --git a/trunk/linux-4.4.x/net/xfrm/xfrm_state.c b/trunk/linux-4.4.x/net/xfrm/xfrm_state.c
index d73c66a64..5be697be3 100644
--- a/trunk/linux-4.4.x/net/xfrm/xfrm_state.c
+++ b/trunk/linux-4.4.x/net/xfrm/xfrm_state.c
@@ -28,6 +28,13 @@
 
 #include "xfrm_hash.h"
 
+#if (defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)) && defined (CONFIG_INET_ESP)
+extern void
+ipsec_eip93Adapter_free(
+		    unsigned int spi
+		);
+#endif
+
 /* Each xfrm_state may be linked to two tables:
 
    1. Hash table by (spi,daddr,ah/esp) to find SA by SPI. (input,ctl)
@@ -533,6 +540,14 @@ int __xfrm_state_delete(struct xfrm_state *x)
 		 */
 		xfrm_state_put(x);
 		err = 0;
+#if (defined (CONFIG_RALINK_HWCRYPTO) || defined (CONFIG_RALINK_HWCRYPTO_MODULE)) && defined (CONFIG_INET_ESP)
+		if (x->type != NULL)
+		{	
+			if (x->type->description[3] == '4')
+        		ipsec_eip93Adapter_free(x->id.spi);
+		}	
+#endif
+
 	}
 
 	return err;
diff --git a/trunk/linux-4.4.x/ralink/Kconfig b/trunk/linux-4.4.x/ralink/Kconfig
new file mode 100644
index 000000000..690a08f79
--- /dev/null
+++ b/trunk/linux-4.4.x/ralink/Kconfig
@@ -0,0 +1,420 @@
+menu "Ralink Module"
+
+###########
+# Debuging
+###########
+source "drivers/net/rt_rdm/Kconfig"
+
+#############
+# Wire
+#############
+
+source "drivers/net/raeth/Kconfig"
+
+config  HW_IPSEC
+	depends on RALINK_MT7621
+	bool    "HW IPSec Enable"
+	    select INET_AH
+		select INET_ESP
+		select INET_XFRM_MODE_TRANSPORT
+		select INET_XFRM_MODE_TUNNEL
+		select UNIX
+		select XFRM
+		select XFRM_USER
+		select NET_KEY
+		select CRYPTO_AEAD
+		select CRYPTO_AUTHENC
+		select CRTPTO_RNG
+		select CRYPTO_CBC
+		select CRYPTO_HMAC
+		select CRYPTO_SHA1
+		select CRYPTO_MD5
+		select CRYPTO_AES
+		select CRYPTO_DES
+		select CRYPTO_ANSI_CPRNG
+		default n
+
+config  RALINK_HWCRYPTO
+	depends on HW_IPSEC
+	tristate "HW Crypto Engine"
+	default m
+
+#############
+# Wireless
+#############
+menuconfig WIFI_DRIVER
+	bool "WiFi Driver Support"
+
+if WIFI_DRIVER
+
+choice
+	prompt "Choose First WiFi Interface"
+	config FIRST_IF_NONE
+	bool "None"
+
+	config FIRST_IF_RT2860
+	bool "RT2860 for rt2860v2 wifi driver"
+	select RTMP_MAC
+	select RALINK_RT2860
+
+	config FIRST_IF_MT7620
+	bool "MT7620 for rlt_wifi wifi driver"
+	select RTMP_MAC
+	select RALINK_RT6352
+
+	config FIRST_IF_MT7628
+	bool "MT7628 for rlt_wifi wifi driver"
+	depends on RALINK_MT7628
+	select MT_MAC
+
+	config FIRST_IF_RT3092
+	bool "RT3092"
+	depends on RALINK_MT7621
+	select RTMP_MAC
+	select RALINK_RT3092
+
+	config FIRST_IF_RT5392
+	bool "RT5392"
+	depends on RALINK_MT7621
+	select RTMP_MAC
+	select RALINK_RT5392
+
+	config FIRST_IF_RT5592
+	bool "RT5592"
+	depends on RALINK_MT7621
+	select RTMP_MAC
+	select RALINK_RT5592
+
+	config FIRST_IF_RT3593
+	bool "RT3593"
+	depends on RALINK_MT7621
+	select RTMP_MAC
+	select RALINK_RT3593
+
+	config FIRST_IF_MT7610E
+	bool "MT7610E"
+	depends on RALINK_MT7621
+	select RLT_MAC
+	select RALINK_MT7610E
+
+	config FIRST_IF_MT7612E
+	bool "MT7612E"
+	depends on RALINK_MT7621
+	select RLT_MAC
+	select RALINK_MT7612E
+
+	config FIRST_IF_MT7602E
+	bool "MT7602E"
+	depends on RALINK_MT7621
+	select RLT_MAC
+	select RALINK_MT7602E
+
+	config FIRST_IF_MT7603E
+	bool "MT7603E"
+	depends on RALINK_MT7621
+	select MT_MAC
+	select RALINK_MT7603E
+
+	config FIRST_IF_MT7637E
+	bool "MT7637E"
+	depends on RALINK_MT7621
+	select WIFI_MT_MAC
+	select MT_MAC
+	select RALINK_MT7637E
+
+	config FIRST_IF_MT7615E
+	bool "MT7615E"
+	depends on RALINK_MT7621
+	select WIFI_MT_MAC
+	select MT_MAC
+	select CHIP_MT7615E
+endchoice
+
+choice
+	prompt "Choose Second WiFi Interface"
+	config SECOND_IF_NONE
+	bool "None"
+
+	config SECOND_IF_RT3092
+	bool "RT3092"
+	select RTMP_MAC
+	select RALINK_RT3092
+
+	config SECOND_IF_RT5392
+	bool "RT5392"
+	select RTMP_MAC
+	select RALINK_RT5392
+
+	config SECOND_IF_RT5592
+	bool "RT5592"
+	select RTMP_MAC
+	select RALINK_RT5592
+
+	config SECOND_IF_RT3593
+	bool "RT3593"
+	select RTMP_MAC
+	select RALINK_RT3593
+
+	config SECOND_IF_RT3572
+	bool "RT3572"
+	select RTMP_MAC
+	select RALINK_RT3572
+
+	config SECOND_IF_RT5572
+	bool "RT5572"
+	select RTMP_MAC
+	select RALINK_RT5572
+
+	config SECOND_IF_MT7610U
+	bool "MT7610U"
+	select RLT_MAC
+	select RALINK_MT7610U
+
+	config SECOND_IF_MT7610E
+	bool "MT7610E"
+	select RLT_MAC
+	select RALINK_MT7610E
+
+	config SECOND_IF_RT8592
+	bool "RT85592"
+	select RLT_MAC
+	select RALINK_RT8592
+
+	config SECOND_IF_MT7612U
+	bool "MT7612U"
+	select RLT_MAC
+	select RALINK_MT7612U
+
+	config SECOND_IF_MT7612E
+	bool "MT7612E"
+	select RLT_MAC
+	select RALINK_MT7612E
+
+	config SECOND_IF_MT7602E
+	bool "MT7602E"
+	select RLT_MAC
+	select RALINK_MT7602E
+
+	config SECOND_IF_MT7603E
+	bool "MT7603E"
+	select MT_MAC
+	select RALINK_MT7603E
+
+	config SECOND_IF_MT7637E
+	bool "MT7637E"
+	select WIFI_MT_MAC
+	select MT_MAC
+	select RALINK_MT7637E
+
+	config SECOND_IF_MT7615E
+	bool "MT7615E"
+	select WIFI_MT_MAC
+	select CHIP_MT7615E
+endchoice
+
+choice
+	prompt "Choose Third WiFi Interface"
+	config THIRD_IF_NONE
+	bool "None"
+
+	config THIRD_IF_MT7615E
+	bool "MT7615E"
+	select WIFI_MT_MAC
+	select MT_MAC
+	select CHIP_MT7615E
+endchoice
+
+config  RT_FIRST_CARD
+        string
+        depends on ! FIRST_IF_NONE
+        default 2860 if FIRST_IF_RT2860
+        default 7620 if FIRST_IF_MT7620
+        default 7628 if FIRST_IF_MT7628
+        default 3090 if FIRST_IF_RT3092
+        default 5392 if FIRST_IF_RT5392
+        default 5592 if FIRST_IF_RT5592
+        default 3593 if FIRST_IF_RT3593
+        default 7610e if FIRST_IF_MT7610E
+	default 7612e if FIRST_IF_MT7612E
+	default 7602e if FIRST_IF_MT7602E
+	default 7603e if FIRST_IF_MT7603E
+	default 7637e if FIRST_IF_MT7637E
+	default 7615e if FIRST_IF_MT7615E
+
+config  RT_SECOND_CARD
+        string
+        depends on ! SECOND_IF_NONE
+        default 3090 if SECOND_IF_RT3092
+        default 5392 if SECOND_IF_RT5392
+        default 5592 if SECOND_IF_RT5592
+        default 3593 if SECOND_IF_RT3593
+        default 8592 if SECOND_IF_RT8592
+        default 3572 if SECOND_IF_RT3572
+        default 5572 if SECOND_IF_RT5572
+        default 7610e if SECOND_IF_MT7610E
+        default 7610u if SECOND_IF_MT7610U
+	default 7612e if SECOND_IF_MT7612E
+	default 7612u if SECOND_IF_MT7612U
+	default 7602e if SECOND_IF_MT7602E
+	default 7603e if SECOND_IF_MT7603E
+	default 7637e if SECOND_IF_MT7637E
+	default 7615e if SECOND_IF_MT7615E
+
+config  RT_THIRD_CARD
+	string
+	depends on ! THIRD_IF_NONE
+	default 7615e if THIRD_IF_MT7615E
+
+config  RT_FIRST_IF_RF_OFFSET
+        hex
+        depends on ! FIRST_IF_NONE
+        default 0x0
+
+config  RT_SECOND_IF_RF_OFFSET
+        hex
+        depends on ! SECOND_IF_NONE
+        default 0x8000
+
+config  RT_THIRD_IF_RF_OFFSET
+	hex
+	depends on ! THIRD_IF_NONE
+	default 0x4000
+
+config  RT2860V2_2850
+        bool "Dual Band"
+        depends on RALINK_RT2880
+
+choice
+        prompt "RF Type"
+        depends on RALINK_RT5350
+        default RALINK_RT5350_1T1R
+
+        config  RALINK_RT5350_1T1R
+        bool "1T1R"
+endchoice
+
+choice
+        prompt "RF Type"
+        depends on RALINK_RT3052
+        default RALINK_RT3052_2T2R
+
+        config  RALINK_RT3050_1T1R
+        bool "1T1R"
+
+        config  RALINK_RT3051_1T2R
+        bool "1T2R"
+
+        config  RALINK_RT3052_2T2R
+        bool "2T2R"
+endchoice
+
+choice
+        prompt "RF Type"
+        depends on  RALINK_RT3352
+
+        config  RALINK_RT3352_2T2R
+        bool "2T2R"
+endchoice
+
+choice
+	prompt "RF Type"
+	depends on RALINK_RT3883
+
+	config  RALINK_RT3662_2T2R
+	bool "2T3R (RT3662)"
+
+	config  RALINK_RT3883_3T3R
+	bool "3T3R (RT3883)"
+endchoice
+
+config RTDEV_MII
+    bool
+    default y if RT2880v2_INIC_MII || RT305x_INIC_MII || RT305x_INIC_USB || RT3680_iNIC_AP
+
+#config  UNIQUE_WPS
+#	bool "Unique WPS for Concurrent AP"
+#        depends on RT2860V2_AP_WSC
+#        depends on RT3090_AP_WSC || RT3572_AP_WSC || RT5392_AP_WSC || RT5572_AP_WSC || RT5592_AP_WSC
+#	default n
+
+#SKB alloc selection
+config WIFI_SKB_ALLOC_SELECT
+        bool "SKB Allocation API Select"
+        default n
+choice
+        prompt "SKB Allocation API Selection"
+        depends on WIFI_SKB_ALLOC_SELECT
+        default WIFI_PAGE_ALLOC_SKB
+
+        config  WIFI_SLAB_ALLOC_SKB
+                bool "SLAB skb allocation"
+
+        config  WIFI_PAGE_ALLOC_SKB
+                bool "Page skb allocation"
+endchoice
+
+
+#source "drivers/net/wireless/rt2860v2_ap/Kconfig"
+#source "drivers/net/wireless/rt2860v2_sta/Kconfig"
+#source "drivers/net/wireless/RTPCI_ap/Kconfig"
+#source "drivers/net/wireless/RT3090_ap/Kconfig"
+#source "drivers/net/wireless/RT5392_ap/Kconfig"
+#source "drivers/net/wireless/RT5592_ap/Kconfig"
+#source "drivers/net/wireless/RT3593_ap/Kconfig"
+#source "drivers/net/wireless/RT3572_ap/Kconfig"
+#source "drivers/net/wireless/RT5572_ap/Kconfig"
+#source "drivers/net/wireless/iNIC/Kconfig"
+#source "drivers/net/wireless/iNIC_RT305x/Kconfig"
+#source "drivers/net/wireless/RT3680_ap/Kconfig"
+#source "drivers/net/wireless/MT7610_ap/Kconfig"
+#source "drivers/net/wireless/rlt_wifi/Kconfig"
+#source "drivers/net/wireless/mt_wifi/embedded/Kconfig"
+#source "drivers/net/wireless/mt_wifi_7615E_4411/embedded/Kconfig"
+source "drivers/net/wireless/mt_wifi_7615E_4421/embedded/Kconfig"
+
+endif # WIFI_DRIVER
+
+#config WIFI_PKT_FWD
+#    bool "WiFi packet forwarding"
+#    depends on WIFI_DRIVER
+#   default n
+
+source "drivers/net/wireless/wifi_forward/wifi_fwd/Kconfig"
+
+config RTDEV
+	bool
+	default y if WIFI_DRIVER && !SECOND_IF_NONE || RTDEV_MII
+	default y if RTDEV_PLC
+
+config WIFI_PKT_FWD
+    bool "WiFi packet forwarding"
+    depends on WIFI_DRIVER
+    default n
+
+config WIFI_PKT_FWD_V1
+    bool "WiFi packet forwarding V1"
+    depends on WIFI_DRIVER
+    default n
+#######
+# USB
+#######
+source "drivers/usb/dwc_otg/Kconfig"
+
+#######
+# NAT
+#######
+choice
+prompt "Ralink NAT Type"
+
+config  RA_NAT_NONE
+bool "None"
+config  RA_NAT_HW
+bool "Hardware"
+depends on !RALINK_RT5350 && !RALINK_MT7628
+endchoice
+
+source "net/nat/hw_nat/Kconfig"
+
+
+endmenu
+
diff --git a/trunk/linux-4.4.x/ralink/Kconfig.misc b/trunk/linux-4.4.x/ralink/Kconfig.misc
new file mode 100644
index 000000000..1709983e1
--- /dev/null
+++ b/trunk/linux-4.4.x/ralink/Kconfig.misc
@@ -0,0 +1,34 @@
+menu "ASUS Miscellaneous options"
+
+config  MODEL_RTAC85U
+	bool "RT-AC85U"
+	default n
+
+config  MODEL_RTAC85P
+	bool "RT-AC85P"
+	default n
+
+config  MODEL_RTACRH26
+	bool "RT-ACRH26"
+	default n
+
+config  MODEL_RPAC87
+	bool "RP-AC87"
+	default n
+
+config  MODEL_RTAC65U
+	bool "RT-AC65U"
+	default n
+config  MODEL_RTN800HP
+    bool "RT-N800HP"
+    default n
+
+config  SINGLE_SKU_IN_DRIVER
+	bool "Single sku in driver, not file"
+	default n
+
+config  DUAL_TRX
+	bool "Dual trx supported"
+	default n
+
+endmenu
-- 
2.34.1

